{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfGNS8O_bleN"
      },
      "source": [
        "## Importação de bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfHCH4bOuJ_L",
        "outputId": "24c915da-8521-4930-ccab-724e63755d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data-science-projects'...\n",
            "remote: Enumerating objects: 23945, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 23945 (delta 1), reused 8 (delta 1), pack-reused 23936 (from 2)\u001b[K\n",
            "Receiving objects: 100% (23945/23945), 120.29 MiB | 10.69 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/luizh3nriqu3/data-science-projects.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2ziHAexg4Od",
        "outputId": "726332c9-efaa-44f2-99bd-15765d7fa882"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/383.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/231.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "umaU36msbOB_"
      },
      "outputs": [],
      "source": [
        "# Visualização\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Manipulação\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "from datetime import datetime\n",
        "import random\n",
        "from itertools import product\n",
        "import optuna\n",
        "\n",
        "# Métricas\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score\n",
        "\n",
        "# DL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM, Input, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U5G_-9Vbog4"
      },
      "source": [
        "## Importação da base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "idw-tt-jbr89",
        "outputId": "3db90bff-f338-4fcd-aeec-18e481b14773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/data-science-projects/deep-learning/data/BBAS3.SA.zip\n",
            "  inflating: /content/data-science-projects/deep-learning/data/BBAS3.SA/._BBAS3.SA  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/BBAS3.SA/.DS_Store  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/BBAS3.SA/._.DS_Store  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/BBAS3.SA/visualizacao.html  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/BBAS3.SA/teste.csv  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/BBAS3.SA/treino.csv  \n",
            "Descompactado: /content/data-science-projects/deep-learning/data/BBAS3.SA.zip\n",
            "Archive:  /content/data-science-projects/deep-learning/data/CSNA3.SA.zip\n",
            "  inflating: /content/data-science-projects/deep-learning/data/CSNA3.SA/._CSNA3.SA  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/CSNA3.SA/.DS_Store  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/CSNA3.SA/._.DS_Store  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/CSNA3.SA/visualizacao.html  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/CSNA3.SA/teste.csv  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/CSNA3.SA/treino.csv  \n",
            "Descompactado: /content/data-science-projects/deep-learning/data/CSNA3.SA.zip\n",
            "Archive:  /content/data-science-projects/deep-learning/data/PETR4.SA.zip\n",
            "  inflating: /content/data-science-projects/deep-learning/data/PETR4.SA/._PETR4.SA  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/PETR4.SA/.DS_Store  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/PETR4.SA/._.DS_Store  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/PETR4.SA/visualizacao.html  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/PETR4.SA/teste.csv  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/PETR4.SA/treino.csv  \n",
            "Descompactado: /content/data-science-projects/deep-learning/data/PETR4.SA.zip\n",
            "Archive:  /content/data-science-projects/deep-learning/data/VALE3.SA.zip\n",
            "  inflating: /content/data-science-projects/deep-learning/data/VALE3.SA/._VALE3.SA  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/VALE3.SA/.DS_Store  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/VALE3.SA/._.DS_Store  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/VALE3.SA/visualizacao.html  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/VALE3.SA/teste.csv  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/VALE3.SA/treino.csv  \n",
            "Descompactado: /content/data-science-projects/deep-learning/data/VALE3.SA.zip\n",
            "Archive:  /content/data-science-projects/deep-learning/data/CDI.zip\n",
            "  inflating: /content/data-science-projects/deep-learning/data/CDI/CDI.csv  \n",
            "  inflating: /content/data-science-projects/deep-learning/data/CDI/._CDI.csv  \n",
            "Descompactado: /content/data-science-projects/deep-learning/data/CDI.zip\n"
          ]
        }
      ],
      "source": [
        "# Lista de arquivos ZIP\n",
        "zip_files = [\n",
        "    \"/content/data-science-projects/deep-learning/data/BBAS3.SA.zip\",\n",
        "    \"/content/data-science-projects/deep-learning/data/CSNA3.SA.zip\",\n",
        "    \"/content/data-science-projects/deep-learning/data/PETR4.SA.zip\",\n",
        "    \"/content/data-science-projects/deep-learning/data/VALE3.SA.zip\",\n",
        "    \"/content/data-science-projects/deep-learning/data/CDI.zip\"\n",
        "]\n",
        "\n",
        "# Descompacta apenas se ainda não estiver descompactado\n",
        "for zip_file in zip_files:\n",
        "    folder_name = zip_file.replace(\".zip\", \"\")  # Define a pasta destino\n",
        "    if not os.path.exists(folder_name):  # Verifica se já foi descompactado\n",
        "        os.makedirs(folder_name, exist_ok=True)  # Cria a pasta se não existir\n",
        "        !unzip -o -j \"{zip_file}\" -d \"{folder_name}\"  # Extração sem estrutura de diretórios\n",
        "        print(f\"Descompactado: {zip_file}\")\n",
        "    else:\n",
        "        print(f\"Já está descompactado: {zip_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zmXMaBMX_axD"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "    df_train = pd.read_csv(os.path.join(path, \"treino.csv\"))\n",
        "    df_test = pd.read_csv(os.path.join(path, \"teste.csv\"))\n",
        "    return df_train, df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dNhLW514eIFt"
      },
      "outputs": [],
      "source": [
        "## BBAS3\n",
        "bb_train, bb_test = load_data(\"/content/data-science-projects/deep-learning/data/BBAS3.SA\")\n",
        "\n",
        "## CSNA3\n",
        "cs_train, cs_test = load_data(\"/content/data-science-projects/deep-learning/data/CSNA3.SA\")\n",
        "\n",
        "## PETR4\n",
        "pe_train, pe_test = load_data(\"/content/data-science-projects/deep-learning/data/PETR4.SA\")\n",
        "\n",
        "## VALE3\n",
        "vl_train, vl_test = load_data(\"/content/data-science-projects/deep-learning/data/VALE3.SA\")\n",
        "\n",
        "## CDI\n",
        "cdi = pd.read_csv(\"/content/data-science-projects/deep-learning/data/CDI/CDI.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cdi.columns:\n",
        "    if col != \"Ano\":\n",
        "        cdi[col] = (\n",
        "            cdi[col]\n",
        "            .astype(str)\n",
        "            .str.replace(\",\", \".\")\n",
        "            .replace(\"---\", None)\n",
        "            .astype(float)\n",
        "        )\n"
      ],
      "metadata": {
        "id": "GY1WRdd5CYRC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bb_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eUoZDsbF96h9",
        "outputId": "a38dcfb1-53eb-42da-9962-823ec196438d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0        Date      Close  Smoothed_Close  Label  \\\n",
              "0           4736  2019-03-26  36.386158       37.917648     -1   \n",
              "1           4737  2019-03-27  34.371300       37.563014     -1   \n",
              "2           4738  2019-03-28  35.571316       37.363844     -1   \n",
              "3           4739  2019-03-29  36.089863       37.236446     -1   \n",
              "4           4740  2019-04-01  36.445412       37.157342     -1   \n",
              "...          ...         ...        ...             ...    ...   \n",
              "1180        5916  2023-12-21  54.290001       53.331493      1   \n",
              "1181        5917  2023-12-22  54.439999       53.442343      1   \n",
              "1182        5918  2023-12-26  54.939999       53.592109      1   \n",
              "1183        5919  2023-12-27  54.860001       53.718898      1   \n",
              "1184        5920  2023-12-28  55.389999       53.886008      1   \n",
              "\n",
              "      Past_1_Days_Close  Past_2_Days_Close  Past_3_Days_Close  \\\n",
              "0             35.549099          35.297241          37.326935   \n",
              "1             36.386158          35.549099          35.297241   \n",
              "2             34.371300          36.386158          35.549099   \n",
              "3             35.571316          34.371300          36.386158   \n",
              "4             36.089863          35.571316          34.371300   \n",
              "...                 ...                ...                ...   \n",
              "1180          54.209999          54.849998          54.650002   \n",
              "1181          54.290001          54.209999          54.849998   \n",
              "1182          54.439999          54.290001          54.209999   \n",
              "1183          54.939999          54.439999          54.290001   \n",
              "1184          54.860001          54.939999          54.439999   \n",
              "\n",
              "      Past_4_Days_Close  Past_5_Days_Close  Past_6_Days_Close  \\\n",
              "0             38.126942          39.001053          39.852917   \n",
              "1             37.326935          38.126942          39.001053   \n",
              "2             35.297241          37.326935          38.126942   \n",
              "3             35.549099          35.297241          37.326935   \n",
              "4             36.386158          35.549099          35.297241   \n",
              "...                 ...                ...                ...   \n",
              "1180          54.610001          53.330002          52.980000   \n",
              "1181          54.650002          54.610001          53.330002   \n",
              "1182          54.849998          54.650002          54.610001   \n",
              "1183          54.209999          54.849998          54.650002   \n",
              "1184          54.290001          54.209999          54.849998   \n",
              "\n",
              "      Past_7_Days_Close  Past_8_Days_Close  Past_9_Days_Close  \\\n",
              "0             40.156639          39.815880          40.119583   \n",
              "1             39.852917          40.156639          39.815880   \n",
              "2             39.001053          39.852917          40.156639   \n",
              "3             38.126942          39.001053          39.852917   \n",
              "4             37.326935          38.126942          39.001053   \n",
              "...                 ...                ...                ...   \n",
              "1180          52.500000          54.097694          54.107632   \n",
              "1181          52.980000          52.500000          54.097694   \n",
              "1182          53.330002          52.980000          52.500000   \n",
              "1183          54.610001          53.330002          52.980000   \n",
              "1184          54.650002          54.610001          53.330002   \n",
              "\n",
              "      Past_10_Days_Close  Past_11_Days_Close  Past_12_Days_Close  \\\n",
              "0              39.512161           39.737267           38.555489   \n",
              "1              40.119583           39.512161           39.737267   \n",
              "2              39.815880           40.119583           39.512161   \n",
              "3              40.156639           39.815880           40.119583   \n",
              "4              39.852917           40.156639           39.815880   \n",
              "...                  ...                 ...                 ...   \n",
              "1180           53.531277           52.676685           53.829391   \n",
              "1181           54.107632           53.531277           52.676685   \n",
              "1182           54.097694           54.107632           53.531277   \n",
              "1183           52.500000           54.097694           54.107632   \n",
              "1184           52.980000           52.500000           54.097694   \n",
              "\n",
              "      Past_13_Days_Close  Past_14_Days_Close  Past_15_Days_Close  \n",
              "0              37.248150           37.395866           37.898129  \n",
              "1              38.555489           37.248150           37.395866  \n",
              "2              39.737267           38.555489           37.248150  \n",
              "3              39.512161           39.737267           38.555489  \n",
              "4              40.119583           39.512161           39.737267  \n",
              "...                  ...                 ...                 ...  \n",
              "1180           53.829391           54.038074           53.928764  \n",
              "1181           53.829391           53.829391           54.038074  \n",
              "1182           52.676685           53.829391           53.829391  \n",
              "1183           53.531277           52.676685           53.829391  \n",
              "1184           54.107632           53.531277           52.676685  \n",
              "\n",
              "[1185 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-757126e5-0cc3-4df9-beea-d4a742d5b421\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "      <th>Smoothed_Close</th>\n",
              "      <th>Label</th>\n",
              "      <th>Past_1_Days_Close</th>\n",
              "      <th>Past_2_Days_Close</th>\n",
              "      <th>Past_3_Days_Close</th>\n",
              "      <th>Past_4_Days_Close</th>\n",
              "      <th>Past_5_Days_Close</th>\n",
              "      <th>Past_6_Days_Close</th>\n",
              "      <th>Past_7_Days_Close</th>\n",
              "      <th>Past_8_Days_Close</th>\n",
              "      <th>Past_9_Days_Close</th>\n",
              "      <th>Past_10_Days_Close</th>\n",
              "      <th>Past_11_Days_Close</th>\n",
              "      <th>Past_12_Days_Close</th>\n",
              "      <th>Past_13_Days_Close</th>\n",
              "      <th>Past_14_Days_Close</th>\n",
              "      <th>Past_15_Days_Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4736</td>\n",
              "      <td>2019-03-26</td>\n",
              "      <td>36.386158</td>\n",
              "      <td>37.917648</td>\n",
              "      <td>-1</td>\n",
              "      <td>35.549099</td>\n",
              "      <td>35.297241</td>\n",
              "      <td>37.326935</td>\n",
              "      <td>38.126942</td>\n",
              "      <td>39.001053</td>\n",
              "      <td>39.852917</td>\n",
              "      <td>40.156639</td>\n",
              "      <td>39.815880</td>\n",
              "      <td>40.119583</td>\n",
              "      <td>39.512161</td>\n",
              "      <td>39.737267</td>\n",
              "      <td>38.555489</td>\n",
              "      <td>37.248150</td>\n",
              "      <td>37.395866</td>\n",
              "      <td>37.898129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4737</td>\n",
              "      <td>2019-03-27</td>\n",
              "      <td>34.371300</td>\n",
              "      <td>37.563014</td>\n",
              "      <td>-1</td>\n",
              "      <td>36.386158</td>\n",
              "      <td>35.549099</td>\n",
              "      <td>35.297241</td>\n",
              "      <td>37.326935</td>\n",
              "      <td>38.126942</td>\n",
              "      <td>39.001053</td>\n",
              "      <td>39.852917</td>\n",
              "      <td>40.156639</td>\n",
              "      <td>39.815880</td>\n",
              "      <td>40.119583</td>\n",
              "      <td>39.512161</td>\n",
              "      <td>39.737267</td>\n",
              "      <td>38.555489</td>\n",
              "      <td>37.248150</td>\n",
              "      <td>37.395866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4738</td>\n",
              "      <td>2019-03-28</td>\n",
              "      <td>35.571316</td>\n",
              "      <td>37.363844</td>\n",
              "      <td>-1</td>\n",
              "      <td>34.371300</td>\n",
              "      <td>36.386158</td>\n",
              "      <td>35.549099</td>\n",
              "      <td>35.297241</td>\n",
              "      <td>37.326935</td>\n",
              "      <td>38.126942</td>\n",
              "      <td>39.001053</td>\n",
              "      <td>39.852917</td>\n",
              "      <td>40.156639</td>\n",
              "      <td>39.815880</td>\n",
              "      <td>40.119583</td>\n",
              "      <td>39.512161</td>\n",
              "      <td>39.737267</td>\n",
              "      <td>38.555489</td>\n",
              "      <td>37.248150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4739</td>\n",
              "      <td>2019-03-29</td>\n",
              "      <td>36.089863</td>\n",
              "      <td>37.236446</td>\n",
              "      <td>-1</td>\n",
              "      <td>35.571316</td>\n",
              "      <td>34.371300</td>\n",
              "      <td>36.386158</td>\n",
              "      <td>35.549099</td>\n",
              "      <td>35.297241</td>\n",
              "      <td>37.326935</td>\n",
              "      <td>38.126942</td>\n",
              "      <td>39.001053</td>\n",
              "      <td>39.852917</td>\n",
              "      <td>40.156639</td>\n",
              "      <td>39.815880</td>\n",
              "      <td>40.119583</td>\n",
              "      <td>39.512161</td>\n",
              "      <td>39.737267</td>\n",
              "      <td>38.555489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4740</td>\n",
              "      <td>2019-04-01</td>\n",
              "      <td>36.445412</td>\n",
              "      <td>37.157342</td>\n",
              "      <td>-1</td>\n",
              "      <td>36.089863</td>\n",
              "      <td>35.571316</td>\n",
              "      <td>34.371300</td>\n",
              "      <td>36.386158</td>\n",
              "      <td>35.549099</td>\n",
              "      <td>35.297241</td>\n",
              "      <td>37.326935</td>\n",
              "      <td>38.126942</td>\n",
              "      <td>39.001053</td>\n",
              "      <td>39.852917</td>\n",
              "      <td>40.156639</td>\n",
              "      <td>39.815880</td>\n",
              "      <td>40.119583</td>\n",
              "      <td>39.512161</td>\n",
              "      <td>39.737267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1180</th>\n",
              "      <td>5916</td>\n",
              "      <td>2023-12-21</td>\n",
              "      <td>54.290001</td>\n",
              "      <td>53.331493</td>\n",
              "      <td>1</td>\n",
              "      <td>54.209999</td>\n",
              "      <td>54.849998</td>\n",
              "      <td>54.650002</td>\n",
              "      <td>54.610001</td>\n",
              "      <td>53.330002</td>\n",
              "      <td>52.980000</td>\n",
              "      <td>52.500000</td>\n",
              "      <td>54.097694</td>\n",
              "      <td>54.107632</td>\n",
              "      <td>53.531277</td>\n",
              "      <td>52.676685</td>\n",
              "      <td>53.829391</td>\n",
              "      <td>53.829391</td>\n",
              "      <td>54.038074</td>\n",
              "      <td>53.928764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1181</th>\n",
              "      <td>5917</td>\n",
              "      <td>2023-12-22</td>\n",
              "      <td>54.439999</td>\n",
              "      <td>53.442343</td>\n",
              "      <td>1</td>\n",
              "      <td>54.290001</td>\n",
              "      <td>54.209999</td>\n",
              "      <td>54.849998</td>\n",
              "      <td>54.650002</td>\n",
              "      <td>54.610001</td>\n",
              "      <td>53.330002</td>\n",
              "      <td>52.980000</td>\n",
              "      <td>52.500000</td>\n",
              "      <td>54.097694</td>\n",
              "      <td>54.107632</td>\n",
              "      <td>53.531277</td>\n",
              "      <td>52.676685</td>\n",
              "      <td>53.829391</td>\n",
              "      <td>53.829391</td>\n",
              "      <td>54.038074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1182</th>\n",
              "      <td>5918</td>\n",
              "      <td>2023-12-26</td>\n",
              "      <td>54.939999</td>\n",
              "      <td>53.592109</td>\n",
              "      <td>1</td>\n",
              "      <td>54.439999</td>\n",
              "      <td>54.290001</td>\n",
              "      <td>54.209999</td>\n",
              "      <td>54.849998</td>\n",
              "      <td>54.650002</td>\n",
              "      <td>54.610001</td>\n",
              "      <td>53.330002</td>\n",
              "      <td>52.980000</td>\n",
              "      <td>52.500000</td>\n",
              "      <td>54.097694</td>\n",
              "      <td>54.107632</td>\n",
              "      <td>53.531277</td>\n",
              "      <td>52.676685</td>\n",
              "      <td>53.829391</td>\n",
              "      <td>53.829391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1183</th>\n",
              "      <td>5919</td>\n",
              "      <td>2023-12-27</td>\n",
              "      <td>54.860001</td>\n",
              "      <td>53.718898</td>\n",
              "      <td>1</td>\n",
              "      <td>54.939999</td>\n",
              "      <td>54.439999</td>\n",
              "      <td>54.290001</td>\n",
              "      <td>54.209999</td>\n",
              "      <td>54.849998</td>\n",
              "      <td>54.650002</td>\n",
              "      <td>54.610001</td>\n",
              "      <td>53.330002</td>\n",
              "      <td>52.980000</td>\n",
              "      <td>52.500000</td>\n",
              "      <td>54.097694</td>\n",
              "      <td>54.107632</td>\n",
              "      <td>53.531277</td>\n",
              "      <td>52.676685</td>\n",
              "      <td>53.829391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1184</th>\n",
              "      <td>5920</td>\n",
              "      <td>2023-12-28</td>\n",
              "      <td>55.389999</td>\n",
              "      <td>53.886008</td>\n",
              "      <td>1</td>\n",
              "      <td>54.860001</td>\n",
              "      <td>54.939999</td>\n",
              "      <td>54.439999</td>\n",
              "      <td>54.290001</td>\n",
              "      <td>54.209999</td>\n",
              "      <td>54.849998</td>\n",
              "      <td>54.650002</td>\n",
              "      <td>54.610001</td>\n",
              "      <td>53.330002</td>\n",
              "      <td>52.980000</td>\n",
              "      <td>52.500000</td>\n",
              "      <td>54.097694</td>\n",
              "      <td>54.107632</td>\n",
              "      <td>53.531277</td>\n",
              "      <td>52.676685</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1185 rows × 20 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-757126e5-0cc3-4df9-beea-d4a742d5b421')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-757126e5-0cc3-4df9-beea-d4a742d5b421 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-757126e5-0cc3-4df9-beea-d4a742d5b421');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8a1b4244-c99d-46e4-ae1b-a826eedcda53\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a1b4244-c99d-46e4-ae1b-a826eedcda53')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8a1b4244-c99d-46e4-ae1b-a826eedcda53 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_dbc76d99-900f-401a-b393-cccd63e23782\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('bb_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dbc76d99-900f-401a-b393-cccd63e23782 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('bb_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bb_test",
              "summary": "{\n  \"name\": \"bb_test\",\n  \"rows\": 1185,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 342,\n        \"min\": 4736,\n        \"max\": 5920,\n        \"num_unique_values\": 1185,\n        \"samples\": [\n          5055,\n          5692,\n          5917\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1185,\n        \"samples\": [\n          \"2020-07-07\",\n          \"2023-01-27\",\n          \"2023-12-22\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.843706076092249,\n        \"min\": 17.26123809814453,\n        \"max\": 55.38999938964844,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          50.03309631347656,\n          36.09466552734375,\n          33.04441452026367\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Smoothed_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.478626862928559,\n        \"min\": 21.2975566732418,\n        \"max\": 53.88600814572215,\n        \"num_unique_values\": 1185,\n        \"samples\": [\n          25.85453506729851,\n          34.90204569432541,\n          53.44234329638167\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          -1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Past_1_Days_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.817227796514107,\n        \"min\": 17.26123809814453,\n        \"max\": 54.93999862670898,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          49.68598556518555,\n          35.29174041748047\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Past_2_Days_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.7918263503841425,\n        \"min\": 17.26123809814453,\n        \"max\": 54.93999862670898,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          48.00003433227539,\n          34.79337310791016\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Past_3_Days_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.766835325113412,\n        \"min\": 17.26123809814453,\n        \"max\": 54.84999847412109,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          47.95044708251953,\n          32.8645133972168\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Past_4_Days_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.743324554203197,\n        \"min\": 17.26123809814453,\n        \"max\": 54.84999847412109,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          48.05953979492188,\n          32.90142059326172\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Past_5_Days_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.7205969364623686,\n        \"min\": 17.26123809814453,\n        \"max\": 54.84999847412109,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          48.396728515625,\n          32.827598571777344\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Past_6_Days_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.698565940039007,\n        \"min\": 17.26123809814453,\n        \"max\": 54.84999847412109,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          49.65623474121094,\n          33.03985977172852\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Past_7_Days_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.675170726846131,\n        \"min\": 17.26123809814453,\n        \"max\": 54.650001525878906,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          48.6446647644043,\n          32.578407287597656\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Past_8_Days_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.651901138398113,\n        \"min\": 17.26123809814453,\n        \"max\": 54.61000061035156,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          48.63475036621094,\n          32.03388977050781\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Past_9_Days_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.628870808929556,\n        \"min\": 17.26123809814453,\n        \"max\": 54.10763168334961,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          48.86284637451172,\n          32.347686767578125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Past_10_Days_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.608273879805326,\n        \"min\": 17.26123809814453,\n        \"max\": 54.10763168334961,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          48.93226623535156,\n          31.90468978881836\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Past_11_Days_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.588556959454912,\n        \"min\": 17.26123809814453,\n        \"max\": 54.10763168334961,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          49.090946197509766,\n          30.5111141204834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Past_12_Days_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.569014773949451,\n        \"min\": 17.26123809814453,\n        \"max\": 54.10763168334961,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          48.71408462524414,\n          30.12349319458008\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Past_13_Days_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.545035546817181,\n        \"min\": 17.26123809814453,\n        \"max\": 54.10763168334961,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          48.95210266113281,\n          30.695688247680664\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Past_14_Days_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.521002374658459,\n        \"min\": 17.26123809814453,\n        \"max\": 54.0380744934082,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          49.39838409423828,\n          32.05235290527344\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Past_15_Days_Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.4984918312556905,\n        \"min\": 17.26123809814453,\n        \"max\": 54.0380744934082,\n        \"num_unique_values\": 1124,\n        \"samples\": [\n          48.41656494140625,\n          31.996978759765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AgoZNjCbqae"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "m3Y6HcPcinUf"
      },
      "outputs": [],
      "source": [
        "df_bb = pd.concat([bb_train, bb_test], ignore_index=True)\n",
        "df_cs = pd.concat([cs_train, cs_test], ignore_index=True)\n",
        "df_pe = pd.concat([pe_train, pe_test], ignore_index=True)\n",
        "df_vl = pd.concat([vl_train, vl_test], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "phExQR2tfKbk"
      },
      "outputs": [],
      "source": [
        "def freq_class(dfs_dict, target):\n",
        "    num_dfs = len(dfs_dict)\n",
        "\n",
        "    cols = 2\n",
        "    rows = math.ceil(num_dfs / cols)\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 5 * rows))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    freq_list = []\n",
        "\n",
        "    for i, (df_name, df) in enumerate(dfs_dict.items()):\n",
        "        freq = df[target].value_counts().reset_index()\n",
        "        freq.columns = ['Classe', 'Frequência']\n",
        "        freq_list.append((df_name, freq))\n",
        "\n",
        "        sns.barplot(x=freq['Classe'], y=freq['Frequência'], ax=axes[i], color=\"blue\")\n",
        "\n",
        "        axes[i].set_title(f'Distribuição de {target} - {df_name}')\n",
        "        axes[i].set_xlabel(target)\n",
        "        axes[i].set_ylabel('Frequência')\n",
        "\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        fig.delaxes(axes[j])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return freq_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ihK9W0aUk41U"
      },
      "outputs": [],
      "source": [
        "def plot_hist(dfs_dict, target, bins=10):\n",
        "    num_dfs = len(dfs_dict)\n",
        "\n",
        "    cols = 2\n",
        "    rows = math.ceil(num_dfs / cols)\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 5 * rows))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, (df_name, df) in enumerate(dfs_dict.items()):\n",
        "        sns.histplot(data=df[target], bins=bins, ax=axes[i], kde=True, color=\"blue\")\n",
        "        axes[i].set_title(f'Histograma de {target} - {df_name}')\n",
        "        axes[i].set_xlabel(target)\n",
        "        axes[i].set_ylabel('Frequência')\n",
        "\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        fig.delaxes(axes[j])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DE86YX5_gOOk",
        "outputId": "4f6c7505-4d6c-414c-9356-882ee343c92b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "dfs_dict = {\"BBAS3\": df_bb, \"CSNA3\": df_cs, \"PETR4\": df_pe, \"VAL3E\": df_vl}\n",
        "frequencias = freq_class(dfs_dict, 'Label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "s7c7i5HCkspL",
        "outputId": "db177e1d-17c9-4b74-a42f-adfea1b7dbdd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "histogramas = plot_hist(dfs_dict, 'Close')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NRBkIUMn-MN"
      },
      "source": [
        "## Pipeline de treinamento e teste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYL-lCz87lAM"
      },
      "source": [
        "### Funções"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0ksWyIGb_2RL"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(train_df, test_df, split_features=None):\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    features = [f\"Past_{i}_Days_Close\" for i in range(1, 16)]\n",
        "    X_train = train_df[features].values\n",
        "    X_test = test_df[features].values\n",
        "\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    y_train = train_df[\"Label\"].replace({-1: 0, 1: 1}).values\n",
        "    y_test = test_df[\"Label\"].replace({-1: 0, 1: 1}).values\n",
        "\n",
        "    if split_features is not None:\n",
        "        processed = []\n",
        "        for feature_group in split_features:\n",
        "            idx = [features.index(col) for col in feature_group]\n",
        "            reshaped_train = X_train[:, idx].reshape((X_train.shape[0], len(feature_group), 1))\n",
        "            reshaped_test = X_test[:, idx].reshape((X_test.shape[0], len(feature_group), 1))\n",
        "            processed.extend([reshaped_train, reshaped_test])\n",
        "        return (*processed, y_train, y_test, features)\n",
        "    else:\n",
        "        X_train = X_train.reshape((X_train.shape[0], len(features), 1))\n",
        "        X_test = X_test.reshape((X_test.shape[0], len(features), 1))\n",
        "        return X_train, X_test, y_train, y_test, features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model_fn, X_train, y_train, X_test, y_test,\n",
        "                prob=0.5, n_trials=20, metric_to_optimize='macro_recall',\n",
        "                model_path='best_model.keras'):\n",
        "\n",
        "    results = []\n",
        "    best_model = None\n",
        "    best_history = None\n",
        "    best_metrics = None\n",
        "    best_y_pred = None\n",
        "\n",
        "    model_dir = \"/content/data-science-projects/deep-learning/models\"\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    model_path = os.path.join(model_dir, os.path.basename(model_path))\n",
        "\n",
        "    def ensure_input_format(X):\n",
        "        if isinstance(X, (list, tuple)):\n",
        "            return X\n",
        "        return [X]\n",
        "\n",
        "    def objective(trial):\n",
        "        nonlocal best_model, best_history, best_metrics, best_y_pred\n",
        "\n",
        "        epochs = trial.suggest_int('epochs', 10, 50)\n",
        "        batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
        "        lr = trial.suggest_float('learning_rate', 1e-5, 1e-2)\n",
        "        stop_patience = trial.suggest_int('stop_patience', 3, 10)\n",
        "        reduce_lr_factor = trial.suggest_float('reduce_lr_factor', 0.1, 0.5)\n",
        "        reduce_lr_patience = trial.suggest_int('reduce_lr_patience', 2, 5)\n",
        "\n",
        "        model = model_fn()\n",
        "        optimizer = Adam(learning_rate=lr)\n",
        "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor=\"val_loss\", patience=stop_patience, restore_best_weights=True, verbose=1),\n",
        "            ReduceLROnPlateau(monitor=\"val_loss\", factor=reduce_lr_factor, patience=reduce_lr_patience, min_lr=1e-6, verbose=1),\n",
        "            ModelCheckpoint(\n",
        "                filepath=model_path,\n",
        "                monitor='val_loss',\n",
        "                save_best_only=True,\n",
        "                save_weights_only=False,\n",
        "                verbose=1\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        X_train_input = ensure_input_format(X_train)\n",
        "        X_test_input = ensure_input_format(X_test)\n",
        "\n",
        "        if len(X_train_input) == 1:\n",
        "            X_train_input = X_train_input[0]\n",
        "            X_test_input = X_test_input[0]\n",
        "\n",
        "        history = model.fit(\n",
        "            X_train_input, y_train,\n",
        "            validation_data=(X_test_input, y_test),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        model.load_weights(model_path)\n",
        "\n",
        "        y_pred_prob = model.predict(X_test_input)\n",
        "        y_pred = (y_pred_prob > prob).astype(int)\n",
        "\n",
        "        report = classification_report(y_test, y_pred, output_dict=True)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        metric_map = {\n",
        "            'macro_recall': report['macro avg']['recall'],\n",
        "            'weighted_recall': report['weighted avg']['recall'],\n",
        "            'Compra (1)_recall': report['1']['recall'],\n",
        "            'Vende (0)_recall': report['0']['recall'],\n",
        "            'Compra (1)_precision': report['1']['precision'],\n",
        "            'Vende (0)_precision': report['0']['precision'],\n",
        "            'accuracy': accuracy\n",
        "        }\n",
        "\n",
        "        if metric_to_optimize == \"val_loss\":\n",
        "            val_loss = min(history.history[\"val_loss\"])\n",
        "            score = -val_loss\n",
        "        else:\n",
        "            score = metric_map.get(metric_to_optimize, report['macro avg']['recall'])\n",
        "\n",
        "        metrics = {\n",
        "            'accuracy': accuracy,\n",
        "            'confusion_matrix': confusion_matrix(y_test, y_pred).tolist(),\n",
        "            'class_metrics': {\n",
        "                'Vende (0)': report['0'],\n",
        "                'Compra (1)': report['1']\n",
        "            },\n",
        "            'macro_avg': report['macro avg'],\n",
        "            'weighted_avg': report['weighted avg']\n",
        "        }\n",
        "\n",
        "        results.append({\n",
        "            'trial': trial.number,\n",
        "            'epochs': epochs,\n",
        "            'batch_size': batch_size,\n",
        "            'learning_rate': lr,\n",
        "            'stop_patience': stop_patience,\n",
        "            'reduce_lr_factor': reduce_lr_factor,\n",
        "            'reduce_lr_patience': reduce_lr_patience,\n",
        "            'recall_Compra(1)': report['1']['recall'],\n",
        "            'recall_Vende(0)': report['0']['recall'],\n",
        "            'precision_Compra(1)': report['1']['precision'],\n",
        "            'precision_Vende(0)': report['0']['precision'],\n",
        "            'macro_recall': report['macro avg']['recall'],\n",
        "            'accuracy': accuracy,\n",
        "            'f1_macro': report['macro avg']['f1-score'],\n",
        "            'f1_weighted': report['weighted avg']['f1-score'],\n",
        "            'min_val_loss': min(history.history[\"val_loss\"])\n",
        "        })\n",
        "\n",
        "        if score > objective.best_score:\n",
        "            objective.best_score = score\n",
        "            best_model = model\n",
        "            best_history = history\n",
        "            best_metrics = metrics\n",
        "            best_y_pred = y_pred\n",
        "\n",
        "        return score\n",
        "\n",
        "    objective.best_score = -np.inf\n",
        "\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "\n",
        "    df_results = pd.DataFrame(results).sort_values(\n",
        "        by=(\"min_val_loss\" if metric_to_optimize == \"val_loss\" else metric_to_optimize),\n",
        "        ascending=(True if metric_to_optimize == \"val_loss\" else False)\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n✅ Melhor combinação encontrada:\")\n",
        "    print(df_results.iloc[0])\n",
        "    print(\"🔍 Hiperparâmetros:\", study.best_params)\n",
        "\n",
        "    return best_model, best_history, df_results, best_metrics, best_y_pred\n"
      ],
      "metadata": {
        "id": "Oa8zNAqioYtm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hfEKqN2lYPiY"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(histories, titles=None):\n",
        "    n = len(histories)\n",
        "    fig, axes = plt.subplots(1, n, figsize=(6 * n, 5), sharey=True)\n",
        "\n",
        "    if titles is None:\n",
        "        titles = [f\"Modelo {i+1}\" for i in range(n)]\n",
        "\n",
        "    for i, history in enumerate(histories):\n",
        "        ax = axes[i] if n > 1 else axes\n",
        "        history_dict = history.history\n",
        "        loss = history_dict['loss']\n",
        "        val_loss = history_dict['val_loss']\n",
        "        epochs = range(1, len(loss) + 1)\n",
        "\n",
        "        ax.plot(epochs, loss, label='Loss Treino', color='blue')\n",
        "        ax.plot(epochs, val_loss, label='Loss Validação', color='orange')\n",
        "        ax.set_title(titles[i])\n",
        "        ax.set_xlabel('Épocas')\n",
        "        ax.set_ylabel('Loss')\n",
        "        ax.grid(True)\n",
        "        ax.legend()\n",
        "\n",
        "    plt.suptitle('Evolução da Loss')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nF4T1J1vvFqN"
      },
      "outputs": [],
      "source": [
        "def run_backtest(predictions, prices, capital, model_name, stock_name,\n",
        "                 metrics, cdi_df=None, metric_optimization=None):\n",
        "    capital_atual = capital\n",
        "    posicao = 0\n",
        "    valor_investido = 0\n",
        "    operacoes = []\n",
        "\n",
        "    for i in range(len(predictions) - 1):\n",
        "        preco_atual = prices[i]\n",
        "\n",
        "        if predictions[i] == 1 and capital_atual >= preco_atual:\n",
        "            qtd_comprada = capital_atual // preco_atual\n",
        "            valor_compra = qtd_comprada * preco_atual\n",
        "            posicao += qtd_comprada\n",
        "            capital_atual -= valor_compra\n",
        "\n",
        "        elif predictions[i] == 0 and posicao > 0:\n",
        "            valor_venda = posicao * preco_atual\n",
        "            capital_atual += valor_venda\n",
        "            retorno = (valor_venda - valor_compra) / valor_compra if valor_compra > 0 else 0\n",
        "            operacoes.append(retorno)\n",
        "            posicao = 0\n",
        "\n",
        "    valor_investido = posicao * prices.iloc[-1]\n",
        "    lucro = (capital_atual + valor_investido) - capital\n",
        "    lucro_percentual = (lucro / capital) * 100\n",
        "\n",
        "    # Cálculo do CDI no mesmo período\n",
        "    lucro_cdi_pct = None\n",
        "    if cdi_df is not None:\n",
        "        try:\n",
        "            # Converter o CDI para formato longo\n",
        "            cdi_long = cdi_df.melt(id_vars='Ano', var_name='Mes', value_name='CDI')\n",
        "            meses_map = {\n",
        "                'Jan': 1, 'Fev': 2, 'Mar': 3, 'Abr': 4, 'Mai': 5, 'Jun': 6,\n",
        "                'Jul': 7, 'Ago': 8, 'Set': 9, 'Out': 10, 'Nov': 11, 'Dez': 12\n",
        "            }\n",
        "            cdi_long['Mes_num'] = cdi_long['Mes'].map(meses_map)\n",
        "            cdi_long['Data'] = pd.to_datetime(dict(year=cdi_long['Ano'], month=cdi_long['Mes_num'], day=1))\n",
        "            cdi_long['CDI'] = cdi_long['CDI'].astype(float) / 100\n",
        "\n",
        "            # Filtrar período\n",
        "            inicio = prices.index.min()\n",
        "            fim = prices.index.max()\n",
        "            cdi_periodo = cdi_long[(cdi_long['Data'] >= inicio) & (cdi_long['Data'] <= fim)]\n",
        "\n",
        "            # Calcular rendimento acumulado\n",
        "            rendimento_cdi = (1 + cdi_periodo['CDI']).prod() - 1\n",
        "            lucro_cdi_pct = rendimento_cdi * 100\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Erro ao calcular o CDI:\", e)\n",
        "\n",
        "    resultado = {\n",
        "        \"Data\": datetime.now(),\n",
        "        \"Modelo\": model_name,\n",
        "        \"Ação\": stock_name,\n",
        "        \"Métrica de Otimização\": metric_optimization,\n",
        "        \"Acurácia\": metrics['accuracy'],\n",
        "        \"Precision\": metrics['macro_avg']['precision'],\n",
        "        \"Recall\": metrics['macro_avg']['recall'],\n",
        "        \"F1\": metrics['macro_avg']['f1-score'],\n",
        "        \"Matriz de Confusão\": metrics['confusion_matrix'],\n",
        "        \"Saldo Inicial\": capital,\n",
        "        \"Saldo Final\": capital_atual,\n",
        "        \"Total de Ações\": posicao,\n",
        "        \"Lucro Total\": lucro,\n",
        "        \"Lucro (%)\": lucro_percentual,\n",
        "        \"Lucro (%) CDI\": lucro_cdi_pct\n",
        "    }\n",
        "\n",
        "    caminho_resultado = \"/content/data-science-projects/deep-learning/results\"\n",
        "    caminho_csv = os.path.join(caminho_resultado, \"backtest_results.csv\")\n",
        "    os.makedirs(caminho_resultado, exist_ok=True)\n",
        "\n",
        "    if os.path.exists(caminho_csv):\n",
        "        df_existente = pd.read_csv(caminho_csv)\n",
        "        df_novo = pd.concat([df_existente, pd.DataFrame([resultado])], ignore_index=True)\n",
        "    else:\n",
        "        df_novo = pd.DataFrame([resultado])\n",
        "\n",
        "    df_novo.to_csv(caminho_csv, index=False)\n",
        "\n",
        "    return df_novo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "b52LZZ9LYpK-"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(metrics_list, titles=None):\n",
        "    n = len(metrics_list)\n",
        "    fig, axes = plt.subplots(1, n, figsize=(6 * n, 5))\n",
        "\n",
        "    if titles is None:\n",
        "        titles = [f\"Modelo {i+1}\" for i in range(n)]\n",
        "\n",
        "    for i, metrics in enumerate(metrics_list):\n",
        "        ax = axes[i] if n > 1 else axes\n",
        "        cm = metrics['confusion_matrix']\n",
        "        labels = list(metrics['class_metrics'].keys())\n",
        "\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=labels, yticklabels=labels, ax=ax)\n",
        "        ax.set_title(titles[i])\n",
        "        ax.set_xlabel('Predito')\n",
        "        ax.set_ylabel('Real')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fEys2VH-eNyH"
      },
      "outputs": [],
      "source": [
        "def show_classification_reports(metrics_list, titles=None):\n",
        "    n = len(metrics_list)\n",
        "    if titles is None:\n",
        "        titles = [f\"Modelo {i+1}\" for i in range(n)]\n",
        "\n",
        "    for i, metrics in enumerate(metrics_list):\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"📊 Relatório de Classificação - {titles[i]}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        for class_name, class_metrics in metrics['class_metrics'].items():\n",
        "            print(f\"\\n{class_name}:\")\n",
        "            print(f\"Precision: {class_metrics['precision']:.2f}\")\n",
        "            print(f\"Recall:    {class_metrics['recall']:.2f}\")\n",
        "            print(f\"F1-Score:  {class_metrics['f1-score']:.2f}\")\n",
        "\n",
        "        print(\"\\nMédias:\")\n",
        "        print(f\"Acurácia:  {metrics['accuracy']:.2f}\")\n",
        "        print(f\"Precision: {metrics['macro_avg']['precision']:.2f}\")\n",
        "        print(f\"Recall:    {metrics['macro_avg']['recall']:.2f}\")\n",
        "        print(f\"F1-Score:  {metrics['macro_avg']['f1-score']:.2f}\")\n",
        "        print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nxLpPKaQunVc"
      },
      "outputs": [],
      "source": [
        "def plot_sell_by(prices_list, predictions_list, titles=None):\n",
        "    n = len(prices_list)\n",
        "    fig, axes = plt.subplots(1, n, figsize=(8 * n, 5))\n",
        "\n",
        "    if titles is None:\n",
        "        titles = [f\"Modelo {i+1}\" for i in range(n)]\n",
        "\n",
        "    for i in range(n):\n",
        "        ax = axes[i] if n > 1 else axes\n",
        "        prices = prices_list[i]\n",
        "        predictions = predictions_list[i]\n",
        "\n",
        "        buy_signals = np.where(predictions == 1)[0]\n",
        "        sell_signals = np.where(predictions == 0)[0]\n",
        "\n",
        "        ax.plot(prices, label='Preço da Ação', color='blue', linewidth=1.5)\n",
        "        ax.scatter(buy_signals, prices[buy_signals], color='green', label='Compra', marker='^', s=100)\n",
        "        ax.scatter(sell_signals, prices[sell_signals], color='red', label='Venda', marker='v', s=100)\n",
        "\n",
        "        ax.set_title(titles[i])\n",
        "        ax.set_xlabel('Tempo')\n",
        "        ax.set_ylabel('Preço da Ação')\n",
        "        ax.grid(True)\n",
        "        ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_cnn_ramificado():\n",
        "    input1 = Input(shape=(7, 1))\n",
        "    input2 = Input(shape=(8, 1))\n",
        "\n",
        "    # Ramo 1\n",
        "    x1 = Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding=\"same\")(input1)\n",
        "    x1 = MaxPooling1D(pool_size=2)(x1)\n",
        "    x1 = Flatten()(x1)\n",
        "    # Ramo 2\n",
        "    x2 = Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding=\"same\")(input2)\n",
        "    x2 = MaxPooling1D(pool_size=2)(x2)\n",
        "    x2 = Flatten()(x2)\n",
        "\n",
        "    # Combina os três ramos\n",
        "    combined = Concatenate()([x1, x2])\n",
        "    combined = Dense(64, activation='relu')(combined)\n",
        "    combined = Dropout(0.3)(combined)\n",
        "    output = Dense(1, activation='sigmoid')(combined)\n",
        "\n",
        "    model = Model(inputs=[input1, input2], outputs=output)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "hClWDR3ohVwz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sId3cwfnDdYN"
      },
      "outputs": [],
      "source": [
        "def model_cnn_sequencial():\n",
        "    return Sequential([\n",
        "        Input(shape=(15, 1)),\n",
        "        Conv1D(filters=64, kernel_size=3, activation=\"relu\"),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(filters=64, kernel_size=3, activation=\"relu\"),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(64, activation=\"relu\"),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation=\"relu\"),\n",
        "        Dense(1, activation=\"sigmoid\")\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jHNpSLnZ64Vw"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.keras.utils.set_random_seed(seed)\n",
        "tf.config.experimental.enable_op_determinism()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgLelBIw82vH"
      },
      "source": [
        "### BBAS3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xt8w6GpWAECu"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, features = preprocess_data(bb_train, bb_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "O4HSmgv74exV"
      },
      "outputs": [],
      "source": [
        "janela_curta = features[:7]\n",
        "janela_longa = features[7:]\n",
        "X_train1, X_test1, X_train2, X_test2, y_train, y_test, features = preprocess_data(bb_train, bb_test, split_features=[janela_curta,janela_longa])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prices = bb_test.set_index(\"Date\")[\"Close\"]\n",
        "titles = [\"Modelo Sequencial\", \"Modelo Ramificado\"]\n",
        "metric_optimization = 'val_loss'"
      ],
      "metadata": {
        "id": "9pK5_w1szT6p"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_seq_model, best_seq_history, df_results, best_seq_metrics, best_seq_y_pred = train_model(\n",
        "    model_fn=model_cnn_sequencial,\n",
        "    model_path = \"BEST_CNN_SEQ_BBAS3.keras\",\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    prob=0.5,\n",
        "    n_trials=30,\n",
        "    metric_to_optimize=metric_optimization\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fbZHOlrO4eek",
        "outputId": "6f7bb610-b92f-4fd5-dcdb-fd8246d6d90f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:10:58,396] A new study created in memory with name: no-name-7dc75bc6-5cc2-4359-baa1-6e8d37067e83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/46\n",
            "\u001b[1m137/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5398 - loss: 0.6939\n",
            "Epoch 1: val_loss improved from inf to 0.76396, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5406 - loss: 0.6936 - val_accuracy: 0.4186 - val_loss: 0.7640 - learning_rate: 0.0097\n",
            "Epoch 2/46\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5512 - loss: 0.6870\n",
            "Epoch 2: val_loss improved from 0.76396 to 0.68658, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5511 - loss: 0.6870 - val_accuracy: 0.5814 - val_loss: 0.6866 - learning_rate: 0.0097\n",
            "Epoch 3/46\n",
            "\u001b[1m141/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5496 - loss: 0.6892\n",
            "Epoch 3: val_loss did not improve from 0.68658\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5500 - loss: 0.6891 - val_accuracy: 0.5688 - val_loss: 0.6913 - learning_rate: 0.0097\n",
            "Epoch 4/46\n",
            "\u001b[1m146/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5473 - loss: 0.6869\n",
            "Epoch 4: val_loss improved from 0.68658 to 0.66170, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5475 - loss: 0.6869 - val_accuracy: 0.6684 - val_loss: 0.6617 - learning_rate: 0.0097\n",
            "Epoch 5/46\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5662 - loss: 0.6783\n",
            "Epoch 5: val_loss improved from 0.66170 to 0.49259, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5661 - loss: 0.6780 - val_accuracy: 0.7958 - val_loss: 0.4926 - learning_rate: 0.0097\n",
            "Epoch 6/46\n",
            "\u001b[1m137/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6440 - loss: 0.6205\n",
            "Epoch 6: val_loss did not improve from 0.49259\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6448 - loss: 0.6193 - val_accuracy: 0.5131 - val_loss: 2.1918 - learning_rate: 0.0097\n",
            "Epoch 7/46\n",
            "\u001b[1m145/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6488 - loss: 0.6040\n",
            "Epoch 7: val_loss did not improve from 0.49259\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6489 - loss: 0.6034 - val_accuracy: 0.8025 - val_loss: 0.5861 - learning_rate: 0.0097\n",
            "Epoch 8/46\n",
            "\u001b[1m147/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6677 - loss: 0.5824\n",
            "Epoch 8: val_loss improved from 0.49259 to 0.47594, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6677 - loss: 0.5823 - val_accuracy: 0.7662 - val_loss: 0.4759 - learning_rate: 0.0097\n",
            "Epoch 9/46\n",
            "\u001b[1m137/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6640 - loss: 0.5593\n",
            "Epoch 9: val_loss did not improve from 0.47594\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6646 - loss: 0.5590 - val_accuracy: 0.6667 - val_loss: 0.5576 - learning_rate: 0.0097\n",
            "Epoch 10/46\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6913 - loss: 0.5382\n",
            "Epoch 10: val_loss improved from 0.47594 to 0.41146, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6913 - loss: 0.5383 - val_accuracy: 0.8177 - val_loss: 0.4115 - learning_rate: 0.0097\n",
            "Epoch 11/46\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6850 - loss: 0.5421\n",
            "Epoch 11: val_loss did not improve from 0.41146\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6851 - loss: 0.5419 - val_accuracy: 0.8295 - val_loss: 0.4675 - learning_rate: 0.0097\n",
            "Epoch 12/46\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6924 - loss: 0.5359\n",
            "Epoch 12: val_loss did not improve from 0.41146\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6925 - loss: 0.5358 - val_accuracy: 0.7958 - val_loss: 0.4962 - learning_rate: 0.0097\n",
            "Epoch 13/46\n",
            "\u001b[1m136/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7048 - loss: 0.5185\n",
            "Epoch 13: val_loss did not improve from 0.41146\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7055 - loss: 0.5177 - val_accuracy: 0.8008 - val_loss: 0.4708 - learning_rate: 0.0097\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:11:16,352] Trial 0 finished with value: -0.4114605784416199 and parameters: {'epochs': 46, 'batch_size': 32, 'learning_rate': 0.009721568748326125, 'stop_patience': 3, 'reduce_lr_factor': 0.26361740565916925, 'reduce_lr_patience': 5}. Best is trial 0 with value: -0.4114605784416199.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5439 - loss: 0.6927\n",
            "Epoch 1: val_loss improved from inf to 0.65626, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.5440 - loss: 0.6927 - val_accuracy: 0.5646 - val_loss: 0.6563 - learning_rate: 0.0045\n",
            "Epoch 2/16\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6082 - loss: 0.6467\n",
            "Epoch 2: val_loss did not improve from 0.65626\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6091 - loss: 0.6458 - val_accuracy: 0.5857 - val_loss: 0.9903 - learning_rate: 0.0045\n",
            "Epoch 3/16\n",
            "\u001b[1m147/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6638 - loss: 0.5855\n",
            "Epoch 3: val_loss did not improve from 0.65626\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6639 - loss: 0.5853 - val_accuracy: 0.4498 - val_loss: 0.8973 - learning_rate: 0.0045\n",
            "Epoch 4/16\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6992 - loss: 0.5356\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0019261125415032446.\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.65626\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6995 - loss: 0.5355 - val_accuracy: 0.6059 - val_loss: 0.9422 - learning_rate: 0.0045\n",
            "Epoch 4: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:11:28,113] Trial 1 finished with value: -0.6562601327896118 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 0.004492779912052873, 'stop_patience': 3, 'reduce_lr_factor': 0.4287128811342522, 'reduce_lr_patience': 3}. Best is trial 0 with value: -0.4114605784416199.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5403 - loss: 0.6905\n",
            "Epoch 1: val_loss improved from inf to 0.64884, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5410 - loss: 0.6903 - val_accuracy: 0.6278 - val_loss: 0.6488 - learning_rate: 0.0034\n",
            "Epoch 2/25\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5917 - loss: 0.6567\n",
            "Epoch 2: val_loss improved from 0.64884 to 0.56037, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5918 - loss: 0.6565 - val_accuracy: 0.7013 - val_loss: 0.5604 - learning_rate: 0.0034\n",
            "Epoch 3/25\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6543 - loss: 0.5935\n",
            "Epoch 3: val_loss did not improve from 0.56037\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6548 - loss: 0.5932 - val_accuracy: 0.5840 - val_loss: 0.7332 - learning_rate: 0.0034\n",
            "Epoch 4/25\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6885 - loss: 0.5492\n",
            "Epoch 4: val_loss improved from 0.56037 to 0.40026, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6891 - loss: 0.5485 - val_accuracy: 0.8169 - val_loss: 0.4003 - learning_rate: 0.0034\n",
            "Epoch 5/25\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7064 - loss: 0.5238\n",
            "Epoch 5: val_loss did not improve from 0.40026\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7064 - loss: 0.5238 - val_accuracy: 0.7941 - val_loss: 0.4286 - learning_rate: 0.0034\n",
            "Epoch 6/25\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7125 - loss: 0.5084\n",
            "Epoch 6: val_loss improved from 0.40026 to 0.37263, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7127 - loss: 0.5083 - val_accuracy: 0.8295 - val_loss: 0.3726 - learning_rate: 0.0034\n",
            "Epoch 7/25\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7107 - loss: 0.5064\n",
            "Epoch 7: val_loss improved from 0.37263 to 0.36696, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7113 - loss: 0.5060 - val_accuracy: 0.8430 - val_loss: 0.3670 - learning_rate: 0.0034\n",
            "Epoch 8/25\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7324 - loss: 0.4918\n",
            "Epoch 8: val_loss did not improve from 0.36696\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7326 - loss: 0.4917 - val_accuracy: 0.7848 - val_loss: 0.4422 - learning_rate: 0.0034\n",
            "Epoch 9/25\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7145 - loss: 0.4988\n",
            "Epoch 9: val_loss did not improve from 0.36696\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7150 - loss: 0.4984 - val_accuracy: 0.7772 - val_loss: 0.4237 - learning_rate: 0.0034\n",
            "Epoch 10/25\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.4773\n",
            "Epoch 10: val_loss did not improve from 0.36696\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7367 - loss: 0.4772 - val_accuracy: 0.7772 - val_loss: 0.4258 - learning_rate: 0.0034\n",
            "Epoch 11/25\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7214 - loss: 0.4916\n",
            "Epoch 11: val_loss did not improve from 0.36696\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7222 - loss: 0.4908 - val_accuracy: 0.8051 - val_loss: 0.4229 - learning_rate: 0.0034\n",
            "Epoch 12/25\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7463 - loss: 0.4722\n",
            "Epoch 12: val_loss improved from 0.36696 to 0.34543, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7467 - loss: 0.4719 - val_accuracy: 0.8422 - val_loss: 0.3454 - learning_rate: 0.0034\n",
            "Epoch 13/25\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7354 - loss: 0.4647\n",
            "Epoch 13: val_loss did not improve from 0.34543\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7356 - loss: 0.4645 - val_accuracy: 0.8228 - val_loss: 0.4220 - learning_rate: 0.0034\n",
            "Epoch 14/25\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7418 - loss: 0.4635\n",
            "Epoch 14: val_loss did not improve from 0.34543\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7423 - loss: 0.4632 - val_accuracy: 0.8430 - val_loss: 0.3620 - learning_rate: 0.0034\n",
            "Epoch 15/25\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7544 - loss: 0.4684\n",
            "Epoch 15: val_loss did not improve from 0.34543\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7550 - loss: 0.4678 - val_accuracy: 0.8363 - val_loss: 0.3662 - learning_rate: 0.0034\n",
            "Epoch 16/25\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7407 - loss: 0.4644\n",
            "Epoch 16: val_loss did not improve from 0.34543\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7411 - loss: 0.4641 - val_accuracy: 0.7662 - val_loss: 0.6008 - learning_rate: 0.0034\n",
            "Epoch 17/25\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7511 - loss: 0.4542\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0015146929250672697.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.34543\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7514 - loss: 0.4540 - val_accuracy: 0.8262 - val_loss: 0.3855 - learning_rate: 0.0034\n",
            "Epoch 18/25\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7754 - loss: 0.4388\n",
            "Epoch 18: val_loss did not improve from 0.34543\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7755 - loss: 0.4387 - val_accuracy: 0.8565 - val_loss: 0.3522 - learning_rate: 0.0015\n",
            "Epoch 19/25\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7997 - loss: 0.4202\n",
            "Epoch 19: val_loss did not improve from 0.34543\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.4198 - val_accuracy: 0.8228 - val_loss: 0.4318 - learning_rate: 0.0015\n",
            "Epoch 20/25\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7958 - loss: 0.4108\n",
            "Epoch 20: val_loss improved from 0.34543 to 0.33792, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7959 - loss: 0.4107 - val_accuracy: 0.8489 - val_loss: 0.3379 - learning_rate: 0.0015\n",
            "Epoch 21/25\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.4055\n",
            "Epoch 21: val_loss did not improve from 0.33792\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8064 - loss: 0.4053 - val_accuracy: 0.8371 - val_loss: 0.3621 - learning_rate: 0.0015\n",
            "Epoch 22/25\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.3868\n",
            "Epoch 22: val_loss improved from 0.33792 to 0.33260, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.3868 - val_accuracy: 0.8667 - val_loss: 0.3326 - learning_rate: 0.0015\n",
            "Epoch 23/25\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8084 - loss: 0.3945\n",
            "Epoch 23: val_loss improved from 0.33260 to 0.33176, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8085 - loss: 0.3943 - val_accuracy: 0.8608 - val_loss: 0.3318 - learning_rate: 0.0015\n",
            "Epoch 24/25\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8146 - loss: 0.3817\n",
            "Epoch 24: val_loss did not improve from 0.33176\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8148 - loss: 0.3815 - val_accuracy: 0.8439 - val_loss: 0.3757 - learning_rate: 0.0015\n",
            "Epoch 25/25\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8242 - loss: 0.3728\n",
            "Epoch 25: val_loss did not improve from 0.33176\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.3726 - val_accuracy: 0.8481 - val_loss: 0.3383 - learning_rate: 0.0015\n",
            "Restoring model weights from the end of the best epoch: 23.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:12:29,747] Trial 2 finished with value: -0.3317584991455078 and parameters: {'epochs': 25, 'batch_size': 16, 'learning_rate': 0.003370026652047647, 'stop_patience': 8, 'reduce_lr_factor': 0.4494602293610046, 'reduce_lr_patience': 5}. Best is trial 2 with value: -0.3317584991455078.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/47\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5520 - loss: 0.6882\n",
            "Epoch 1: val_loss improved from inf to 0.58405, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5527 - loss: 0.6878 - val_accuracy: 0.6498 - val_loss: 0.5840 - learning_rate: 0.0018\n",
            "Epoch 2/47\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6426 - loss: 0.6165\n",
            "Epoch 2: val_loss did not improve from 0.58405\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6430 - loss: 0.6161 - val_accuracy: 0.6093 - val_loss: 1.2098 - learning_rate: 0.0018\n",
            "Epoch 3/47\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6999 - loss: 0.5566\n",
            "Epoch 3: val_loss improved from 0.58405 to 0.41784, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7000 - loss: 0.5564 - val_accuracy: 0.8084 - val_loss: 0.4178 - learning_rate: 0.0018\n",
            "Epoch 4/47\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6949 - loss: 0.5401\n",
            "Epoch 4: val_loss improved from 0.41784 to 0.41613, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6952 - loss: 0.5397 - val_accuracy: 0.8034 - val_loss: 0.4161 - learning_rate: 0.0018\n",
            "Epoch 5/47\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7125 - loss: 0.5147\n",
            "Epoch 5: val_loss improved from 0.41613 to 0.35106, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7129 - loss: 0.5145 - val_accuracy: 0.8397 - val_loss: 0.3511 - learning_rate: 0.0018\n",
            "Epoch 6/47\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7244 - loss: 0.5095\n",
            "Epoch 6: val_loss did not improve from 0.35106\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7248 - loss: 0.5091 - val_accuracy: 0.8194 - val_loss: 0.3904 - learning_rate: 0.0018\n",
            "Epoch 7/47\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.5030\n",
            "Epoch 7: val_loss did not improve from 0.35106\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7335 - loss: 0.5030 - val_accuracy: 0.7451 - val_loss: 0.5215 - learning_rate: 0.0018\n",
            "Epoch 8/47\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7287 - loss: 0.5010\n",
            "Epoch 8: val_loss improved from 0.35106 to 0.34885, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7289 - loss: 0.5008 - val_accuracy: 0.8422 - val_loss: 0.3488 - learning_rate: 0.0018\n",
            "Epoch 9/47\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7417 - loss: 0.4798\n",
            "Epoch 9: val_loss did not improve from 0.34885\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7418 - loss: 0.4797 - val_accuracy: 0.8473 - val_loss: 0.3690 - learning_rate: 0.0018\n",
            "Epoch 10/47\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7514 - loss: 0.4652\n",
            "Epoch 10: val_loss did not improve from 0.34885\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7518 - loss: 0.4647 - val_accuracy: 0.7451 - val_loss: 0.6314 - learning_rate: 0.0018\n",
            "Epoch 11/47\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7465 - loss: 0.4733\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0006994495120667126.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.34885\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7466 - loss: 0.4731 - val_accuracy: 0.8203 - val_loss: 0.3743 - learning_rate: 0.0018\n",
            "Epoch 12/47\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7735 - loss: 0.4334\n",
            "Epoch 12: val_loss did not improve from 0.34885\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7739 - loss: 0.4328 - val_accuracy: 0.8068 - val_loss: 0.4168 - learning_rate: 6.9945e-04\n",
            "Epoch 13/47\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.4141\n",
            "Epoch 13: val_loss did not improve from 0.34885\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7875 - loss: 0.4139 - val_accuracy: 0.8312 - val_loss: 0.3497 - learning_rate: 6.9945e-04\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:12:59,854] Trial 3 finished with value: -0.3488464057445526 and parameters: {'epochs': 47, 'batch_size': 16, 'learning_rate': 0.0017835238938513941, 'stop_patience': 5, 'reduce_lr_factor': 0.3921727630483849, 'reduce_lr_patience': 3}. Best is trial 2 with value: -0.3317584991455078.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/46\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5451 - loss: 0.6918\n",
            "Epoch 1: val_loss improved from inf to 0.68308, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5453 - loss: 0.6917 - val_accuracy: 0.6152 - val_loss: 0.6831 - learning_rate: 0.0076\n",
            "Epoch 2/46\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5466 - loss: 0.6884\n",
            "Epoch 2: val_loss did not improve from 0.68308\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5468 - loss: 0.6884 - val_accuracy: 0.5696 - val_loss: 0.6857 - learning_rate: 0.0076\n",
            "Epoch 3/46\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5561 - loss: 0.6851\n",
            "Epoch 3: val_loss did not improve from 0.68308\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5563 - loss: 0.6850 - val_accuracy: 0.5468 - val_loss: 0.7643 - learning_rate: 0.0076\n",
            "Epoch 4/46\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6100 - loss: 0.6372\n",
            "Epoch 4: val_loss improved from 0.68308 to 0.58798, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6103 - loss: 0.6369 - val_accuracy: 0.7131 - val_loss: 0.5880 - learning_rate: 0.0076\n",
            "Epoch 5/46\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6493 - loss: 0.5806\n",
            "Epoch 5: val_loss improved from 0.58798 to 0.38240, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6495 - loss: 0.5805 - val_accuracy: 0.8304 - val_loss: 0.3824 - learning_rate: 0.0076\n",
            "Epoch 6/46\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6773 - loss: 0.5409\n",
            "Epoch 6: val_loss did not improve from 0.38240\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6776 - loss: 0.5409 - val_accuracy: 0.7772 - val_loss: 0.5204 - learning_rate: 0.0076\n",
            "Epoch 7/46\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6719 - loss: 0.5566\n",
            "Epoch 7: val_loss did not improve from 0.38240\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6720 - loss: 0.5564 - val_accuracy: 0.7747 - val_loss: 0.4717 - learning_rate: 0.0076\n",
            "Epoch 8/46\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6881 - loss: 0.5279\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00361127357177541.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.38240\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6881 - loss: 0.5280 - val_accuracy: 0.5831 - val_loss: 0.7083 - learning_rate: 0.0076\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:13:16,337] Trial 4 finished with value: -0.3823961019515991 and parameters: {'epochs': 46, 'batch_size': 16, 'learning_rate': 0.007554379714504587, 'stop_patience': 3, 'reduce_lr_factor': 0.47803707090487835, 'reduce_lr_patience': 3}. Best is trial 2 with value: -0.3317584991455078.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/36\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5471 - loss: 0.6932\n",
            "Epoch 1: val_loss improved from inf to 0.77198, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5477 - loss: 0.6928 - val_accuracy: 0.4186 - val_loss: 0.7720 - learning_rate: 0.0093\n",
            "Epoch 2/36\n",
            "\u001b[1m65/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5533 - loss: 0.6827\n",
            "Epoch 2: val_loss improved from 0.77198 to 0.66312, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5540 - loss: 0.6825 - val_accuracy: 0.5789 - val_loss: 0.6631 - learning_rate: 0.0093\n",
            "Epoch 3/36\n",
            "\u001b[1m67/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5739 - loss: 0.6640\n",
            "Epoch 3: val_loss improved from 0.66312 to 0.61799, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5749 - loss: 0.6627 - val_accuracy: 0.6895 - val_loss: 0.6180 - learning_rate: 0.0093\n",
            "Epoch 4/36\n",
            "\u001b[1m69/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6221 - loss: 0.6096\n",
            "Epoch 4: val_loss improved from 0.61799 to 0.49158, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6228 - loss: 0.6090 - val_accuracy: 0.7392 - val_loss: 0.4916 - learning_rate: 0.0093\n",
            "Epoch 5/36\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6547 - loss: 0.5865\n",
            "Epoch 5: val_loss did not improve from 0.49158\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6552 - loss: 0.5857 - val_accuracy: 0.7241 - val_loss: 0.5477 - learning_rate: 0.0093\n",
            "Epoch 6/36\n",
            "\u001b[1m65/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6753 - loss: 0.5666\n",
            "Epoch 6: val_loss did not improve from 0.49158\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6758 - loss: 0.5648 - val_accuracy: 0.8008 - val_loss: 0.5385 - learning_rate: 0.0093\n",
            "Epoch 7/36\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6833 - loss: 0.5569\n",
            "Epoch 7: val_loss improved from 0.49158 to 0.39053, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6834 - loss: 0.5559 - val_accuracy: 0.8253 - val_loss: 0.3905 - learning_rate: 0.0093\n",
            "Epoch 8/36\n",
            "\u001b[1m66/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6913 - loss: 0.5297\n",
            "Epoch 8: val_loss did not improve from 0.39053\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6919 - loss: 0.5286 - val_accuracy: 0.7722 - val_loss: 0.6272 - learning_rate: 0.0093\n",
            "Epoch 9/36\n",
            "\u001b[1m66/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6890 - loss: 0.5310\n",
            "Epoch 9: val_loss did not improve from 0.39053\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6892 - loss: 0.5305 - val_accuracy: 0.8270 - val_loss: 0.4166 - learning_rate: 0.0093\n",
            "Epoch 10/36\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6895 - loss: 0.5368\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.002643304935228377.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.39053\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6902 - loss: 0.5360 - val_accuracy: 0.7992 - val_loss: 0.4744 - learning_rate: 0.0093\n",
            "Epoch 11/36\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7027 - loss: 0.5150\n",
            "Epoch 11: val_loss improved from 0.39053 to 0.37339, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7029 - loss: 0.5146 - val_accuracy: 0.8278 - val_loss: 0.3734 - learning_rate: 0.0026\n",
            "Epoch 12/36\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7068 - loss: 0.5090\n",
            "Epoch 12: val_loss did not improve from 0.37339\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7071 - loss: 0.5087 - val_accuracy: 0.8253 - val_loss: 0.3775 - learning_rate: 0.0026\n",
            "Epoch 13/36\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7071 - loss: 0.5074\n",
            "Epoch 13: val_loss improved from 0.37339 to 0.37278, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7074 - loss: 0.5068 - val_accuracy: 0.8371 - val_loss: 0.3728 - learning_rate: 0.0026\n",
            "Epoch 14/36\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7079 - loss: 0.5062\n",
            "Epoch 14: val_loss improved from 0.37278 to 0.36702, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7082 - loss: 0.5058 - val_accuracy: 0.8414 - val_loss: 0.3670 - learning_rate: 0.0026\n",
            "Epoch 15/36\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7066 - loss: 0.4992\n",
            "Epoch 15: val_loss did not improve from 0.36702\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7071 - loss: 0.4989 - val_accuracy: 0.8008 - val_loss: 0.4188 - learning_rate: 0.0026\n",
            "Epoch 16/36\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7079 - loss: 0.5043\n",
            "Epoch 16: val_loss improved from 0.36702 to 0.36325, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7086 - loss: 0.5038 - val_accuracy: 0.8388 - val_loss: 0.3633 - learning_rate: 0.0026\n",
            "Epoch 17/36\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7075 - loss: 0.5007\n",
            "Epoch 17: val_loss did not improve from 0.36325\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7077 - loss: 0.5003 - val_accuracy: 0.8397 - val_loss: 0.3641 - learning_rate: 0.0026\n",
            "Epoch 18/36\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7038 - loss: 0.5049\n",
            "Epoch 18: val_loss improved from 0.36325 to 0.36204, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7041 - loss: 0.5045 - val_accuracy: 0.8346 - val_loss: 0.3620 - learning_rate: 0.0026\n",
            "Epoch 19/36\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7065 - loss: 0.5015\n",
            "Epoch 19: val_loss improved from 0.36204 to 0.36109, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7065 - loss: 0.5014 - val_accuracy: 0.8380 - val_loss: 0.3611 - learning_rate: 0.0026\n",
            "Epoch 20/36\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7091 - loss: 0.4983\n",
            "Epoch 20: val_loss did not improve from 0.36109\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7094 - loss: 0.4980 - val_accuracy: 0.8354 - val_loss: 0.3629 - learning_rate: 0.0026\n",
            "Epoch 21/36\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7083 - loss: 0.4990\n",
            "Epoch 21: val_loss did not improve from 0.36109\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7086 - loss: 0.4986 - val_accuracy: 0.8371 - val_loss: 0.3640 - learning_rate: 0.0026\n",
            "Epoch 22/36\n",
            "\u001b[1m67/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7093 - loss: 0.4933\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00075283437415724.\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.36109\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7094 - loss: 0.4930 - val_accuracy: 0.8481 - val_loss: 0.3648 - learning_rate: 0.0026\n",
            "Epoch 23/36\n",
            "\u001b[1m65/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7055 - loss: 0.4946\n",
            "Epoch 23: val_loss did not improve from 0.36109\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7063 - loss: 0.4938 - val_accuracy: 0.7932 - val_loss: 0.4133 - learning_rate: 7.5283e-04\n",
            "Epoch 24/36\n",
            "\u001b[1m65/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7155 - loss: 0.4906\n",
            "Epoch 24: val_loss did not improve from 0.36109\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7161 - loss: 0.4900 - val_accuracy: 0.8101 - val_loss: 0.3851 - learning_rate: 7.5283e-04\n",
            "Epoch 24: early stopping\n",
            "Restoring model weights from the end of the best epoch: 19.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:13:35,371] Trial 5 finished with value: -0.3610948622226715 and parameters: {'epochs': 36, 'batch_size': 64, 'learning_rate': 0.00928100665387011, 'stop_patience': 5, 'reduce_lr_factor': 0.2848079995284004, 'reduce_lr_patience': 3}. Best is trial 2 with value: -0.3317584991455078.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5549 - loss: 0.6885\n",
            "Epoch 1: val_loss improved from inf to 0.67750, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5552 - loss: 0.6883 - val_accuracy: 0.5629 - val_loss: 0.6775 - learning_rate: 0.0012\n",
            "Epoch 2/25\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6235 - loss: 0.6387\n",
            "Epoch 2: val_loss improved from 0.67750 to 0.55844, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6241 - loss: 0.6381 - val_accuracy: 0.7038 - val_loss: 0.5584 - learning_rate: 0.0012\n",
            "Epoch 3/25\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6739 - loss: 0.5679\n",
            "Epoch 3: val_loss improved from 0.55844 to 0.55734, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6741 - loss: 0.5677 - val_accuracy: 0.7392 - val_loss: 0.5573 - learning_rate: 0.0012\n",
            "Epoch 4/25\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6985 - loss: 0.5366\n",
            "Epoch 4: val_loss improved from 0.55734 to 0.37537, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6987 - loss: 0.5365 - val_accuracy: 0.8312 - val_loss: 0.3754 - learning_rate: 0.0012\n",
            "Epoch 5/25\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7122 - loss: 0.5174\n",
            "Epoch 5: val_loss did not improve from 0.37537\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7127 - loss: 0.5171 - val_accuracy: 0.7924 - val_loss: 0.4323 - learning_rate: 0.0012\n",
            "Epoch 6/25\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7351 - loss: 0.5071\n",
            "Epoch 6: val_loss improved from 0.37537 to 0.35454, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7353 - loss: 0.5066 - val_accuracy: 0.8329 - val_loss: 0.3545 - learning_rate: 0.0012\n",
            "Epoch 7/25\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7356 - loss: 0.4947\n",
            "Epoch 7: val_loss did not improve from 0.35454\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7360 - loss: 0.4944 - val_accuracy: 0.8059 - val_loss: 0.4414 - learning_rate: 0.0012\n",
            "Epoch 8/25\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7454 - loss: 0.4782\n",
            "Epoch 8: val_loss did not improve from 0.35454\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7455 - loss: 0.4781 - val_accuracy: 0.8397 - val_loss: 0.3679 - learning_rate: 0.0012\n",
            "Epoch 9/25\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7524 - loss: 0.4776\n",
            "Epoch 9: val_loss improved from 0.35454 to 0.34198, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7525 - loss: 0.4774 - val_accuracy: 0.8549 - val_loss: 0.3420 - learning_rate: 0.0012\n",
            "Epoch 10/25\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7536 - loss: 0.4756\n",
            "Epoch 10: val_loss did not improve from 0.34198\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7541 - loss: 0.4748 - val_accuracy: 0.8532 - val_loss: 0.3447 - learning_rate: 0.0012\n",
            "Epoch 11/25\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7527 - loss: 0.4600\n",
            "Epoch 11: val_loss did not improve from 0.34198\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7530 - loss: 0.4598 - val_accuracy: 0.8422 - val_loss: 0.3651 - learning_rate: 0.0012\n",
            "Epoch 12/25\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7702 - loss: 0.4489\n",
            "Epoch 12: val_loss improved from 0.34198 to 0.34142, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7706 - loss: 0.4483 - val_accuracy: 0.8532 - val_loss: 0.3414 - learning_rate: 0.0012\n",
            "Epoch 13/25\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7668 - loss: 0.4478\n",
            "Epoch 13: val_loss improved from 0.34142 to 0.33841, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4475 - val_accuracy: 0.8540 - val_loss: 0.3384 - learning_rate: 0.0012\n",
            "Epoch 14/25\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7699 - loss: 0.4402\n",
            "Epoch 14: val_loss did not improve from 0.33841\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7702 - loss: 0.4401 - val_accuracy: 0.8498 - val_loss: 0.3409 - learning_rate: 0.0012\n",
            "Epoch 15/25\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7757 - loss: 0.4346\n",
            "Epoch 15: val_loss did not improve from 0.33841\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7758 - loss: 0.4345 - val_accuracy: 0.8540 - val_loss: 0.3421 - learning_rate: 0.0012\n",
            "Epoch 16/25\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7847 - loss: 0.4281\n",
            "Epoch 16: val_loss did not improve from 0.33841\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7848 - loss: 0.4279 - val_accuracy: 0.8515 - val_loss: 0.3414 - learning_rate: 0.0012\n",
            "Epoch 17/25\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7744 - loss: 0.4445\n",
            "Epoch 17: val_loss improved from 0.33841 to 0.33161, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7748 - loss: 0.4434 - val_accuracy: 0.8565 - val_loss: 0.3316 - learning_rate: 0.0012\n",
            "Epoch 18/25\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7819 - loss: 0.4234\n",
            "Epoch 18: val_loss did not improve from 0.33161\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7822 - loss: 0.4232 - val_accuracy: 0.8388 - val_loss: 0.3394 - learning_rate: 0.0012\n",
            "Epoch 19/25\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7855 - loss: 0.4230\n",
            "Epoch 19: val_loss did not improve from 0.33161\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7856 - loss: 0.4230 - val_accuracy: 0.8464 - val_loss: 0.3504 - learning_rate: 0.0012\n",
            "Epoch 20/25\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.4201\n",
            "Epoch 20: val_loss improved from 0.33161 to 0.31466, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7888 - loss: 0.4195 - val_accuracy: 0.8489 - val_loss: 0.3147 - learning_rate: 0.0012\n",
            "Epoch 21/25\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7944 - loss: 0.4058\n",
            "Epoch 21: val_loss did not improve from 0.31466\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7946 - loss: 0.4055 - val_accuracy: 0.8354 - val_loss: 0.3792 - learning_rate: 0.0012\n",
            "Epoch 22/25\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7989 - loss: 0.4079\n",
            "Epoch 22: val_loss did not improve from 0.31466\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7990 - loss: 0.4078 - val_accuracy: 0.8439 - val_loss: 0.3602 - learning_rate: 0.0012\n",
            "Epoch 23/25\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7933 - loss: 0.4105\n",
            "Epoch 23: val_loss did not improve from 0.31466\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7936 - loss: 0.4101 - val_accuracy: 0.8236 - val_loss: 0.3716 - learning_rate: 0.0012\n",
            "Epoch 24/25\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7983 - loss: 0.4059\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002345739381289262.\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.31466\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.4054 - val_accuracy: 0.8084 - val_loss: 0.4437 - learning_rate: 0.0012\n",
            "Epoch 25/25\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8177 - loss: 0.3690\n",
            "Epoch 25: val_loss did not improve from 0.31466\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8178 - loss: 0.3689 - val_accuracy: 0.8422 - val_loss: 0.3396 - learning_rate: 2.3457e-04\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:14:22,116] Trial 6 finished with value: -0.3146595358848572 and parameters: {'epochs': 25, 'batch_size': 16, 'learning_rate': 0.0011531042128168033, 'stop_patience': 7, 'reduce_lr_factor': 0.20342821574718967, 'reduce_lr_patience': 4}. Best is trial 6 with value: -0.3146595358848572.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/36\n",
            "\u001b[1m134/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5365 - loss: 0.6935\n",
            "Epoch 1: val_loss improved from inf to 0.68172, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5375 - loss: 0.6932 - val_accuracy: 0.5814 - val_loss: 0.6817 - learning_rate: 0.0088\n",
            "Epoch 2/36\n",
            "\u001b[1m135/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5412 - loss: 0.6871\n",
            "Epoch 2: val_loss improved from 0.68172 to 0.63618, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5419 - loss: 0.6869 - val_accuracy: 0.6903 - val_loss: 0.6362 - learning_rate: 0.0088\n",
            "Epoch 3/36\n",
            "\u001b[1m145/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5767 - loss: 0.6585\n",
            "Epoch 3: val_loss did not improve from 0.63618\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5775 - loss: 0.6578 - val_accuracy: 0.6684 - val_loss: 0.7789 - learning_rate: 0.0088\n",
            "Epoch 4/36\n",
            "\u001b[1m141/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6510 - loss: 0.5838\n",
            "Epoch 4: val_loss improved from 0.63618 to 0.45666, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6515 - loss: 0.5837 - val_accuracy: 0.8118 - val_loss: 0.4567 - learning_rate: 0.0088\n",
            "Epoch 5/36\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6638 - loss: 0.5734\n",
            "Epoch 5: val_loss improved from 0.45666 to 0.44364, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6642 - loss: 0.5729 - val_accuracy: 0.8169 - val_loss: 0.4436 - learning_rate: 0.0088\n",
            "Epoch 6/36\n",
            "\u001b[1m138/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6634 - loss: 0.5530\n",
            "Epoch 6: val_loss did not improve from 0.44364\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6643 - loss: 0.5532 - val_accuracy: 0.7646 - val_loss: 0.4676 - learning_rate: 0.0088\n",
            "Epoch 7/36\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6754 - loss: 0.5579\n",
            "Epoch 7: val_loss improved from 0.44364 to 0.42527, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6756 - loss: 0.5574 - val_accuracy: 0.8245 - val_loss: 0.4253 - learning_rate: 0.0088\n",
            "Epoch 8/36\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6889 - loss: 0.5378\n",
            "Epoch 8: val_loss did not improve from 0.42527\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6892 - loss: 0.5374 - val_accuracy: 0.8262 - val_loss: 0.5244 - learning_rate: 0.0088\n",
            "Epoch 9/36\n",
            "\u001b[1m145/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6796 - loss: 0.5429\n",
            "Epoch 9: val_loss did not improve from 0.42527\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6799 - loss: 0.5425 - val_accuracy: 0.7907 - val_loss: 0.6039 - learning_rate: 0.0088\n",
            "Epoch 10/36\n",
            "\u001b[1m141/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6767 - loss: 0.5432\n",
            "Epoch 10: val_loss did not improve from 0.42527\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6773 - loss: 0.5425 - val_accuracy: 0.8287 - val_loss: 0.4418 - learning_rate: 0.0088\n",
            "Epoch 11/36\n",
            "\u001b[1m147/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6873 - loss: 0.5353\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0025168630197685386.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.42527\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6873 - loss: 0.5352 - val_accuracy: 0.7975 - val_loss: 0.5179 - learning_rate: 0.0088\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:14:36,889] Trial 7 finished with value: -0.4252716302871704 and parameters: {'epochs': 36, 'batch_size': 32, 'learning_rate': 0.00876288610319252, 'stop_patience': 4, 'reduce_lr_factor': 0.28721851140174737, 'reduce_lr_patience': 4}. Best is trial 6 with value: -0.3146595358848572.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5406 - loss: 0.6933\n",
            "Epoch 1: val_loss improved from inf to 0.67937, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5412 - loss: 0.6930 - val_accuracy: 0.6110 - val_loss: 0.6794 - learning_rate: 0.0039\n",
            "Epoch 2/40\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6110 - loss: 0.6531\n",
            "Epoch 2: val_loss improved from 0.67937 to 0.66935, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6118 - loss: 0.6521 - val_accuracy: 0.5806 - val_loss: 0.6693 - learning_rate: 0.0039\n",
            "Epoch 3/40\n",
            "\u001b[1m146/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6222 - loss: 0.6081\n",
            "Epoch 3: val_loss did not improve from 0.66935\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6226 - loss: 0.6078 - val_accuracy: 0.6532 - val_loss: 0.6758 - learning_rate: 0.0039\n",
            "Epoch 4/40\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6758 - loss: 0.5787\n",
            "Epoch 4: val_loss did not improve from 0.66935\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6765 - loss: 0.5778 - val_accuracy: 0.5688 - val_loss: 0.9530 - learning_rate: 0.0039\n",
            "Epoch 5/40\n",
            "\u001b[1m147/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6852 - loss: 0.5488\n",
            "Epoch 5: val_loss improved from 0.66935 to 0.42637, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6854 - loss: 0.5486 - val_accuracy: 0.8143 - val_loss: 0.4264 - learning_rate: 0.0039\n",
            "Epoch 6/40\n",
            "\u001b[1m134/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6708 - loss: 0.5612\n",
            "Epoch 6: val_loss did not improve from 0.42637\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6738 - loss: 0.5584 - val_accuracy: 0.7274 - val_loss: 0.8604 - learning_rate: 0.0039\n",
            "Epoch 7/40\n",
            "\u001b[1m137/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7185 - loss: 0.5036\n",
            "Epoch 7: val_loss did not improve from 0.42637\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7192 - loss: 0.5033 - val_accuracy: 0.6219 - val_loss: 1.5122 - learning_rate: 0.0039\n",
            "Epoch 8/40\n",
            "\u001b[1m135/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7303 - loss: 0.5231\n",
            "Epoch 8: val_loss improved from 0.42637 to 0.35904, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7301 - loss: 0.5219 - val_accuracy: 0.8515 - val_loss: 0.3590 - learning_rate: 0.0039\n",
            "Epoch 9/40\n",
            "\u001b[1m141/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7225 - loss: 0.4946\n",
            "Epoch 9: val_loss did not improve from 0.35904\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7227 - loss: 0.4947 - val_accuracy: 0.7519 - val_loss: 0.5955 - learning_rate: 0.0039\n",
            "Epoch 10/40\n",
            "\u001b[1m138/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7387 - loss: 0.4908\n",
            "Epoch 10: val_loss did not improve from 0.35904\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7394 - loss: 0.4899 - val_accuracy: 0.6101 - val_loss: 1.3226 - learning_rate: 0.0039\n",
            "Epoch 11/40\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7426 - loss: 0.4614\n",
            "Epoch 11: val_loss did not improve from 0.35904\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7430 - loss: 0.4614 - val_accuracy: 0.7013 - val_loss: 0.7882 - learning_rate: 0.0039\n",
            "Epoch 12/40\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7250 - loss: 0.4740\n",
            "Epoch 12: val_loss did not improve from 0.35904\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7256 - loss: 0.4737 - val_accuracy: 0.6169 - val_loss: 1.0214 - learning_rate: 0.0039\n",
            "Epoch 13/40\n",
            "\u001b[1m136/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7443 - loss: 0.4677\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.000996467912108425.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.35904\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7444 - loss: 0.4679 - val_accuracy: 0.7376 - val_loss: 0.5403 - learning_rate: 0.0039\n",
            "Epoch 14/40\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.4309\n",
            "Epoch 14: val_loss did not improve from 0.35904\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7763 - loss: 0.4302 - val_accuracy: 0.7865 - val_loss: 0.4605 - learning_rate: 9.9647e-04\n",
            "Epoch 15/40\n",
            "\u001b[1m146/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8000 - loss: 0.4182\n",
            "Epoch 15: val_loss did not improve from 0.35904\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8001 - loss: 0.4180 - val_accuracy: 0.8498 - val_loss: 0.3609 - learning_rate: 9.9647e-04\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:14:57,716] Trial 8 finished with value: -0.35904166102409363 and parameters: {'epochs': 40, 'batch_size': 32, 'learning_rate': 0.003932487731588975, 'stop_patience': 7, 'reduce_lr_factor': 0.25339377815478004, 'reduce_lr_patience': 5}. Best is trial 6 with value: -0.3146595358848572.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/11\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5415 - loss: 0.6927\n",
            "Epoch 1: val_loss improved from inf to 0.68056, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5415 - loss: 0.6927 - val_accuracy: 0.5814 - val_loss: 0.6806 - learning_rate: 0.0061\n",
            "Epoch 2/11\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5473 - loss: 0.6898\n",
            "Epoch 2: val_loss improved from 0.68056 to 0.67772, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5474 - loss: 0.6898 - val_accuracy: 0.5814 - val_loss: 0.6777 - learning_rate: 0.0061\n",
            "Epoch 3/11\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5486 - loss: 0.6889\n",
            "Epoch 3: val_loss did not improve from 0.67772\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5487 - loss: 0.6889 - val_accuracy: 0.4608 - val_loss: 0.7009 - learning_rate: 0.0061\n",
            "Epoch 4/11\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5499 - loss: 0.6847\n",
            "Epoch 4: val_loss did not improve from 0.67772\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5506 - loss: 0.6843 - val_accuracy: 0.4759 - val_loss: 0.8108 - learning_rate: 0.0061\n",
            "Epoch 5/11\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6249 - loss: 0.6328\n",
            "Epoch 5: val_loss improved from 0.67772 to 0.47220, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6251 - loss: 0.6327 - val_accuracy: 0.7696 - val_loss: 0.4722 - learning_rate: 0.0061\n",
            "Epoch 6/11\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6783 - loss: 0.5650\n",
            "Epoch 6: val_loss improved from 0.47220 to 0.41748, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6788 - loss: 0.5646 - val_accuracy: 0.8203 - val_loss: 0.4175 - learning_rate: 0.0061\n",
            "Epoch 7/11\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6843 - loss: 0.5542\n",
            "Epoch 7: val_loss did not improve from 0.41748\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6845 - loss: 0.5540 - val_accuracy: 0.7612 - val_loss: 0.5368 - learning_rate: 0.0061\n",
            "Epoch 8/11\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7014 - loss: 0.5425\n",
            "Epoch 8: val_loss did not improve from 0.41748\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7014 - loss: 0.5423 - val_accuracy: 0.8152 - val_loss: 0.4275 - learning_rate: 0.0061\n",
            "Epoch 9/11\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7097 - loss: 0.5287\n",
            "Epoch 9: val_loss did not improve from 0.41748\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7098 - loss: 0.5285 - val_accuracy: 0.6869 - val_loss: 0.5830 - learning_rate: 0.0061\n",
            "Epoch 10/11\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7163 - loss: 0.5166\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0017047385671629552.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.41748\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7165 - loss: 0.5165 - val_accuracy: 0.7367 - val_loss: 0.6140 - learning_rate: 0.0061\n",
            "Epoch 11/11\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7319 - loss: 0.4956\n",
            "Epoch 11: val_loss did not improve from 0.41748\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7319 - loss: 0.4956 - val_accuracy: 0.8051 - val_loss: 0.4370 - learning_rate: 0.0017\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:15:22,368] Trial 9 finished with value: -0.41748377680778503 and parameters: {'epochs': 11, 'batch_size': 16, 'learning_rate': 0.006129626235579851, 'stop_patience': 9, 'reduce_lr_factor': 0.2781146053274137, 'reduce_lr_patience': 4}. Best is trial 6 with value: -0.3146595358848572.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m67/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5480 - loss: 0.6896\n",
            "Epoch 1: val_loss improved from inf to 0.66986, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5496 - loss: 0.6891 - val_accuracy: 0.5367 - val_loss: 0.6699 - learning_rate: 6.2368e-04\n",
            "Epoch 2/25\n",
            "\u001b[1m67/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5817 - loss: 0.6691\n",
            "Epoch 2: val_loss improved from 0.66986 to 0.50698, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5829 - loss: 0.6680 - val_accuracy: 0.7764 - val_loss: 0.5070 - learning_rate: 6.2368e-04\n",
            "Epoch 3/25\n",
            "\u001b[1m65/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6481 - loss: 0.6296\n",
            "Epoch 3: val_loss improved from 0.50698 to 0.42589, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6492 - loss: 0.6273 - val_accuracy: 0.8000 - val_loss: 0.4259 - learning_rate: 6.2368e-04\n",
            "Epoch 4/25\n",
            "\u001b[1m65/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6712 - loss: 0.5741\n",
            "Epoch 4: val_loss improved from 0.42589 to 0.38739, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6726 - loss: 0.5725 - val_accuracy: 0.8321 - val_loss: 0.3874 - learning_rate: 6.2368e-04\n",
            "Epoch 5/25\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6978 - loss: 0.5479\n",
            "Epoch 5: val_loss did not improve from 0.38739\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6981 - loss: 0.5471 - val_accuracy: 0.8017 - val_loss: 0.4581 - learning_rate: 6.2368e-04\n",
            "Epoch 6/25\n",
            "\u001b[1m69/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7120 - loss: 0.5328\n",
            "Epoch 6: val_loss improved from 0.38739 to 0.38715, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7124 - loss: 0.5320 - val_accuracy: 0.8405 - val_loss: 0.3871 - learning_rate: 6.2368e-04\n",
            "Epoch 7/25\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7060 - loss: 0.5166\n",
            "Epoch 7: val_loss did not improve from 0.38715\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7063 - loss: 0.5165 - val_accuracy: 0.8228 - val_loss: 0.4156 - learning_rate: 6.2368e-04\n",
            "Epoch 8/25\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7291 - loss: 0.5063\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.322020552613926e-05.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.38715\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7293 - loss: 0.5058 - val_accuracy: 0.8211 - val_loss: 0.4028 - learning_rate: 6.2368e-04\n",
            "Epoch 9/25\n",
            "\u001b[1m67/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7490 - loss: 0.4819\n",
            "Epoch 9: val_loss did not improve from 0.38715\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7510 - loss: 0.4802 - val_accuracy: 0.7941 - val_loss: 0.4357 - learning_rate: 9.3220e-05\n",
            "Epoch 10/25\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7658 - loss: 0.4692\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.393345039832051e-05.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.38715\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7661 - loss: 0.4689 - val_accuracy: 0.8059 - val_loss: 0.4125 - learning_rate: 9.3220e-05\n",
            "Epoch 11/25\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7885 - loss: 0.4594\n",
            "Epoch 11: val_loss did not improve from 0.38715\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7885 - loss: 0.4592 - val_accuracy: 0.7890 - val_loss: 0.4368 - learning_rate: 1.3933e-05\n",
            "Epoch 12/25\n",
            "\u001b[1m65/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7772 - loss: 0.4576\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.0826069818018e-06.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.38715\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7787 - loss: 0.4563 - val_accuracy: 0.7823 - val_loss: 0.4561 - learning_rate: 1.3933e-05\n",
            "Epoch 13/25\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7815 - loss: 0.4569\n",
            "Epoch 13: val_loss did not improve from 0.38715\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7815 - loss: 0.4568 - val_accuracy: 0.7823 - val_loss: 0.4571 - learning_rate: 2.0826e-06\n",
            "Epoch 14/25\n",
            "\u001b[1m67/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7780 - loss: 0.4597\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.38715\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7788 - loss: 0.4587 - val_accuracy: 0.7823 - val_loss: 0.4567 - learning_rate: 2.0826e-06\n",
            "Epoch 15/25\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7849 - loss: 0.4601\n",
            "Epoch 15: val_loss did not improve from 0.38715\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7850 - loss: 0.4598 - val_accuracy: 0.7840 - val_loss: 0.4547 - learning_rate: 1.0000e-06\n",
            "Epoch 16/25\n",
            "\u001b[1m66/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7809 - loss: 0.4594\n",
            "Epoch 16: val_loss did not improve from 0.38715\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7823 - loss: 0.4580 - val_accuracy: 0.7831 - val_loss: 0.4558 - learning_rate: 1.0000e-06\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:15:35,321] Trial 10 finished with value: -0.38714686036109924 and parameters: {'epochs': 25, 'batch_size': 64, 'learning_rate': 0.0006236794187461012, 'stop_patience': 10, 'reduce_lr_factor': 0.14946814215351428, 'reduce_lr_patience': 2}. Best is trial 6 with value: -0.3146595358848572.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/24\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5530 - loss: 0.6919\n",
            "Epoch 1: val_loss improved from inf to 0.80121, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5534 - loss: 0.6917 - val_accuracy: 0.4582 - val_loss: 0.8012 - learning_rate: 0.0027\n",
            "Epoch 2/24\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5809 - loss: 0.6719\n",
            "Epoch 2: val_loss improved from 0.80121 to 0.59234, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5815 - loss: 0.6714 - val_accuracy: 0.6481 - val_loss: 0.5923 - learning_rate: 0.0027\n",
            "Epoch 3/24\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6315 - loss: 0.6139\n",
            "Epoch 3: val_loss improved from 0.59234 to 0.41732, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6320 - loss: 0.6137 - val_accuracy: 0.8219 - val_loss: 0.4173 - learning_rate: 0.0027\n",
            "Epoch 4/24\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6798 - loss: 0.5691\n",
            "Epoch 4: val_loss improved from 0.41732 to 0.37254, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6802 - loss: 0.5686 - val_accuracy: 0.8414 - val_loss: 0.3725 - learning_rate: 0.0027\n",
            "Epoch 5/24\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7033 - loss: 0.5398\n",
            "Epoch 5: val_loss did not improve from 0.37254\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7038 - loss: 0.5393 - val_accuracy: 0.7992 - val_loss: 0.4166 - learning_rate: 0.0027\n",
            "Epoch 6/24\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7073 - loss: 0.5225\n",
            "Epoch 6: val_loss did not improve from 0.37254\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7082 - loss: 0.5220 - val_accuracy: 0.7755 - val_loss: 0.5593 - learning_rate: 0.0027\n",
            "Epoch 7/24\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7049 - loss: 0.5099\n",
            "Epoch 7: val_loss improved from 0.37254 to 0.35414, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7058 - loss: 0.5094 - val_accuracy: 0.8346 - val_loss: 0.3541 - learning_rate: 0.0027\n",
            "Epoch 8/24\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7084 - loss: 0.5076\n",
            "Epoch 8: val_loss improved from 0.35414 to 0.34827, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7089 - loss: 0.5074 - val_accuracy: 0.8473 - val_loss: 0.3483 - learning_rate: 0.0027\n",
            "Epoch 9/24\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7246 - loss: 0.4798\n",
            "Epoch 9: val_loss did not improve from 0.34827\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7247 - loss: 0.4797 - val_accuracy: 0.8346 - val_loss: 0.3662 - learning_rate: 0.0027\n",
            "Epoch 10/24\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7416 - loss: 0.4714\n",
            "Epoch 10: val_loss improved from 0.34827 to 0.34232, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7418 - loss: 0.4711 - val_accuracy: 0.8506 - val_loss: 0.3423 - learning_rate: 0.0027\n",
            "Epoch 11/24\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7480 - loss: 0.4593\n",
            "Epoch 11: val_loss did not improve from 0.34232\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7483 - loss: 0.4592 - val_accuracy: 0.8498 - val_loss: 0.3525 - learning_rate: 0.0027\n",
            "Epoch 12/24\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7480 - loss: 0.4589\n",
            "Epoch 12: val_loss did not improve from 0.34232\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7482 - loss: 0.4586 - val_accuracy: 0.8169 - val_loss: 0.4521 - learning_rate: 0.0027\n",
            "Epoch 13/24\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7474 - loss: 0.4602\n",
            "Epoch 13: val_loss did not improve from 0.34232\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7475 - loss: 0.4601 - val_accuracy: 0.7924 - val_loss: 0.5167 - learning_rate: 0.0027\n",
            "Epoch 14/24\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7617 - loss: 0.4493\n",
            "Epoch 14: val_loss did not improve from 0.34232\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7622 - loss: 0.4490 - val_accuracy: 0.8245 - val_loss: 0.4170 - learning_rate: 0.0027\n",
            "Epoch 15/24\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7589 - loss: 0.4445\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0004467624455627584.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.34232\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7591 - loss: 0.4444 - val_accuracy: 0.7772 - val_loss: 0.5828 - learning_rate: 0.0027\n",
            "Epoch 16/24\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8081 - loss: 0.4008\n",
            "Epoch 16: val_loss improved from 0.34232 to 0.32943, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.4007 - val_accuracy: 0.8498 - val_loss: 0.3294 - learning_rate: 4.4676e-04\n",
            "Epoch 17/24\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.3746\n",
            "Epoch 17: val_loss improved from 0.32943 to 0.31898, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8310 - loss: 0.3741 - val_accuracy: 0.8565 - val_loss: 0.3190 - learning_rate: 4.4676e-04\n",
            "Epoch 18/24\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8360 - loss: 0.3556\n",
            "Epoch 18: val_loss did not improve from 0.31898\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8363 - loss: 0.3552 - val_accuracy: 0.8388 - val_loss: 0.3619 - learning_rate: 4.4676e-04\n",
            "Epoch 19/24\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.3485\n",
            "Epoch 19: val_loss did not improve from 0.31898\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8410 - loss: 0.3483 - val_accuracy: 0.8464 - val_loss: 0.3496 - learning_rate: 4.4676e-04\n",
            "Epoch 20/24\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8449 - loss: 0.3444\n",
            "Epoch 20: val_loss did not improve from 0.31898\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8450 - loss: 0.3443 - val_accuracy: 0.8338 - val_loss: 0.3826 - learning_rate: 4.4676e-04\n",
            "Epoch 21/24\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8475 - loss: 0.3385\n",
            "Epoch 21: val_loss did not improve from 0.31898\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8476 - loss: 0.3383 - val_accuracy: 0.8489 - val_loss: 0.3337 - learning_rate: 4.4676e-04\n",
            "Epoch 22/24\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8502 - loss: 0.3285\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 7.338966600280759e-05.\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.31898\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8503 - loss: 0.3283 - val_accuracy: 0.8464 - val_loss: 0.3394 - learning_rate: 4.4676e-04\n",
            "Epoch 23/24\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8610 - loss: 0.3135\n",
            "Epoch 23: val_loss did not improve from 0.31898\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8611 - loss: 0.3131 - val_accuracy: 0.8017 - val_loss: 0.4904 - learning_rate: 7.3390e-05\n",
            "Epoch 24/24\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8674 - loss: 0.3057\n",
            "Epoch 24: val_loss did not improve from 0.31898\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8675 - loss: 0.3055 - val_accuracy: 0.8051 - val_loss: 0.4800 - learning_rate: 7.3390e-05\n",
            "Restoring model weights from the end of the best epoch: 17.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:16:23,088] Trial 11 finished with value: -0.31898051500320435 and parameters: {'epochs': 24, 'batch_size': 16, 'learning_rate': 0.002719683792365846, 'stop_patience': 8, 'reduce_lr_factor': 0.1642699951599007, 'reduce_lr_patience': 5}. Best is trial 6 with value: -0.3146595358848572.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/22\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5448 - loss: 0.6890\n",
            "Epoch 1: val_loss improved from inf to 0.69380, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5452 - loss: 0.6889 - val_accuracy: 0.5072 - val_loss: 0.6938 - learning_rate: 0.0024\n",
            "Epoch 2/22\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5751 - loss: 0.6720\n",
            "Epoch 2: val_loss did not improve from 0.69380\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5758 - loss: 0.6715 - val_accuracy: 0.5148 - val_loss: 0.6953 - learning_rate: 0.0024\n",
            "Epoch 3/22\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6543 - loss: 0.6045\n",
            "Epoch 3: val_loss did not improve from 0.69380\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6545 - loss: 0.6040 - val_accuracy: 0.5907 - val_loss: 0.7882 - learning_rate: 0.0024\n",
            "Epoch 4/22\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7013 - loss: 0.5594\n",
            "Epoch 4: val_loss improved from 0.69380 to 0.37929, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7014 - loss: 0.5586 - val_accuracy: 0.8346 - val_loss: 0.3793 - learning_rate: 0.0024\n",
            "Epoch 5/22\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7196 - loss: 0.5131\n",
            "Epoch 5: val_loss did not improve from 0.37929\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7196 - loss: 0.5131 - val_accuracy: 0.6582 - val_loss: 0.7286 - learning_rate: 0.0024\n",
            "Epoch 6/22\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7226 - loss: 0.5108\n",
            "Epoch 6: val_loss improved from 0.37929 to 0.34309, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7227 - loss: 0.5107 - val_accuracy: 0.8489 - val_loss: 0.3431 - learning_rate: 0.0024\n",
            "Epoch 7/22\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7233 - loss: 0.4996\n",
            "Epoch 7: val_loss did not improve from 0.34309\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7235 - loss: 0.4995 - val_accuracy: 0.8312 - val_loss: 0.3670 - learning_rate: 0.0024\n",
            "Epoch 8/22\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7381 - loss: 0.4867\n",
            "Epoch 8: val_loss improved from 0.34309 to 0.34084, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7384 - loss: 0.4864 - val_accuracy: 0.8439 - val_loss: 0.3408 - learning_rate: 0.0024\n",
            "Epoch 9/22\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7470 - loss: 0.4708\n",
            "Epoch 9: val_loss improved from 0.34084 to 0.32147, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7472 - loss: 0.4705 - val_accuracy: 0.8667 - val_loss: 0.3215 - learning_rate: 0.0024\n",
            "Epoch 10/22\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7376 - loss: 0.4779\n",
            "Epoch 10: val_loss did not improve from 0.32147\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7383 - loss: 0.4771 - val_accuracy: 0.8211 - val_loss: 0.4113 - learning_rate: 0.0024\n",
            "Epoch 11/22\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7509 - loss: 0.4596\n",
            "Epoch 11: val_loss did not improve from 0.32147\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7511 - loss: 0.4590 - val_accuracy: 0.8447 - val_loss: 0.3360 - learning_rate: 0.0024\n",
            "Epoch 12/22\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7526 - loss: 0.4598\n",
            "Epoch 12: val_loss did not improve from 0.32147\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7531 - loss: 0.4593 - val_accuracy: 0.8295 - val_loss: 0.4065 - learning_rate: 0.0024\n",
            "Epoch 13/22\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7563 - loss: 0.4535\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0003473559696450484.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.32147\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7567 - loss: 0.4532 - val_accuracy: 0.8397 - val_loss: 0.3561 - learning_rate: 0.0024\n",
            "Epoch 14/22\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8021 - loss: 0.4131\n",
            "Epoch 14: val_loss did not improve from 0.32147\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8023 - loss: 0.4129 - val_accuracy: 0.8295 - val_loss: 0.4083 - learning_rate: 3.4736e-04\n",
            "Epoch 15/22\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8171 - loss: 0.3861\n",
            "Epoch 15: val_loss did not improve from 0.32147\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8171 - loss: 0.3859 - val_accuracy: 0.8177 - val_loss: 0.4148 - learning_rate: 3.4736e-04\n",
            "Epoch 16/22\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.3712\n",
            "Epoch 16: val_loss did not improve from 0.32147\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8286 - loss: 0.3710 - val_accuracy: 0.8439 - val_loss: 0.3612 - learning_rate: 3.4736e-04\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:16:56,097] Trial 12 finished with value: -0.3214709460735321 and parameters: {'epochs': 22, 'batch_size': 16, 'learning_rate': 0.0023993585829373476, 'stop_patience': 7, 'reduce_lr_factor': 0.14477033993683475, 'reduce_lr_patience': 4}. Best is trial 6 with value: -0.3146595358848572.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5439 - loss: 0.6890\n",
            "Epoch 1: val_loss improved from inf to 0.57125, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5449 - loss: 0.6887 - val_accuracy: 0.8194 - val_loss: 0.5712 - learning_rate: 5.0003e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6136 - loss: 0.6544\n",
            "Epoch 2: val_loss improved from 0.57125 to 0.56228, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6136 - loss: 0.6544 - val_accuracy: 0.7072 - val_loss: 0.5623 - learning_rate: 5.0003e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6708 - loss: 0.5864\n",
            "Epoch 3: val_loss did not improve from 0.56228\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6709 - loss: 0.5863 - val_accuracy: 0.6422 - val_loss: 0.8821 - learning_rate: 5.0003e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6966 - loss: 0.5470\n",
            "Epoch 4: val_loss improved from 0.56228 to 0.47708, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6970 - loss: 0.5466 - val_accuracy: 0.7823 - val_loss: 0.4771 - learning_rate: 5.0003e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7051 - loss: 0.5255\n",
            "Epoch 5: val_loss did not improve from 0.47708\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7055 - loss: 0.5253 - val_accuracy: 0.7865 - val_loss: 0.4806 - learning_rate: 5.0003e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7186 - loss: 0.5046\n",
            "Epoch 6: val_loss improved from 0.47708 to 0.34760, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7187 - loss: 0.5046 - val_accuracy: 0.8447 - val_loss: 0.3476 - learning_rate: 5.0003e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7349 - loss: 0.4902\n",
            "Epoch 7: val_loss did not improve from 0.34760\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7350 - loss: 0.4901 - val_accuracy: 0.8203 - val_loss: 0.3966 - learning_rate: 5.0003e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7386 - loss: 0.4822\n",
            "Epoch 8: val_loss did not improve from 0.34760\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7391 - loss: 0.4818 - val_accuracy: 0.7806 - val_loss: 0.5036 - learning_rate: 5.0003e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7587 - loss: 0.4691\n",
            "Epoch 9: val_loss did not improve from 0.34760\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7588 - loss: 0.4689 - val_accuracy: 0.8464 - val_loss: 0.3504 - learning_rate: 5.0003e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7578 - loss: 0.4575\n",
            "Epoch 10: val_loss did not improve from 0.34760\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7579 - loss: 0.4574 - val_accuracy: 0.8143 - val_loss: 0.4088 - learning_rate: 5.0003e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7562 - loss: 0.4631\n",
            "Epoch 11: val_loss improved from 0.34760 to 0.31891, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7564 - loss: 0.4629 - val_accuracy: 0.8675 - val_loss: 0.3189 - learning_rate: 5.0003e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7661 - loss: 0.4542\n",
            "Epoch 12: val_loss did not improve from 0.31891\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7668 - loss: 0.4536 - val_accuracy: 0.8177 - val_loss: 0.3946 - learning_rate: 5.0003e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7804 - loss: 0.4489\n",
            "Epoch 13: val_loss did not improve from 0.31891\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7806 - loss: 0.4485 - val_accuracy: 0.8582 - val_loss: 0.3195 - learning_rate: 5.0003e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.4388\n",
            "Epoch 14: val_loss did not improve from 0.31891\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7744 - loss: 0.4386 - val_accuracy: 0.8540 - val_loss: 0.3331 - learning_rate: 5.0003e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7809 - loss: 0.4340\n",
            "Epoch 15: val_loss did not improve from 0.31891\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7817 - loss: 0.4334 - val_accuracy: 0.8540 - val_loss: 0.3303 - learning_rate: 5.0003e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7841 - loss: 0.4344\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.726929006610021e-05.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.31891\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7842 - loss: 0.4343 - val_accuracy: 0.8506 - val_loss: 0.3357 - learning_rate: 5.0003e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.4081\n",
            "Epoch 17: val_loss did not improve from 0.31891\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.4075 - val_accuracy: 0.8152 - val_loss: 0.3805 - learning_rate: 9.7269e-05\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:17:30,301] Trial 13 finished with value: -0.3189051151275635 and parameters: {'epochs': 30, 'batch_size': 16, 'learning_rate': 0.0005000309569960677, 'stop_patience': 6, 'reduce_lr_factor': 0.19452654593547689, 'reduce_lr_patience': 5}. Best is trial 6 with value: -0.3146595358848572.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/31\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5038 - loss: 0.6938\n",
            "Epoch 1: val_loss improved from inf to 0.69018, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5045 - loss: 0.6938 - val_accuracy: 0.5949 - val_loss: 0.6902 - learning_rate: 2.5694e-05\n",
            "Epoch 2/31\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5686 - loss: 0.6906\n",
            "Epoch 2: val_loss did not improve from 0.69018\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5685 - loss: 0.6905 - val_accuracy: 0.4329 - val_loss: 0.6914 - learning_rate: 2.5694e-05\n",
            "Epoch 3/31\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5649 - loss: 0.6879\n",
            "Epoch 3: val_loss did not improve from 0.69018\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5649 - loss: 0.6879 - val_accuracy: 0.4287 - val_loss: 0.6931 - learning_rate: 2.5694e-05\n",
            "Epoch 4/31\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5729 - loss: 0.6869\n",
            "Epoch 4: val_loss did not improve from 0.69018\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5732 - loss: 0.6869 - val_accuracy: 0.4346 - val_loss: 0.6922 - learning_rate: 2.5694e-05\n",
            "Epoch 5/31\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5756 - loss: 0.6853\n",
            "Epoch 5: val_loss improved from 0.69018 to 0.68705, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5758 - loss: 0.6853 - val_accuracy: 0.4506 - val_loss: 0.6871 - learning_rate: 2.5694e-05\n",
            "Epoch 6/31\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5805 - loss: 0.6822\n",
            "Epoch 6: val_loss did not improve from 0.68705\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5806 - loss: 0.6822 - val_accuracy: 0.4329 - val_loss: 0.6965 - learning_rate: 2.5694e-05\n",
            "Epoch 7/31\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5847 - loss: 0.6791\n",
            "Epoch 7: val_loss improved from 0.68705 to 0.68200, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5847 - loss: 0.6791 - val_accuracy: 0.4667 - val_loss: 0.6820 - learning_rate: 2.5694e-05\n",
            "Epoch 8/31\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5898 - loss: 0.6769\n",
            "Epoch 8: val_loss improved from 0.68200 to 0.67258, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5898 - loss: 0.6769 - val_accuracy: 0.4987 - val_loss: 0.6726 - learning_rate: 2.5694e-05\n",
            "Epoch 9/31\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5855 - loss: 0.6744\n",
            "Epoch 9: val_loss improved from 0.67258 to 0.67147, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5859 - loss: 0.6744 - val_accuracy: 0.4979 - val_loss: 0.6715 - learning_rate: 2.5694e-05\n",
            "Epoch 10/31\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5919 - loss: 0.6741\n",
            "Epoch 10: val_loss improved from 0.67147 to 0.66649, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5920 - loss: 0.6739 - val_accuracy: 0.5190 - val_loss: 0.6665 - learning_rate: 2.5694e-05\n",
            "Epoch 11/31\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5870 - loss: 0.6684\n",
            "Epoch 11: val_loss improved from 0.66649 to 0.63533, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5873 - loss: 0.6683 - val_accuracy: 0.6135 - val_loss: 0.6353 - learning_rate: 2.5694e-05\n",
            "Epoch 12/31\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5975 - loss: 0.6641\n",
            "Epoch 12: val_loss improved from 0.63533 to 0.63215, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5976 - loss: 0.6641 - val_accuracy: 0.6034 - val_loss: 0.6322 - learning_rate: 2.5694e-05\n",
            "Epoch 13/31\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5949 - loss: 0.6611\n",
            "Epoch 13: val_loss improved from 0.63215 to 0.61478, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5953 - loss: 0.6610 - val_accuracy: 0.6430 - val_loss: 0.6148 - learning_rate: 2.5694e-05\n",
            "Epoch 14/31\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6026 - loss: 0.6544\n",
            "Epoch 14: val_loss improved from 0.61478 to 0.59414, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6029 - loss: 0.6543 - val_accuracy: 0.6970 - val_loss: 0.5941 - learning_rate: 2.5694e-05\n",
            "Epoch 15/31\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6066 - loss: 0.6552\n",
            "Epoch 15: val_loss did not improve from 0.59414\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6068 - loss: 0.6551 - val_accuracy: 0.6549 - val_loss: 0.6012 - learning_rate: 2.5694e-05\n",
            "Epoch 16/31\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6153 - loss: 0.6492\n",
            "Epoch 16: val_loss improved from 0.59414 to 0.56569, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6154 - loss: 0.6491 - val_accuracy: 0.7443 - val_loss: 0.5657 - learning_rate: 2.5694e-05\n",
            "Epoch 17/31\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6221 - loss: 0.6431\n",
            "Epoch 17: val_loss improved from 0.56569 to 0.56527, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6221 - loss: 0.6430 - val_accuracy: 0.7249 - val_loss: 0.5653 - learning_rate: 2.5694e-05\n",
            "Epoch 18/31\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6269 - loss: 0.6377\n",
            "Epoch 18: val_loss did not improve from 0.56527\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6269 - loss: 0.6377 - val_accuracy: 0.6996 - val_loss: 0.5656 - learning_rate: 2.5694e-05\n",
            "Epoch 19/31\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6400 - loss: 0.6320\n",
            "Epoch 19: val_loss improved from 0.56527 to 0.55219, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6400 - loss: 0.6319 - val_accuracy: 0.7156 - val_loss: 0.5522 - learning_rate: 2.5694e-05\n",
            "Epoch 20/31\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6410 - loss: 0.6267\n",
            "Epoch 20: val_loss improved from 0.55219 to 0.54877, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6412 - loss: 0.6266 - val_accuracy: 0.7089 - val_loss: 0.5488 - learning_rate: 2.5694e-05\n",
            "Epoch 21/31\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6560 - loss: 0.6203\n",
            "Epoch 21: val_loss improved from 0.54877 to 0.54103, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6560 - loss: 0.6202 - val_accuracy: 0.7097 - val_loss: 0.5410 - learning_rate: 2.5694e-05\n",
            "Epoch 22/31\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6541 - loss: 0.6175\n",
            "Epoch 22: val_loss did not improve from 0.54103\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6544 - loss: 0.6173 - val_accuracy: 0.6599 - val_loss: 0.5794 - learning_rate: 2.5694e-05\n",
            "Epoch 23/31\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6630 - loss: 0.6119\n",
            "Epoch 23: val_loss improved from 0.54103 to 0.51666, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6633 - loss: 0.6117 - val_accuracy: 0.7384 - val_loss: 0.5167 - learning_rate: 2.5694e-05\n",
            "Epoch 24/31\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6773 - loss: 0.6070\n",
            "Epoch 24: val_loss did not improve from 0.51666\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6773 - loss: 0.6070 - val_accuracy: 0.6734 - val_loss: 0.5712 - learning_rate: 2.5694e-05\n",
            "Epoch 25/31\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6806 - loss: 0.6008\n",
            "Epoch 25: val_loss did not improve from 0.51666\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6807 - loss: 0.6006 - val_accuracy: 0.7122 - val_loss: 0.5341 - learning_rate: 2.5694e-05\n",
            "Epoch 26/31\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6833 - loss: 0.5923\n",
            "Epoch 26: val_loss did not improve from 0.51666\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6834 - loss: 0.5921 - val_accuracy: 0.6987 - val_loss: 0.5559 - learning_rate: 2.5694e-05\n",
            "Epoch 27/31\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6913 - loss: 0.5890\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 5.4344633385038855e-06.\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.51666\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6913 - loss: 0.5889 - val_accuracy: 0.7097 - val_loss: 0.5450 - learning_rate: 2.5694e-05\n",
            "Epoch 28/31\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6910 - loss: 0.5877\n",
            "Epoch 28: val_loss did not improve from 0.51666\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6912 - loss: 0.5874 - val_accuracy: 0.7241 - val_loss: 0.5247 - learning_rate: 5.4345e-06\n",
            "Epoch 29/31\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6947 - loss: 0.5854\n",
            "Epoch 29: val_loss did not improve from 0.51666\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6948 - loss: 0.5853 - val_accuracy: 0.7241 - val_loss: 0.5225 - learning_rate: 5.4345e-06\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 23.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:18:31,247] Trial 14 finished with value: -0.5166605114936829 and parameters: {'epochs': 31, 'batch_size': 16, 'learning_rate': 2.569358473629977e-05, 'stop_patience': 6, 'reduce_lr_factor': 0.21151050878746627, 'reduce_lr_patience': 4}. Best is trial 6 with value: -0.3146595358848572.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/31\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5580 - loss: 0.6873\n",
            "Epoch 1: val_loss improved from inf to 0.54054, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5584 - loss: 0.6870 - val_accuracy: 0.7190 - val_loss: 0.5405 - learning_rate: 0.0011\n",
            "Epoch 2/31\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6537 - loss: 0.6112\n",
            "Epoch 2: val_loss improved from 0.54054 to 0.40400, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6544 - loss: 0.6102 - val_accuracy: 0.8338 - val_loss: 0.4040 - learning_rate: 0.0011\n",
            "Epoch 3/31\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6964 - loss: 0.5417\n",
            "Epoch 3: val_loss improved from 0.40400 to 0.38089, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6970 - loss: 0.5413 - val_accuracy: 0.8143 - val_loss: 0.3809 - learning_rate: 0.0011\n",
            "Epoch 4/31\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7233 - loss: 0.5157\n",
            "Epoch 4: val_loss improved from 0.38089 to 0.35022, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7237 - loss: 0.5155 - val_accuracy: 0.8523 - val_loss: 0.3502 - learning_rate: 0.0011\n",
            "Epoch 5/31\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7322 - loss: 0.4946\n",
            "Epoch 5: val_loss improved from 0.35022 to 0.31704, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7323 - loss: 0.4945 - val_accuracy: 0.8650 - val_loss: 0.3170 - learning_rate: 0.0011\n",
            "Epoch 6/31\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7425 - loss: 0.4841\n",
            "Epoch 6: val_loss did not improve from 0.31704\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7430 - loss: 0.4836 - val_accuracy: 0.8633 - val_loss: 0.3195 - learning_rate: 0.0011\n",
            "Epoch 7/31\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7435 - loss: 0.4781\n",
            "Epoch 7: val_loss improved from 0.31704 to 0.31545, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7437 - loss: 0.4780 - val_accuracy: 0.8650 - val_loss: 0.3154 - learning_rate: 0.0011\n",
            "Epoch 8/31\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7394 - loss: 0.4899\n",
            "Epoch 8: val_loss did not improve from 0.31545\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7397 - loss: 0.4894 - val_accuracy: 0.8565 - val_loss: 0.3171 - learning_rate: 0.0011\n",
            "Epoch 9/31\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7591 - loss: 0.4580\n",
            "Epoch 9: val_loss improved from 0.31545 to 0.31147, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7592 - loss: 0.4580 - val_accuracy: 0.8684 - val_loss: 0.3115 - learning_rate: 0.0011\n",
            "Epoch 10/31\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7560 - loss: 0.4624\n",
            "Epoch 10: val_loss did not improve from 0.31147\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7562 - loss: 0.4622 - val_accuracy: 0.8287 - val_loss: 0.3436 - learning_rate: 0.0011\n",
            "Epoch 11/31\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.4627\n",
            "Epoch 11: val_loss improved from 0.31147 to 0.30687, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7604 - loss: 0.4627 - val_accuracy: 0.8717 - val_loss: 0.3069 - learning_rate: 0.0011\n",
            "Epoch 12/31\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7669 - loss: 0.4511\n",
            "Epoch 12: val_loss did not improve from 0.30687\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4509 - val_accuracy: 0.8405 - val_loss: 0.3507 - learning_rate: 0.0011\n",
            "Epoch 13/31\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7743 - loss: 0.4316\n",
            "Epoch 13: val_loss did not improve from 0.30687\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7746 - loss: 0.4315 - val_accuracy: 0.8582 - val_loss: 0.3203 - learning_rate: 0.0011\n",
            "Epoch 14/31\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7786 - loss: 0.4358\n",
            "Epoch 14: val_loss improved from 0.30687 to 0.30247, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7788 - loss: 0.4356 - val_accuracy: 0.8709 - val_loss: 0.3025 - learning_rate: 0.0011\n",
            "Epoch 15/31\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7796 - loss: 0.4291\n",
            "Epoch 15: val_loss did not improve from 0.30247\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7798 - loss: 0.4289 - val_accuracy: 0.8051 - val_loss: 0.4389 - learning_rate: 0.0011\n",
            "Epoch 16/31\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7819 - loss: 0.4370\n",
            "Epoch 16: val_loss did not improve from 0.30247\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7821 - loss: 0.4367 - val_accuracy: 0.8304 - val_loss: 0.3502 - learning_rate: 0.0011\n",
            "Epoch 17/31\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7830 - loss: 0.4095\n",
            "Epoch 17: val_loss did not improve from 0.30247\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7833 - loss: 0.4094 - val_accuracy: 0.8565 - val_loss: 0.3251 - learning_rate: 0.0011\n",
            "Epoch 18/31\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7843 - loss: 0.4173\n",
            "Epoch 18: val_loss did not improve from 0.30247\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7849 - loss: 0.4169 - val_accuracy: 0.8397 - val_loss: 0.3574 - learning_rate: 0.0011\n",
            "Epoch 19/31\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7909 - loss: 0.4159\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00039613149123344284.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.30247\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7911 - loss: 0.4157 - val_accuracy: 0.8675 - val_loss: 0.3100 - learning_rate: 0.0011\n",
            "Epoch 20/31\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.3873\n",
            "Epoch 20: val_loss did not improve from 0.30247\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.3872 - val_accuracy: 0.8599 - val_loss: 0.3074 - learning_rate: 3.9613e-04\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:19:19,425] Trial 15 finished with value: -0.30246502161026 and parameters: {'epochs': 31, 'batch_size': 16, 'learning_rate': 0.0011175725426261116, 'stop_patience': 6, 'reduce_lr_factor': 0.3544570736105101, 'reduce_lr_patience': 5}. Best is trial 15 with value: -0.30246502161026.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/17\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5355 - loss: 0.6942\n",
            "Epoch 1: val_loss improved from inf to 0.67790, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5358 - loss: 0.6942 - val_accuracy: 0.6447 - val_loss: 0.6779 - learning_rate: 0.0059\n",
            "Epoch 2/17\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5525 - loss: 0.6857\n",
            "Epoch 2: val_loss improved from 0.67790 to 0.67568, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5526 - loss: 0.6856 - val_accuracy: 0.6152 - val_loss: 0.6757 - learning_rate: 0.0059\n",
            "Epoch 3/17\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5768 - loss: 0.6660\n",
            "Epoch 3: val_loss improved from 0.67568 to 0.62074, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5774 - loss: 0.6654 - val_accuracy: 0.6624 - val_loss: 0.6207 - learning_rate: 0.0059\n",
            "Epoch 4/17\n",
            "\u001b[1m66/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6234 - loss: 0.6582\n",
            "Epoch 4: val_loss improved from 0.62074 to 0.56946, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6234 - loss: 0.6563 - val_accuracy: 0.7013 - val_loss: 0.5695 - learning_rate: 0.0059\n",
            "Epoch 5/17\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6700 - loss: 0.5823\n",
            "Epoch 5: val_loss improved from 0.56946 to 0.39620, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6701 - loss: 0.5822 - val_accuracy: 0.8287 - val_loss: 0.3962 - learning_rate: 0.0059\n",
            "Epoch 6/17\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6909 - loss: 0.5550\n",
            "Epoch 6: val_loss improved from 0.39620 to 0.38040, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6910 - loss: 0.5547 - val_accuracy: 0.8397 - val_loss: 0.3804 - learning_rate: 0.0059\n",
            "Epoch 7/17\n",
            "\u001b[1m65/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6972 - loss: 0.5419\n",
            "Epoch 7: val_loss did not improve from 0.38040\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6983 - loss: 0.5401 - val_accuracy: 0.8000 - val_loss: 0.3916 - learning_rate: 0.0059\n",
            "Epoch 8/17\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7162 - loss: 0.5233\n",
            "Epoch 8: val_loss improved from 0.38040 to 0.37050, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7163 - loss: 0.5231 - val_accuracy: 0.8430 - val_loss: 0.3705 - learning_rate: 0.0059\n",
            "Epoch 9/17\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7234 - loss: 0.5119\n",
            "Epoch 9: val_loss did not improve from 0.37050\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7236 - loss: 0.5116 - val_accuracy: 0.8447 - val_loss: 0.3899 - learning_rate: 0.0059\n",
            "Epoch 10/17\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7345 - loss: 0.4979\n",
            "Epoch 10: val_loss did not improve from 0.37050\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7350 - loss: 0.4970 - val_accuracy: 0.8143 - val_loss: 0.4440 - learning_rate: 0.0059\n",
            "Epoch 11/17\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7404 - loss: 0.4835\n",
            "Epoch 11: val_loss did not improve from 0.37050\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7406 - loss: 0.4831 - val_accuracy: 0.7806 - val_loss: 0.4129 - learning_rate: 0.0059\n",
            "Epoch 12/17\n",
            "\u001b[1m64/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7431 - loss: 0.4838\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0020642116616414814.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.37050\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7440 - loss: 0.4820 - val_accuracy: 0.8000 - val_loss: 0.5911 - learning_rate: 0.0059\n",
            "Epoch 13/17\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7462 - loss: 0.4688\n",
            "Epoch 13: val_loss improved from 0.37050 to 0.35141, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7476 - loss: 0.4669 - val_accuracy: 0.8464 - val_loss: 0.3514 - learning_rate: 0.0021\n",
            "Epoch 14/17\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7803 - loss: 0.4322\n",
            "Epoch 14: val_loss did not improve from 0.35141\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7805 - loss: 0.4320 - val_accuracy: 0.8388 - val_loss: 0.3515 - learning_rate: 0.0021\n",
            "Epoch 15/17\n",
            "\u001b[1m66/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7726 - loss: 0.4323\n",
            "Epoch 15: val_loss did not improve from 0.35141\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7748 - loss: 0.4301 - val_accuracy: 0.8380 - val_loss: 0.3739 - learning_rate: 0.0021\n",
            "Epoch 16/17\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7882 - loss: 0.4166\n",
            "Epoch 16: val_loss improved from 0.35141 to 0.34803, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7889 - loss: 0.4158 - val_accuracy: 0.8397 - val_loss: 0.3480 - learning_rate: 0.0021\n",
            "Epoch 17/17\n",
            "\u001b[1m65/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7965 - loss: 0.4101\n",
            "Epoch 17: val_loss improved from 0.34803 to 0.33557, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7969 - loss: 0.4091 - val_accuracy: 0.8405 - val_loss: 0.3356 - learning_rate: 0.0021\n",
            "Restoring model weights from the end of the best epoch: 17.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:19:35,335] Trial 16 finished with value: -0.3355708718299866 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 0.005904596817204087, 'stop_patience': 8, 'reduce_lr_factor': 0.349594010215752, 'reduce_lr_patience': 4}. Best is trial 15 with value: -0.30246502161026.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/31\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5545 - loss: 0.6874\n",
            "Epoch 1: val_loss improved from inf to 0.93518, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5548 - loss: 0.6871 - val_accuracy: 0.5013 - val_loss: 0.9352 - learning_rate: 0.0014\n",
            "Epoch 2/31\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6384 - loss: 0.6235\n",
            "Epoch 2: val_loss improved from 0.93518 to 0.43756, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6391 - loss: 0.6225 - val_accuracy: 0.7722 - val_loss: 0.4376 - learning_rate: 0.0014\n",
            "Epoch 3/31\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6767 - loss: 0.5618\n",
            "Epoch 3: val_loss did not improve from 0.43756\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6770 - loss: 0.5616 - val_accuracy: 0.6473 - val_loss: 0.5674 - learning_rate: 0.0014\n",
            "Epoch 4/31\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6966 - loss: 0.5328\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0004834772817846599.\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.43756\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6967 - loss: 0.5327 - val_accuracy: 0.7865 - val_loss: 0.4478 - learning_rate: 0.0014\n",
            "Epoch 5/31\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7172 - loss: 0.4902\n",
            "Epoch 5: val_loss improved from 0.43756 to 0.36727, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7173 - loss: 0.4901 - val_accuracy: 0.8405 - val_loss: 0.3673 - learning_rate: 4.8348e-04\n",
            "Epoch 6/31\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7530 - loss: 0.4753\n",
            "Epoch 6: val_loss did not improve from 0.36727\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7534 - loss: 0.4747 - val_accuracy: 0.8093 - val_loss: 0.4270 - learning_rate: 4.8348e-04\n",
            "Epoch 7/31\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7575 - loss: 0.4576\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00016820686493040143.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.36727\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7577 - loss: 0.4575 - val_accuracy: 0.8127 - val_loss: 0.4023 - learning_rate: 4.8348e-04\n",
            "Epoch 8/31\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7940 - loss: 0.4316\n",
            "Epoch 8: val_loss improved from 0.36727 to 0.33053, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7942 - loss: 0.4314 - val_accuracy: 0.8506 - val_loss: 0.3305 - learning_rate: 1.6821e-04\n",
            "Epoch 9/31\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4177\n",
            "Epoch 9: val_loss did not improve from 0.33053\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8040 - loss: 0.4177 - val_accuracy: 0.8582 - val_loss: 0.3310 - learning_rate: 1.6821e-04\n",
            "Epoch 10/31\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8072 - loss: 0.4074\n",
            "Epoch 10: val_loss improved from 0.33053 to 0.32950, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8073 - loss: 0.4070 - val_accuracy: 0.8574 - val_loss: 0.3295 - learning_rate: 1.6821e-04\n",
            "Epoch 11/31\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.4078\n",
            "Epoch 11: val_loss did not improve from 0.32950\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8164 - loss: 0.4073 - val_accuracy: 0.8506 - val_loss: 0.3378 - learning_rate: 1.6821e-04\n",
            "Epoch 12/31\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8166 - loss: 0.3986\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 5.852095011208433e-05.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.32950\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8167 - loss: 0.3985 - val_accuracy: 0.8397 - val_loss: 0.3502 - learning_rate: 1.6821e-04\n",
            "Epoch 13/31\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8259 - loss: 0.3866\n",
            "Epoch 13: val_loss did not improve from 0.32950\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8262 - loss: 0.3858 - val_accuracy: 0.7949 - val_loss: 0.4484 - learning_rate: 5.8521e-05\n",
            "Epoch 14/31\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8314 - loss: 0.3815\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.0360057643241436e-05.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.32950\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8315 - loss: 0.3813 - val_accuracy: 0.8000 - val_loss: 0.4249 - learning_rate: 5.8521e-05\n",
            "Epoch 15/31\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8323 - loss: 0.3712\n",
            "Epoch 15: val_loss did not improve from 0.32950\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8325 - loss: 0.3708 - val_accuracy: 0.8076 - val_loss: 0.4147 - learning_rate: 2.0360e-05\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:20:09,893] Trial 17 finished with value: -0.3295001983642578 and parameters: {'epochs': 31, 'batch_size': 16, 'learning_rate': 0.0013896595989517496, 'stop_patience': 5, 'reduce_lr_factor': 0.3479105851427029, 'reduce_lr_patience': 2}. Best is trial 15 with value: -0.30246502161026.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5438 - loss: 0.6915\n",
            "Epoch 1: val_loss improved from inf to 0.62106, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5441 - loss: 0.6914 - val_accuracy: 0.6878 - val_loss: 0.6211 - learning_rate: 0.0014\n",
            "Epoch 2/40\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6075 - loss: 0.6508\n",
            "Epoch 2: val_loss did not improve from 0.62106\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6080 - loss: 0.6503 - val_accuracy: 0.5823 - val_loss: 0.7765 - learning_rate: 0.0014\n",
            "Epoch 3/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6633 - loss: 0.5790\n",
            "Epoch 3: val_loss improved from 0.62106 to 0.58403, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6633 - loss: 0.5789 - val_accuracy: 0.6684 - val_loss: 0.5840 - learning_rate: 0.0014\n",
            "Epoch 4/40\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6968 - loss: 0.5354\n",
            "Epoch 4: val_loss improved from 0.58403 to 0.45746, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6971 - loss: 0.5352 - val_accuracy: 0.7932 - val_loss: 0.4575 - learning_rate: 0.0014\n",
            "Epoch 5/40\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7137 - loss: 0.5158\n",
            "Epoch 5: val_loss improved from 0.45746 to 0.35790, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7140 - loss: 0.5156 - val_accuracy: 0.8422 - val_loss: 0.3579 - learning_rate: 0.0014\n",
            "Epoch 6/40\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7168 - loss: 0.5055\n",
            "Epoch 6: val_loss did not improve from 0.35790\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7171 - loss: 0.5053 - val_accuracy: 0.8084 - val_loss: 0.4896 - learning_rate: 0.0014\n",
            "Epoch 7/40\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.5039\n",
            "Epoch 7: val_loss did not improve from 0.35790\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7317 - loss: 0.5030 - val_accuracy: 0.8084 - val_loss: 0.4549 - learning_rate: 0.0014\n",
            "Epoch 8/40\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7475 - loss: 0.4830\n",
            "Epoch 8: val_loss improved from 0.35790 to 0.34993, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7476 - loss: 0.4828 - val_accuracy: 0.8388 - val_loss: 0.3499 - learning_rate: 0.0014\n",
            "Epoch 9/40\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7459 - loss: 0.4763\n",
            "Epoch 9: val_loss did not improve from 0.34993\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7463 - loss: 0.4758 - val_accuracy: 0.8135 - val_loss: 0.4061 - learning_rate: 0.0014\n",
            "Epoch 10/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7445 - loss: 0.4707\n",
            "Epoch 10: val_loss improved from 0.34993 to 0.34254, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7445 - loss: 0.4706 - val_accuracy: 0.8414 - val_loss: 0.3425 - learning_rate: 0.0014\n",
            "Epoch 11/40\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7496 - loss: 0.4757\n",
            "Epoch 11: val_loss did not improve from 0.34254\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7499 - loss: 0.4753 - val_accuracy: 0.8405 - val_loss: 0.3685 - learning_rate: 0.0014\n",
            "Epoch 12/40\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7583 - loss: 0.4629\n",
            "Epoch 12: val_loss did not improve from 0.34254\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7584 - loss: 0.4626 - val_accuracy: 0.8489 - val_loss: 0.3493 - learning_rate: 0.0014\n",
            "Epoch 13/40\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7551 - loss: 0.4579\n",
            "Epoch 13: val_loss did not improve from 0.34254\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7553 - loss: 0.4576 - val_accuracy: 0.7662 - val_loss: 0.4614 - learning_rate: 0.0014\n",
            "Epoch 14/40\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7640 - loss: 0.4463\n",
            "Epoch 14: val_loss did not improve from 0.34254\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7642 - loss: 0.4459 - val_accuracy: 0.8321 - val_loss: 0.3714 - learning_rate: 0.0014\n",
            "Epoch 15/40\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7644 - loss: 0.4502\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00014273325105087305.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.34254\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7650 - loss: 0.4496 - val_accuracy: 0.8278 - val_loss: 0.3487 - learning_rate: 0.0014\n",
            "Epoch 16/40\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.4161\n",
            "Epoch 16: val_loss did not improve from 0.34254\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7980 - loss: 0.4146 - val_accuracy: 0.8143 - val_loss: 0.3961 - learning_rate: 1.4273e-04\n",
            "Epoch 17/40\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8270 - loss: 0.3805\n",
            "Epoch 17: val_loss did not improve from 0.34254\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8271 - loss: 0.3801 - val_accuracy: 0.8312 - val_loss: 0.3536 - learning_rate: 1.4273e-04\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:20:43,582] Trial 18 finished with value: -0.3425428569316864 and parameters: {'epochs': 40, 'batch_size': 16, 'learning_rate': 0.001423593156946144, 'stop_patience': 7, 'reduce_lr_factor': 0.1002626709505014, 'reduce_lr_patience': 5}. Best is trial 15 with value: -0.30246502161026.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/18\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5380 - loss: 0.6923\n",
            "Epoch 1: val_loss improved from inf to 0.73193, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.5391 - loss: 0.6918 - val_accuracy: 0.4219 - val_loss: 0.7319 - learning_rate: 0.0052\n",
            "Epoch 2/18\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5624 - loss: 0.6782\n",
            "Epoch 2: val_loss did not improve from 0.73193\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5626 - loss: 0.6781 - val_accuracy: 0.5814 - val_loss: 0.7377 - learning_rate: 0.0052\n",
            "Epoch 3/18\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6058 - loss: 0.6460\n",
            "Epoch 3: val_loss improved from 0.73193 to 0.49947, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6064 - loss: 0.6455 - val_accuracy: 0.7384 - val_loss: 0.4995 - learning_rate: 0.0052\n",
            "Epoch 4/18\n",
            "\u001b[1m64/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6535 - loss: 0.6085\n",
            "Epoch 4: val_loss did not improve from 0.49947\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6517 - loss: 0.6096 - val_accuracy: 0.7274 - val_loss: 0.5251 - learning_rate: 0.0052\n",
            "Epoch 5/18\n",
            "\u001b[1m65/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6738 - loss: 0.5661\n",
            "Epoch 5: val_loss improved from 0.49947 to 0.48079, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6729 - loss: 0.5670 - val_accuracy: 0.7755 - val_loss: 0.4808 - learning_rate: 0.0052\n",
            "Epoch 6/18\n",
            "\u001b[1m66/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6679 - loss: 0.5511\n",
            "Epoch 6: val_loss did not improve from 0.48079\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6694 - loss: 0.5503 - val_accuracy: 0.5949 - val_loss: 0.6867 - learning_rate: 0.0052\n",
            "Epoch 7/18\n",
            "\u001b[1m65/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6861 - loss: 0.5306\n",
            "Epoch 7: val_loss did not improve from 0.48079\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6888 - loss: 0.5286 - val_accuracy: 0.7578 - val_loss: 0.5635 - learning_rate: 0.0052\n",
            "Epoch 8/18\n",
            "\u001b[1m64/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7142 - loss: 0.5205\n",
            "Epoch 8: val_loss improved from 0.48079 to 0.41066, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7166 - loss: 0.5182 - val_accuracy: 0.8008 - val_loss: 0.4107 - learning_rate: 0.0052\n",
            "Epoch 9/18\n",
            "\u001b[1m65/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7296 - loss: 0.5072\n",
            "Epoch 9: val_loss did not improve from 0.41066\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7304 - loss: 0.5058 - val_accuracy: 0.7907 - val_loss: 0.4794 - learning_rate: 0.0052\n",
            "Epoch 10/18\n",
            "\u001b[1m66/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7341 - loss: 0.4785\n",
            "Epoch 10: val_loss improved from 0.41066 to 0.37206, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7341 - loss: 0.4785 - val_accuracy: 0.8430 - val_loss: 0.3721 - learning_rate: 0.0052\n",
            "Epoch 11/18\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7309 - loss: 0.4846\n",
            "Epoch 11: val_loss did not improve from 0.37206\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7311 - loss: 0.4841 - val_accuracy: 0.7992 - val_loss: 0.4656 - learning_rate: 0.0052\n",
            "Epoch 12/18\n",
            "\u001b[1m67/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7295 - loss: 0.5044\n",
            "Epoch 12: val_loss improved from 0.37206 to 0.36793, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7309 - loss: 0.5016 - val_accuracy: 0.8295 - val_loss: 0.3679 - learning_rate: 0.0052\n",
            "Epoch 13/18\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7566 - loss: 0.4646\n",
            "Epoch 13: val_loss did not improve from 0.36793\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7566 - loss: 0.4645 - val_accuracy: 0.7949 - val_loss: 0.4375 - learning_rate: 0.0052\n",
            "Epoch 14/18\n",
            "\u001b[1m66/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7527 - loss: 0.4666\n",
            "Epoch 14: val_loss did not improve from 0.36793\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7528 - loss: 0.4664 - val_accuracy: 0.8211 - val_loss: 0.3884 - learning_rate: 0.0052\n",
            "Epoch 15/18\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7416 - loss: 0.4615\n",
            "Epoch 15: val_loss did not improve from 0.36793\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7418 - loss: 0.4613 - val_accuracy: 0.7730 - val_loss: 0.4924 - learning_rate: 0.0052\n",
            "Epoch 16/18\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7589 - loss: 0.4632\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0016928492863852588.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.36793\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7591 - loss: 0.4625 - val_accuracy: 0.8017 - val_loss: 0.4080 - learning_rate: 0.0052\n",
            "Epoch 17/18\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7763 - loss: 0.4238\n",
            "Epoch 17: val_loss improved from 0.36793 to 0.36368, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7769 - loss: 0.4231 - val_accuracy: 0.8388 - val_loss: 0.3637 - learning_rate: 0.0017\n",
            "Epoch 18/18\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8023 - loss: 0.4047\n",
            "Epoch 18: val_loss did not improve from 0.36368\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8018 - loss: 0.4046 - val_accuracy: 0.8093 - val_loss: 0.4223 - learning_rate: 0.0017\n",
            "Restoring model weights from the end of the best epoch: 17.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:20:59,953] Trial 19 finished with value: -0.36368051171302795 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 0.0051779947657113745, 'stop_patience': 6, 'reduce_lr_factor': 0.32693144286536235, 'reduce_lr_patience': 4}. Best is trial 15 with value: -0.30246502161026.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5532 - loss: 0.6923\n",
            "Epoch 1: val_loss improved from inf to 0.78613, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5536 - loss: 0.6919 - val_accuracy: 0.4768 - val_loss: 0.7861 - learning_rate: 0.0030\n",
            "Epoch 2/35\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6052 - loss: 0.6554\n",
            "Epoch 2: val_loss did not improve from 0.78613\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6054 - loss: 0.6552 - val_accuracy: 0.4278 - val_loss: 1.0306 - learning_rate: 0.0030\n",
            "Epoch 3/35\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6563 - loss: 0.5867\n",
            "Epoch 3: val_loss improved from 0.78613 to 0.61787, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6565 - loss: 0.5866 - val_accuracy: 0.5603 - val_loss: 0.6179 - learning_rate: 0.0030\n",
            "Epoch 4/35\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6773 - loss: 0.5536\n",
            "Epoch 4: val_loss did not improve from 0.61787\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6776 - loss: 0.5533 - val_accuracy: 0.7241 - val_loss: 0.7193 - learning_rate: 0.0030\n",
            "Epoch 5/35\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7027 - loss: 0.5266\n",
            "Epoch 5: val_loss did not improve from 0.61787\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7028 - loss: 0.5264 - val_accuracy: 0.5215 - val_loss: 1.4257 - learning_rate: 0.0030\n",
            "Epoch 6/35\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7014 - loss: 0.5125\n",
            "Epoch 6: val_loss improved from 0.61787 to 0.38053, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7017 - loss: 0.5125 - val_accuracy: 0.8278 - val_loss: 0.3805 - learning_rate: 0.0030\n",
            "Epoch 7/35\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7193 - loss: 0.5070\n",
            "Epoch 7: val_loss did not improve from 0.38053\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7197 - loss: 0.5065 - val_accuracy: 0.8211 - val_loss: 0.3958 - learning_rate: 0.0030\n",
            "Epoch 8/35\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7247 - loss: 0.4933\n",
            "Epoch 8: val_loss improved from 0.38053 to 0.37886, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7251 - loss: 0.4932 - val_accuracy: 0.8321 - val_loss: 0.3789 - learning_rate: 0.0030\n",
            "Epoch 9/35\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7243 - loss: 0.4874\n",
            "Epoch 9: val_loss did not improve from 0.37886\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7244 - loss: 0.4873 - val_accuracy: 0.7992 - val_loss: 0.4511 - learning_rate: 0.0030\n",
            "Epoch 10/35\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.4770\n",
            "Epoch 10: val_loss improved from 0.37886 to 0.35357, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7330 - loss: 0.4768 - val_accuracy: 0.8456 - val_loss: 0.3536 - learning_rate: 0.0030\n",
            "Epoch 11/35\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7397 - loss: 0.4778\n",
            "Epoch 11: val_loss did not improve from 0.35357\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7399 - loss: 0.4777 - val_accuracy: 0.8329 - val_loss: 0.3661 - learning_rate: 0.0030\n",
            "Epoch 12/35\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7454 - loss: 0.4713\n",
            "Epoch 12: val_loss improved from 0.35357 to 0.34382, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7456 - loss: 0.4710 - val_accuracy: 0.8380 - val_loss: 0.3438 - learning_rate: 0.0030\n",
            "Epoch 13/35\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.4604\n",
            "Epoch 13: val_loss did not improve from 0.34382\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7501 - loss: 0.4603 - val_accuracy: 0.8397 - val_loss: 0.3619 - learning_rate: 0.0030\n",
            "Epoch 14/35\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7477 - loss: 0.4534\n",
            "Epoch 14: val_loss did not improve from 0.34382\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7479 - loss: 0.4533 - val_accuracy: 0.8481 - val_loss: 0.3454 - learning_rate: 0.0030\n",
            "Epoch 15/35\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7554 - loss: 0.4554\n",
            "Epoch 15: val_loss did not improve from 0.34382\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7555 - loss: 0.4553 - val_accuracy: 0.8481 - val_loss: 0.3724 - learning_rate: 0.0030\n",
            "Epoch 16/35\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7558 - loss: 0.4534\n",
            "Epoch 16: val_loss did not improve from 0.34382\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7563 - loss: 0.4531 - val_accuracy: 0.8338 - val_loss: 0.4169 - learning_rate: 0.0030\n",
            "Epoch 17/35\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7728 - loss: 0.4422\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006559155719488708.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.34382\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7728 - loss: 0.4422 - val_accuracy: 0.8473 - val_loss: 0.3692 - learning_rate: 0.0030\n",
            "Epoch 18/35\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8000 - loss: 0.4056\n",
            "Epoch 18: val_loss did not improve from 0.34382\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8004 - loss: 0.4052 - val_accuracy: 0.8498 - val_loss: 0.3620 - learning_rate: 6.5592e-04\n",
            "Epoch 19/35\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.3786\n",
            "Epoch 19: val_loss did not improve from 0.34382\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8181 - loss: 0.3781 - val_accuracy: 0.8557 - val_loss: 0.3486 - learning_rate: 6.5592e-04\n",
            "Epoch 20/35\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8272 - loss: 0.3705\n",
            "Epoch 20: val_loss did not improve from 0.34382\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8275 - loss: 0.3701 - val_accuracy: 0.8540 - val_loss: 0.3529 - learning_rate: 6.5592e-04\n",
            "Epoch 21/35\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.3663\n",
            "Epoch 21: val_loss did not improve from 0.34382\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8256 - loss: 0.3658 - val_accuracy: 0.8489 - val_loss: 0.3624 - learning_rate: 6.5592e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:21:45,206] Trial 20 finished with value: -0.3438217341899872 and parameters: {'epochs': 35, 'batch_size': 16, 'learning_rate': 0.0029699554738020946, 'stop_patience': 9, 'reduce_lr_factor': 0.22085029851040527, 'reduce_lr_patience': 5}. Best is trial 15 with value: -0.30246502161026.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/28\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5555 - loss: 0.6914\n",
            "Epoch 1: val_loss improved from inf to 0.67731, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5556 - loss: 0.6914 - val_accuracy: 0.5814 - val_loss: 0.6773 - learning_rate: 5.8834e-05\n",
            "Epoch 2/28\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5593 - loss: 0.6880\n",
            "Epoch 2: val_loss improved from 0.67731 to 0.67346, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5595 - loss: 0.6880 - val_accuracy: 0.6819 - val_loss: 0.6735 - learning_rate: 5.8834e-05\n",
            "Epoch 3/28\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5662 - loss: 0.6831\n",
            "Epoch 3: val_loss improved from 0.67346 to 0.66135, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5663 - loss: 0.6831 - val_accuracy: 0.6776 - val_loss: 0.6614 - learning_rate: 5.8834e-05\n",
            "Epoch 4/28\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5707 - loss: 0.6787\n",
            "Epoch 4: val_loss did not improve from 0.66135\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5708 - loss: 0.6787 - val_accuracy: 0.5435 - val_loss: 0.6650 - learning_rate: 5.8834e-05\n",
            "Epoch 5/28\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5791 - loss: 0.6700\n",
            "Epoch 5: val_loss improved from 0.66135 to 0.64086, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5792 - loss: 0.6700 - val_accuracy: 0.6017 - val_loss: 0.6409 - learning_rate: 5.8834e-05\n",
            "Epoch 6/28\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5936 - loss: 0.6592\n",
            "Epoch 6: val_loss improved from 0.64086 to 0.58773, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5937 - loss: 0.6592 - val_accuracy: 0.7359 - val_loss: 0.5877 - learning_rate: 5.8834e-05\n",
            "Epoch 7/28\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6061 - loss: 0.6465\n",
            "Epoch 7: val_loss improved from 0.58773 to 0.56074, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6065 - loss: 0.6462 - val_accuracy: 0.7274 - val_loss: 0.5607 - learning_rate: 5.8834e-05\n",
            "Epoch 8/28\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6382 - loss: 0.6324\n",
            "Epoch 8: val_loss improved from 0.56074 to 0.52448, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6384 - loss: 0.6321 - val_accuracy: 0.7460 - val_loss: 0.5245 - learning_rate: 5.8834e-05\n",
            "Epoch 9/28\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6634 - loss: 0.6143\n",
            "Epoch 9: val_loss improved from 0.52448 to 0.46802, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6636 - loss: 0.6140 - val_accuracy: 0.7857 - val_loss: 0.4680 - learning_rate: 5.8834e-05\n",
            "Epoch 10/28\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6873 - loss: 0.5968\n",
            "Epoch 10: val_loss improved from 0.46802 to 0.42277, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6873 - loss: 0.5966 - val_accuracy: 0.8228 - val_loss: 0.4228 - learning_rate: 5.8834e-05\n",
            "Epoch 11/28\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6995 - loss: 0.5818\n",
            "Epoch 11: val_loss improved from 0.42277 to 0.41708, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6996 - loss: 0.5816 - val_accuracy: 0.8169 - val_loss: 0.4171 - learning_rate: 5.8834e-05\n",
            "Epoch 12/28\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7113 - loss: 0.5660\n",
            "Epoch 12: val_loss improved from 0.41708 to 0.40220, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7113 - loss: 0.5659 - val_accuracy: 0.8228 - val_loss: 0.4022 - learning_rate: 5.8834e-05\n",
            "Epoch 13/28\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.5484\n",
            "Epoch 13: val_loss improved from 0.40220 to 0.39261, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7285 - loss: 0.5481 - val_accuracy: 0.8270 - val_loss: 0.3926 - learning_rate: 5.8834e-05\n",
            "Epoch 14/28\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7187 - loss: 0.5467\n",
            "Epoch 14: val_loss did not improve from 0.39261\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7189 - loss: 0.5464 - val_accuracy: 0.8203 - val_loss: 0.3960 - learning_rate: 5.8834e-05\n",
            "Epoch 15/28\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7329 - loss: 0.5347\n",
            "Epoch 15: val_loss did not improve from 0.39261\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7331 - loss: 0.5346 - val_accuracy: 0.8219 - val_loss: 0.4019 - learning_rate: 5.8834e-05\n",
            "Epoch 16/28\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7378 - loss: 0.5241\n",
            "Epoch 16: val_loss did not improve from 0.39261\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.5238 - val_accuracy: 0.8287 - val_loss: 0.3988 - learning_rate: 5.8834e-05\n",
            "Epoch 17/28\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7341 - loss: 0.5236\n",
            "Epoch 17: val_loss did not improve from 0.39261\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 0.5231 - val_accuracy: 0.8245 - val_loss: 0.3982 - learning_rate: 5.8834e-05\n",
            "Epoch 18/28\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7455 - loss: 0.5121\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.205483958791271e-05.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.39261\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7455 - loss: 0.5120 - val_accuracy: 0.8236 - val_loss: 0.4067 - learning_rate: 5.8834e-05\n",
            "Epoch 19/28\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7561 - loss: 0.5088\n",
            "Epoch 19: val_loss did not improve from 0.39261\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7562 - loss: 0.5085 - val_accuracy: 0.7738 - val_loss: 0.4890 - learning_rate: 1.2055e-05\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:22:23,461] Trial 21 finished with value: -0.3926068842411041 and parameters: {'epochs': 28, 'batch_size': 16, 'learning_rate': 5.883383735221729e-05, 'stop_patience': 6, 'reduce_lr_factor': 0.20489636885444698, 'reduce_lr_patience': 5}. Best is trial 15 with value: -0.30246502161026.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/29\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5418 - loss: 0.6897\n",
            "Epoch 1: val_loss improved from inf to 0.64960, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5425 - loss: 0.6895 - val_accuracy: 0.6068 - val_loss: 0.6496 - learning_rate: 9.2489e-04\n",
            "Epoch 2/29\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6304 - loss: 0.6301\n",
            "Epoch 2: val_loss did not improve from 0.64960\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6312 - loss: 0.6293 - val_accuracy: 0.6160 - val_loss: 0.6910 - learning_rate: 9.2489e-04\n",
            "Epoch 3/29\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6765 - loss: 0.5605\n",
            "Epoch 3: val_loss improved from 0.64960 to 0.45642, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6768 - loss: 0.5603 - val_accuracy: 0.7764 - val_loss: 0.4564 - learning_rate: 9.2489e-04\n",
            "Epoch 4/29\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6970 - loss: 0.5375\n",
            "Epoch 4: val_loss improved from 0.45642 to 0.40508, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6973 - loss: 0.5371 - val_accuracy: 0.8008 - val_loss: 0.4051 - learning_rate: 9.2489e-04\n",
            "Epoch 5/29\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7071 - loss: 0.5124\n",
            "Epoch 5: val_loss did not improve from 0.40508\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7075 - loss: 0.5122 - val_accuracy: 0.7840 - val_loss: 0.4192 - learning_rate: 9.2489e-04\n",
            "Epoch 6/29\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7263 - loss: 0.4981\n",
            "Epoch 6: val_loss improved from 0.40508 to 0.36656, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7265 - loss: 0.4980 - val_accuracy: 0.8439 - val_loss: 0.3666 - learning_rate: 9.2489e-04\n",
            "Epoch 7/29\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7288 - loss: 0.4890\n",
            "Epoch 7: val_loss did not improve from 0.36656\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7295 - loss: 0.4886 - val_accuracy: 0.7502 - val_loss: 0.5040 - learning_rate: 9.2489e-04\n",
            "Epoch 8/29\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7243 - loss: 0.4875\n",
            "Epoch 8: val_loss improved from 0.36656 to 0.32998, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7244 - loss: 0.4874 - val_accuracy: 0.8549 - val_loss: 0.3300 - learning_rate: 9.2489e-04\n",
            "Epoch 9/29\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7349 - loss: 0.4762\n",
            "Epoch 9: val_loss did not improve from 0.32998\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7355 - loss: 0.4759 - val_accuracy: 0.8211 - val_loss: 0.3658 - learning_rate: 9.2489e-04\n",
            "Epoch 10/29\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.4781\n",
            "Epoch 10: val_loss did not improve from 0.32998\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7409 - loss: 0.4780 - val_accuracy: 0.8447 - val_loss: 0.3613 - learning_rate: 9.2489e-04\n",
            "Epoch 11/29\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7481 - loss: 0.4631\n",
            "Epoch 11: val_loss did not improve from 0.32998\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7487 - loss: 0.4627 - val_accuracy: 0.8287 - val_loss: 0.3719 - learning_rate: 9.2489e-04\n",
            "Epoch 12/29\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7552 - loss: 0.4674\n",
            "Epoch 12: val_loss did not improve from 0.32998\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7554 - loss: 0.4671 - val_accuracy: 0.8169 - val_loss: 0.3884 - learning_rate: 9.2489e-04\n",
            "Epoch 13/29\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7569 - loss: 0.4616\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0003587290756221871.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.32998\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7571 - loss: 0.4613 - val_accuracy: 0.8211 - val_loss: 0.3842 - learning_rate: 9.2489e-04\n",
            "Epoch 14/29\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7767 - loss: 0.4368\n",
            "Epoch 14: val_loss did not improve from 0.32998\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7772 - loss: 0.4362 - val_accuracy: 0.8565 - val_loss: 0.3358 - learning_rate: 3.5873e-04\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:22:54,531] Trial 22 finished with value: -0.32998356223106384 and parameters: {'epochs': 29, 'batch_size': 16, 'learning_rate': 0.0009248869788278925, 'stop_patience': 6, 'reduce_lr_factor': 0.3878626153768958, 'reduce_lr_patience': 5}. Best is trial 15 with value: -0.30246502161026.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5465 - loss: 0.6892\n",
            "Epoch 1: val_loss improved from inf to 0.64883, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5476 - loss: 0.6886 - val_accuracy: 0.6228 - val_loss: 0.6488 - learning_rate: 0.0020\n",
            "Epoch 2/20\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6358 - loss: 0.6157\n",
            "Epoch 2: val_loss improved from 0.64883 to 0.41690, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6366 - loss: 0.6150 - val_accuracy: 0.7992 - val_loss: 0.4169 - learning_rate: 0.0020\n",
            "Epoch 3/20\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6847 - loss: 0.5574\n",
            "Epoch 3: val_loss did not improve from 0.41690\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6851 - loss: 0.5571 - val_accuracy: 0.7544 - val_loss: 0.5556 - learning_rate: 0.0020\n",
            "Epoch 4/20\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7095 - loss: 0.5259\n",
            "Epoch 4: val_loss improved from 0.41690 to 0.36739, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7096 - loss: 0.5258 - val_accuracy: 0.8346 - val_loss: 0.3674 - learning_rate: 0.0020\n",
            "Epoch 5/20\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7183 - loss: 0.5152\n",
            "Epoch 5: val_loss did not improve from 0.36739\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7188 - loss: 0.5148 - val_accuracy: 0.7637 - val_loss: 0.5489 - learning_rate: 0.0020\n",
            "Epoch 6/20\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7284 - loss: 0.4970\n",
            "Epoch 6: val_loss did not improve from 0.36739\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7289 - loss: 0.4964 - val_accuracy: 0.8160 - val_loss: 0.3686 - learning_rate: 0.0020\n",
            "Epoch 7/20\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7266 - loss: 0.4972\n",
            "Epoch 7: val_loss did not improve from 0.36739\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7272 - loss: 0.4966 - val_accuracy: 0.7696 - val_loss: 0.4631 - learning_rate: 0.0020\n",
            "Epoch 8/20\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7667 - loss: 0.4701\n",
            "Epoch 8: val_loss improved from 0.36739 to 0.33851, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7667 - loss: 0.4700 - val_accuracy: 0.8515 - val_loss: 0.3385 - learning_rate: 0.0020\n",
            "Epoch 9/20\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7402 - loss: 0.4774\n",
            "Epoch 9: val_loss did not improve from 0.33851\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7405 - loss: 0.4771 - val_accuracy: 0.8186 - val_loss: 0.3500 - learning_rate: 0.0020\n",
            "Epoch 10/20\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7562 - loss: 0.4673\n",
            "Epoch 10: val_loss improved from 0.33851 to 0.31827, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7564 - loss: 0.4669 - val_accuracy: 0.8523 - val_loss: 0.3183 - learning_rate: 0.0020\n",
            "Epoch 11/20\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7521 - loss: 0.4638\n",
            "Epoch 11: val_loss improved from 0.31827 to 0.31600, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7521 - loss: 0.4638 - val_accuracy: 0.8624 - val_loss: 0.3160 - learning_rate: 0.0020\n",
            "Epoch 12/20\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7584 - loss: 0.4572\n",
            "Epoch 12: val_loss did not improve from 0.31600\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7585 - loss: 0.4571 - val_accuracy: 0.8574 - val_loss: 0.3247 - learning_rate: 0.0020\n",
            "Epoch 13/20\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7702 - loss: 0.4492\n",
            "Epoch 13: val_loss did not improve from 0.31600\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7706 - loss: 0.4485 - val_accuracy: 0.8633 - val_loss: 0.3242 - learning_rate: 0.0020\n",
            "Epoch 14/20\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7714 - loss: 0.4421\n",
            "Epoch 14: val_loss did not improve from 0.31600\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7716 - loss: 0.4419 - val_accuracy: 0.8211 - val_loss: 0.3811 - learning_rate: 0.0020\n",
            "Epoch 15/20\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7831 - loss: 0.4274\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00034249394696280535.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.31600\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7832 - loss: 0.4271 - val_accuracy: 0.8312 - val_loss: 0.3963 - learning_rate: 0.0020\n",
            "Epoch 16/20\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8132 - loss: 0.3896\n",
            "Epoch 16: val_loss improved from 0.31600 to 0.30410, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.3888 - val_accuracy: 0.8667 - val_loss: 0.3041 - learning_rate: 3.4249e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8283 - loss: 0.3551\n",
            "Epoch 17: val_loss did not improve from 0.30410\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8286 - loss: 0.3548 - val_accuracy: 0.8624 - val_loss: 0.3090 - learning_rate: 3.4249e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8411 - loss: 0.3509\n",
            "Epoch 18: val_loss improved from 0.30410 to 0.29924, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8415 - loss: 0.3502 - val_accuracy: 0.8658 - val_loss: 0.2992 - learning_rate: 3.4249e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8452 - loss: 0.3382\n",
            "Epoch 19: val_loss did not improve from 0.29924\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8452 - loss: 0.3381 - val_accuracy: 0.8515 - val_loss: 0.3233 - learning_rate: 3.4249e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8519 - loss: 0.3338\n",
            "Epoch 20: val_loss did not improve from 0.29924\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8519 - loss: 0.3338 - val_accuracy: 0.8641 - val_loss: 0.3093 - learning_rate: 3.4249e-04\n",
            "Restoring model weights from the end of the best epoch: 18.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:23:32,934] Trial 23 finished with value: -0.2992369532585144 and parameters: {'epochs': 20, 'batch_size': 16, 'learning_rate': 0.0019772383596792587, 'stop_patience': 5, 'reduce_lr_factor': 0.17321834212101725, 'reduce_lr_patience': 4}. Best is trial 23 with value: -0.2992369532585144.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5443 - loss: 0.6887\n",
            "Epoch 1: val_loss improved from inf to 0.65393, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5451 - loss: 0.6885 - val_accuracy: 0.6278 - val_loss: 0.6539 - learning_rate: 0.0021\n",
            "Epoch 2/20\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5894 - loss: 0.6574\n",
            "Epoch 2: val_loss did not improve from 0.65393\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5896 - loss: 0.6573 - val_accuracy: 0.4312 - val_loss: 1.2324 - learning_rate: 0.0021\n",
            "Epoch 3/20\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6543 - loss: 0.5909\n",
            "Epoch 3: val_loss improved from 0.65393 to 0.52739, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6546 - loss: 0.5904 - val_accuracy: 0.7519 - val_loss: 0.5274 - learning_rate: 0.0021\n",
            "Epoch 4/20\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6989 - loss: 0.5365\n",
            "Epoch 4: val_loss improved from 0.52739 to 0.42456, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6989 - loss: 0.5365 - val_accuracy: 0.8380 - val_loss: 0.4246 - learning_rate: 0.0021\n",
            "Epoch 5/20\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6976 - loss: 0.5273\n",
            "Epoch 5: val_loss did not improve from 0.42456\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6984 - loss: 0.5266 - val_accuracy: 0.7367 - val_loss: 0.5310 - learning_rate: 0.0021\n",
            "Epoch 6/20\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7200 - loss: 0.5052\n",
            "Epoch 6: val_loss did not improve from 0.42456\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7204 - loss: 0.5049 - val_accuracy: 0.8447 - val_loss: 0.4579 - learning_rate: 0.0021\n",
            "Epoch 7/20\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7302 - loss: 0.4943\n",
            "Epoch 7: val_loss did not improve from 0.42456\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7303 - loss: 0.4943 - val_accuracy: 0.6414 - val_loss: 0.8678 - learning_rate: 0.0021\n",
            "Epoch 8/20\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7153 - loss: 0.4949\n",
            "Epoch 8: val_loss improved from 0.42456 to 0.40725, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7159 - loss: 0.4943 - val_accuracy: 0.8152 - val_loss: 0.4072 - learning_rate: 0.0021\n",
            "Epoch 9/20\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7328 - loss: 0.4810\n",
            "Epoch 9: val_loss improved from 0.40725 to 0.37399, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.4806 - val_accuracy: 0.8304 - val_loss: 0.3740 - learning_rate: 0.0021\n",
            "Epoch 10/20\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7461 - loss: 0.4654\n",
            "Epoch 10: val_loss improved from 0.37399 to 0.32140, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7464 - loss: 0.4653 - val_accuracy: 0.8565 - val_loss: 0.3214 - learning_rate: 0.0021\n",
            "Epoch 11/20\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7497 - loss: 0.4586\n",
            "Epoch 11: val_loss did not improve from 0.32140\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7501 - loss: 0.4584 - val_accuracy: 0.8473 - val_loss: 0.3546 - learning_rate: 0.0021\n",
            "Epoch 12/20\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7602 - loss: 0.4582\n",
            "Epoch 12: val_loss did not improve from 0.32140\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7604 - loss: 0.4581 - val_accuracy: 0.8388 - val_loss: 0.3999 - learning_rate: 0.0021\n",
            "Epoch 13/20\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7628 - loss: 0.4618\n",
            "Epoch 13: val_loss did not improve from 0.32140\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7629 - loss: 0.4616 - val_accuracy: 0.8354 - val_loss: 0.4813 - learning_rate: 0.0021\n",
            "Epoch 14/20\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7816 - loss: 0.4460\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00021739069852012155.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.32140\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7816 - loss: 0.4458 - val_accuracy: 0.8118 - val_loss: 0.3933 - learning_rate: 0.0021\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:24:01,501] Trial 24 finished with value: -0.3213954567909241 and parameters: {'epochs': 20, 'batch_size': 16, 'learning_rate': 0.00209864434159468, 'stop_patience': 4, 'reduce_lr_factor': 0.10358624837160317, 'reduce_lr_patience': 4}. Best is trial 23 with value: -0.2992369532585144.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5577 - loss: 0.6888\n",
            "Epoch 1: val_loss improved from inf to 0.76519, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5580 - loss: 0.6887 - val_accuracy: 0.5409 - val_loss: 0.7652 - learning_rate: 0.0013\n",
            "Epoch 2/12\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6248 - loss: 0.6325\n",
            "Epoch 2: val_loss improved from 0.76519 to 0.50413, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6255 - loss: 0.6316 - val_accuracy: 0.7308 - val_loss: 0.5041 - learning_rate: 0.0013\n",
            "Epoch 3/12\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6814 - loss: 0.5571\n",
            "Epoch 3: val_loss improved from 0.50413 to 0.39626, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6816 - loss: 0.5569 - val_accuracy: 0.8084 - val_loss: 0.3963 - learning_rate: 0.0013\n",
            "Epoch 4/12\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6924 - loss: 0.5313\n",
            "Epoch 4: val_loss did not improve from 0.39626\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6933 - loss: 0.5308 - val_accuracy: 0.8143 - val_loss: 0.3992 - learning_rate: 0.0013\n",
            "Epoch 5/12\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7212 - loss: 0.5054\n",
            "Epoch 5: val_loss improved from 0.39626 to 0.37571, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7217 - loss: 0.5051 - val_accuracy: 0.8127 - val_loss: 0.3757 - learning_rate: 0.0013\n",
            "Epoch 6/12\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7249 - loss: 0.4982\n",
            "Epoch 6: val_loss improved from 0.37571 to 0.35544, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7250 - loss: 0.4981 - val_accuracy: 0.8422 - val_loss: 0.3554 - learning_rate: 0.0013\n",
            "Epoch 7/12\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7379 - loss: 0.4856\n",
            "Epoch 7: val_loss did not improve from 0.35544\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7381 - loss: 0.4854 - val_accuracy: 0.8278 - val_loss: 0.3583 - learning_rate: 0.0013\n",
            "Epoch 8/12\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7494 - loss: 0.4721\n",
            "Epoch 8: val_loss improved from 0.35544 to 0.34892, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7496 - loss: 0.4720 - val_accuracy: 0.8498 - val_loss: 0.3489 - learning_rate: 0.0013\n",
            "Epoch 9/12\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7397 - loss: 0.4744\n",
            "Epoch 9: val_loss did not improve from 0.34892\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7404 - loss: 0.4740 - val_accuracy: 0.8253 - val_loss: 0.3823 - learning_rate: 0.0013\n",
            "Epoch 10/12\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7455 - loss: 0.4735\n",
            "Epoch 10: val_loss improved from 0.34892 to 0.32693, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7461 - loss: 0.4729 - val_accuracy: 0.8523 - val_loss: 0.3269 - learning_rate: 0.0013\n",
            "Epoch 11/12\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7544 - loss: 0.4560\n",
            "Epoch 11: val_loss did not improve from 0.32693\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7551 - loss: 0.4553 - val_accuracy: 0.8515 - val_loss: 0.3309 - learning_rate: 0.0013\n",
            "Epoch 12/12\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7643 - loss: 0.4433\n",
            "Epoch 12: val_loss did not improve from 0.32693\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7646 - loss: 0.4431 - val_accuracy: 0.8498 - val_loss: 0.3537 - learning_rate: 0.0013\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:24:28,015] Trial 25 finished with value: -0.326930969953537 and parameters: {'epochs': 12, 'batch_size': 16, 'learning_rate': 0.0013355323983946384, 'stop_patience': 4, 'reduce_lr_factor': 0.23079778621637145, 'reduce_lr_patience': 4}. Best is trial 23 with value: -0.2992369532585144.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5365 - loss: 0.6903\n",
            "Epoch 1: val_loss improved from inf to 0.74699, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5365 - loss: 0.6903 - val_accuracy: 0.5173 - val_loss: 0.7470 - learning_rate: 0.0036\n",
            "Epoch 2/15\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5634 - loss: 0.6791\n",
            "Epoch 2: val_loss improved from 0.74699 to 0.51818, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5638 - loss: 0.6787 - val_accuracy: 0.7325 - val_loss: 0.5182 - learning_rate: 0.0036\n",
            "Epoch 3/15\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6367 - loss: 0.6115\n",
            "Epoch 3: val_loss improved from 0.51818 to 0.49289, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6368 - loss: 0.6113 - val_accuracy: 0.7376 - val_loss: 0.4929 - learning_rate: 0.0036\n",
            "Epoch 4/15\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6984 - loss: 0.5501\n",
            "Epoch 4: val_loss improved from 0.49289 to 0.38508, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6988 - loss: 0.5495 - val_accuracy: 0.8414 - val_loss: 0.3851 - learning_rate: 0.0036\n",
            "Epoch 5/15\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7124 - loss: 0.5168\n",
            "Epoch 5: val_loss did not improve from 0.38508\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7126 - loss: 0.5167 - val_accuracy: 0.7966 - val_loss: 0.4849 - learning_rate: 0.0036\n",
            "Epoch 6/15\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7084 - loss: 0.5181\n",
            "Epoch 6: val_loss improved from 0.38508 to 0.38387, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7084 - loss: 0.5180 - val_accuracy: 0.8262 - val_loss: 0.3839 - learning_rate: 0.0036\n",
            "Epoch 7/15\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7227 - loss: 0.4944\n",
            "Epoch 7: val_loss did not improve from 0.38387\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7229 - loss: 0.4943 - val_accuracy: 0.7848 - val_loss: 0.4782 - learning_rate: 0.0036\n",
            "Epoch 8/15\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.4886\n",
            "Epoch 8: val_loss improved from 0.38387 to 0.37622, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7368 - loss: 0.4880 - val_accuracy: 0.8262 - val_loss: 0.3762 - learning_rate: 0.0036\n",
            "Epoch 9/15\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7282 - loss: 0.4889\n",
            "Epoch 9: val_loss did not improve from 0.37622\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7286 - loss: 0.4886 - val_accuracy: 0.8354 - val_loss: 0.3828 - learning_rate: 0.0036\n",
            "Epoch 10/15\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7465 - loss: 0.4783\n",
            "Epoch 10: val_loss did not improve from 0.37622\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7465 - loss: 0.4782 - val_accuracy: 0.7511 - val_loss: 0.8615 - learning_rate: 0.0036\n",
            "Epoch 11/15\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7583 - loss: 0.4682\n",
            "Epoch 11: val_loss improved from 0.37622 to 0.36859, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7587 - loss: 0.4675 - val_accuracy: 0.8270 - val_loss: 0.3686 - learning_rate: 0.0036\n",
            "Epoch 12/15\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7378 - loss: 0.4677\n",
            "Epoch 12: val_loss did not improve from 0.36859\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7385 - loss: 0.4673 - val_accuracy: 0.8439 - val_loss: 0.4059 - learning_rate: 0.0036\n",
            "Epoch 13/15\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7511 - loss: 0.4580\n",
            "Epoch 13: val_loss did not improve from 0.36859\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7519 - loss: 0.4575 - val_accuracy: 0.8143 - val_loss: 0.3905 - learning_rate: 0.0036\n",
            "Epoch 14/15\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7591 - loss: 0.4523\n",
            "Epoch 14: val_loss improved from 0.36859 to 0.34970, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7593 - loss: 0.4522 - val_accuracy: 0.8473 - val_loss: 0.3497 - learning_rate: 0.0036\n",
            "Epoch 15/15\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7644 - loss: 0.4442\n",
            "Epoch 15: val_loss did not improve from 0.34970\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7647 - loss: 0.4438 - val_accuracy: 0.8329 - val_loss: 0.3802 - learning_rate: 0.0036\n",
            "Restoring model weights from the end of the best epoch: 14.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:24:59,101] Trial 26 finished with value: -0.3496985137462616 and parameters: {'epochs': 15, 'batch_size': 16, 'learning_rate': 0.003570055972303471, 'stop_patience': 5, 'reduce_lr_factor': 0.17644525236344005, 'reduce_lr_patience': 3}. Best is trial 23 with value: -0.2992369532585144.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5615 - loss: 0.6866\n",
            "Epoch 1: val_loss improved from inf to 0.54529, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5617 - loss: 0.6864 - val_accuracy: 0.7384 - val_loss: 0.5453 - learning_rate: 0.0020\n",
            "Epoch 2/20\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6302 - loss: 0.6199\n",
            "Epoch 2: val_loss improved from 0.54529 to 0.41614, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6306 - loss: 0.6194 - val_accuracy: 0.8228 - val_loss: 0.4161 - learning_rate: 0.0020\n",
            "Epoch 3/20\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6947 - loss: 0.5541\n",
            "Epoch 3: val_loss did not improve from 0.41614\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6949 - loss: 0.5540 - val_accuracy: 0.7316 - val_loss: 0.6061 - learning_rate: 0.0020\n",
            "Epoch 4/20\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6991 - loss: 0.5453\n",
            "Epoch 4: val_loss did not improve from 0.41614\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6992 - loss: 0.5452 - val_accuracy: 0.7570 - val_loss: 0.5513 - learning_rate: 0.0020\n",
            "Epoch 5/20\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7045 - loss: 0.5253\n",
            "Epoch 5: val_loss did not improve from 0.41614\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7046 - loss: 0.5252 - val_accuracy: 0.7266 - val_loss: 0.6051 - learning_rate: 0.0020\n",
            "Epoch 6/20\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7243 - loss: 0.5044\n",
            "Epoch 6: val_loss improved from 0.41614 to 0.35908, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7248 - loss: 0.5035 - val_accuracy: 0.8464 - val_loss: 0.3591 - learning_rate: 0.0020\n",
            "Epoch 7/20\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7356 - loss: 0.4859\n",
            "Epoch 7: val_loss improved from 0.35908 to 0.33841, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7357 - loss: 0.4858 - val_accuracy: 0.8473 - val_loss: 0.3384 - learning_rate: 0.0020\n",
            "Epoch 8/20\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7349 - loss: 0.4869\n",
            "Epoch 8: val_loss did not improve from 0.33841\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7356 - loss: 0.4861 - val_accuracy: 0.8262 - val_loss: 0.3961 - learning_rate: 0.0020\n",
            "Epoch 9/20\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7463 - loss: 0.4680\n",
            "Epoch 9: val_loss did not improve from 0.33841\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7466 - loss: 0.4673 - val_accuracy: 0.7899 - val_loss: 0.4405 - learning_rate: 0.0020\n",
            "Epoch 10/20\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7646 - loss: 0.4614\n",
            "Epoch 10: val_loss did not improve from 0.33841\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7646 - loss: 0.4608 - val_accuracy: 0.7755 - val_loss: 0.5047 - learning_rate: 0.0020\n",
            "Epoch 11/20\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7483 - loss: 0.4655\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0006404240827478399.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.33841\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7488 - loss: 0.4650 - val_accuracy: 0.8262 - val_loss: 0.3915 - learning_rate: 0.0020\n",
            "Epoch 12/20\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7694 - loss: 0.4366\n",
            "Epoch 12: val_loss did not improve from 0.33841\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7697 - loss: 0.4362 - val_accuracy: 0.8363 - val_loss: 0.3669 - learning_rate: 6.4042e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.3989\n",
            "Epoch 13: val_loss improved from 0.33841 to 0.33624, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7979 - loss: 0.3983 - val_accuracy: 0.8557 - val_loss: 0.3362 - learning_rate: 6.4042e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8003 - loss: 0.3858\n",
            "Epoch 14: val_loss improved from 0.33624 to 0.33135, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8003 - loss: 0.3858 - val_accuracy: 0.8515 - val_loss: 0.3313 - learning_rate: 6.4042e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8134 - loss: 0.3817\n",
            "Epoch 15: val_loss did not improve from 0.33135\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8136 - loss: 0.3814 - val_accuracy: 0.8616 - val_loss: 0.3338 - learning_rate: 6.4042e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8204 - loss: 0.3742\n",
            "Epoch 16: val_loss did not improve from 0.33135\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8207 - loss: 0.3736 - val_accuracy: 0.8549 - val_loss: 0.3357 - learning_rate: 6.4042e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8170 - loss: 0.3700\n",
            "Epoch 17: val_loss improved from 0.33135 to 0.32742, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8170 - loss: 0.3699 - val_accuracy: 0.8565 - val_loss: 0.3274 - learning_rate: 6.4042e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8233 - loss: 0.3656\n",
            "Epoch 18: val_loss improved from 0.32742 to 0.31586, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8234 - loss: 0.3655 - val_accuracy: 0.8658 - val_loss: 0.3159 - learning_rate: 6.4042e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8186 - loss: 0.3662\n",
            "Epoch 19: val_loss did not improve from 0.31586\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8193 - loss: 0.3654 - val_accuracy: 0.8582 - val_loss: 0.3395 - learning_rate: 6.4042e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8272 - loss: 0.3649\n",
            "Epoch 20: val_loss did not improve from 0.31586\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8273 - loss: 0.3648 - val_accuracy: 0.8532 - val_loss: 0.3295 - learning_rate: 6.4042e-04\n",
            "Restoring model weights from the end of the best epoch: 18.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:25:39,326] Trial 27 finished with value: -0.3158554136753082 and parameters: {'epochs': 20, 'batch_size': 16, 'learning_rate': 0.0020243864215191308, 'stop_patience': 7, 'reduce_lr_factor': 0.31635467958056274, 'reduce_lr_patience': 4}. Best is trial 23 with value: -0.2992369532585144.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/27\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5405 - loss: 0.6916\n",
            "Epoch 1: val_loss improved from inf to 0.67991, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.5409 - loss: 0.6915 - val_accuracy: 0.6287 - val_loss: 0.6799 - learning_rate: 0.0045\n",
            "Epoch 2/27\n",
            "\u001b[1m136/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5563 - loss: 0.6827\n",
            "Epoch 2: val_loss did not improve from 0.67991\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5576 - loss: 0.6817 - val_accuracy: 0.4321 - val_loss: 0.9825 - learning_rate: 0.0045\n",
            "Epoch 3/27\n",
            "\u001b[1m147/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6418 - loss: 0.6151\n",
            "Epoch 3: val_loss did not improve from 0.67991\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6420 - loss: 0.6150 - val_accuracy: 0.5975 - val_loss: 0.8166 - learning_rate: 0.0045\n",
            "Epoch 4/27\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6817 - loss: 0.5645\n",
            "Epoch 4: val_loss did not improve from 0.67991\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6819 - loss: 0.5642 - val_accuracy: 0.4954 - val_loss: 1.1881 - learning_rate: 0.0045\n",
            "Epoch 5/27\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7016 - loss: 0.5380\n",
            "Epoch 5: val_loss improved from 0.67991 to 0.65182, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7018 - loss: 0.5377 - val_accuracy: 0.7224 - val_loss: 0.6518 - learning_rate: 0.0045\n",
            "Epoch 6/27\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7015 - loss: 0.5210\n",
            "Epoch 6: val_loss improved from 0.65182 to 0.39432, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7019 - loss: 0.5206 - val_accuracy: 0.8093 - val_loss: 0.3943 - learning_rate: 0.0045\n",
            "Epoch 7/27\n",
            "\u001b[1m135/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6983 - loss: 0.5169\n",
            "Epoch 7: val_loss did not improve from 0.39432\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6994 - loss: 0.5168 - val_accuracy: 0.8093 - val_loss: 0.3972 - learning_rate: 0.0045\n",
            "Epoch 8/27\n",
            "\u001b[1m137/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7255 - loss: 0.5066\n",
            "Epoch 8: val_loss improved from 0.39432 to 0.38876, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7261 - loss: 0.5053 - val_accuracy: 0.8152 - val_loss: 0.3888 - learning_rate: 0.0045\n",
            "Epoch 9/27\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7301 - loss: 0.4931\n",
            "Epoch 9: val_loss did not improve from 0.38876\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7302 - loss: 0.4930 - val_accuracy: 0.7713 - val_loss: 0.5525 - learning_rate: 0.0045\n",
            "Epoch 10/27\n",
            "\u001b[1m146/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7170 - loss: 0.5061\n",
            "Epoch 10: val_loss improved from 0.38876 to 0.36383, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7173 - loss: 0.5055 - val_accuracy: 0.8295 - val_loss: 0.3638 - learning_rate: 0.0045\n",
            "Epoch 11/27\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7458 - loss: 0.4797\n",
            "Epoch 11: val_loss improved from 0.36383 to 0.35670, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7458 - loss: 0.4795 - val_accuracy: 0.8253 - val_loss: 0.3567 - learning_rate: 0.0045\n",
            "Epoch 12/27\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7232 - loss: 0.4859\n",
            "Epoch 12: val_loss did not improve from 0.35670\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7242 - loss: 0.4850 - val_accuracy: 0.8177 - val_loss: 0.4185 - learning_rate: 0.0045\n",
            "Epoch 13/27\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7477 - loss: 0.4716\n",
            "Epoch 13: val_loss did not improve from 0.35670\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7482 - loss: 0.4710 - val_accuracy: 0.8177 - val_loss: 0.4376 - learning_rate: 0.0045\n",
            "Epoch 14/27\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7581 - loss: 0.4606\n",
            "Epoch 14: val_loss did not improve from 0.35670\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7582 - loss: 0.4605 - val_accuracy: 0.8051 - val_loss: 0.4363 - learning_rate: 0.0045\n",
            "Epoch 15/27\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7638 - loss: 0.4507\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005899857668813009.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.35670\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7642 - loss: 0.4498 - val_accuracy: 0.8211 - val_loss: 0.4246 - learning_rate: 0.0045\n",
            "Epoch 16/27\n",
            "\u001b[1m146/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8004 - loss: 0.4113\n",
            "Epoch 16: val_loss did not improve from 0.35670\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8007 - loss: 0.4108 - val_accuracy: 0.8076 - val_loss: 0.4265 - learning_rate: 5.8999e-04\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:26:01,590] Trial 28 finished with value: -0.356697142124176 and parameters: {'epochs': 27, 'batch_size': 32, 'learning_rate': 0.004488962358622572, 'stop_patience': 5, 'reduce_lr_factor': 0.1314303252644311, 'reduce_lr_patience': 4}. Best is trial 23 with value: -0.2992369532585144.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/42\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5624 - loss: 0.6888\n",
            "Epoch 1: val_loss improved from inf to 0.70012, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5625 - loss: 0.6888 - val_accuracy: 0.4658 - val_loss: 0.7001 - learning_rate: 9.9726e-04\n",
            "Epoch 2/42\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5900 - loss: 0.6676\n",
            "Epoch 2: val_loss improved from 0.70012 to 0.53226, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5914 - loss: 0.6663 - val_accuracy: 0.7131 - val_loss: 0.5323 - learning_rate: 9.9726e-04\n",
            "Epoch 3/42\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6430 - loss: 0.6123\n",
            "Epoch 3: val_loss improved from 0.53226 to 0.40229, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6441 - loss: 0.6112 - val_accuracy: 0.8186 - val_loss: 0.4023 - learning_rate: 9.9726e-04\n",
            "Epoch 4/42\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6832 - loss: 0.5705\n",
            "Epoch 4: val_loss did not improve from 0.40229\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6833 - loss: 0.5703 - val_accuracy: 0.7713 - val_loss: 0.5691 - learning_rate: 9.9726e-04\n",
            "Epoch 5/42\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6872 - loss: 0.5442\n",
            "Epoch 5: val_loss improved from 0.40229 to 0.39019, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6880 - loss: 0.5431 - val_accuracy: 0.8236 - val_loss: 0.3902 - learning_rate: 9.9726e-04\n",
            "Epoch 6/42\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7050 - loss: 0.5210\n",
            "Epoch 6: val_loss improved from 0.39019 to 0.36652, saving model to BEST_CNN_SEQ_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7063 - loss: 0.5201 - val_accuracy: 0.8354 - val_loss: 0.3665 - learning_rate: 9.9726e-04\n",
            "Epoch 7/42\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7222 - loss: 0.5098\n",
            "Epoch 7: val_loss did not improve from 0.36652\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7223 - loss: 0.5096 - val_accuracy: 0.7198 - val_loss: 0.5560 - learning_rate: 9.9726e-04\n",
            "Epoch 8/42\n",
            "\u001b[1m66/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7368 - loss: 0.4905\n",
            "Epoch 8: val_loss did not improve from 0.36652\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7375 - loss: 0.4905 - val_accuracy: 0.7983 - val_loss: 0.4721 - learning_rate: 9.9726e-04\n",
            "Epoch 9/42\n",
            "\u001b[1m65/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7406 - loss: 0.4863\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00024888580407491756.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.36652\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7416 - loss: 0.4853 - val_accuracy: 0.8076 - val_loss: 0.3969 - learning_rate: 9.9726e-04\n",
            "Epoch 10/42\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7714 - loss: 0.4496\n",
            "Epoch 10: val_loss did not improve from 0.36652\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7716 - loss: 0.4493 - val_accuracy: 0.7840 - val_loss: 0.4585 - learning_rate: 2.4889e-04\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:26:11,523] Trial 29 finished with value: -0.3665199875831604 and parameters: {'epochs': 42, 'batch_size': 64, 'learning_rate': 0.0009972626825711542, 'stop_patience': 4, 'reduce_lr_factor': 0.2495689597652122, 'reduce_lr_patience': 3}. Best is trial 23 with value: -0.2992369532585144.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Melhor combinação encontrada:\n",
            "trial                  23.000000\n",
            "epochs                 20.000000\n",
            "batch_size             16.000000\n",
            "learning_rate           0.001977\n",
            "stop_patience           5.000000\n",
            "reduce_lr_factor        0.173218\n",
            "reduce_lr_patience      4.000000\n",
            "recall_Compra(1)        0.852823\n",
            "recall_Vende(0)         0.875181\n",
            "precision_Compra(1)     0.831041\n",
            "precision_Vende(0)      0.892012\n",
            "macro_recall            0.864002\n",
            "accuracy                0.865823\n",
            "f1_macro                0.862654\n",
            "f1_weighted             0.866052\n",
            "min_val_loss            0.299237\n",
            "Name: 0, dtype: float64\n",
            "🔍 Hiperparâmetros: {'epochs': 20, 'batch_size': 16, 'learning_rate': 0.0019772383596792587, 'stop_patience': 5, 'reduce_lr_factor': 0.17321834212101725, 'reduce_lr_patience': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_ram_model, best_ram_history, df_results, best_ram_metrics, best_ram_y_pred = train_model(\n",
        "    model_fn=model_cnn_ramificado,\n",
        "    model_path = \"BEST_CNN_RAM_BBAS3.keras\",\n",
        "    X_train=[X_train1, X_train2],\n",
        "    y_train=y_train,\n",
        "    X_test=[X_test1, X_test2],\n",
        "    y_test=y_test,\n",
        "    prob=0.5,\n",
        "    n_trials=30,\n",
        "    metric_to_optimize=metric_optimization\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--EYr2kVhY7c",
        "outputId": "e800ddb1-8401-4dd4-a5d4-e8035d148bf6",
        "collapsed": true
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:26:11,540] A new study created in memory with name: no-name-cdfa3d72-135b-4b17-8949-a92637b30324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/31\n",
            "\u001b[1m132/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5796 - loss: 0.6849\n",
            "Epoch 1: val_loss improved from inf to 0.93564, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5812 - loss: 0.6826 - val_accuracy: 0.5300 - val_loss: 0.9356 - learning_rate: 0.0085\n",
            "Epoch 2/31\n",
            "\u001b[1m133/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6847 - loss: 0.5691\n",
            "Epoch 2: val_loss improved from 0.93564 to 0.27595, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6852 - loss: 0.5690 - val_accuracy: 0.8895 - val_loss: 0.2760 - learning_rate: 0.0085\n",
            "Epoch 3/31\n",
            "\u001b[1m132/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7191 - loss: 0.5127\n",
            "Epoch 3: val_loss improved from 0.27595 to 0.27416, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7189 - loss: 0.5127 - val_accuracy: 0.8903 - val_loss: 0.2742 - learning_rate: 0.0085\n",
            "Epoch 4/31\n",
            "\u001b[1m132/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.5010\n",
            "Epoch 4: val_loss did not improve from 0.27416\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7291 - loss: 0.5011 - val_accuracy: 0.8895 - val_loss: 0.2836 - learning_rate: 0.0085\n",
            "Epoch 5/31\n",
            "\u001b[1m146/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7415 - loss: 0.4666\n",
            "Epoch 5: val_loss improved from 0.27416 to 0.26686, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7414 - loss: 0.4667 - val_accuracy: 0.8810 - val_loss: 0.2669 - learning_rate: 0.0085\n",
            "Epoch 6/31\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7445 - loss: 0.4825\n",
            "Epoch 6: val_loss did not improve from 0.26686\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7445 - loss: 0.4823 - val_accuracy: 0.8025 - val_loss: 0.4209 - learning_rate: 0.0085\n",
            "Epoch 7/31\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7545 - loss: 0.4534\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0016937728495551958.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.26686\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7544 - loss: 0.4536 - val_accuracy: 0.8447 - val_loss: 0.3307 - learning_rate: 0.0085\n",
            "Epoch 8/31\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7756 - loss: 0.4289\n",
            "Epoch 8: val_loss did not improve from 0.26686\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7765 - loss: 0.4280 - val_accuracy: 0.8945 - val_loss: 0.2710 - learning_rate: 0.0017\n",
            "Epoch 9/31\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8029 - loss: 0.4035\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00033737384452652323.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.26686\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.4033 - val_accuracy: 0.8844 - val_loss: 0.2779 - learning_rate: 0.0017\n",
            "Epoch 10/31\n",
            "\u001b[1m129/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8098 - loss: 0.3871\n",
            "Epoch 10: val_loss did not improve from 0.26686\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8105 - loss: 0.3870 - val_accuracy: 0.8270 - val_loss: 0.3577 - learning_rate: 3.3737e-04\n",
            "Epoch 11/31\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8157 - loss: 0.3822\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 6.719974915005909e-05.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.26686\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8160 - loss: 0.3821 - val_accuracy: 0.8270 - val_loss: 0.3576 - learning_rate: 3.3737e-04\n",
            "Epoch 12/31\n",
            "\u001b[1m130/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8364 - loss: 0.3738\n",
            "Epoch 12: val_loss did not improve from 0.26686\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8362 - loss: 0.3737 - val_accuracy: 0.8270 - val_loss: 0.3544 - learning_rate: 6.7200e-05\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:26:25,452] Trial 0 finished with value: -0.26685887575149536 and parameters: {'epochs': 31, 'batch_size': 32, 'learning_rate': 0.008503523308395624, 'stop_patience': 7, 'reduce_lr_factor': 0.19918482246031155, 'reduce_lr_patience': 2}. Best is trial 0 with value: -0.26685887575149536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/37\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5839 - loss: 0.6786\n",
            "Epoch 1: val_loss improved from inf to 0.43488, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5852 - loss: 0.6773 - val_accuracy: 0.8380 - val_loss: 0.4349 - learning_rate: 0.0012\n",
            "Epoch 2/37\n",
            "\u001b[1m277/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6658 - loss: 0.6037\n",
            "Epoch 2: val_loss did not improve from 0.43488\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6666 - loss: 0.6030 - val_accuracy: 0.7637 - val_loss: 0.4639 - learning_rate: 0.0012\n",
            "Epoch 3/37\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7044 - loss: 0.5374\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.000444938235506921.\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.43488\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7044 - loss: 0.5374 - val_accuracy: 0.7797 - val_loss: 0.4405 - learning_rate: 0.0012\n",
            "Epoch 4/37\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7366 - loss: 0.4958\n",
            "Epoch 4: val_loss improved from 0.43488 to 0.32789, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.4955 - val_accuracy: 0.8489 - val_loss: 0.3279 - learning_rate: 4.4494e-04\n",
            "Epoch 5/37\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7614 - loss: 0.4741\n",
            "Epoch 5: val_loss improved from 0.32789 to 0.32267, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7614 - loss: 0.4741 - val_accuracy: 0.8532 - val_loss: 0.3227 - learning_rate: 4.4494e-04\n",
            "Epoch 6/37\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7545 - loss: 0.4678\n",
            "Epoch 6: val_loss did not improve from 0.32267\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7546 - loss: 0.4678 - val_accuracy: 0.8236 - val_loss: 0.3888 - learning_rate: 4.4494e-04\n",
            "Epoch 7/37\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7680 - loss: 0.4599\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00016366848459238313.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.32267\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7680 - loss: 0.4599 - val_accuracy: 0.8118 - val_loss: 0.4496 - learning_rate: 4.4494e-04\n",
            "Epoch 8/37\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7763 - loss: 0.4408\n",
            "Epoch 8: val_loss improved from 0.32267 to 0.27826, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7764 - loss: 0.4407 - val_accuracy: 0.8768 - val_loss: 0.2783 - learning_rate: 1.6367e-04\n",
            "Epoch 9/37\n",
            "\u001b[1m279/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7868 - loss: 0.4330\n",
            "Epoch 9: val_loss did not improve from 0.27826\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7868 - loss: 0.4330 - val_accuracy: 0.8776 - val_loss: 0.2838 - learning_rate: 1.6367e-04\n",
            "Epoch 10/37\n",
            "\u001b[1m277/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7919 - loss: 0.4351\n",
            "Epoch 10: val_loss improved from 0.27826 to 0.27416, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7921 - loss: 0.4347 - val_accuracy: 0.8802 - val_loss: 0.2742 - learning_rate: 1.6367e-04\n",
            "Epoch 11/37\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8017 - loss: 0.4256\n",
            "Epoch 11: val_loss improved from 0.27416 to 0.27235, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8017 - loss: 0.4255 - val_accuracy: 0.8827 - val_loss: 0.2723 - learning_rate: 1.6367e-04\n",
            "Epoch 12/37\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8045 - loss: 0.4247\n",
            "Epoch 12: val_loss did not improve from 0.27235\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8044 - loss: 0.4246 - val_accuracy: 0.8819 - val_loss: 0.2732 - learning_rate: 1.6367e-04\n",
            "Epoch 13/37\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.4226\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.020470315164172e-05.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.27235\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7987 - loss: 0.4225 - val_accuracy: 0.8793 - val_loss: 0.2751 - learning_rate: 1.6367e-04\n",
            "Epoch 14/37\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8109 - loss: 0.4154\n",
            "Epoch 14: val_loss did not improve from 0.27235\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8108 - loss: 0.4153 - val_accuracy: 0.8574 - val_loss: 0.3190 - learning_rate: 6.0205e-05\n",
            "Epoch 15/37\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8114 - loss: 0.4110\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.214602410366993e-05.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.27235\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8114 - loss: 0.4109 - val_accuracy: 0.8616 - val_loss: 0.3088 - learning_rate: 6.0205e-05\n",
            "Epoch 16/37\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8166 - loss: 0.4158\n",
            "Epoch 16: val_loss did not improve from 0.27235\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8166 - loss: 0.4158 - val_accuracy: 0.8515 - val_loss: 0.3221 - learning_rate: 2.2146e-05\n",
            "Epoch 17/37\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8136 - loss: 0.4098\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 8.146313687101213e-06.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.27235\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8136 - loss: 0.4098 - val_accuracy: 0.8667 - val_loss: 0.2966 - learning_rate: 2.2146e-05\n",
            "Epoch 18/37\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8069 - loss: 0.4151\n",
            "Epoch 18: val_loss did not improve from 0.27235\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8072 - loss: 0.4147 - val_accuracy: 0.8489 - val_loss: 0.3232 - learning_rate: 8.1463e-06\n",
            "Epoch 19/37\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8132 - loss: 0.4131\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.996584239213588e-06.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.27235\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8132 - loss: 0.4129 - val_accuracy: 0.8515 - val_loss: 0.3166 - learning_rate: 8.1463e-06\n",
            "Epoch 20/37\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8142 - loss: 0.4110\n",
            "Epoch 20: val_loss did not improve from 0.27235\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8142 - loss: 0.4110 - val_accuracy: 0.8489 - val_loss: 0.3198 - learning_rate: 2.9966e-06\n",
            "Epoch 21/37\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8147 - loss: 0.4127\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.1022797753121082e-06.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.27235\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8147 - loss: 0.4126 - val_accuracy: 0.8498 - val_loss: 0.3165 - learning_rate: 2.9966e-06\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:26:55,158] Trial 1 finished with value: -0.27234846353530884 and parameters: {'epochs': 37, 'batch_size': 16, 'learning_rate': 0.0012095793746372085, 'stop_patience': 10, 'reduce_lr_factor': 0.36784541180353114, 'reduce_lr_patience': 2}. Best is trial 0 with value: -0.26685887575149536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/31\n",
            "\u001b[1m69/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5847 - loss: 0.6765\n",
            "Epoch 1: val_loss improved from inf to 0.37546, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5867 - loss: 0.6746 - val_accuracy: 0.8802 - val_loss: 0.3755 - learning_rate: 0.0083\n",
            "Epoch 2/31\n",
            "\u001b[1m60/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6468 - loss: 0.6075\n",
            "Epoch 2: val_loss did not improve from 0.37546\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6505 - loss: 0.6039 - val_accuracy: 0.7840 - val_loss: 0.4200 - learning_rate: 0.0083\n",
            "Epoch 3/31\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7095 - loss: 0.5244\n",
            "Epoch 3: val_loss improved from 0.37546 to 0.29659, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7096 - loss: 0.5244 - val_accuracy: 0.8751 - val_loss: 0.2966 - learning_rate: 0.0083\n",
            "Epoch 4/31\n",
            "\u001b[1m60/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7055 - loss: 0.5132\n",
            "Epoch 4: val_loss did not improve from 0.29659\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7062 - loss: 0.5118 - val_accuracy: 0.8422 - val_loss: 0.3324 - learning_rate: 0.0083\n",
            "Epoch 5/31\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7256 - loss: 0.4825\n",
            "Epoch 5: val_loss improved from 0.29659 to 0.25839, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7256 - loss: 0.4818 - val_accuracy: 0.8970 - val_loss: 0.2584 - learning_rate: 0.0083\n",
            "Epoch 6/31\n",
            "\u001b[1m61/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7530 - loss: 0.4701\n",
            "Epoch 6: val_loss did not improve from 0.25839\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7526 - loss: 0.4691 - val_accuracy: 0.8962 - val_loss: 0.2586 - learning_rate: 0.0083\n",
            "Epoch 7/31\n",
            "\u001b[1m66/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7437 - loss: 0.4697\n",
            "Epoch 7: val_loss did not improve from 0.25839\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7436 - loss: 0.4691 - val_accuracy: 0.8017 - val_loss: 0.4815 - learning_rate: 0.0083\n",
            "Epoch 8/31\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7665 - loss: 0.4413\n",
            "Epoch 8: val_loss did not improve from 0.25839\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7666 - loss: 0.4412 - val_accuracy: 0.8827 - val_loss: 0.2728 - learning_rate: 0.0083\n",
            "Epoch 9/31\n",
            "\u001b[1m69/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7746 - loss: 0.4429\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.003050540894987254.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.25839\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7744 - loss: 0.4427 - val_accuracy: 0.8101 - val_loss: 0.4019 - learning_rate: 0.0083\n",
            "Epoch 10/31\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7941 - loss: 0.4183\n",
            "Epoch 10: val_loss improved from 0.25839 to 0.25567, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7941 - loss: 0.4179 - val_accuracy: 0.8937 - val_loss: 0.2557 - learning_rate: 0.0031\n",
            "Epoch 11/31\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8015 - loss: 0.3933\n",
            "Epoch 11: val_loss did not improve from 0.25567\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8014 - loss: 0.3935 - val_accuracy: 0.8835 - val_loss: 0.2687 - learning_rate: 0.0031\n",
            "Epoch 12/31\n",
            "\u001b[1m61/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8019 - loss: 0.3954\n",
            "Epoch 12: val_loss did not improve from 0.25567\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8025 - loss: 0.3949 - val_accuracy: 0.8937 - val_loss: 0.2801 - learning_rate: 0.0031\n",
            "Epoch 13/31\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.3906\n",
            "Epoch 13: val_loss did not improve from 0.25567\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8035 - loss: 0.3906 - val_accuracy: 0.8667 - val_loss: 0.3036 - learning_rate: 0.0031\n",
            "Epoch 14/31\n",
            "\u001b[1m61/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8077 - loss: 0.3882\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.001117435312650662.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.25567\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.3869 - val_accuracy: 0.8852 - val_loss: 0.2800 - learning_rate: 0.0031\n",
            "Epoch 15/31\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8353 - loss: 0.3653\n",
            "Epoch 15: val_loss did not improve from 0.25567\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8353 - loss: 0.3652 - val_accuracy: 0.8017 - val_loss: 0.4593 - learning_rate: 0.0011\n",
            "Epoch 16/31\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8443 - loss: 0.3586\n",
            "Epoch 16: val_loss did not improve from 0.25567\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8442 - loss: 0.3586 - val_accuracy: 0.8354 - val_loss: 0.3808 - learning_rate: 0.0011\n",
            "Epoch 17/31\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8449 - loss: 0.3557\n",
            "Epoch 17: val_loss did not improve from 0.25567\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8449 - loss: 0.3557 - val_accuracy: 0.8059 - val_loss: 0.4538 - learning_rate: 0.0011\n",
            "Epoch 18/31\n",
            "\u001b[1m60/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8476 - loss: 0.3522\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0004093246820840899.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.25567\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8472 - loss: 0.3518 - val_accuracy: 0.8017 - val_loss: 0.4325 - learning_rate: 0.0011\n",
            "Epoch 19/31\n",
            "\u001b[1m60/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8559 - loss: 0.3445\n",
            "Epoch 19: val_loss did not improve from 0.25567\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8557 - loss: 0.3442 - val_accuracy: 0.8076 - val_loss: 0.3866 - learning_rate: 4.0932e-04\n",
            "Epoch 20/31\n",
            "\u001b[1m61/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8574 - loss: 0.3316\n",
            "Epoch 20: val_loss did not improve from 0.25567\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.3327 - val_accuracy: 0.8135 - val_loss: 0.3545 - learning_rate: 4.0932e-04\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:27:10,763] Trial 2 finished with value: -0.25567013025283813 and parameters: {'epochs': 31, 'batch_size': 64, 'learning_rate': 0.008327819059289357, 'stop_patience': 10, 'reduce_lr_factor': 0.3663072823635134, 'reduce_lr_patience': 4}. Best is trial 2 with value: -0.25567013025283813.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/11\n",
            "\u001b[1m69/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5750 - loss: 0.6850\n",
            "Epoch 1: val_loss improved from inf to 0.44941, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5764 - loss: 0.6834 - val_accuracy: 0.8700 - val_loss: 0.4494 - learning_rate: 0.0043\n",
            "Epoch 2/11\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6621 - loss: 0.5944\n",
            "Epoch 2: val_loss improved from 0.44941 to 0.30744, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6630 - loss: 0.5934 - val_accuracy: 0.8641 - val_loss: 0.3074 - learning_rate: 0.0043\n",
            "Epoch 3/11\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6901 - loss: 0.5397\n",
            "Epoch 3: val_loss did not improve from 0.30744\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6907 - loss: 0.5391 - val_accuracy: 0.8549 - val_loss: 0.3222 - learning_rate: 0.0043\n",
            "Epoch 4/11\n",
            "\u001b[1m67/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6999 - loss: 0.5225\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0010112561242671873.\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.30744\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7014 - loss: 0.5224 - val_accuracy: 0.8439 - val_loss: 0.3443 - learning_rate: 0.0043\n",
            "Epoch 5/11\n",
            "\u001b[1m67/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7494 - loss: 0.4713\n",
            "Epoch 5: val_loss did not improve from 0.30744\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7497 - loss: 0.4707 - val_accuracy: 0.8464 - val_loss: 0.3361 - learning_rate: 0.0010\n",
            "Epoch 6/11\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7642 - loss: 0.4562\n",
            "Epoch 6: val_loss improved from 0.30744 to 0.28194, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7646 - loss: 0.4559 - val_accuracy: 0.8751 - val_loss: 0.2819 - learning_rate: 0.0010\n",
            "Epoch 7/11\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7732 - loss: 0.4478\n",
            "Epoch 7: val_loss improved from 0.28194 to 0.26883, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7735 - loss: 0.4476 - val_accuracy: 0.8835 - val_loss: 0.2688 - learning_rate: 0.0010\n",
            "Epoch 8/11\n",
            "\u001b[1m67/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7683 - loss: 0.4420\n",
            "Epoch 8: val_loss did not improve from 0.26883\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7689 - loss: 0.4417 - val_accuracy: 0.8734 - val_loss: 0.2881 - learning_rate: 0.0010\n",
            "Epoch 9/11\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7898 - loss: 0.4342\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00023668451093598222.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.26883\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7895 - loss: 0.4342 - val_accuracy: 0.8776 - val_loss: 0.2878 - learning_rate: 0.0010\n",
            "Epoch 10/11\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7852 - loss: 0.4311\n",
            "Epoch 10: val_loss did not improve from 0.26883\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7854 - loss: 0.4305 - val_accuracy: 0.8709 - val_loss: 0.2875 - learning_rate: 2.3668e-04\n",
            "Epoch 11/11\n",
            "\u001b[1m69/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.4207\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 5.539601394790941e-05.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.26883\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.4205 - val_accuracy: 0.8540 - val_loss: 0.3042 - learning_rate: 2.3668e-04\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:27:19,253] Trial 3 finished with value: -0.2688263952732086 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 0.004320684004082756, 'stop_patience': 9, 'reduce_lr_factor': 0.23405001389257737, 'reduce_lr_patience': 2}. Best is trial 2 with value: -0.25567013025283813.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/48\n",
            "\u001b[1m146/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5836 - loss: 0.6762\n",
            "Epoch 1: val_loss improved from inf to 1.41385, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.5844 - loss: 0.6756 - val_accuracy: 0.4616 - val_loss: 1.4139 - learning_rate: 0.0043\n",
            "Epoch 2/48\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6768 - loss: 0.5748\n",
            "Epoch 2: val_loss improved from 1.41385 to 0.36375, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6768 - loss: 0.5748 - val_accuracy: 0.8304 - val_loss: 0.3638 - learning_rate: 0.0043\n",
            "Epoch 3/48\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7109 - loss: 0.5236\n",
            "Epoch 3: val_loss did not improve from 0.36375\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7111 - loss: 0.5235 - val_accuracy: 0.7603 - val_loss: 0.4667 - learning_rate: 0.0043\n",
            "Epoch 4/48\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7263 - loss: 0.4914\n",
            "Epoch 4: val_loss improved from 0.36375 to 0.26890, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7265 - loss: 0.4913 - val_accuracy: 0.8920 - val_loss: 0.2689 - learning_rate: 0.0043\n",
            "Epoch 5/48\n",
            "\u001b[1m134/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7342 - loss: 0.4726\n",
            "Epoch 5: val_loss did not improve from 0.26890\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7351 - loss: 0.4722 - val_accuracy: 0.8152 - val_loss: 0.4131 - learning_rate: 0.0043\n",
            "Epoch 6/48\n",
            "\u001b[1m145/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7388 - loss: 0.4660\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0013266112321367763.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.26890\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7390 - loss: 0.4661 - val_accuracy: 0.8785 - val_loss: 0.3007 - learning_rate: 0.0043\n",
            "Epoch 7/48\n",
            "\u001b[1m138/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7630 - loss: 0.4292\n",
            "Epoch 7: val_loss improved from 0.26890 to 0.26121, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7637 - loss: 0.4291 - val_accuracy: 0.8869 - val_loss: 0.2612 - learning_rate: 0.0013\n",
            "Epoch 8/48\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.4218\n",
            "Epoch 8: val_loss improved from 0.26121 to 0.25959, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7784 - loss: 0.4216 - val_accuracy: 0.8886 - val_loss: 0.2596 - learning_rate: 0.0013\n",
            "Epoch 9/48\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7822 - loss: 0.4137\n",
            "Epoch 9: val_loss did not improve from 0.25959\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7824 - loss: 0.4137 - val_accuracy: 0.8447 - val_loss: 0.3490 - learning_rate: 0.0013\n",
            "Epoch 10/48\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7901 - loss: 0.4068\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00041344695894345187.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.25959\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7901 - loss: 0.4069 - val_accuracy: 0.8312 - val_loss: 0.3519 - learning_rate: 0.0013\n",
            "Epoch 11/48\n",
            "\u001b[1m141/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8007 - loss: 0.3997\n",
            "Epoch 11: val_loss did not improve from 0.25959\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.3995 - val_accuracy: 0.8599 - val_loss: 0.3174 - learning_rate: 4.1345e-04\n",
            "Epoch 12/48\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8189 - loss: 0.3845\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001288534088535398.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.25959\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8189 - loss: 0.3845 - val_accuracy: 0.8186 - val_loss: 0.3805 - learning_rate: 4.1345e-04\n",
            "Epoch 13/48\n",
            "\u001b[1m136/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8315 - loss: 0.3788\n",
            "Epoch 13: val_loss did not improve from 0.25959\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8307 - loss: 0.3792 - val_accuracy: 0.8371 - val_loss: 0.3433 - learning_rate: 1.2885e-04\n",
            "Epoch 14/48\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.3834\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.0157996870827105e-05.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.25959\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8283 - loss: 0.3834 - val_accuracy: 0.8414 - val_loss: 0.3255 - learning_rate: 1.2885e-04\n",
            "Epoch 15/48\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8260 - loss: 0.3815\n",
            "Epoch 15: val_loss did not improve from 0.25959\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8261 - loss: 0.3814 - val_accuracy: 0.8430 - val_loss: 0.3224 - learning_rate: 4.0158e-05\n",
            "Epoch 16/48\n",
            "\u001b[1m135/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8259 - loss: 0.3829\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.2515498642209585e-05.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.25959\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8258 - loss: 0.3827 - val_accuracy: 0.8464 - val_loss: 0.3174 - learning_rate: 4.0158e-05\n",
            "Epoch 17/48\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8158 - loss: 0.3864\n",
            "Epoch 17: val_loss did not improve from 0.25959\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8166 - loss: 0.3859 - val_accuracy: 0.8422 - val_loss: 0.3242 - learning_rate: 1.2515e-05\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:27:36,498] Trial 4 finished with value: -0.25958603620529175 and parameters: {'epochs': 48, 'batch_size': 32, 'learning_rate': 0.004256645916280987, 'stop_patience': 9, 'reduce_lr_factor': 0.3116564510517096, 'reduce_lr_patience': 2}. Best is trial 2 with value: -0.25567013025283813.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/36\n",
            "\u001b[1m136/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5718 - loss: 0.6881\n",
            "Epoch 1: val_loss improved from inf to 0.41167, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5740 - loss: 0.6862 - val_accuracy: 0.8498 - val_loss: 0.4117 - learning_rate: 0.0078\n",
            "Epoch 2/36\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6611 - loss: 0.5995\n",
            "Epoch 2: val_loss improved from 0.41167 to 0.37151, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6616 - loss: 0.5985 - val_accuracy: 0.8236 - val_loss: 0.3715 - learning_rate: 0.0078\n",
            "Epoch 3/36\n",
            "\u001b[1m145/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7078 - loss: 0.5286\n",
            "Epoch 3: val_loss improved from 0.37151 to 0.29462, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7079 - loss: 0.5284 - val_accuracy: 0.8667 - val_loss: 0.2946 - learning_rate: 0.0078\n",
            "Epoch 4/36\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 0.4930\n",
            "Epoch 4: val_loss did not improve from 0.29462\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7310 - loss: 0.4929 - val_accuracy: 0.6228 - val_loss: 1.2638 - learning_rate: 0.0078\n",
            "Epoch 5/36\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7269 - loss: 0.4950\n",
            "Epoch 5: val_loss did not improve from 0.29462\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7273 - loss: 0.4945 - val_accuracy: 0.6895 - val_loss: 1.0295 - learning_rate: 0.0078\n",
            "Epoch 6/36\n",
            "\u001b[1m141/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7410 - loss: 0.4805\n",
            "Epoch 6: val_loss did not improve from 0.29462\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7414 - loss: 0.4797 - val_accuracy: 0.8084 - val_loss: 0.5600 - learning_rate: 0.0078\n",
            "Epoch 7/36\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 0.4855\n",
            "Epoch 7: val_loss did not improve from 0.29462\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7399 - loss: 0.4851 - val_accuracy: 0.8456 - val_loss: 0.3452 - learning_rate: 0.0078\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:27:46,754] Trial 5 finished with value: -0.294619083404541 and parameters: {'epochs': 36, 'batch_size': 32, 'learning_rate': 0.00782051987571768, 'stop_patience': 4, 'reduce_lr_factor': 0.20861694208413528, 'reduce_lr_patience': 5}. Best is trial 2 with value: -0.25567013025283813.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/17\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5700 - loss: 0.6850\n",
            "Epoch 1: val_loss improved from inf to 0.63672, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5709 - loss: 0.6842 - val_accuracy: 0.6025 - val_loss: 0.6367 - learning_rate: 0.0032\n",
            "Epoch 2/17\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6216 - loss: 0.6297\n",
            "Epoch 2: val_loss improved from 0.63672 to 0.41624, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6226 - loss: 0.6289 - val_accuracy: 0.7941 - val_loss: 0.4162 - learning_rate: 0.0032\n",
            "Epoch 3/17\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7005 - loss: 0.5453\n",
            "Epoch 3: val_loss improved from 0.41624 to 0.31400, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7009 - loss: 0.5447 - val_accuracy: 0.8675 - val_loss: 0.3140 - learning_rate: 0.0032\n",
            "Epoch 4/17\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7105 - loss: 0.5087\n",
            "Epoch 4: val_loss did not improve from 0.31400\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7110 - loss: 0.5085 - val_accuracy: 0.7190 - val_loss: 0.8335 - learning_rate: 0.0032\n",
            "Epoch 5/17\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7245 - loss: 0.4947\n",
            "Epoch 5: val_loss did not improve from 0.31400\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7249 - loss: 0.4943 - val_accuracy: 0.7831 - val_loss: 0.5664 - learning_rate: 0.0032\n",
            "Epoch 6/17\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7300 - loss: 0.4721\n",
            "Epoch 6: val_loss did not improve from 0.31400\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7315 - loss: 0.4712 - val_accuracy: 0.8380 - val_loss: 0.3456 - learning_rate: 0.0032\n",
            "Epoch 7/17\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7365 - loss: 0.4647\n",
            "Epoch 7: val_loss did not improve from 0.31400\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7368 - loss: 0.4643 - val_accuracy: 0.7975 - val_loss: 0.5617 - learning_rate: 0.0032\n",
            "Epoch 8/17\n",
            "\u001b[1m69/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7484 - loss: 0.4475\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0010067524119626013.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.31400\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7485 - loss: 0.4470 - val_accuracy: 0.8203 - val_loss: 0.4441 - learning_rate: 0.0032\n",
            "Epoch 9/17\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7623 - loss: 0.4266\n",
            "Epoch 9: val_loss improved from 0.31400 to 0.26927, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7626 - loss: 0.4264 - val_accuracy: 0.8751 - val_loss: 0.2693 - learning_rate: 0.0010\n",
            "Epoch 10/17\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7748 - loss: 0.4211\n",
            "Epoch 10: val_loss did not improve from 0.26927\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7749 - loss: 0.4209 - val_accuracy: 0.8793 - val_loss: 0.2882 - learning_rate: 0.0010\n",
            "Epoch 11/17\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7925 - loss: 0.4076\n",
            "Epoch 11: val_loss did not improve from 0.26927\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7927 - loss: 0.4074 - val_accuracy: 0.8388 - val_loss: 0.3326 - learning_rate: 0.0010\n",
            "Epoch 12/17\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7918 - loss: 0.4059\n",
            "Epoch 12: val_loss did not improve from 0.26927\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7919 - loss: 0.4057 - val_accuracy: 0.8743 - val_loss: 0.2872 - learning_rate: 0.0010\n",
            "Epoch 13/17\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7965 - loss: 0.4019\n",
            "Epoch 13: val_loss did not improve from 0.26927\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7965 - loss: 0.4018 - val_accuracy: 0.8776 - val_loss: 0.2879 - learning_rate: 0.0010\n",
            "Epoch 14/17\n",
            "\u001b[1m66/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.3992\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0003122000015365788.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.26927\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8037 - loss: 0.3988 - val_accuracy: 0.8810 - val_loss: 0.2812 - learning_rate: 0.0010\n",
            "Epoch 15/17\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8193 - loss: 0.3876\n",
            "Epoch 15: val_loss did not improve from 0.26927\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8194 - loss: 0.3876 - val_accuracy: 0.8532 - val_loss: 0.3130 - learning_rate: 3.1220e-04\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:27:57,791] Trial 6 finished with value: -0.2692745327949524 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 0.003246477918177164, 'stop_patience': 6, 'reduce_lr_factor': 0.3101060510525818, 'reduce_lr_patience': 5}. Best is trial 2 with value: -0.25567013025283813.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/49\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5480 - loss: 0.6872\n",
            "Epoch 1: val_loss improved from inf to 0.51380, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5499 - loss: 0.6862 - val_accuracy: 0.8338 - val_loss: 0.5138 - learning_rate: 0.0020\n",
            "Epoch 2/49\n",
            "\u001b[1m69/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6416 - loss: 0.6272\n",
            "Epoch 2: val_loss improved from 0.51380 to 0.45700, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6427 - loss: 0.6257 - val_accuracy: 0.7586 - val_loss: 0.4570 - learning_rate: 0.0020\n",
            "Epoch 3/49\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6915 - loss: 0.5702\n",
            "Epoch 3: val_loss did not improve from 0.45700\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6923 - loss: 0.5694 - val_accuracy: 0.7738 - val_loss: 0.4667 - learning_rate: 0.0020\n",
            "Epoch 4/49\n",
            "\u001b[1m69/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7164 - loss: 0.5239\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005830020778874018.\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.45700\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7167 - loss: 0.5232 - val_accuracy: 0.7747 - val_loss: 0.5245 - learning_rate: 0.0020\n",
            "Epoch 5/49\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7439 - loss: 0.4932\n",
            "Epoch 5: val_loss improved from 0.45700 to 0.40298, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7445 - loss: 0.4926 - val_accuracy: 0.8093 - val_loss: 0.4030 - learning_rate: 5.8300e-04\n",
            "Epoch 6/49\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7542 - loss: 0.4740\n",
            "Epoch 6: val_loss improved from 0.40298 to 0.36810, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7544 - loss: 0.4740 - val_accuracy: 0.8219 - val_loss: 0.3681 - learning_rate: 5.8300e-04\n",
            "Epoch 7/49\n",
            "\u001b[1m62/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7680 - loss: 0.4649\n",
            "Epoch 7: val_loss did not improve from 0.36810\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7680 - loss: 0.4646 - val_accuracy: 0.8152 - val_loss: 0.4001 - learning_rate: 5.8300e-04\n",
            "Epoch 8/49\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7654 - loss: 0.4579\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00017120261974529782.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.36810\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7656 - loss: 0.4578 - val_accuracy: 0.8042 - val_loss: 0.4180 - learning_rate: 5.8300e-04\n",
            "Epoch 9/49\n",
            "\u001b[1m66/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7955 - loss: 0.4453\n",
            "Epoch 9: val_loss improved from 0.36810 to 0.28500, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7950 - loss: 0.4451 - val_accuracy: 0.8793 - val_loss: 0.2850 - learning_rate: 1.7120e-04\n",
            "Epoch 10/49\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7767 - loss: 0.4459\n",
            "Epoch 10: val_loss did not improve from 0.28500\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7769 - loss: 0.4457 - val_accuracy: 0.8768 - val_loss: 0.2855 - learning_rate: 1.7120e-04\n",
            "Epoch 11/49\n",
            "\u001b[1m69/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7952 - loss: 0.4390\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 5.027484167878791e-05.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.28500\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7949 - loss: 0.4388 - val_accuracy: 0.8692 - val_loss: 0.2938 - learning_rate: 1.7120e-04\n",
            "Epoch 12/49\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7974 - loss: 0.4324\n",
            "Epoch 12: val_loss did not improve from 0.28500\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7974 - loss: 0.4324 - val_accuracy: 0.8624 - val_loss: 0.3092 - learning_rate: 5.0275e-05\n",
            "Epoch 13/49\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.4315\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.4763557700991305e-05.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.28500\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8052 - loss: 0.4314 - val_accuracy: 0.8700 - val_loss: 0.2958 - learning_rate: 5.0275e-05\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:28:08,546] Trial 7 finished with value: -0.28500330448150635 and parameters: {'epochs': 49, 'batch_size': 64, 'learning_rate': 0.0019853165252729987, 'stop_patience': 4, 'reduce_lr_factor': 0.2936569758922601, 'reduce_lr_patience': 2}. Best is trial 2 with value: -0.25567013025283813.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5658 - loss: 0.6816\n",
            "Epoch 1: val_loss improved from inf to 0.44009, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5678 - loss: 0.6802 - val_accuracy: 0.8236 - val_loss: 0.4401 - learning_rate: 0.0021\n",
            "Epoch 2/35\n",
            "\u001b[1m147/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6546 - loss: 0.6062\n",
            "Epoch 2: val_loss improved from 0.44009 to 0.36484, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6547 - loss: 0.6060 - val_accuracy: 0.8549 - val_loss: 0.3648 - learning_rate: 0.0021\n",
            "Epoch 3/35\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7164 - loss: 0.5422\n",
            "Epoch 3: val_loss improved from 0.36484 to 0.31037, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7168 - loss: 0.5417 - val_accuracy: 0.8557 - val_loss: 0.3104 - learning_rate: 0.0021\n",
            "Epoch 4/35\n",
            "\u001b[1m145/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7235 - loss: 0.5107\n",
            "Epoch 4: val_loss improved from 0.31037 to 0.30211, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7236 - loss: 0.5105 - val_accuracy: 0.8624 - val_loss: 0.3021 - learning_rate: 0.0021\n",
            "Epoch 5/35\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7415 - loss: 0.4985\n",
            "Epoch 5: val_loss did not improve from 0.30211\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7413 - loss: 0.4982 - val_accuracy: 0.8574 - val_loss: 0.3144 - learning_rate: 0.0021\n",
            "Epoch 6/35\n",
            "\u001b[1m138/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.4699\n",
            "Epoch 6: val_loss did not improve from 0.30211\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7437 - loss: 0.4700 - val_accuracy: 0.8422 - val_loss: 0.3452 - learning_rate: 0.0021\n",
            "Epoch 7/35\n",
            "\u001b[1m146/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7505 - loss: 0.4568\n",
            "Epoch 7: val_loss did not improve from 0.30211\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7506 - loss: 0.4567 - val_accuracy: 0.7688 - val_loss: 0.5384 - learning_rate: 0.0021\n",
            "Epoch 8/35\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7575 - loss: 0.4504\n",
            "Epoch 8: val_loss improved from 0.30211 to 0.27929, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7576 - loss: 0.4505 - val_accuracy: 0.8776 - val_loss: 0.2793 - learning_rate: 0.0021\n",
            "Epoch 9/35\n",
            "\u001b[1m145/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7760 - loss: 0.4414\n",
            "Epoch 9: val_loss improved from 0.27929 to 0.25414, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7758 - loss: 0.4416 - val_accuracy: 0.8970 - val_loss: 0.2541 - learning_rate: 0.0021\n",
            "Epoch 10/35\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7749 - loss: 0.4290\n",
            "Epoch 10: val_loss improved from 0.25414 to 0.25244, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7749 - loss: 0.4290 - val_accuracy: 0.8945 - val_loss: 0.2524 - learning_rate: 0.0021\n",
            "Epoch 11/35\n",
            "\u001b[1m137/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7728 - loss: 0.4332\n",
            "Epoch 11: val_loss did not improve from 0.25244\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7728 - loss: 0.4337 - val_accuracy: 0.8481 - val_loss: 0.3368 - learning_rate: 0.0021\n",
            "Epoch 12/35\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.4274\n",
            "Epoch 12: val_loss did not improve from 0.25244\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7837 - loss: 0.4279 - val_accuracy: 0.8835 - val_loss: 0.2781 - learning_rate: 0.0021\n",
            "Epoch 13/35\n",
            "\u001b[1m141/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7856 - loss: 0.4210\n",
            "Epoch 13: val_loss did not improve from 0.25244\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7855 - loss: 0.4213 - val_accuracy: 0.8751 - val_loss: 0.2875 - learning_rate: 0.0021\n",
            "Epoch 14/35\n",
            "\u001b[1m131/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7796 - loss: 0.4235\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008045346114313272.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.25244\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7800 - loss: 0.4237 - val_accuracy: 0.8481 - val_loss: 0.3444 - learning_rate: 0.0021\n",
            "Epoch 15/35\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7874 - loss: 0.4058\n",
            "Epoch 15: val_loss did not improve from 0.25244\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7879 - loss: 0.4053 - val_accuracy: 0.8768 - val_loss: 0.2881 - learning_rate: 8.0453e-04\n",
            "Epoch 16/35\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8163 - loss: 0.3857\n",
            "Epoch 16: val_loss did not improve from 0.25244\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.3856 - val_accuracy: 0.8844 - val_loss: 0.2614 - learning_rate: 8.0453e-04\n",
            "Epoch 17/35\n",
            "\u001b[1m135/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.3761\n",
            "Epoch 17: val_loss did not improve from 0.25244\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8235 - loss: 0.3761 - val_accuracy: 0.8928 - val_loss: 0.2628 - learning_rate: 8.0453e-04\n",
            "Epoch 18/35\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8229 - loss: 0.3719\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00030477469786087955.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.25244\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8230 - loss: 0.3719 - val_accuracy: 0.8759 - val_loss: 0.2966 - learning_rate: 8.0453e-04\n",
            "Epoch 19/35\n",
            "\u001b[1m137/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3630\n",
            "Epoch 19: val_loss did not improve from 0.25244\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8445 - loss: 0.3624 - val_accuracy: 0.8405 - val_loss: 0.3569 - learning_rate: 3.0477e-04\n",
            "Epoch 20/35\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8441 - loss: 0.3543\n",
            "Epoch 20: val_loss did not improve from 0.25244\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8439 - loss: 0.3541 - val_accuracy: 0.8287 - val_loss: 0.3715 - learning_rate: 3.0477e-04\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:28:33,145] Trial 8 finished with value: -0.25244078040122986 and parameters: {'epochs': 35, 'batch_size': 32, 'learning_rate': 0.002123785020514167, 'stop_patience': 10, 'reduce_lr_factor': 0.3788211245036218, 'reduce_lr_patience': 4}. Best is trial 8 with value: -0.25244078040122986.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/18\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5787 - loss: 0.6829\n",
            "Epoch 1: val_loss improved from inf to 0.48529, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5789 - loss: 0.6826 - val_accuracy: 0.7646 - val_loss: 0.4853 - learning_rate: 0.0096\n",
            "Epoch 2/18\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6790 - loss: 0.5818\n",
            "Epoch 2: val_loss improved from 0.48529 to 0.40600, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6788 - loss: 0.5815 - val_accuracy: 0.8582 - val_loss: 0.4060 - learning_rate: 0.0096\n",
            "Epoch 3/18\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6817 - loss: 0.5337\n",
            "Epoch 3: val_loss did not improve from 0.40600\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6819 - loss: 0.5338 - val_accuracy: 0.6717 - val_loss: 0.8218 - learning_rate: 0.0096\n",
            "Epoch 4/18\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7072 - loss: 0.5057\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.002278896182563638.\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.40600\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7075 - loss: 0.5056 - val_accuracy: 0.6717 - val_loss: 0.6504 - learning_rate: 0.0096\n",
            "Epoch 5/18\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7478 - loss: 0.4574\n",
            "Epoch 5: val_loss improved from 0.40600 to 0.32237, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7480 - loss: 0.4572 - val_accuracy: 0.8430 - val_loss: 0.3224 - learning_rate: 0.0023\n",
            "Epoch 6/18\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7676 - loss: 0.4368\n",
            "Epoch 6: val_loss improved from 0.32237 to 0.26566, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7676 - loss: 0.4368 - val_accuracy: 0.8835 - val_loss: 0.2657 - learning_rate: 0.0023\n",
            "Epoch 7/18\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7679 - loss: 0.4311\n",
            "Epoch 7: val_loss did not improve from 0.26566\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7679 - loss: 0.4312 - val_accuracy: 0.8557 - val_loss: 0.3162 - learning_rate: 0.0023\n",
            "Epoch 8/18\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7801 - loss: 0.4283\n",
            "Epoch 8: val_loss improved from 0.26566 to 0.25479, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7800 - loss: 0.4282 - val_accuracy: 0.8979 - val_loss: 0.2548 - learning_rate: 0.0023\n",
            "Epoch 9/18\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7867 - loss: 0.4131\n",
            "Epoch 9: val_loss did not improve from 0.25479\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7868 - loss: 0.4131 - val_accuracy: 0.8970 - val_loss: 0.2750 - learning_rate: 0.0023\n",
            "Epoch 10/18\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7919 - loss: 0.4050\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005389986836180103.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.25479\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7918 - loss: 0.4052 - val_accuracy: 0.8743 - val_loss: 0.2837 - learning_rate: 0.0023\n",
            "Epoch 11/18\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8177 - loss: 0.3901\n",
            "Epoch 11: val_loss did not improve from 0.25479\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8176 - loss: 0.3901 - val_accuracy: 0.8591 - val_loss: 0.3085 - learning_rate: 5.3900e-04\n",
            "Epoch 12/18\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.3875\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00012748258322487855.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.25479\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8231 - loss: 0.3874 - val_accuracy: 0.8439 - val_loss: 0.3341 - learning_rate: 5.3900e-04\n",
            "Epoch 13/18\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8353 - loss: 0.3772\n",
            "Epoch 13: val_loss did not improve from 0.25479\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8353 - loss: 0.3772 - val_accuracy: 0.8329 - val_loss: 0.3670 - learning_rate: 1.2748e-04\n",
            "Epoch 14/18\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.3811\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 3.015185108140012e-05.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.25479\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.3810 - val_accuracy: 0.8135 - val_loss: 0.3800 - learning_rate: 1.2748e-04\n",
            "Epoch 15/18\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8379 - loss: 0.3710\n",
            "Epoch 15: val_loss did not improve from 0.25479\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8378 - loss: 0.3711 - val_accuracy: 0.8127 - val_loss: 0.3721 - learning_rate: 3.0152e-05\n",
            "Epoch 16/18\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8360 - loss: 0.3721\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 7.131438034473661e-06.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.25479\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8359 - loss: 0.3721 - val_accuracy: 0.8093 - val_loss: 0.3800 - learning_rate: 3.0152e-05\n",
            "Epoch 17/18\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.3761\n",
            "Epoch 17: val_loss did not improve from 0.25479\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8334 - loss: 0.3760 - val_accuracy: 0.8101 - val_loss: 0.3773 - learning_rate: 7.1314e-06\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:28:58,140] Trial 9 finished with value: -0.2547924220561981 and parameters: {'epochs': 18, 'batch_size': 16, 'learning_rate': 0.009635215154678339, 'stop_patience': 9, 'reduce_lr_factor': 0.2365174264377901, 'reduce_lr_patience': 2}. Best is trial 8 with value: -0.25244078040122986.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/41\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5665 - loss: 0.6862\n",
            "Epoch 1: val_loss improved from inf to 0.45880, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5678 - loss: 0.6850 - val_accuracy: 0.8624 - val_loss: 0.4588 - learning_rate: 0.0060\n",
            "Epoch 2/41\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6309 - loss: 0.6226\n",
            "Epoch 2: val_loss did not improve from 0.45880\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6315 - loss: 0.6219 - val_accuracy: 0.7105 - val_loss: 0.5729 - learning_rate: 0.0060\n",
            "Epoch 3/41\n",
            "\u001b[1m137/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6919 - loss: 0.5519\n",
            "Epoch 3: val_loss did not improve from 0.45880\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6920 - loss: 0.5514 - val_accuracy: 0.6920 - val_loss: 0.6039 - learning_rate: 0.0060\n",
            "Epoch 4/41\n",
            "\u001b[1m141/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7234 - loss: 0.5001\n",
            "Epoch 4: val_loss improved from 0.45880 to 0.37651, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7226 - loss: 0.5018 - val_accuracy: 0.8785 - val_loss: 0.3765 - learning_rate: 0.0060\n",
            "Epoch 5/41\n",
            "\u001b[1m135/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7131 - loss: 0.4976\n",
            "Epoch 5: val_loss did not improve from 0.37651\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7136 - loss: 0.4976 - val_accuracy: 0.8143 - val_loss: 0.3792 - learning_rate: 0.0060\n",
            "Epoch 6/41\n",
            "\u001b[1m137/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7231 - loss: 0.4735\n",
            "Epoch 6: val_loss improved from 0.37651 to 0.25667, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7235 - loss: 0.4738 - val_accuracy: 0.8819 - val_loss: 0.2567 - learning_rate: 0.0060\n",
            "Epoch 7/41\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7444 - loss: 0.4540\n",
            "Epoch 7: val_loss did not improve from 0.25667\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7451 - loss: 0.4539 - val_accuracy: 0.8835 - val_loss: 0.2656 - learning_rate: 0.0060\n",
            "Epoch 8/41\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.4729\n",
            "Epoch 8: val_loss did not improve from 0.25667\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7301 - loss: 0.4730 - val_accuracy: 0.7789 - val_loss: 0.4756 - learning_rate: 0.0060\n",
            "Epoch 9/41\n",
            "\u001b[1m141/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7570 - loss: 0.4454\n",
            "Epoch 9: val_loss did not improve from 0.25667\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7573 - loss: 0.4452 - val_accuracy: 0.8540 - val_loss: 0.3170 - learning_rate: 0.0060\n",
            "Epoch 10/41\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7567 - loss: 0.4447\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0029280645105451445.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.25667\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7568 - loss: 0.4448 - val_accuracy: 0.7958 - val_loss: 0.4583 - learning_rate: 0.0060\n",
            "Epoch 11/41\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7649 - loss: 0.4283\n",
            "Epoch 11: val_loss did not improve from 0.25667\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7650 - loss: 0.4279 - val_accuracy: 0.8844 - val_loss: 0.2844 - learning_rate: 0.0029\n",
            "Epoch 12/41\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7802 - loss: 0.4067\n",
            "Epoch 12: val_loss did not improve from 0.25667\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7802 - loss: 0.4067 - val_accuracy: 0.8624 - val_loss: 0.3064 - learning_rate: 0.0029\n",
            "Epoch 13/41\n",
            "\u001b[1m131/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7794 - loss: 0.4032\n",
            "Epoch 13: val_loss did not improve from 0.25667\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7794 - loss: 0.4038 - val_accuracy: 0.8068 - val_loss: 0.4301 - learning_rate: 0.0029\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:29:14,230] Trial 10 finished with value: -0.25667327642440796 and parameters: {'epochs': 41, 'batch_size': 32, 'learning_rate': 0.005960231225823626, 'stop_patience': 7, 'reduce_lr_factor': 0.4912669360484204, 'reduce_lr_patience': 4}. Best is trial 8 with value: -0.25244078040122986.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/22\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5738 - loss: 0.6920\n",
            "Epoch 1: val_loss improved from inf to 1.01915, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5743 - loss: 0.6915 - val_accuracy: 0.4819 - val_loss: 1.0191 - learning_rate: 0.0100\n",
            "Epoch 2/22\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6512 - loss: 0.6097\n",
            "Epoch 2: val_loss improved from 1.01915 to 0.46148, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6521 - loss: 0.6086 - val_accuracy: 0.7477 - val_loss: 0.4615 - learning_rate: 0.0100\n",
            "Epoch 3/22\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7024 - loss: 0.5252\n",
            "Epoch 3: val_loss did not improve from 0.46148\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7024 - loss: 0.5254 - val_accuracy: 0.5435 - val_loss: 1.0095 - learning_rate: 0.0100\n",
            "Epoch 4/22\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7149 - loss: 0.4996\n",
            "Epoch 4: val_loss did not improve from 0.46148\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7149 - loss: 0.4996 - val_accuracy: 0.6076 - val_loss: 1.0266 - learning_rate: 0.0100\n",
            "Epoch 5/22\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7107 - loss: 0.5005\n",
            "Epoch 5: val_loss improved from 0.46148 to 0.26333, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7109 - loss: 0.5004 - val_accuracy: 0.8869 - val_loss: 0.2633 - learning_rate: 0.0100\n",
            "Epoch 6/22\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7397 - loss: 0.4735\n",
            "Epoch 6: val_loss did not improve from 0.26333\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7397 - loss: 0.4736 - val_accuracy: 0.7907 - val_loss: 0.4773 - learning_rate: 0.0100\n",
            "Epoch 7/22\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.4866\n",
            "Epoch 7: val_loss did not improve from 0.26333\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.4866 - val_accuracy: 0.8675 - val_loss: 0.3077 - learning_rate: 0.0100\n",
            "Epoch 8/22\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7307 - loss: 0.4769\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0010588507629654704.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.26333\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7308 - loss: 0.4768 - val_accuracy: 0.6852 - val_loss: 0.7799 - learning_rate: 0.0100\n",
            "Epoch 9/22\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7460 - loss: 0.4391\n",
            "Epoch 9: val_loss did not improve from 0.26333\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7464 - loss: 0.4389 - val_accuracy: 0.8759 - val_loss: 0.2792 - learning_rate: 0.0011\n",
            "Epoch 10/22\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7569 - loss: 0.4324\n",
            "Epoch 10: val_loss did not improve from 0.26333\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7572 - loss: 0.4324 - val_accuracy: 0.8954 - val_loss: 0.2643 - learning_rate: 0.0011\n",
            "Epoch 11/22\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7656 - loss: 0.4270\n",
            "Epoch 11: val_loss improved from 0.26333 to 0.25345, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7658 - loss: 0.4270 - val_accuracy: 0.8996 - val_loss: 0.2534 - learning_rate: 0.0011\n",
            "Epoch 12/22\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7651 - loss: 0.4280\n",
            "Epoch 12: val_loss did not improve from 0.25345\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7650 - loss: 0.4280 - val_accuracy: 0.8895 - val_loss: 0.2643 - learning_rate: 0.0011\n",
            "Epoch 13/22\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7662 - loss: 0.4245\n",
            "Epoch 13: val_loss did not improve from 0.25345\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7663 - loss: 0.4245 - val_accuracy: 0.8861 - val_loss: 0.2830 - learning_rate: 0.0011\n",
            "Epoch 14/22\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7739 - loss: 0.4223\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00011256543260487136.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.25345\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7739 - loss: 0.4223 - val_accuracy: 0.8886 - val_loss: 0.2765 - learning_rate: 0.0011\n",
            "Epoch 15/22\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7747 - loss: 0.4155\n",
            "Epoch 15: val_loss did not improve from 0.25345\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7745 - loss: 0.4156 - val_accuracy: 0.8582 - val_loss: 0.3281 - learning_rate: 1.1257e-04\n",
            "Epoch 16/22\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7672 - loss: 0.4173\n",
            "Epoch 16: val_loss did not improve from 0.25345\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7672 - loss: 0.4173 - val_accuracy: 0.8464 - val_loss: 0.3348 - learning_rate: 1.1257e-04\n",
            "Epoch 17/22\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7724 - loss: 0.4154\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.1966725216608702e-05.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.25345\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7725 - loss: 0.4154 - val_accuracy: 0.8430 - val_loss: 0.3296 - learning_rate: 1.1257e-04\n",
            "Epoch 18/22\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7742 - loss: 0.4187\n",
            "Epoch 18: val_loss did not improve from 0.25345\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7742 - loss: 0.4187 - val_accuracy: 0.8414 - val_loss: 0.3302 - learning_rate: 1.1967e-05\n",
            "Epoch 19/22\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7728 - loss: 0.4107\n",
            "Epoch 19: val_loss did not improve from 0.25345\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7728 - loss: 0.4107 - val_accuracy: 0.8405 - val_loss: 0.3346 - learning_rate: 1.1967e-05\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:29:43,378] Trial 11 finished with value: -0.25344571471214294 and parameters: {'epochs': 22, 'batch_size': 16, 'learning_rate': 0.00996011805721664, 'stop_patience': 8, 'reduce_lr_factor': 0.10630906075174756, 'reduce_lr_patience': 3}. Best is trial 8 with value: -0.25244078040122986.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5665 - loss: 0.6827\n",
            "Epoch 1: val_loss improved from inf to 0.42327, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5669 - loss: 0.6823 - val_accuracy: 0.8751 - val_loss: 0.4233 - learning_rate: 0.0068\n",
            "Epoch 2/25\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6643 - loss: 0.5972\n",
            "Epoch 2: val_loss improved from 0.42327 to 0.33286, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6645 - loss: 0.5969 - val_accuracy: 0.8591 - val_loss: 0.3329 - learning_rate: 0.0068\n",
            "Epoch 3/25\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7173 - loss: 0.5184\n",
            "Epoch 3: val_loss improved from 0.33286 to 0.31562, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7172 - loss: 0.5183 - val_accuracy: 0.8684 - val_loss: 0.3156 - learning_rate: 0.0068\n",
            "Epoch 4/25\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.4878\n",
            "Epoch 4: val_loss improved from 0.31562 to 0.29064, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7298 - loss: 0.4880 - val_accuracy: 0.8768 - val_loss: 0.2906 - learning_rate: 0.0068\n",
            "Epoch 5/25\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7342 - loss: 0.4780\n",
            "Epoch 5: val_loss did not improve from 0.29064\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7342 - loss: 0.4785 - val_accuracy: 0.7722 - val_loss: 0.5561 - learning_rate: 0.0068\n",
            "Epoch 6/25\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7431 - loss: 0.4677\n",
            "Epoch 6: val_loss did not improve from 0.29064\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7432 - loss: 0.4676 - val_accuracy: 0.6852 - val_loss: 0.9780 - learning_rate: 0.0068\n",
            "Epoch 7/25\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7502 - loss: 0.4571\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0007000988512071708.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.29064\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7502 - loss: 0.4571 - val_accuracy: 0.8523 - val_loss: 0.3428 - learning_rate: 0.0068\n",
            "Epoch 8/25\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7759 - loss: 0.4186\n",
            "Epoch 8: val_loss improved from 0.29064 to 0.26087, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.4185 - val_accuracy: 0.8861 - val_loss: 0.2609 - learning_rate: 7.0010e-04\n",
            "Epoch 9/25\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7797 - loss: 0.4056\n",
            "Epoch 9: val_loss improved from 0.26087 to 0.25853, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7800 - loss: 0.4056 - val_accuracy: 0.8979 - val_loss: 0.2585 - learning_rate: 7.0010e-04\n",
            "Epoch 10/25\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.3977\n",
            "Epoch 10: val_loss improved from 0.25853 to 0.25562, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7991 - loss: 0.3975 - val_accuracy: 0.8937 - val_loss: 0.2556 - learning_rate: 7.0010e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8061 - loss: 0.3890\n",
            "Epoch 11: val_loss did not improve from 0.25562\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.3890 - val_accuracy: 0.8911 - val_loss: 0.2650 - learning_rate: 7.0010e-04\n",
            "Epoch 12/25\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.3783\n",
            "Epoch 12: val_loss did not improve from 0.25562\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8238 - loss: 0.3783 - val_accuracy: 0.8928 - val_loss: 0.2648 - learning_rate: 7.0010e-04\n",
            "Epoch 13/25\n",
            "\u001b[1m277/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8323 - loss: 0.3724\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 7.15668359756882e-05.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.25562\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8318 - loss: 0.3724 - val_accuracy: 0.8785 - val_loss: 0.2761 - learning_rate: 7.0010e-04\n",
            "Epoch 14/25\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.3607\n",
            "Epoch 14: val_loss did not improve from 0.25562\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8354 - loss: 0.3607 - val_accuracy: 0.8439 - val_loss: 0.3341 - learning_rate: 7.1567e-05\n",
            "Epoch 15/25\n",
            "\u001b[1m278/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8537 - loss: 0.3576\n",
            "Epoch 15: val_loss did not improve from 0.25562\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8531 - loss: 0.3577 - val_accuracy: 0.8447 - val_loss: 0.3298 - learning_rate: 7.1567e-05\n",
            "Epoch 16/25\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3613\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 7.315840963857392e-06.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.25562\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8424 - loss: 0.3613 - val_accuracy: 0.8422 - val_loss: 0.3332 - learning_rate: 7.1567e-05\n",
            "Epoch 17/25\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.3568\n",
            "Epoch 17: val_loss did not improve from 0.25562\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.3567 - val_accuracy: 0.8397 - val_loss: 0.3409 - learning_rate: 7.3158e-06\n",
            "Epoch 18/25\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8381 - loss: 0.3609\n",
            "Epoch 18: val_loss did not improve from 0.25562\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8381 - loss: 0.3609 - val_accuracy: 0.8346 - val_loss: 0.3474 - learning_rate: 7.3158e-06\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:30:11,650] Trial 12 finished with value: -0.25561702251434326 and parameters: {'epochs': 25, 'batch_size': 16, 'learning_rate': 0.0068486807248542385, 'stop_patience': 8, 'reduce_lr_factor': 0.10222389873356422, 'reduce_lr_patience': 3}. Best is trial 8 with value: -0.25244078040122986.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/24\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5856 - loss: 0.6835\n",
            "Epoch 1: val_loss improved from inf to 0.57433, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5858 - loss: 0.6834 - val_accuracy: 0.8658 - val_loss: 0.5743 - learning_rate: 3.4013e-04\n",
            "Epoch 2/24\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6124 - loss: 0.6465\n",
            "Epoch 2: val_loss improved from 0.57433 to 0.47499, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6130 - loss: 0.6460 - val_accuracy: 0.7966 - val_loss: 0.4750 - learning_rate: 3.4013e-04\n",
            "Epoch 3/24\n",
            "\u001b[1m278/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6643 - loss: 0.6092\n",
            "Epoch 3: val_loss improved from 0.47499 to 0.38999, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6647 - loss: 0.6086 - val_accuracy: 0.8608 - val_loss: 0.3900 - learning_rate: 3.4013e-04\n",
            "Epoch 4/24\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6981 - loss: 0.5724\n",
            "Epoch 4: val_loss improved from 0.38999 to 0.36188, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6982 - loss: 0.5723 - val_accuracy: 0.8278 - val_loss: 0.3619 - learning_rate: 3.4013e-04\n",
            "Epoch 5/24\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7194 - loss: 0.5430\n",
            "Epoch 5: val_loss improved from 0.36188 to 0.34493, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7195 - loss: 0.5428 - val_accuracy: 0.8346 - val_loss: 0.3449 - learning_rate: 3.4013e-04\n",
            "Epoch 6/24\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7296 - loss: 0.5186\n",
            "Epoch 6: val_loss did not improve from 0.34493\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7299 - loss: 0.5186 - val_accuracy: 0.8169 - val_loss: 0.3888 - learning_rate: 3.4013e-04\n",
            "Epoch 7/24\n",
            "\u001b[1m279/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7437 - loss: 0.5057\n",
            "Epoch 7: val_loss did not improve from 0.34493\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7439 - loss: 0.5055 - val_accuracy: 0.8354 - val_loss: 0.3496 - learning_rate: 3.4013e-04\n",
            "Epoch 8/24\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7403 - loss: 0.4932\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00015913464849030655.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.34493\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7406 - loss: 0.4931 - val_accuracy: 0.8270 - val_loss: 0.3693 - learning_rate: 3.4013e-04\n",
            "Epoch 9/24\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7717 - loss: 0.4813\n",
            "Epoch 9: val_loss improved from 0.34493 to 0.29461, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7717 - loss: 0.4813 - val_accuracy: 0.8717 - val_loss: 0.2946 - learning_rate: 1.5913e-04\n",
            "Epoch 10/24\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7726 - loss: 0.4693\n",
            "Epoch 10: val_loss improved from 0.29461 to 0.29146, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7726 - loss: 0.4693 - val_accuracy: 0.8709 - val_loss: 0.2915 - learning_rate: 1.5913e-04\n",
            "Epoch 11/24\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7777 - loss: 0.4658\n",
            "Epoch 11: val_loss improved from 0.29146 to 0.28765, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7776 - loss: 0.4658 - val_accuracy: 0.8700 - val_loss: 0.2877 - learning_rate: 1.5913e-04\n",
            "Epoch 12/24\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7778 - loss: 0.4615\n",
            "Epoch 12: val_loss improved from 0.28765 to 0.28750, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7780 - loss: 0.4613 - val_accuracy: 0.8717 - val_loss: 0.2875 - learning_rate: 1.5913e-04\n",
            "Epoch 13/24\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7832 - loss: 0.4569\n",
            "Epoch 13: val_loss did not improve from 0.28750\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7832 - loss: 0.4569 - val_accuracy: 0.8743 - val_loss: 0.2876 - learning_rate: 1.5913e-04\n",
            "Epoch 14/24\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7827 - loss: 0.4566\n",
            "Epoch 14: val_loss improved from 0.28750 to 0.28516, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7827 - loss: 0.4566 - val_accuracy: 0.8768 - val_loss: 0.2852 - learning_rate: 1.5913e-04\n",
            "Epoch 15/24\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7889 - loss: 0.4485\n",
            "Epoch 15: val_loss improved from 0.28516 to 0.28304, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7888 - loss: 0.4484 - val_accuracy: 0.8751 - val_loss: 0.2830 - learning_rate: 1.5913e-04\n",
            "Epoch 16/24\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7879 - loss: 0.4477\n",
            "Epoch 16: val_loss did not improve from 0.28304\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7877 - loss: 0.4475 - val_accuracy: 0.8759 - val_loss: 0.2856 - learning_rate: 1.5913e-04\n",
            "Epoch 17/24\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7945 - loss: 0.4417\n",
            "Epoch 17: val_loss improved from 0.28304 to 0.27999, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7945 - loss: 0.4416 - val_accuracy: 0.8793 - val_loss: 0.2800 - learning_rate: 1.5913e-04\n",
            "Epoch 18/24\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7924 - loss: 0.4362\n",
            "Epoch 18: val_loss did not improve from 0.27999\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7924 - loss: 0.4361 - val_accuracy: 0.8793 - val_loss: 0.2817 - learning_rate: 1.5913e-04\n",
            "Epoch 19/24\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7946 - loss: 0.4332\n",
            "Epoch 19: val_loss did not improve from 0.27999\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7946 - loss: 0.4330 - val_accuracy: 0.8793 - val_loss: 0.2808 - learning_rate: 1.5913e-04\n",
            "Epoch 20/24\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7936 - loss: 0.4314\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 7.445268458322324e-05.\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.27999\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.4314 - val_accuracy: 0.8802 - val_loss: 0.2818 - learning_rate: 1.5913e-04\n",
            "Epoch 21/24\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7926 - loss: 0.4263\n",
            "Epoch 21: val_loss did not improve from 0.27999\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.4263 - val_accuracy: 0.8498 - val_loss: 0.3349 - learning_rate: 7.4453e-05\n",
            "Epoch 22/24\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8021 - loss: 0.4254\n",
            "Epoch 22: val_loss did not improve from 0.27999\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8022 - loss: 0.4253 - val_accuracy: 0.8591 - val_loss: 0.3188 - learning_rate: 7.4453e-05\n",
            "Epoch 23/24\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8053 - loss: 0.4236\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 3.4833407757292155e-05.\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.27999\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.4235 - val_accuracy: 0.8658 - val_loss: 0.3095 - learning_rate: 7.4453e-05\n",
            "Epoch 23: early stopping\n",
            "Restoring model weights from the end of the best epoch: 17.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:30:46,389] Trial 13 finished with value: -0.27998948097229004 and parameters: {'epochs': 24, 'batch_size': 16, 'learning_rate': 0.0003401332831839501, 'stop_patience': 6, 'reduce_lr_factor': 0.467859663225282, 'reduce_lr_patience': 3}. Best is trial 8 with value: -0.25244078040122986.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/24\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6191 - loss: 0.6681\n",
            "Epoch 1: val_loss improved from inf to 0.81037, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6193 - loss: 0.6679 - val_accuracy: 0.5738 - val_loss: 0.8104 - learning_rate: 0.0022\n",
            "Epoch 2/24\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6765 - loss: 0.5689\n",
            "Epoch 2: val_loss improved from 0.81037 to 0.46944, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6768 - loss: 0.5688 - val_accuracy: 0.7797 - val_loss: 0.4694 - learning_rate: 0.0022\n",
            "Epoch 3/24\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7221 - loss: 0.5132\n",
            "Epoch 3: val_loss improved from 0.46944 to 0.33863, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7223 - loss: 0.5131 - val_accuracy: 0.8430 - val_loss: 0.3386 - learning_rate: 0.0022\n",
            "Epoch 4/24\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7341 - loss: 0.4838\n",
            "Epoch 4: val_loss did not improve from 0.33863\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7343 - loss: 0.4838 - val_accuracy: 0.7139 - val_loss: 0.6421 - learning_rate: 0.0022\n",
            "Epoch 5/24\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7454 - loss: 0.4782\n",
            "Epoch 5: val_loss improved from 0.33863 to 0.28549, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7455 - loss: 0.4781 - val_accuracy: 0.8785 - val_loss: 0.2855 - learning_rate: 0.0022\n",
            "Epoch 6/24\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7417 - loss: 0.4689\n",
            "Epoch 6: val_loss did not improve from 0.28549\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7418 - loss: 0.4689 - val_accuracy: 0.7949 - val_loss: 0.4440 - learning_rate: 0.0022\n",
            "Epoch 7/24\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7618 - loss: 0.4536\n",
            "Epoch 7: val_loss did not improve from 0.28549\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7618 - loss: 0.4537 - val_accuracy: 0.7882 - val_loss: 0.4936 - learning_rate: 0.0022\n",
            "Epoch 8/24\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7673 - loss: 0.4434\n",
            "Epoch 8: val_loss did not improve from 0.28549\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7672 - loss: 0.4435 - val_accuracy: 0.8599 - val_loss: 0.3196 - learning_rate: 0.0022\n",
            "Epoch 9/24\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7693 - loss: 0.4338\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002608814959254667.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.28549\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7693 - loss: 0.4340 - val_accuracy: 0.7747 - val_loss: 0.5487 - learning_rate: 0.0022\n",
            "Epoch 10/24\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7881 - loss: 0.4080\n",
            "Epoch 10: val_loss improved from 0.28549 to 0.27296, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7884 - loss: 0.4078 - val_accuracy: 0.8835 - val_loss: 0.2730 - learning_rate: 2.6088e-04\n",
            "Epoch 11/24\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8101 - loss: 0.3880\n",
            "Epoch 11: val_loss improved from 0.27296 to 0.27053, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8101 - loss: 0.3880 - val_accuracy: 0.8776 - val_loss: 0.2705 - learning_rate: 2.6088e-04\n",
            "Epoch 12/24\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8116 - loss: 0.3822\n",
            "Epoch 12: val_loss did not improve from 0.27053\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8116 - loss: 0.3822 - val_accuracy: 0.8776 - val_loss: 0.2767 - learning_rate: 2.6088e-04\n",
            "Epoch 13/24\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8271 - loss: 0.3769\n",
            "Epoch 13: val_loss did not improve from 0.27053\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.3768 - val_accuracy: 0.8785 - val_loss: 0.2761 - learning_rate: 2.6088e-04\n",
            "Epoch 14/24\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.3732\n",
            "Epoch 14: val_loss did not improve from 0.27053\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.3732 - val_accuracy: 0.8667 - val_loss: 0.2927 - learning_rate: 2.6088e-04\n",
            "Epoch 15/24\n",
            "\u001b[1m279/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8337 - loss: 0.3661\n",
            "Epoch 15: val_loss improved from 0.27053 to 0.26189, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8336 - loss: 0.3661 - val_accuracy: 0.8903 - val_loss: 0.2619 - learning_rate: 2.6088e-04\n",
            "Epoch 16/24\n",
            "\u001b[1m278/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8368 - loss: 0.3644\n",
            "Epoch 16: val_loss did not improve from 0.26189\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8368 - loss: 0.3643 - val_accuracy: 0.8692 - val_loss: 0.2975 - learning_rate: 2.6088e-04\n",
            "Epoch 17/24\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8392 - loss: 0.3615\n",
            "Epoch 17: val_loss improved from 0.26189 to 0.25470, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8391 - loss: 0.3614 - val_accuracy: 0.8962 - val_loss: 0.2547 - learning_rate: 2.6088e-04\n",
            "Epoch 18/24\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.3568\n",
            "Epoch 18: val_loss did not improve from 0.25470\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.3568 - val_accuracy: 0.8675 - val_loss: 0.2930 - learning_rate: 2.6088e-04\n",
            "Epoch 19/24\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8522 - loss: 0.3507\n",
            "Epoch 19: val_loss did not improve from 0.25470\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 0.3508 - val_accuracy: 0.8726 - val_loss: 0.2880 - learning_rate: 2.6088e-04\n",
            "Epoch 20/24\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8480 - loss: 0.3496\n",
            "Epoch 20: val_loss did not improve from 0.25470\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8480 - loss: 0.3497 - val_accuracy: 0.8768 - val_loss: 0.2732 - learning_rate: 2.6088e-04\n",
            "Epoch 21/24\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8513 - loss: 0.3514\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 3.0277493045504108e-05.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.25470\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8513 - loss: 0.3513 - val_accuracy: 0.8591 - val_loss: 0.3112 - learning_rate: 2.6088e-04\n",
            "Epoch 22/24\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8565 - loss: 0.3411\n",
            "Epoch 22: val_loss did not improve from 0.25470\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8565 - loss: 0.3411 - val_accuracy: 0.8388 - val_loss: 0.3506 - learning_rate: 3.0277e-05\n",
            "Epoch 23/24\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8538 - loss: 0.3464\n",
            "Epoch 23: val_loss did not improve from 0.25470\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8538 - loss: 0.3464 - val_accuracy: 0.8414 - val_loss: 0.3422 - learning_rate: 3.0277e-05\n",
            "Epoch 24/24\n",
            "\u001b[1m278/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8601 - loss: 0.3460\n",
            "Epoch 24: val_loss did not improve from 0.25470\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8600 - loss: 0.3458 - val_accuracy: 0.8380 - val_loss: 0.3504 - learning_rate: 3.0277e-05\n",
            "Restoring model weights from the end of the best epoch: 17.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:31:21,196] Trial 14 finished with value: -0.2546989321708679 and parameters: {'epochs': 24, 'batch_size': 16, 'learning_rate': 0.002247846499642902, 'stop_patience': 8, 'reduce_lr_factor': 0.11605841476987051, 'reduce_lr_patience': 4}. Best is trial 8 with value: -0.25244078040122986.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/41\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5724 - loss: 0.6804\n",
            "Epoch 1: val_loss improved from inf to 0.63792, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5735 - loss: 0.6794 - val_accuracy: 0.6540 - val_loss: 0.6379 - learning_rate: 0.0053\n",
            "Epoch 2/41\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6906 - loss: 0.5742\n",
            "Epoch 2: val_loss improved from 0.63792 to 0.33764, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6905 - loss: 0.5742 - val_accuracy: 0.8439 - val_loss: 0.3376 - learning_rate: 0.0053\n",
            "Epoch 3/41\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7029 - loss: 0.5293\n",
            "Epoch 3: val_loss improved from 0.33764 to 0.31699, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7032 - loss: 0.5292 - val_accuracy: 0.8574 - val_loss: 0.3170 - learning_rate: 0.0053\n",
            "Epoch 4/41\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7254 - loss: 0.4979\n",
            "Epoch 4: val_loss improved from 0.31699 to 0.30499, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7254 - loss: 0.4981 - val_accuracy: 0.8928 - val_loss: 0.3050 - learning_rate: 0.0053\n",
            "Epoch 5/41\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7213 - loss: 0.4710\n",
            "Epoch 5: val_loss did not improve from 0.30499\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7214 - loss: 0.4710 - val_accuracy: 0.8110 - val_loss: 0.4113 - learning_rate: 0.0053\n",
            "Epoch 6/41\n",
            "\u001b[1m141/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7465 - loss: 0.4556\n",
            "Epoch 6: val_loss did not improve from 0.30499\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7463 - loss: 0.4559 - val_accuracy: 0.8430 - val_loss: 0.3286 - learning_rate: 0.0053\n",
            "Epoch 7/41\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7483 - loss: 0.4586\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0022170946415227483.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.30499\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7484 - loss: 0.4587 - val_accuracy: 0.8481 - val_loss: 0.3317 - learning_rate: 0.0053\n",
            "Epoch 8/41\n",
            "\u001b[1m146/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7609 - loss: 0.4384\n",
            "Epoch 8: val_loss improved from 0.30499 to 0.28664, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7611 - loss: 0.4382 - val_accuracy: 0.8827 - val_loss: 0.2866 - learning_rate: 0.0022\n",
            "Epoch 9/41\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8034 - loss: 0.4069\n",
            "Epoch 9: val_loss improved from 0.28664 to 0.26568, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.4070 - val_accuracy: 0.8903 - val_loss: 0.2657 - learning_rate: 0.0022\n",
            "Epoch 10/41\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7878 - loss: 0.4064\n",
            "Epoch 10: val_loss did not improve from 0.26568\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7882 - loss: 0.4061 - val_accuracy: 0.8692 - val_loss: 0.3033 - learning_rate: 0.0022\n",
            "Epoch 11/41\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7766 - loss: 0.4067\n",
            "Epoch 11: val_loss did not improve from 0.26568\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7769 - loss: 0.4065 - val_accuracy: 0.8717 - val_loss: 0.2896 - learning_rate: 0.0022\n",
            "Epoch 12/41\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7913 - loss: 0.3995\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0009249525273981266.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.26568\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7914 - loss: 0.3996 - val_accuracy: 0.8911 - val_loss: 0.2742 - learning_rate: 0.0022\n",
            "Epoch 13/41\n",
            "\u001b[1m137/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8077 - loss: 0.3888\n",
            "Epoch 13: val_loss did not improve from 0.26568\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.3886 - val_accuracy: 0.8869 - val_loss: 0.2757 - learning_rate: 9.2495e-04\n",
            "Epoch 14/41\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.3718\n",
            "Epoch 14: val_loss did not improve from 0.26568\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8253 - loss: 0.3717 - val_accuracy: 0.8911 - val_loss: 0.2678 - learning_rate: 9.2495e-04\n",
            "Epoch 15/41\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8282 - loss: 0.3680\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0003858821076771382.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.26568\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8283 - loss: 0.3679 - val_accuracy: 0.8878 - val_loss: 0.2745 - learning_rate: 9.2495e-04\n",
            "Epoch 16/41\n",
            "\u001b[1m136/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.3561\n",
            "Epoch 16: val_loss did not improve from 0.26568\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8375 - loss: 0.3559 - val_accuracy: 0.8287 - val_loss: 0.3636 - learning_rate: 3.8588e-04\n",
            "Epoch 17/41\n",
            "\u001b[1m145/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8529 - loss: 0.3451\n",
            "Epoch 17: val_loss did not improve from 0.26568\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8527 - loss: 0.3452 - val_accuracy: 0.8295 - val_loss: 0.3507 - learning_rate: 3.8588e-04\n",
            "Epoch 18/41\n",
            "\u001b[1m146/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8429 - loss: 0.3488\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001609866427113533.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.26568\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8428 - loss: 0.3488 - val_accuracy: 0.8338 - val_loss: 0.3504 - learning_rate: 3.8588e-04\n",
            "Epoch 19/41\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8502 - loss: 0.3414\n",
            "Epoch 19: val_loss did not improve from 0.26568\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8503 - loss: 0.3413 - val_accuracy: 0.8270 - val_loss: 0.3481 - learning_rate: 1.6099e-04\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:31:40,781] Trial 15 finished with value: -0.26568374037742615 and parameters: {'epochs': 41, 'batch_size': 32, 'learning_rate': 0.005314336149323822, 'stop_patience': 10, 'reduce_lr_factor': 0.41719126819732166, 'reduce_lr_patience': 3}. Best is trial 8 with value: -0.25244078040122986.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/19\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5620 - loss: 0.6793\n",
            "Epoch 1: val_loss improved from inf to 0.40448, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5630 - loss: 0.6786 - val_accuracy: 0.8819 - val_loss: 0.4045 - learning_rate: 0.0034\n",
            "Epoch 2/19\n",
            "\u001b[1m132/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6742 - loss: 0.5844\n",
            "Epoch 2: val_loss improved from 0.40448 to 0.36585, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6770 - loss: 0.5827 - val_accuracy: 0.8253 - val_loss: 0.3658 - learning_rate: 0.0034\n",
            "Epoch 3/19\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7096 - loss: 0.5176\n",
            "Epoch 3: val_loss improved from 0.36585 to 0.26616, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7101 - loss: 0.5173 - val_accuracy: 0.8903 - val_loss: 0.2662 - learning_rate: 0.0034\n",
            "Epoch 4/19\n",
            "\u001b[1m145/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7287 - loss: 0.4892\n",
            "Epoch 4: val_loss did not improve from 0.26616\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7289 - loss: 0.4892 - val_accuracy: 0.7232 - val_loss: 0.6349 - learning_rate: 0.0034\n",
            "Epoch 5/19\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7257 - loss: 0.4795\n",
            "Epoch 5: val_loss did not improve from 0.26616\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7261 - loss: 0.4798 - val_accuracy: 0.8667 - val_loss: 0.3099 - learning_rate: 0.0034\n",
            "Epoch 6/19\n",
            "\u001b[1m137/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7454 - loss: 0.4648\n",
            "Epoch 6: val_loss did not improve from 0.26616\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7454 - loss: 0.4651 - val_accuracy: 0.8540 - val_loss: 0.3222 - learning_rate: 0.0034\n",
            "Epoch 7/19\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7605 - loss: 0.4571\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005196750361020101.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.26616\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7604 - loss: 0.4576 - val_accuracy: 0.8025 - val_loss: 0.3998 - learning_rate: 0.0034\n",
            "Epoch 8/19\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7659 - loss: 0.4342\n",
            "Epoch 8: val_loss did not improve from 0.26616\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7669 - loss: 0.4334 - val_accuracy: 0.8582 - val_loss: 0.3078 - learning_rate: 5.1968e-04\n",
            "Epoch 9/19\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7907 - loss: 0.4139\n",
            "Epoch 9: val_loss did not improve from 0.26616\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7910 - loss: 0.4137 - val_accuracy: 0.8447 - val_loss: 0.3279 - learning_rate: 5.1968e-04\n",
            "Epoch 10/19\n",
            "\u001b[1m136/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8010 - loss: 0.4070\n",
            "Epoch 10: val_loss did not improve from 0.26616\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8009 - loss: 0.4070 - val_accuracy: 0.8456 - val_loss: 0.3296 - learning_rate: 5.1968e-04\n",
            "Epoch 11/19\n",
            "\u001b[1m135/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8077 - loss: 0.3989\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 8.056744361068116e-05.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.26616\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.3990 - val_accuracy: 0.8709 - val_loss: 0.2962 - learning_rate: 5.1968e-04\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:31:54,269] Trial 16 finished with value: -0.26615914702415466 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.0033520009531193998, 'stop_patience': 8, 'reduce_lr_factor': 0.15503427962243052, 'reduce_lr_patience': 4}. Best is trial 8 with value: -0.25244078040122986.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5671 - loss: 0.6825\n",
            "Epoch 1: val_loss improved from inf to 1.14582, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5679 - loss: 0.6815 - val_accuracy: 0.4641 - val_loss: 1.1458 - learning_rate: 0.0098\n",
            "Epoch 2/12\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6598 - loss: 0.5800\n",
            "Epoch 2: val_loss improved from 1.14582 to 0.40674, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6597 - loss: 0.5798 - val_accuracy: 0.8641 - val_loss: 0.4067 - learning_rate: 0.0098\n",
            "Epoch 3/12\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6924 - loss: 0.5356\n",
            "Epoch 3: val_loss improved from 0.40674 to 0.33986, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6924 - loss: 0.5354 - val_accuracy: 0.8262 - val_loss: 0.3399 - learning_rate: 0.0098\n",
            "Epoch 4/12\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7081 - loss: 0.4969\n",
            "Epoch 4: val_loss did not improve from 0.33986\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7085 - loss: 0.4969 - val_accuracy: 0.7916 - val_loss: 0.5044 - learning_rate: 0.0098\n",
            "Epoch 5/12\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7134 - loss: 0.4815\n",
            "Epoch 5: val_loss did not improve from 0.33986\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7133 - loss: 0.4818 - val_accuracy: 0.6751 - val_loss: 0.5321 - learning_rate: 0.0098\n",
            "Epoch 6/12\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7346 - loss: 0.4803\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.004061295215192818.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.33986\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7347 - loss: 0.4803 - val_accuracy: 0.8228 - val_loss: 0.3586 - learning_rate: 0.0098\n",
            "Epoch 7/12\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7513 - loss: 0.4438\n",
            "Epoch 7: val_loss improved from 0.33986 to 0.28609, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7513 - loss: 0.4438 - val_accuracy: 0.8886 - val_loss: 0.2861 - learning_rate: 0.0041\n",
            "Epoch 8/12\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7598 - loss: 0.4383\n",
            "Epoch 8: val_loss did not improve from 0.28609\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7597 - loss: 0.4384 - val_accuracy: 0.8143 - val_loss: 0.3799 - learning_rate: 0.0041\n",
            "Epoch 9/12\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7686 - loss: 0.4349\n",
            "Epoch 9: val_loss did not improve from 0.28609\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7688 - loss: 0.4348 - val_accuracy: 0.8169 - val_loss: 0.3563 - learning_rate: 0.0041\n",
            "Epoch 10/12\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.4226\n",
            "Epoch 10: val_loss improved from 0.28609 to 0.27027, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7742 - loss: 0.4229 - val_accuracy: 0.8886 - val_loss: 0.2703 - learning_rate: 0.0041\n",
            "Epoch 11/12\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7727 - loss: 0.4192\n",
            "Epoch 11: val_loss did not improve from 0.27027\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7725 - loss: 0.4198 - val_accuracy: 0.8262 - val_loss: 0.3708 - learning_rate: 0.0041\n",
            "Epoch 12/12\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7775 - loss: 0.4110\n",
            "Epoch 12: val_loss did not improve from 0.27027\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7775 - loss: 0.4112 - val_accuracy: 0.8380 - val_loss: 0.4640 - learning_rate: 0.0041\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:32:12,725] Trial 17 finished with value: -0.2702689468860626 and parameters: {'epochs': 12, 'batch_size': 16, 'learning_rate': 0.00978134837196886, 'stop_patience': 5, 'reduce_lr_factor': 0.41520810829841676, 'reduce_lr_patience': 3}. Best is trial 8 with value: -0.25244078040122986.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/27\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5247 - loss: 0.6934\n",
            "Epoch 1: val_loss improved from inf to 0.66740, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5260 - loss: 0.6932 - val_accuracy: 0.7291 - val_loss: 0.6674 - learning_rate: 7.1564e-05\n",
            "Epoch 2/27\n",
            "\u001b[1m145/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5854 - loss: 0.6876\n",
            "Epoch 2: val_loss improved from 0.66740 to 0.64032, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5858 - loss: 0.6875 - val_accuracy: 0.8489 - val_loss: 0.6403 - learning_rate: 7.1564e-05\n",
            "Epoch 3/27\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6011 - loss: 0.6750\n",
            "Epoch 3: val_loss improved from 0.64032 to 0.61283, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6015 - loss: 0.6748 - val_accuracy: 0.8658 - val_loss: 0.6128 - learning_rate: 7.1564e-05\n",
            "Epoch 4/27\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6050 - loss: 0.6641\n",
            "Epoch 4: val_loss improved from 0.61283 to 0.59324, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6056 - loss: 0.6639 - val_accuracy: 0.8278 - val_loss: 0.5932 - learning_rate: 7.1564e-05\n",
            "Epoch 5/27\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6180 - loss: 0.6538\n",
            "Epoch 5: val_loss improved from 0.59324 to 0.57052, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6180 - loss: 0.6538 - val_accuracy: 0.7873 - val_loss: 0.5705 - learning_rate: 7.1564e-05\n",
            "Epoch 6/27\n",
            "\u001b[1m141/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6282 - loss: 0.6426\n",
            "Epoch 6: val_loss improved from 0.57052 to 0.53760, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6283 - loss: 0.6424 - val_accuracy: 0.8270 - val_loss: 0.5376 - learning_rate: 7.1564e-05\n",
            "Epoch 7/27\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6324 - loss: 0.6354\n",
            "Epoch 7: val_loss improved from 0.53760 to 0.51098, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6324 - loss: 0.6354 - val_accuracy: 0.8380 - val_loss: 0.5110 - learning_rate: 7.1564e-05\n",
            "Epoch 8/27\n",
            "\u001b[1m136/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6346 - loss: 0.6252\n",
            "Epoch 8: val_loss improved from 0.51098 to 0.49649, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6349 - loss: 0.6249 - val_accuracy: 0.8253 - val_loss: 0.4965 - learning_rate: 7.1564e-05\n",
            "Epoch 9/27\n",
            "\u001b[1m141/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6503 - loss: 0.6175\n",
            "Epoch 9: val_loss improved from 0.49649 to 0.47816, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6506 - loss: 0.6174 - val_accuracy: 0.8270 - val_loss: 0.4782 - learning_rate: 7.1564e-05\n",
            "Epoch 10/27\n",
            "\u001b[1m134/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6461 - loss: 0.6116\n",
            "Epoch 10: val_loss improved from 0.47816 to 0.45699, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6470 - loss: 0.6113 - val_accuracy: 0.8515 - val_loss: 0.4570 - learning_rate: 7.1564e-05\n",
            "Epoch 11/27\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6714 - loss: 0.6004\n",
            "Epoch 11: val_loss improved from 0.45699 to 0.44731, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6714 - loss: 0.6004 - val_accuracy: 0.8253 - val_loss: 0.4473 - learning_rate: 7.1564e-05\n",
            "Epoch 12/27\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6830 - loss: 0.5922\n",
            "Epoch 12: val_loss improved from 0.44731 to 0.42503, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6830 - loss: 0.5921 - val_accuracy: 0.8591 - val_loss: 0.4250 - learning_rate: 7.1564e-05\n",
            "Epoch 13/27\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6769 - loss: 0.5857\n",
            "Epoch 13: val_loss did not improve from 0.42503\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6772 - loss: 0.5855 - val_accuracy: 0.7857 - val_loss: 0.4482 - learning_rate: 7.1564e-05\n",
            "Epoch 14/27\n",
            "\u001b[1m135/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6959 - loss: 0.5771\n",
            "Epoch 14: val_loss improved from 0.42503 to 0.41850, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6961 - loss: 0.5770 - val_accuracy: 0.8186 - val_loss: 0.4185 - learning_rate: 7.1564e-05\n",
            "Epoch 15/27\n",
            "\u001b[1m134/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7041 - loss: 0.5691\n",
            "Epoch 15: val_loss improved from 0.41850 to 0.41283, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7042 - loss: 0.5689 - val_accuracy: 0.8110 - val_loss: 0.4128 - learning_rate: 7.1564e-05\n",
            "Epoch 16/27\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7151 - loss: 0.5637\n",
            "Epoch 16: val_loss improved from 0.41283 to 0.38303, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7151 - loss: 0.5636 - val_accuracy: 0.8523 - val_loss: 0.3830 - learning_rate: 7.1564e-05\n",
            "Epoch 17/27\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7070 - loss: 0.5570\n",
            "Epoch 17: val_loss did not improve from 0.38303\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7073 - loss: 0.5570 - val_accuracy: 0.8211 - val_loss: 0.3922 - learning_rate: 7.1564e-05\n",
            "Epoch 18/27\n",
            "\u001b[1m134/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7242 - loss: 0.5511\n",
            "Epoch 18: val_loss improved from 0.38303 to 0.37864, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7238 - loss: 0.5510 - val_accuracy: 0.8397 - val_loss: 0.3786 - learning_rate: 7.1564e-05\n",
            "Epoch 19/27\n",
            "\u001b[1m133/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.5447\n",
            "Epoch 19: val_loss did not improve from 0.37864\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7261 - loss: 0.5448 - val_accuracy: 0.8068 - val_loss: 0.3926 - learning_rate: 7.1564e-05\n",
            "Epoch 20/27\n",
            "\u001b[1m132/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.5383\n",
            "Epoch 20: val_loss improved from 0.37864 to 0.37298, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7374 - loss: 0.5383 - val_accuracy: 0.8295 - val_loss: 0.3730 - learning_rate: 7.1564e-05\n",
            "Epoch 21/27\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7421 - loss: 0.5371\n",
            "Epoch 21: val_loss did not improve from 0.37298\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7420 - loss: 0.5369 - val_accuracy: 0.8101 - val_loss: 0.3811 - learning_rate: 7.1564e-05\n",
            "Epoch 22/27\n",
            "\u001b[1m132/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7376 - loss: 0.5280\n",
            "Epoch 22: val_loss improved from 0.37298 to 0.37225, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7376 - loss: 0.5280 - val_accuracy: 0.8177 - val_loss: 0.3722 - learning_rate: 7.1564e-05\n",
            "Epoch 23/27\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7461 - loss: 0.5262\n",
            "Epoch 23: val_loss did not improve from 0.37225\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7460 - loss: 0.5262 - val_accuracy: 0.8084 - val_loss: 0.3884 - learning_rate: 7.1564e-05\n",
            "Epoch 24/27\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7446 - loss: 0.5216\n",
            "Epoch 24: val_loss improved from 0.37225 to 0.36360, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7447 - loss: 0.5215 - val_accuracy: 0.8270 - val_loss: 0.3636 - learning_rate: 7.1564e-05\n",
            "Epoch 25/27\n",
            "\u001b[1m138/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7558 - loss: 0.5187\n",
            "Epoch 25: val_loss did not improve from 0.36360\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7556 - loss: 0.5184 - val_accuracy: 0.8135 - val_loss: 0.3733 - learning_rate: 7.1564e-05\n",
            "Epoch 26/27\n",
            "\u001b[1m143/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7528 - loss: 0.5145\n",
            "Epoch 26: val_loss improved from 0.36360 to 0.35390, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7527 - loss: 0.5144 - val_accuracy: 0.8380 - val_loss: 0.3539 - learning_rate: 7.1564e-05\n",
            "Epoch 27/27\n",
            "\u001b[1m136/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7586 - loss: 0.5111\n",
            "Epoch 27: val_loss did not improve from 0.35390\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7582 - loss: 0.5109 - val_accuracy: 0.8312 - val_loss: 0.3585 - learning_rate: 7.1564e-05\n",
            "Restoring model weights from the end of the best epoch: 26.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:32:45,650] Trial 18 finished with value: -0.35390326380729675 and parameters: {'epochs': 27, 'batch_size': 32, 'learning_rate': 7.156396669792632e-05, 'stop_patience': 3, 'reduce_lr_factor': 0.36058289596246423, 'reduce_lr_patience': 5}. Best is trial 8 with value: -0.25244078040122986.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5877 - loss: 0.6763\n",
            "Epoch 1: val_loss improved from inf to 0.56329, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5879 - loss: 0.6761 - val_accuracy: 0.7165 - val_loss: 0.5633 - learning_rate: 0.0066\n",
            "Epoch 2/35\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6477 - loss: 0.6039\n",
            "Epoch 2: val_loss improved from 0.56329 to 0.40695, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6491 - loss: 0.6024 - val_accuracy: 0.7890 - val_loss: 0.4069 - learning_rate: 0.0066\n",
            "Epoch 3/35\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7133 - loss: 0.5255\n",
            "Epoch 3: val_loss improved from 0.40695 to 0.34336, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7133 - loss: 0.5253 - val_accuracy: 0.8405 - val_loss: 0.3434 - learning_rate: 0.0066\n",
            "Epoch 4/35\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7258 - loss: 0.4930\n",
            "Epoch 4: val_loss did not improve from 0.34336\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7258 - loss: 0.4930 - val_accuracy: 0.7941 - val_loss: 0.4674 - learning_rate: 0.0066\n",
            "Epoch 5/35\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7356 - loss: 0.4767\n",
            "Epoch 5: val_loss did not improve from 0.34336\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7356 - loss: 0.4767 - val_accuracy: 0.6970 - val_loss: 0.6302 - learning_rate: 0.0066\n",
            "Epoch 6/35\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7462 - loss: 0.4705\n",
            "Epoch 6: val_loss did not improve from 0.34336\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7463 - loss: 0.4708 - val_accuracy: 0.8439 - val_loss: 0.3603 - learning_rate: 0.0066\n",
            "Epoch 7/35\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7635 - loss: 0.4559\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0017653107823338106.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.34336\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7634 - loss: 0.4558 - val_accuracy: 0.7249 - val_loss: 0.4750 - learning_rate: 0.0066\n",
            "Epoch 8/35\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7801 - loss: 0.4243\n",
            "Epoch 8: val_loss improved from 0.34336 to 0.25395, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7805 - loss: 0.4241 - val_accuracy: 0.8895 - val_loss: 0.2539 - learning_rate: 0.0018\n",
            "Epoch 9/35\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.4052\n",
            "Epoch 9: val_loss did not improve from 0.25395\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7996 - loss: 0.4052 - val_accuracy: 0.8338 - val_loss: 0.3949 - learning_rate: 0.0018\n",
            "Epoch 10/35\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8217 - loss: 0.3952\n",
            "Epoch 10: val_loss did not improve from 0.25395\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8215 - loss: 0.3952 - val_accuracy: 0.8641 - val_loss: 0.3146 - learning_rate: 0.0018\n",
            "Epoch 11/35\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8184 - loss: 0.3864\n",
            "Epoch 11: val_loss did not improve from 0.25395\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8184 - loss: 0.3864 - val_accuracy: 0.8624 - val_loss: 0.3222 - learning_rate: 0.0018\n",
            "Epoch 12/35\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8202 - loss: 0.3824\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0004753345494941804.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.25395\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8201 - loss: 0.3825 - val_accuracy: 0.8852 - val_loss: 0.2839 - learning_rate: 0.0018\n",
            "Epoch 13/35\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8337 - loss: 0.3679\n",
            "Epoch 13: val_loss did not improve from 0.25395\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8338 - loss: 0.3677 - val_accuracy: 0.8523 - val_loss: 0.3260 - learning_rate: 4.7533e-04\n",
            "Epoch 14/35\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8499 - loss: 0.3597\n",
            "Epoch 14: val_loss did not improve from 0.25395\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8498 - loss: 0.3597 - val_accuracy: 0.8633 - val_loss: 0.3165 - learning_rate: 4.7533e-04\n",
            "Epoch 15/35\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8492 - loss: 0.3571\n",
            "Epoch 15: val_loss did not improve from 0.25395\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.3571 - val_accuracy: 0.8624 - val_loss: 0.3364 - learning_rate: 4.7533e-04\n",
            "Epoch 16/35\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8524 - loss: 0.3559\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00012799046029730895.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.25395\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8524 - loss: 0.3559 - val_accuracy: 0.8540 - val_loss: 0.3462 - learning_rate: 4.7533e-04\n",
            "Epoch 17/35\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.3479\n",
            "Epoch 17: val_loss did not improve from 0.25395\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.3478 - val_accuracy: 0.8203 - val_loss: 0.3780 - learning_rate: 1.2799e-04\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:33:12,832] Trial 19 finished with value: -0.253948450088501 and parameters: {'epochs': 35, 'batch_size': 16, 'learning_rate': 0.006556060829559928, 'stop_patience': 9, 'reduce_lr_factor': 0.2692639500667372, 'reduce_lr_patience': 4}. Best is trial 8 with value: -0.25244078040122986.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/44\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5618 - loss: 0.6797\n",
            "Epoch 1: val_loss improved from inf to 0.68875, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5641 - loss: 0.6782 - val_accuracy: 0.5637 - val_loss: 0.6888 - learning_rate: 0.0029\n",
            "Epoch 2/44\n",
            "\u001b[1m137/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6607 - loss: 0.5984\n",
            "Epoch 2: val_loss improved from 0.68875 to 0.57925, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6624 - loss: 0.5970 - val_accuracy: 0.7181 - val_loss: 0.5793 - learning_rate: 0.0029\n",
            "Epoch 3/44\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7171 - loss: 0.5275\n",
            "Epoch 3: val_loss improved from 0.57925 to 0.35821, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7171 - loss: 0.5276 - val_accuracy: 0.8262 - val_loss: 0.3582 - learning_rate: 0.0029\n",
            "Epoch 4/44\n",
            "\u001b[1m141/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7303 - loss: 0.5066\n",
            "Epoch 4: val_loss did not improve from 0.35821\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7304 - loss: 0.5067 - val_accuracy: 0.7857 - val_loss: 0.4448 - learning_rate: 0.0029\n",
            "Epoch 5/44\n",
            "\u001b[1m137/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7421 - loss: 0.4805\n",
            "Epoch 5: val_loss improved from 0.35821 to 0.30862, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7420 - loss: 0.4808 - val_accuracy: 0.8650 - val_loss: 0.3086 - learning_rate: 0.0029\n",
            "Epoch 6/44\n",
            "\u001b[1m142/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7571 - loss: 0.4623\n",
            "Epoch 6: val_loss did not improve from 0.30862\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7569 - loss: 0.4626 - val_accuracy: 0.8464 - val_loss: 0.3338 - learning_rate: 0.0029\n",
            "Epoch 7/44\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7579 - loss: 0.4561\n",
            "Epoch 7: val_loss improved from 0.30862 to 0.29745, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7579 - loss: 0.4564 - val_accuracy: 0.8692 - val_loss: 0.2975 - learning_rate: 0.0029\n",
            "Epoch 8/44\n",
            "\u001b[1m140/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7422 - loss: 0.4705\n",
            "Epoch 8: val_loss improved from 0.29745 to 0.27403, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7427 - loss: 0.4705 - val_accuracy: 0.8945 - val_loss: 0.2740 - learning_rate: 0.0029\n",
            "Epoch 9/44\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7597 - loss: 0.4525\n",
            "Epoch 9: val_loss did not improve from 0.27403\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7596 - loss: 0.4526 - val_accuracy: 0.8515 - val_loss: 0.3222 - learning_rate: 0.0029\n",
            "Epoch 10/44\n",
            "\u001b[1m136/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7709 - loss: 0.4387\n",
            "Epoch 10: val_loss improved from 0.27403 to 0.27063, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7702 - loss: 0.4392 - val_accuracy: 0.8852 - val_loss: 0.2706 - learning_rate: 0.0029\n",
            "Epoch 11/44\n",
            "\u001b[1m136/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7711 - loss: 0.4350\n",
            "Epoch 11: val_loss did not improve from 0.27063\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7707 - loss: 0.4357 - val_accuracy: 0.8684 - val_loss: 0.3032 - learning_rate: 0.0029\n",
            "Epoch 12/44\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7675 - loss: 0.4245\n",
            "Epoch 12: val_loss did not improve from 0.27063\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7675 - loss: 0.4245 - val_accuracy: 0.8000 - val_loss: 0.4007 - learning_rate: 0.0029\n",
            "Epoch 13/44\n",
            "\u001b[1m145/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7740 - loss: 0.4314\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00044709971807080384.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.27063\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7741 - loss: 0.4315 - val_accuracy: 0.8759 - val_loss: 0.3015 - learning_rate: 0.0029\n",
            "Epoch 14/44\n",
            "\u001b[1m133/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7998 - loss: 0.4118\n",
            "Epoch 14: val_loss did not improve from 0.27063\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8005 - loss: 0.4105 - val_accuracy: 0.8574 - val_loss: 0.3283 - learning_rate: 4.4710e-04\n",
            "Epoch 15/44\n",
            "\u001b[1m144/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8232 - loss: 0.3837\n",
            "Epoch 15: val_loss did not improve from 0.27063\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8232 - loss: 0.3836 - val_accuracy: 0.8692 - val_loss: 0.2927 - learning_rate: 4.4710e-04\n",
            "Epoch 16/44\n",
            "\u001b[1m141/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8188 - loss: 0.3785\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.802063381228757e-05.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.27063\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8189 - loss: 0.3784 - val_accuracy: 0.8473 - val_loss: 0.3375 - learning_rate: 4.4710e-04\n",
            "Epoch 17/44\n",
            "\u001b[1m137/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.3667\n",
            "Epoch 17: val_loss did not improve from 0.27063\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8376 - loss: 0.3666 - val_accuracy: 0.8456 - val_loss: 0.3268 - learning_rate: 6.8021e-05\n",
            "Epoch 18/44\n",
            "\u001b[1m139/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8440 - loss: 0.3671\n",
            "Epoch 18: val_loss did not improve from 0.27063\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8440 - loss: 0.3669 - val_accuracy: 0.8447 - val_loss: 0.3274 - learning_rate: 6.8021e-05\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:33:34,612] Trial 20 finished with value: -0.27063363790512085 and parameters: {'epochs': 44, 'batch_size': 32, 'learning_rate': 0.0029387869694841705, 'stop_patience': 8, 'reduce_lr_factor': 0.15213750435667475, 'reduce_lr_patience': 3}. Best is trial 8 with value: -0.25244078040122986.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5844 - loss: 0.6856\n",
            "Epoch 1: val_loss improved from inf to 0.77501, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5848 - loss: 0.6850 - val_accuracy: 0.5992 - val_loss: 0.7750 - learning_rate: 0.0068\n",
            "Epoch 2/35\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6585 - loss: 0.5921\n",
            "Epoch 2: val_loss improved from 0.77501 to 0.62464, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6585 - loss: 0.5921 - val_accuracy: 0.6008 - val_loss: 0.6246 - learning_rate: 0.0068\n",
            "Epoch 3/35\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7085 - loss: 0.5340\n",
            "Epoch 3: val_loss did not improve from 0.62464\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7084 - loss: 0.5339 - val_accuracy: 0.6717 - val_loss: 0.7716 - learning_rate: 0.0068\n",
            "Epoch 4/35\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7178 - loss: 0.5111\n",
            "Epoch 4: val_loss improved from 0.62464 to 0.36849, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7175 - loss: 0.5113 - val_accuracy: 0.8515 - val_loss: 0.3685 - learning_rate: 0.0068\n",
            "Epoch 5/35\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7199 - loss: 0.4995\n",
            "Epoch 5: val_loss did not improve from 0.36849\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7199 - loss: 0.5000 - val_accuracy: 0.7806 - val_loss: 0.4525 - learning_rate: 0.0068\n",
            "Epoch 6/35\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7351 - loss: 0.4812\n",
            "Epoch 6: val_loss improved from 0.36849 to 0.24615, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7350 - loss: 0.4813 - val_accuracy: 0.8970 - val_loss: 0.2461 - learning_rate: 0.0068\n",
            "Epoch 7/35\n",
            "\u001b[1m277/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7519 - loss: 0.4658\n",
            "Epoch 7: val_loss did not improve from 0.24615\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7513 - loss: 0.4663 - val_accuracy: 0.8692 - val_loss: 0.2758 - learning_rate: 0.0068\n",
            "Epoch 8/35\n",
            "\u001b[1m279/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7457 - loss: 0.4575\n",
            "Epoch 8: val_loss did not improve from 0.24615\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7461 - loss: 0.4578 - val_accuracy: 0.8692 - val_loss: 0.3034 - learning_rate: 0.0068\n",
            "Epoch 9/35\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7555 - loss: 0.4500\n",
            "Epoch 9: val_loss did not improve from 0.24615\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7556 - loss: 0.4502 - val_accuracy: 0.8979 - val_loss: 0.2495 - learning_rate: 0.0068\n",
            "Epoch 10/35\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7681 - loss: 0.4351\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0018935041726072092.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.24615\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7680 - loss: 0.4352 - val_accuracy: 0.8641 - val_loss: 0.2910 - learning_rate: 0.0068\n",
            "Epoch 11/35\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: 0.4142\n",
            "Epoch 11: val_loss did not improve from 0.24615\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: 0.4140 - val_accuracy: 0.8692 - val_loss: 0.3066 - learning_rate: 0.0019\n",
            "Epoch 12/35\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8097 - loss: 0.3893\n",
            "Epoch 12: val_loss did not improve from 0.24615\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8098 - loss: 0.3892 - val_accuracy: 0.8954 - val_loss: 0.2479 - learning_rate: 0.0019\n",
            "Epoch 13/35\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8204 - loss: 0.3812\n",
            "Epoch 13: val_loss did not improve from 0.24615\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8203 - loss: 0.3813 - val_accuracy: 0.8869 - val_loss: 0.2735 - learning_rate: 0.0019\n",
            "Epoch 14/35\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8290 - loss: 0.3703\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005247351612813552.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.24615\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.3704 - val_accuracy: 0.8802 - val_loss: 0.2867 - learning_rate: 0.0019\n",
            "Epoch 15/35\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8479 - loss: 0.3553\n",
            "Epoch 15: val_loss did not improve from 0.24615\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8480 - loss: 0.3552 - val_accuracy: 0.8397 - val_loss: 0.3548 - learning_rate: 5.2474e-04\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:33:56,835] Trial 21 finished with value: -0.2461479902267456 and parameters: {'epochs': 35, 'batch_size': 16, 'learning_rate': 0.006832700372369997, 'stop_patience': 9, 'reduce_lr_factor': 0.2771238472175331, 'reduce_lr_patience': 4}. Best is trial 21 with value: -0.2461479902267456.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/33\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5656 - loss: 0.6891\n",
            "Epoch 1: val_loss improved from inf to 0.73177, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5658 - loss: 0.6888 - val_accuracy: 0.5392 - val_loss: 0.7318 - learning_rate: 0.0074\n",
            "Epoch 2/33\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6564 - loss: 0.5853\n",
            "Epoch 2: val_loss improved from 0.73177 to 0.54683, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6568 - loss: 0.5850 - val_accuracy: 0.7030 - val_loss: 0.5468 - learning_rate: 0.0074\n",
            "Epoch 3/33\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7088 - loss: 0.5041\n",
            "Epoch 3: val_loss improved from 0.54683 to 0.26404, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7086 - loss: 0.5041 - val_accuracy: 0.8911 - val_loss: 0.2640 - learning_rate: 0.0074\n",
            "Epoch 4/33\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.4825\n",
            "Epoch 4: val_loss did not improve from 0.26404\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7321 - loss: 0.4827 - val_accuracy: 0.7426 - val_loss: 0.5761 - learning_rate: 0.0074\n",
            "Epoch 5/33\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7449 - loss: 0.4672\n",
            "Epoch 5: val_loss did not improve from 0.26404\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7450 - loss: 0.4674 - val_accuracy: 0.8017 - val_loss: 0.3955 - learning_rate: 0.0074\n",
            "Epoch 6/33\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7372 - loss: 0.4628\n",
            "Epoch 6: val_loss improved from 0.26404 to 0.25650, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7372 - loss: 0.4628 - val_accuracy: 0.8903 - val_loss: 0.2565 - learning_rate: 0.0074\n",
            "Epoch 7/33\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7572 - loss: 0.4511\n",
            "Epoch 7: val_loss did not improve from 0.25650\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7572 - loss: 0.4512 - val_accuracy: 0.8844 - val_loss: 0.2588 - learning_rate: 0.0074\n",
            "Epoch 8/33\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.4501\n",
            "Epoch 8: val_loss did not improve from 0.25650\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7438 - loss: 0.4502 - val_accuracy: 0.8110 - val_loss: 0.4539 - learning_rate: 0.0074\n",
            "Epoch 9/33\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7546 - loss: 0.4427\n",
            "Epoch 9: val_loss did not improve from 0.25650\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7543 - loss: 0.4431 - val_accuracy: 0.8920 - val_loss: 0.2596 - learning_rate: 0.0074\n",
            "Epoch 10/33\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7547 - loss: 0.4433\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0030791687751782.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.25650\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7546 - loss: 0.4435 - val_accuracy: 0.8641 - val_loss: 0.3182 - learning_rate: 0.0074\n",
            "Epoch 11/33\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7760 - loss: 0.4198\n",
            "Epoch 11: val_loss did not improve from 0.25650\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7762 - loss: 0.4199 - val_accuracy: 0.8591 - val_loss: 0.3592 - learning_rate: 0.0031\n",
            "Epoch 12/33\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7974 - loss: 0.3991\n",
            "Epoch 12: val_loss did not improve from 0.25650\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7974 - loss: 0.3992 - val_accuracy: 0.7789 - val_loss: 0.6063 - learning_rate: 0.0031\n",
            "Epoch 13/33\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8080 - loss: 0.3947\n",
            "Epoch 13: val_loss did not improve from 0.25650\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8079 - loss: 0.3946 - val_accuracy: 0.8405 - val_loss: 0.4508 - learning_rate: 0.0031\n",
            "Epoch 14/33\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8163 - loss: 0.3809\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0012785331909452133.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.25650\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8162 - loss: 0.3810 - val_accuracy: 0.7949 - val_loss: 0.5545 - learning_rate: 0.0031\n",
            "Epoch 15/33\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.3641\n",
            "Epoch 15: val_loss did not improve from 0.25650\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8253 - loss: 0.3641 - val_accuracy: 0.8793 - val_loss: 0.2788 - learning_rate: 0.0013\n",
            "Epoch 16/33\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8390 - loss: 0.3583\n",
            "Epoch 16: val_loss did not improve from 0.25650\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 0.3582 - val_accuracy: 0.8878 - val_loss: 0.2667 - learning_rate: 0.0013\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:34:21,080] Trial 22 finished with value: -0.2565048933029175 and parameters: {'epochs': 33, 'batch_size': 16, 'learning_rate': 0.0074157482172003755, 'stop_patience': 10, 'reduce_lr_factor': 0.41522024367467036, 'reduce_lr_patience': 4}. Best is trial 21 with value: -0.2461479902267456.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/29\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5866 - loss: 0.6762\n",
            "Epoch 1: val_loss improved from inf to 0.51459, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5870 - loss: 0.6756 - val_accuracy: 0.7224 - val_loss: 0.5146 - learning_rate: 0.0050\n",
            "Epoch 2/29\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6591 - loss: 0.5906\n",
            "Epoch 2: val_loss did not improve from 0.51459\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6593 - loss: 0.5903 - val_accuracy: 0.7485 - val_loss: 0.5435 - learning_rate: 0.0050\n",
            "Epoch 3/29\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6967 - loss: 0.5346\n",
            "Epoch 3: val_loss did not improve from 0.51459\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6969 - loss: 0.5344 - val_accuracy: 0.6346 - val_loss: 0.7952 - learning_rate: 0.0050\n",
            "Epoch 4/29\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7153 - loss: 0.4905\n",
            "Epoch 4: val_loss improved from 0.51459 to 0.51117, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7157 - loss: 0.4907 - val_accuracy: 0.7671 - val_loss: 0.5112 - learning_rate: 0.0050\n",
            "Epoch 5/29\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7224 - loss: 0.4810\n",
            "Epoch 5: val_loss improved from 0.51117 to 0.33355, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7223 - loss: 0.4813 - val_accuracy: 0.8498 - val_loss: 0.3335 - learning_rate: 0.0050\n",
            "Epoch 6/29\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.4602\n",
            "Epoch 6: val_loss improved from 0.33355 to 0.28359, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7435 - loss: 0.4601 - val_accuracy: 0.8726 - val_loss: 0.2836 - learning_rate: 0.0050\n",
            "Epoch 7/29\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7484 - loss: 0.4510\n",
            "Epoch 7: val_loss did not improve from 0.28359\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7482 - loss: 0.4512 - val_accuracy: 0.7122 - val_loss: 0.5388 - learning_rate: 0.0050\n",
            "Epoch 8/29\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7486 - loss: 0.4450\n",
            "Epoch 8: val_loss did not improve from 0.28359\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7486 - loss: 0.4451 - val_accuracy: 0.7688 - val_loss: 0.6174 - learning_rate: 0.0050\n",
            "Epoch 9/29\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7455 - loss: 0.4465\n",
            "Epoch 9: val_loss did not improve from 0.28359\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7453 - loss: 0.4465 - val_accuracy: 0.7198 - val_loss: 0.7856 - learning_rate: 0.0050\n",
            "Epoch 10/29\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7645 - loss: 0.4288\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0017027683787157108.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.28359\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7644 - loss: 0.4291 - val_accuracy: 0.7350 - val_loss: 0.5615 - learning_rate: 0.0050\n",
            "Epoch 11/29\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7769 - loss: 0.4141\n",
            "Epoch 11: val_loss did not improve from 0.28359\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7770 - loss: 0.4140 - val_accuracy: 0.8591 - val_loss: 0.3071 - learning_rate: 0.0017\n",
            "Epoch 12/29\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7777 - loss: 0.4013\n",
            "Epoch 12: val_loss improved from 0.28359 to 0.26173, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7778 - loss: 0.4013 - val_accuracy: 0.8903 - val_loss: 0.2617 - learning_rate: 0.0017\n",
            "Epoch 13/29\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8069 - loss: 0.3819\n",
            "Epoch 13: val_loss did not improve from 0.26173\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8068 - loss: 0.3820 - val_accuracy: 0.8810 - val_loss: 0.2958 - learning_rate: 0.0017\n",
            "Epoch 14/29\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7994 - loss: 0.3848\n",
            "Epoch 14: val_loss did not improve from 0.26173\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7993 - loss: 0.3850 - val_accuracy: 0.7916 - val_loss: 0.4582 - learning_rate: 0.0017\n",
            "Epoch 15/29\n",
            "\u001b[1m283/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.3836\n",
            "Epoch 15: val_loss did not improve from 0.26173\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.3835 - val_accuracy: 0.8422 - val_loss: 0.3525 - learning_rate: 0.0017\n",
            "Epoch 16/29\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8206 - loss: 0.3754\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005774182937815094.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.26173\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8204 - loss: 0.3756 - val_accuracy: 0.8886 - val_loss: 0.2684 - learning_rate: 0.0017\n",
            "Epoch 17/29\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8464 - loss: 0.3523\n",
            "Epoch 17: val_loss did not improve from 0.26173\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8462 - loss: 0.3523 - val_accuracy: 0.8793 - val_loss: 0.2863 - learning_rate: 5.7742e-04\n",
            "Epoch 18/29\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8465 - loss: 0.3428\n",
            "Epoch 18: val_loss did not improve from 0.26173\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8466 - loss: 0.3428 - val_accuracy: 0.8802 - val_loss: 0.2798 - learning_rate: 5.7742e-04\n",
            "Epoch 19/29\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8509 - loss: 0.3353\n",
            "Epoch 19: val_loss did not improve from 0.26173\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8508 - loss: 0.3353 - val_accuracy: 0.8675 - val_loss: 0.3011 - learning_rate: 5.7742e-04\n",
            "Epoch 20/29\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3332\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001958057822044805.\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.26173\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3332 - val_accuracy: 0.8819 - val_loss: 0.2749 - learning_rate: 5.7742e-04\n",
            "Epoch 21/29\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8528 - loss: 0.3291\n",
            "Epoch 21: val_loss did not improve from 0.26173\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8531 - loss: 0.3289 - val_accuracy: 0.8540 - val_loss: 0.3109 - learning_rate: 1.9581e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:34:52,023] Trial 23 finished with value: -0.26172542572021484 and parameters: {'epochs': 29, 'batch_size': 16, 'learning_rate': 0.005021351447133433, 'stop_patience': 9, 'reduce_lr_factor': 0.33910560058530115, 'reduce_lr_patience': 4}. Best is trial 21 with value: -0.2461479902267456.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/38\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5941 - loss: 0.6790\n",
            "Epoch 1: val_loss improved from inf to 1.25440, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5943 - loss: 0.6786 - val_accuracy: 0.4743 - val_loss: 1.2544 - learning_rate: 0.0090\n",
            "Epoch 2/38\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6456 - loss: 0.6079\n",
            "Epoch 2: val_loss improved from 1.25440 to 0.52272, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6458 - loss: 0.6076 - val_accuracy: 0.6743 - val_loss: 0.5227 - learning_rate: 0.0090\n",
            "Epoch 3/38\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6870 - loss: 0.5342\n",
            "Epoch 3: val_loss did not improve from 0.52272\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6870 - loss: 0.5341 - val_accuracy: 0.5637 - val_loss: 1.2966 - learning_rate: 0.0090\n",
            "Epoch 4/38\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7088 - loss: 0.5139\n",
            "Epoch 4: val_loss improved from 0.52272 to 0.26855, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7085 - loss: 0.5138 - val_accuracy: 0.8878 - val_loss: 0.2686 - learning_rate: 0.0090\n",
            "Epoch 5/38\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7180 - loss: 0.4802\n",
            "Epoch 5: val_loss did not improve from 0.26855\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7179 - loss: 0.4806 - val_accuracy: 0.7224 - val_loss: 0.5285 - learning_rate: 0.0090\n",
            "Epoch 6/38\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7249 - loss: 0.4754\n",
            "Epoch 6: val_loss did not improve from 0.26855\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7248 - loss: 0.4757 - val_accuracy: 0.7426 - val_loss: 0.4409 - learning_rate: 0.0090\n",
            "Epoch 7/38\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7424 - loss: 0.4622\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.003961721973269532.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.26855\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7423 - loss: 0.4623 - val_accuracy: 0.8262 - val_loss: 0.3786 - learning_rate: 0.0090\n",
            "Epoch 8/38\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7561 - loss: 0.4420\n",
            "Epoch 8: val_loss did not improve from 0.26855\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7562 - loss: 0.4419 - val_accuracy: 0.8869 - val_loss: 0.3278 - learning_rate: 0.0040\n",
            "Epoch 9/38\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7599 - loss: 0.4318\n",
            "Epoch 9: val_loss did not improve from 0.26855\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7605 - loss: 0.4316 - val_accuracy: 0.8785 - val_loss: 0.2792 - learning_rate: 0.0040\n",
            "Epoch 10/38\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7731 - loss: 0.4187\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0017449140486684618.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.26855\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7731 - loss: 0.4187 - val_accuracy: 0.8743 - val_loss: 0.2860 - learning_rate: 0.0040\n",
            "Epoch 11/38\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7997 - loss: 0.4024\n",
            "Epoch 11: val_loss improved from 0.26855 to 0.25768, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7998 - loss: 0.4022 - val_accuracy: 0.8954 - val_loss: 0.2577 - learning_rate: 0.0017\n",
            "Epoch 12/38\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.3843\n",
            "Epoch 12: val_loss did not improve from 0.25768\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8124 - loss: 0.3844 - val_accuracy: 0.8886 - val_loss: 0.2705 - learning_rate: 0.0017\n",
            "Epoch 13/38\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.3836\n",
            "Epoch 13: val_loss did not improve from 0.25768\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8095 - loss: 0.3836 - val_accuracy: 0.8945 - val_loss: 0.2729 - learning_rate: 0.0017\n",
            "Epoch 14/38\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.3681\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007685358047628221.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.25768\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8252 - loss: 0.3681 - val_accuracy: 0.8844 - val_loss: 0.2770 - learning_rate: 0.0017\n",
            "Epoch 15/38\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8318 - loss: 0.3582\n",
            "Epoch 15: val_loss did not improve from 0.25768\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8318 - loss: 0.3583 - val_accuracy: 0.8684 - val_loss: 0.3561 - learning_rate: 7.6854e-04\n",
            "Epoch 16/38\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8351 - loss: 0.3463\n",
            "Epoch 16: val_loss did not improve from 0.25768\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8351 - loss: 0.3464 - val_accuracy: 0.8759 - val_loss: 0.3094 - learning_rate: 7.6854e-04\n",
            "Epoch 17/38\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8511 - loss: 0.3430\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0003384964916611231.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.25768\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8509 - loss: 0.3430 - val_accuracy: 0.8852 - val_loss: 0.2873 - learning_rate: 7.6854e-04\n",
            "Epoch 18/38\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8535 - loss: 0.3340\n",
            "Epoch 18: val_loss did not improve from 0.25768\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8534 - loss: 0.3340 - val_accuracy: 0.8388 - val_loss: 0.3915 - learning_rate: 3.3850e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:35:23,883] Trial 24 finished with value: -0.25768089294433594 and parameters: {'epochs': 38, 'batch_size': 16, 'learning_rate': 0.008994850373630693, 'stop_patience': 7, 'reduce_lr_factor': 0.44044334568104077, 'reduce_lr_patience': 3}. Best is trial 21 with value: -0.2461479902267456.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5733 - loss: 0.6881\n",
            "Epoch 1: val_loss improved from inf to 0.69030, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5736 - loss: 0.6877 - val_accuracy: 0.6025 - val_loss: 0.6903 - learning_rate: 0.0059\n",
            "Epoch 2/20\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6654 - loss: 0.5848\n",
            "Epoch 2: val_loss improved from 0.69030 to 0.42575, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6656 - loss: 0.5846 - val_accuracy: 0.7916 - val_loss: 0.4257 - learning_rate: 0.0059\n",
            "Epoch 3/20\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6986 - loss: 0.5369\n",
            "Epoch 3: val_loss did not improve from 0.42575\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6985 - loss: 0.5370 - val_accuracy: 0.7131 - val_loss: 0.5392 - learning_rate: 0.0059\n",
            "Epoch 4/20\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7238 - loss: 0.5047\n",
            "Epoch 4: val_loss did not improve from 0.42575\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7233 - loss: 0.5054 - val_accuracy: 0.7705 - val_loss: 0.4740 - learning_rate: 0.0059\n",
            "Epoch 5/20\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7319 - loss: 0.4783\n",
            "Epoch 5: val_loss did not improve from 0.42575\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7319 - loss: 0.4784 - val_accuracy: 0.7477 - val_loss: 0.5536 - learning_rate: 0.0059\n",
            "Epoch 6/20\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7460 - loss: 0.4634\n",
            "Epoch 6: val_loss did not improve from 0.42575\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7460 - loss: 0.4635 - val_accuracy: 0.7485 - val_loss: 0.5682 - learning_rate: 0.0059\n",
            "Epoch 7/20\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7473 - loss: 0.4616\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009491549995655895.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.42575\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7474 - loss: 0.4617 - val_accuracy: 0.7705 - val_loss: 0.5687 - learning_rate: 0.0059\n",
            "Epoch 8/20\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7748 - loss: 0.4195\n",
            "Epoch 8: val_loss improved from 0.42575 to 0.25842, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7748 - loss: 0.4195 - val_accuracy: 0.8920 - val_loss: 0.2584 - learning_rate: 9.4916e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7880 - loss: 0.4004\n",
            "Epoch 9: val_loss improved from 0.25842 to 0.24668, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7881 - loss: 0.4004 - val_accuracy: 0.8937 - val_loss: 0.2467 - learning_rate: 9.4916e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8023 - loss: 0.3925\n",
            "Epoch 10: val_loss improved from 0.24668 to 0.24424, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8024 - loss: 0.3924 - val_accuracy: 0.8987 - val_loss: 0.2442 - learning_rate: 9.4916e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.3820\n",
            "Epoch 11: val_loss did not improve from 0.24424\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8063 - loss: 0.3821 - val_accuracy: 0.8970 - val_loss: 0.2486 - learning_rate: 9.4916e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8199 - loss: 0.3794\n",
            "Epoch 12: val_loss did not improve from 0.24424\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8199 - loss: 0.3795 - val_accuracy: 0.8793 - val_loss: 0.2813 - learning_rate: 9.4916e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8334 - loss: 0.3676\n",
            "Epoch 13: val_loss did not improve from 0.24424\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8329 - loss: 0.3678 - val_accuracy: 0.8895 - val_loss: 0.2697 - learning_rate: 9.4916e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8182 - loss: 0.3734\n",
            "Epoch 14: val_loss did not improve from 0.24424\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8182 - loss: 0.3734 - val_accuracy: 0.8954 - val_loss: 0.2489 - learning_rate: 9.4916e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8259 - loss: 0.3639\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00015351460024948894.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.24424\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8257 - loss: 0.3639 - val_accuracy: 0.8962 - val_loss: 0.2519 - learning_rate: 9.4916e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8340 - loss: 0.3590\n",
            "Epoch 16: val_loss did not improve from 0.24424\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8342 - loss: 0.3588 - val_accuracy: 0.8489 - val_loss: 0.3399 - learning_rate: 1.5351e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8458 - loss: 0.3442\n",
            "Epoch 17: val_loss did not improve from 0.24424\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8459 - loss: 0.3441 - val_accuracy: 0.8346 - val_loss: 0.3813 - learning_rate: 1.5351e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8426 - loss: 0.3513\n",
            "Epoch 18: val_loss did not improve from 0.24424\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8427 - loss: 0.3513 - val_accuracy: 0.8371 - val_loss: 0.3592 - learning_rate: 1.5351e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:35:56,709] Trial 25 finished with value: -0.24424085021018982 and parameters: {'epochs': 20, 'batch_size': 16, 'learning_rate': 0.005868465979939357, 'stop_patience': 8, 'reduce_lr_factor': 0.16173817527997966, 'reduce_lr_patience': 5}. Best is trial 25 with value: -0.24424085021018982.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5837 - loss: 0.6759\n",
            "Epoch 1: val_loss improved from inf to 0.62727, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5845 - loss: 0.6752 - val_accuracy: 0.6270 - val_loss: 0.6273 - learning_rate: 0.0063\n",
            "Epoch 2/15\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6767 - loss: 0.5868\n",
            "Epoch 2: val_loss improved from 0.62727 to 0.37350, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6767 - loss: 0.5867 - val_accuracy: 0.8186 - val_loss: 0.3735 - learning_rate: 0.0063\n",
            "Epoch 3/15\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6988 - loss: 0.5280\n",
            "Epoch 3: val_loss did not improve from 0.37350\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6992 - loss: 0.5279 - val_accuracy: 0.7266 - val_loss: 0.6059 - learning_rate: 0.0063\n",
            "Epoch 4/15\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7226 - loss: 0.4928\n",
            "Epoch 4: val_loss improved from 0.37350 to 0.29460, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7224 - loss: 0.4930 - val_accuracy: 0.8844 - val_loss: 0.2946 - learning_rate: 0.0063\n",
            "Epoch 5/15\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7393 - loss: 0.4800\n",
            "Epoch 5: val_loss did not improve from 0.29460\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7393 - loss: 0.4800 - val_accuracy: 0.7840 - val_loss: 0.4215 - learning_rate: 0.0063\n",
            "Epoch 6/15\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7452 - loss: 0.4671\n",
            "Epoch 6: val_loss did not improve from 0.29460\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7451 - loss: 0.4674 - val_accuracy: 0.8068 - val_loss: 0.3787 - learning_rate: 0.0063\n",
            "Epoch 7/15\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7435 - loss: 0.4522\n",
            "Epoch 7: val_loss did not improve from 0.29460\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7436 - loss: 0.4522 - val_accuracy: 0.7679 - val_loss: 0.4696 - learning_rate: 0.0063\n",
            "Epoch 8/15\n",
            "\u001b[1m290/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7574 - loss: 0.4568\n",
            "Epoch 8: val_loss did not improve from 0.29460\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7573 - loss: 0.4570 - val_accuracy: 0.7426 - val_loss: 0.5273 - learning_rate: 0.0063\n",
            "Epoch 9/15\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7679 - loss: 0.4407\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00165798556325645.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.29460\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7679 - loss: 0.4407 - val_accuracy: 0.7401 - val_loss: 0.5412 - learning_rate: 0.0063\n",
            "Epoch 10/15\n",
            "\u001b[1m278/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7780 - loss: 0.4147\n",
            "Epoch 10: val_loss did not improve from 0.29460\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7786 - loss: 0.4142 - val_accuracy: 0.8684 - val_loss: 0.3021 - learning_rate: 0.0017\n",
            "Epoch 11/15\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8093 - loss: 0.3880\n",
            "Epoch 11: val_loss improved from 0.29460 to 0.25966, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8093 - loss: 0.3881 - val_accuracy: 0.8954 - val_loss: 0.2597 - learning_rate: 0.0017\n",
            "Epoch 12/15\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8117 - loss: 0.3801\n",
            "Epoch 12: val_loss did not improve from 0.25966\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8116 - loss: 0.3802 - val_accuracy: 0.8709 - val_loss: 0.2916 - learning_rate: 0.0017\n",
            "Epoch 13/15\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8290 - loss: 0.3777\n",
            "Epoch 13: val_loss did not improve from 0.25966\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8289 - loss: 0.3777 - val_accuracy: 0.8371 - val_loss: 0.3951 - learning_rate: 0.0017\n",
            "Epoch 14/15\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.3723\n",
            "Epoch 14: val_loss did not improve from 0.25966\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8296 - loss: 0.3722 - val_accuracy: 0.8895 - val_loss: 0.2686 - learning_rate: 0.0017\n",
            "Epoch 15/15\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8329 - loss: 0.3607\n",
            "Epoch 15: val_loss improved from 0.25966 to 0.25166, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8327 - loss: 0.3608 - val_accuracy: 0.8954 - val_loss: 0.2517 - learning_rate: 0.0017\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:36:28,018] Trial 26 finished with value: -0.251655250787735 and parameters: {'epochs': 15, 'batch_size': 16, 'learning_rate': 0.006260327435835131, 'stop_patience': 10, 'reduce_lr_factor': 0.26484006715832986, 'reduce_lr_patience': 5}. Best is trial 25 with value: -0.24424085021018982.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5947 - loss: 0.6759\n",
            "Epoch 1: val_loss improved from inf to 0.41053, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5951 - loss: 0.6754 - val_accuracy: 0.8363 - val_loss: 0.4105 - learning_rate: 0.0060\n",
            "Epoch 2/14\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6808 - loss: 0.5848\n",
            "Epoch 2: val_loss improved from 0.41053 to 0.31910, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6808 - loss: 0.5847 - val_accuracy: 0.8616 - val_loss: 0.3191 - learning_rate: 0.0060\n",
            "Epoch 3/14\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7067 - loss: 0.5315\n",
            "Epoch 3: val_loss improved from 0.31910 to 0.30012, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7068 - loss: 0.5313 - val_accuracy: 0.8776 - val_loss: 0.3001 - learning_rate: 0.0060\n",
            "Epoch 4/14\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7319 - loss: 0.4883\n",
            "Epoch 4: val_loss did not improve from 0.30012\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7319 - loss: 0.4883 - val_accuracy: 0.8835 - val_loss: 0.3149 - learning_rate: 0.0060\n",
            "Epoch 5/14\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7315 - loss: 0.4699\n",
            "Epoch 5: val_loss did not improve from 0.30012\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7317 - loss: 0.4700 - val_accuracy: 0.8245 - val_loss: 0.3797 - learning_rate: 0.0060\n",
            "Epoch 6/14\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7471 - loss: 0.4564\n",
            "Epoch 6: val_loss did not improve from 0.30012\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7470 - loss: 0.4565 - val_accuracy: 0.8574 - val_loss: 0.3122 - learning_rate: 0.0060\n",
            "Epoch 7/14\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7498 - loss: 0.4496\n",
            "Epoch 7: val_loss did not improve from 0.30012\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7499 - loss: 0.4497 - val_accuracy: 0.8143 - val_loss: 0.3773 - learning_rate: 0.0060\n",
            "Epoch 8/14\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7573 - loss: 0.4392\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0015618466671958203.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.30012\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7574 - loss: 0.4395 - val_accuracy: 0.7992 - val_loss: 0.5343 - learning_rate: 0.0060\n",
            "Epoch 9/14\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7824 - loss: 0.4169\n",
            "Epoch 9: val_loss did not improve from 0.30012\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7824 - loss: 0.4168 - val_accuracy: 0.8008 - val_loss: 0.4793 - learning_rate: 0.0016\n",
            "Epoch 10/14\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8002 - loss: 0.4000\n",
            "Epoch 10: val_loss did not improve from 0.30012\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8001 - loss: 0.4000 - val_accuracy: 0.7975 - val_loss: 0.4745 - learning_rate: 0.0016\n",
            "Epoch 11/14\n",
            "\u001b[1m288/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8052 - loss: 0.3943\n",
            "Epoch 11: val_loss did not improve from 0.30012\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8051 - loss: 0.3943 - val_accuracy: 0.8464 - val_loss: 0.3682 - learning_rate: 0.0016\n",
            "Epoch 12/14\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8095 - loss: 0.3829\n",
            "Epoch 12: val_loss did not improve from 0.30012\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8094 - loss: 0.3829 - val_accuracy: 0.8726 - val_loss: 0.3118 - learning_rate: 0.0016\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:36:48,154] Trial 27 finished with value: -0.3001175820827484 and parameters: {'epochs': 14, 'batch_size': 16, 'learning_rate': 0.00595041255498833, 'stop_patience': 9, 'reduce_lr_factor': 0.2624770318512393, 'reduce_lr_patience': 5}. Best is trial 25 with value: -0.24424085021018982.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m291/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5651 - loss: 0.6835\n",
            "Epoch 1: val_loss improved from inf to 0.58536, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5654 - loss: 0.6831 - val_accuracy: 0.6574 - val_loss: 0.5854 - learning_rate: 0.0069\n",
            "Epoch 2/15\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6773 - loss: 0.5691\n",
            "Epoch 2: val_loss improved from 0.58536 to 0.34745, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6778 - loss: 0.5685 - val_accuracy: 0.8523 - val_loss: 0.3474 - learning_rate: 0.0069\n",
            "Epoch 3/15\n",
            "\u001b[1m293/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7064 - loss: 0.5228\n",
            "Epoch 3: val_loss did not improve from 0.34745\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7064 - loss: 0.5228 - val_accuracy: 0.8110 - val_loss: 0.4273 - learning_rate: 0.0069\n",
            "Epoch 4/15\n",
            "\u001b[1m285/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7125 - loss: 0.4979\n",
            "Epoch 4: val_loss did not improve from 0.34745\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7126 - loss: 0.4980 - val_accuracy: 0.7688 - val_loss: 0.5034 - learning_rate: 0.0069\n",
            "Epoch 5/15\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7252 - loss: 0.4746\n",
            "Epoch 5: val_loss did not improve from 0.34745\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7254 - loss: 0.4750 - val_accuracy: 0.8093 - val_loss: 0.4652 - learning_rate: 0.0069\n",
            "Epoch 6/15\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7321 - loss: 0.4577\n",
            "Epoch 6: val_loss did not improve from 0.34745\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7322 - loss: 0.4578 - val_accuracy: 0.8084 - val_loss: 0.4383 - learning_rate: 0.0069\n",
            "Epoch 7/15\n",
            "\u001b[1m289/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7438 - loss: 0.4546\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.001198636501579148.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.34745\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7439 - loss: 0.4546 - val_accuracy: 0.8059 - val_loss: 0.4141 - learning_rate: 0.0069\n",
            "Epoch 8/15\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7680 - loss: 0.4307\n",
            "Epoch 8: val_loss improved from 0.34745 to 0.26065, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7680 - loss: 0.4307 - val_accuracy: 0.8937 - val_loss: 0.2606 - learning_rate: 0.0012\n",
            "Epoch 9/15\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7944 - loss: 0.4160\n",
            "Epoch 9: val_loss did not improve from 0.26065\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7943 - loss: 0.4160 - val_accuracy: 0.8869 - val_loss: 0.2734 - learning_rate: 0.0012\n",
            "Epoch 10/15\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7921 - loss: 0.4040\n",
            "Epoch 10: val_loss did not improve from 0.26065\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7922 - loss: 0.4039 - val_accuracy: 0.8928 - val_loss: 0.2700 - learning_rate: 0.0012\n",
            "Epoch 11/15\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.3987\n",
            "Epoch 11: val_loss improved from 0.26065 to 0.24930, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.3985 - val_accuracy: 0.8979 - val_loss: 0.2493 - learning_rate: 0.0012\n",
            "Epoch 12/15\n",
            "\u001b[1m281/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8131 - loss: 0.3895\n",
            "Epoch 12: val_loss did not improve from 0.24930\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8129 - loss: 0.3895 - val_accuracy: 0.8768 - val_loss: 0.2781 - learning_rate: 0.0012\n",
            "Epoch 13/15\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8053 - loss: 0.3841\n",
            "Epoch 13: val_loss did not improve from 0.24930\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.3842 - val_accuracy: 0.8987 - val_loss: 0.2496 - learning_rate: 0.0012\n",
            "Epoch 14/15\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8191 - loss: 0.3766\n",
            "Epoch 14: val_loss did not improve from 0.24930\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8190 - loss: 0.3766 - val_accuracy: 0.8785 - val_loss: 0.2846 - learning_rate: 0.0012\n",
            "Epoch 15/15\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8170 - loss: 0.3760\n",
            "Epoch 15: val_loss did not improve from 0.24930\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8170 - loss: 0.3759 - val_accuracy: 0.8920 - val_loss: 0.2575 - learning_rate: 0.0012\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:37:12,968] Trial 28 finished with value: -0.24929989874362946 and parameters: {'epochs': 15, 'batch_size': 16, 'learning_rate': 0.006884545977483798, 'stop_patience': 7, 'reduce_lr_factor': 0.174105380114725, 'reduce_lr_patience': 5}. Best is trial 25 with value: -0.24424085021018982.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5923 - loss: 0.6763\n",
            "Epoch 1: val_loss improved from inf to 0.67220, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5930 - loss: 0.6760 - val_accuracy: 0.5502 - val_loss: 0.6722 - learning_rate: 0.0073\n",
            "Epoch 2/20\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6664 - loss: 0.5903\n",
            "Epoch 2: val_loss improved from 0.67220 to 0.37731, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6671 - loss: 0.5892 - val_accuracy: 0.8405 - val_loss: 0.3773 - learning_rate: 0.0073\n",
            "Epoch 3/20\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7093 - loss: 0.5179\n",
            "Epoch 3: val_loss did not improve from 0.37731\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7094 - loss: 0.5179 - val_accuracy: 0.5654 - val_loss: 1.0724 - learning_rate: 0.0073\n",
            "Epoch 4/20\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7315 - loss: 0.4829\n",
            "Epoch 4: val_loss did not improve from 0.37731\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7314 - loss: 0.4833 - val_accuracy: 0.7257 - val_loss: 0.8141 - learning_rate: 0.0073\n",
            "Epoch 5/20\n",
            "\u001b[1m280/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7239 - loss: 0.4956\n",
            "Epoch 5: val_loss did not improve from 0.37731\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7242 - loss: 0.4954 - val_accuracy: 0.7367 - val_loss: 0.5578 - learning_rate: 0.0073\n",
            "Epoch 6/20\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7387 - loss: 0.4596\n",
            "Epoch 6: val_loss improved from 0.37731 to 0.36133, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7389 - loss: 0.4597 - val_accuracy: 0.8211 - val_loss: 0.3613 - learning_rate: 0.0073\n",
            "Epoch 7/20\n",
            "\u001b[1m286/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7540 - loss: 0.4553\n",
            "Epoch 7: val_loss improved from 0.36133 to 0.27349, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7539 - loss: 0.4553 - val_accuracy: 0.8835 - val_loss: 0.2735 - learning_rate: 0.0073\n",
            "Epoch 8/20\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7517 - loss: 0.4436\n",
            "Epoch 8: val_loss did not improve from 0.27349\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7517 - loss: 0.4437 - val_accuracy: 0.7840 - val_loss: 0.4025 - learning_rate: 0.0073\n",
            "Epoch 9/20\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7637 - loss: 0.4355\n",
            "Epoch 9: val_loss improved from 0.27349 to 0.25891, saving model to BEST_CNN_RAM_BBAS3.keras\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7636 - loss: 0.4357 - val_accuracy: 0.8937 - val_loss: 0.2589 - learning_rate: 0.0073\n",
            "Epoch 10/20\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7639 - loss: 0.4304\n",
            "Epoch 10: val_loss did not improve from 0.25891\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7639 - loss: 0.4305 - val_accuracy: 0.4970 - val_loss: 3.1320 - learning_rate: 0.0073\n",
            "Epoch 11/20\n",
            "\u001b[1m294/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7626 - loss: 0.4387\n",
            "Epoch 11: val_loss did not improve from 0.25891\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7626 - loss: 0.4386 - val_accuracy: 0.8641 - val_loss: 0.3361 - learning_rate: 0.0073\n",
            "Epoch 12/20\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7667 - loss: 0.4266\n",
            "Epoch 12: val_loss did not improve from 0.25891\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7665 - loss: 0.4267 - val_accuracy: 0.8439 - val_loss: 0.3525 - learning_rate: 0.0073\n",
            "Epoch 13/20\n",
            "\u001b[1m284/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7746 - loss: 0.4241\n",
            "Epoch 13: val_loss did not improve from 0.25891\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7744 - loss: 0.4242 - val_accuracy: 0.6582 - val_loss: 1.3035 - learning_rate: 0.0073\n",
            "Epoch 14/20\n",
            "\u001b[1m287/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7787 - loss: 0.4228\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0013100078725705089.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.25891\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7784 - loss: 0.4230 - val_accuracy: 0.8852 - val_loss: 0.2699 - learning_rate: 0.0073\n",
            "Epoch 15/20\n",
            "\u001b[1m282/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7885 - loss: 0.3972\n",
            "Epoch 15: val_loss did not improve from 0.25891\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7891 - loss: 0.3968 - val_accuracy: 0.8667 - val_loss: 0.2961 - learning_rate: 0.0013\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:37:37,876] Trial 29 finished with value: -0.25890862941741943 and parameters: {'epochs': 20, 'batch_size': 16, 'learning_rate': 0.0073250583695426115, 'stop_patience': 6, 'reduce_lr_factor': 0.17883924089718486, 'reduce_lr_patience': 5}. Best is trial 25 with value: -0.24424085021018982.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Melhor combinação encontrada:\n",
            "trial                  25.000000\n",
            "epochs                 20.000000\n",
            "batch_size             16.000000\n",
            "learning_rate           0.005868\n",
            "stop_patience           8.000000\n",
            "reduce_lr_factor        0.161738\n",
            "reduce_lr_patience      5.000000\n",
            "recall_Compra(1)        0.866935\n",
            "recall_Vende(0)         0.921626\n",
            "precision_Compra(1)     0.888430\n",
            "precision_Vende(0)      0.905849\n",
            "macro_recall            0.894281\n",
            "accuracy                0.898734\n",
            "f1_macro                0.895610\n",
            "f1_weighted             0.898551\n",
            "min_val_loss            0.244241\n",
            "Name: 0, dtype: float64\n",
            "🔍 Hiperparâmetros: {'epochs': 20, 'batch_size': 16, 'learning_rate': 0.005868465979939357, 'stop_patience': 8, 'reduce_lr_factor': 0.16173817527997966, 'reduce_lr_patience': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_history([best_seq_history, best_ram_history], titles=titles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "c6U1EqYWh0jJ",
        "outputId": "edec439a-6b11-4b78-fcc7-df8c47c77ac0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix([best_seq_metrics, best_ram_metrics], titles=titles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "9Cc9LRN_h9Nf",
        "outputId": "663ed137-74b2-45c3-c20e-5f7a97d0c335"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_classification_reports(\n",
        "    metrics_list=[best_seq_metrics, best_ram_metrics],\n",
        "    titles=titles\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGq8fyWUioU8",
        "outputId": "5e4b7c14-2405-4e8c-b5ea-93bb562746ec"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "📊 Relatório de Classificação - Modelo Sequencial\n",
            "==================================================\n",
            "\n",
            "Vende (0):\n",
            "Precision: 0.89\n",
            "Recall:    0.88\n",
            "F1-Score:  0.88\n",
            "\n",
            "Compra (1):\n",
            "Precision: 0.83\n",
            "Recall:    0.85\n",
            "F1-Score:  0.84\n",
            "\n",
            "Médias:\n",
            "Acurácia:  0.87\n",
            "Precision: 0.86\n",
            "Recall:    0.86\n",
            "F1-Score:  0.86\n",
            "\n",
            "\n",
            "==================================================\n",
            "📊 Relatório de Classificação - Modelo Ramificado\n",
            "==================================================\n",
            "\n",
            "Vende (0):\n",
            "Precision: 0.91\n",
            "Recall:    0.92\n",
            "F1-Score:  0.91\n",
            "\n",
            "Compra (1):\n",
            "Precision: 0.89\n",
            "Recall:    0.87\n",
            "F1-Score:  0.88\n",
            "\n",
            "Médias:\n",
            "Acurácia:  0.90\n",
            "Precision: 0.90\n",
            "Recall:    0.89\n",
            "F1-Score:  0.90\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "_wjzjxIEFJxN",
        "outputId": "c9cb964e-bb9d-4889-8c2e-0bf378ca3c12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-cadec49cf654>:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  preco_atual = prices[i]\n",
            "<ipython-input-17-cadec49cf654>:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  preco_atual = prices[i]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Data          Modelo   Ação Métrica de Otimização  \\\n",
              "0  2025-04-13 14:10:15.041119  CNN Sequencial  CSAN3              val_loss   \n",
              "1  2025-04-13 14:10:15.069407  CNN Ramificado  CSAN3              val_loss   \n",
              "2  2025-04-13 14:37:38.702181  CNN Sequencial  BBAS3              val_loss   \n",
              "3  2025-04-13 14:37:38.727148  CNN Ramificado  BBAS3              val_loss   \n",
              "\n",
              "   Acurácia  Precision    Recall        F1      Matriz de Confusão  \\\n",
              "0  0.885329   0.882166  0.882586  0.882373  [[619, 69], [67, 431]]   \n",
              "1  0.881956   0.880287  0.876629  0.878284  [[626, 62], [78, 420]]   \n",
              "2  0.865823   0.861527  0.864002  0.862654  [[603, 86], [73, 423]]   \n",
              "3  0.898734   0.897139  0.894281  0.895610  [[635, 54], [66, 430]]   \n",
              "\n",
              "   Saldo Inicial  Saldo Final  Total de Ações   Lucro Total   Lucro (%)  \\\n",
              "0          10000     3.640817           990.0   9467.040666   94.670407   \n",
              "1          10000     8.435907          1065.0  10946.335745  109.463357   \n",
              "2          10000    39.235968           247.0   3720.565817   37.205658   \n",
              "3          10000    38.974524           310.0   7209.874334   72.098743   \n",
              "\n",
              "   Lucro (%) CDI  \n",
              "0       42.26921  \n",
              "1       42.26921  \n",
              "2       42.26921  \n",
              "3       42.26921  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6928ba55-76a6-43f5-9856-96dcee1460ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Ação</th>\n",
              "      <th>Métrica de Otimização</th>\n",
              "      <th>Acurácia</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Matriz de Confusão</th>\n",
              "      <th>Saldo Inicial</th>\n",
              "      <th>Saldo Final</th>\n",
              "      <th>Total de Ações</th>\n",
              "      <th>Lucro Total</th>\n",
              "      <th>Lucro (%)</th>\n",
              "      <th>Lucro (%) CDI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-04-13 14:10:15.041119</td>\n",
              "      <td>CNN Sequencial</td>\n",
              "      <td>CSAN3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.885329</td>\n",
              "      <td>0.882166</td>\n",
              "      <td>0.882586</td>\n",
              "      <td>0.882373</td>\n",
              "      <td>[[619, 69], [67, 431]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>3.640817</td>\n",
              "      <td>990.0</td>\n",
              "      <td>9467.040666</td>\n",
              "      <td>94.670407</td>\n",
              "      <td>42.26921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-04-13 14:10:15.069407</td>\n",
              "      <td>CNN Ramificado</td>\n",
              "      <td>CSAN3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.881956</td>\n",
              "      <td>0.880287</td>\n",
              "      <td>0.876629</td>\n",
              "      <td>0.878284</td>\n",
              "      <td>[[626, 62], [78, 420]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>8.435907</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>10946.335745</td>\n",
              "      <td>109.463357</td>\n",
              "      <td>42.26921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-04-13 14:37:38.702181</td>\n",
              "      <td>CNN Sequencial</td>\n",
              "      <td>BBAS3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.865823</td>\n",
              "      <td>0.861527</td>\n",
              "      <td>0.864002</td>\n",
              "      <td>0.862654</td>\n",
              "      <td>[[603, 86], [73, 423]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>39.235968</td>\n",
              "      <td>247.0</td>\n",
              "      <td>3720.565817</td>\n",
              "      <td>37.205658</td>\n",
              "      <td>42.26921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-04-13 14:37:38.727148</td>\n",
              "      <td>CNN Ramificado</td>\n",
              "      <td>BBAS3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.898734</td>\n",
              "      <td>0.897139</td>\n",
              "      <td>0.894281</td>\n",
              "      <td>0.895610</td>\n",
              "      <td>[[635, 54], [66, 430]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>38.974524</td>\n",
              "      <td>310.0</td>\n",
              "      <td>7209.874334</td>\n",
              "      <td>72.098743</td>\n",
              "      <td>42.26921</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6928ba55-76a6-43f5-9856-96dcee1460ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6928ba55-76a6-43f5-9856-96dcee1460ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6928ba55-76a6-43f5-9856-96dcee1460ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e4a6d4dd-e75e-4145-aa24-1b0d24713e52\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e4a6d4dd-e75e-4145-aa24-1b0d24713e52')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e4a6d4dd-e75e-4145-aa24-1b0d24713e52 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6a982247-a43c-4b81-9e4b-fca5a8025b8b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('resultado_backtest')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6a982247-a43c-4b81-9e4b-fca5a8025b8b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('resultado_backtest');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "resultado_backtest",
              "summary": "{\n  \"name\": \"resultado_backtest\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Data\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"2025-04-13 14:10:15.069407\",\n          \"2025-04-13 14:37:38.727148\",\n          \"2025-04-13 14:10:15.041119\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"CNN Ramificado\",\n          \"CNN Sequencial\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\\u00e7\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"BBAS3\",\n          \"CSAN3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"M\\u00e9trica de Otimiza\\u00e7\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"val_loss\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Acur\\u00e1cia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01352932495027703,\n        \"min\": 0.8658227848101265,\n        \"max\": 0.8987341772151899,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8819561551433389\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014600054166141381,\n        \"min\": 0.8615265458434568,\n        \"max\": 0.8971392697563103,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8802869200301773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012600977380211383,\n        \"min\": 0.8640020014981975,\n        \"max\": 0.8942805140690107,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.876628607453068\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013575108808073668,\n        \"min\": 0.8626537641463015,\n        \"max\": 0.8956100425781823,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8782840722495895\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Matriz de Confus\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Saldo Inicial\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 10000,\n        \"max\": 10000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          10000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Saldo Final\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.191572754550187,\n        \"min\": 3.640817165378394,\n        \"max\": 39.23596763610476,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          8.435907363906153\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total de A\\u00e7\\u00f5es\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 434.2802474593259,\n        \"min\": 247.0,\n        \"max\": 1065.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1065.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lucro Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3144.4826790540774,\n        \"min\": 3720.565816879269,\n        \"max\": 10946.335744857804,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          10946.335744857804\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lucro (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31.444826790540766,\n        \"min\": 37.20565816879269,\n        \"max\": 109.46335744857802,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          109.46335744857802\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lucro (%) CDI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.105427357601002e-15,\n        \"min\": 42.2692096209317,\n        \"max\": 42.269209620931704,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          42.269209620931704\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "resultado_backtest = run_backtest(\n",
        "    predictions=best_seq_y_pred,\n",
        "    prices=prices,\n",
        "    capital=10000,\n",
        "    model_name=\"CNN Sequencial\",\n",
        "    stock_name=\"BBAS3\",\n",
        "    metrics = best_seq_metrics,\n",
        "    cdi_df = cdi,\n",
        "    metric_optimization = metric_optimization\n",
        "\n",
        ")\n",
        "\n",
        "resultado_backtest = run_backtest(\n",
        "    predictions=best_ram_y_pred,\n",
        "    prices=prices,\n",
        "    capital=10000,\n",
        "    model_name=\"CNN Ramificado\",\n",
        "    stock_name=\"BBAS3\",\n",
        "    metrics = best_ram_metrics,\n",
        "    cdi_df = cdi,\n",
        "    metric_optimization = metric_optimization\n",
        ")\n",
        "\n",
        "resultado_backtest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPIFWax3Oz8m"
      },
      "source": [
        "### CSNA3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OdCYsrUxO_YZ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, features = preprocess_data(cs_train, cs_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "janela_curta = features[:7]\n",
        "janela_longa = features[7:]\n",
        "X_train1, X_test1, X_train2, X_test2, y_train, y_test, features = preprocess_data(cs_train, cs_test, split_features=[janela_curta,janela_longa])"
      ],
      "metadata": {
        "id": "ZGclnghCzn_7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "IbFUv9A6PH3I"
      },
      "outputs": [],
      "source": [
        "titles = [\"Modelo Sequencial\", \"Modelo Ramificado\"]\n",
        "prices = cs_test.set_index(\"Date\")[\"Close\"]\n",
        "metric_optimization = 'val_loss'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_seq_model, best_seq_history, df_results, best_seq_metrics, best_seq_y_pred = train_model(\n",
        "    model_fn=model_cnn_sequencial,\n",
        "    model_path = \"BEST_CNN_SEQ_CSNA3.keras\",\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    prob=0.5,\n",
        "    n_trials=30,\n",
        "    metric_to_optimize=metric_optimization\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u461vzW61bnp",
        "outputId": "0d75c6be-31d0-4bb5-f36b-decd5cd446ca"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:48:09,380] A new study created in memory with name: no-name-5d4fe75f-420d-4b96-b138-48bfa81f1693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/42\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5438 - loss: 0.6891\n",
            "Epoch 1: val_loss improved from inf to 0.64025, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.5448 - loss: 0.6887 - val_accuracy: 0.5978 - val_loss: 0.6402 - learning_rate: 0.0035\n",
            "Epoch 2/42\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6121 - loss: 0.6495\n",
            "Epoch 2: val_loss improved from 0.64025 to 0.47252, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6131 - loss: 0.6485 - val_accuracy: 0.8120 - val_loss: 0.4725 - learning_rate: 0.0035\n",
            "Epoch 3/42\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6982 - loss: 0.5730\n",
            "Epoch 3: val_loss did not improve from 0.47252\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6984 - loss: 0.5724 - val_accuracy: 0.7226 - val_loss: 0.5127 - learning_rate: 0.0035\n",
            "Epoch 4/42\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7261 - loss: 0.5283\n",
            "Epoch 4: val_loss improved from 0.47252 to 0.36433, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7284 - loss: 0.5247 - val_accuracy: 0.8255 - val_loss: 0.3643 - learning_rate: 0.0035\n",
            "Epoch 5/42\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7699 - loss: 0.4533\n",
            "Epoch 5: val_loss did not improve from 0.36433\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7695 - loss: 0.4534 - val_accuracy: 0.8229 - val_loss: 0.3800 - learning_rate: 0.0035\n",
            "Epoch 6/42\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7880 - loss: 0.4426\n",
            "Epoch 6: val_loss improved from 0.36433 to 0.32368, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7880 - loss: 0.4423 - val_accuracy: 0.8524 - val_loss: 0.3237 - learning_rate: 0.0035\n",
            "Epoch 7/42\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7920 - loss: 0.4181\n",
            "Epoch 7: val_loss did not improve from 0.32368\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7922 - loss: 0.4178 - val_accuracy: 0.8196 - val_loss: 0.3645 - learning_rate: 0.0035\n",
            "Epoch 8/42\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7769 - loss: 0.4571\n",
            "Epoch 8: val_loss did not improve from 0.32368\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7773 - loss: 0.4566 - val_accuracy: 0.8128 - val_loss: 0.4448 - learning_rate: 0.0035\n",
            "Epoch 9/42\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7959 - loss: 0.4322\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0015376091993542812.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.32368\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7952 - loss: 0.4325 - val_accuracy: 0.8592 - val_loss: 0.3328 - learning_rate: 0.0035\n",
            "Epoch 10/42\n",
            "\u001b[1m64/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8298 - loss: 0.3663\n",
            "Epoch 10: val_loss did not improve from 0.32368\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8315 - loss: 0.3645 - val_accuracy: 0.8600 - val_loss: 0.3365 - learning_rate: 0.0015\n",
            "Epoch 11/42\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8358 - loss: 0.3598\n",
            "Epoch 11: val_loss did not improve from 0.32368\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8372 - loss: 0.3584 - val_accuracy: 0.8516 - val_loss: 0.3479 - learning_rate: 0.0015\n",
            "Epoch 12/42\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8380 - loss: 0.3493\n",
            "Epoch 12: val_loss improved from 0.32368 to 0.31812, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8389 - loss: 0.3487 - val_accuracy: 0.8634 - val_loss: 0.3181 - learning_rate: 0.0015\n",
            "Epoch 13/42\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8352 - loss: 0.3526\n",
            "Epoch 13: val_loss did not improve from 0.31812\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8355 - loss: 0.3524 - val_accuracy: 0.8524 - val_loss: 0.3384 - learning_rate: 0.0015\n",
            "Epoch 14/42\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8481 - loss: 0.3400\n",
            "Epoch 14: val_loss did not improve from 0.31812\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8483 - loss: 0.3394 - val_accuracy: 0.8373 - val_loss: 0.3698 - learning_rate: 0.0015\n",
            "Epoch 15/42\n",
            "\u001b[1m64/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8285 - loss: 0.3523\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006686673289872662.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.31812\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8304 - loss: 0.3506 - val_accuracy: 0.8491 - val_loss: 0.3497 - learning_rate: 0.0015\n",
            "Epoch 16/42\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8481 - loss: 0.3405\n",
            "Epoch 16: val_loss did not improve from 0.31812\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8483 - loss: 0.3402 - val_accuracy: 0.8381 - val_loss: 0.4411 - learning_rate: 6.6867e-04\n",
            "Epoch 17/42\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8639 - loss: 0.3095\n",
            "Epoch 17: val_loss did not improve from 0.31812\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8650 - loss: 0.3088 - val_accuracy: 0.8406 - val_loss: 0.4469 - learning_rate: 6.6867e-04\n",
            "Epoch 18/42\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8679 - loss: 0.3081\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002907865034673295.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.31812\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8686 - loss: 0.3072 - val_accuracy: 0.8432 - val_loss: 0.4366 - learning_rate: 6.6867e-04\n",
            "Epoch 19/42\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8677 - loss: 0.2984\n",
            "Epoch 19: val_loss did not improve from 0.31812\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8685 - loss: 0.2974 - val_accuracy: 0.8238 - val_loss: 0.5327 - learning_rate: 2.9079e-04\n",
            "Epoch 20/42\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8815 - loss: 0.2829\n",
            "Epoch 20: val_loss did not improve from 0.31812\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8815 - loss: 0.2830 - val_accuracy: 0.8212 - val_loss: 0.5417 - learning_rate: 2.9079e-04\n",
            "Epoch 21/42\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8786 - loss: 0.2860\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00012645569354572387.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.31812\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8790 - loss: 0.2858 - val_accuracy: 0.8212 - val_loss: 0.5463 - learning_rate: 2.9079e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:48:39,279] Trial 0 finished with value: -0.31811511516571045 and parameters: {'epochs': 42, 'batch_size': 64, 'learning_rate': 0.00353575229194107, 'stop_patience': 9, 'reduce_lr_factor': 0.4348747081349842, 'reduce_lr_patience': 3}. Best is trial 0 with value: -0.31811511516571045.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/42\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5602 - loss: 0.6862\n",
            "Epoch 1: val_loss improved from inf to 0.62294, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5603 - loss: 0.6859 - val_accuracy: 0.7917 - val_loss: 0.6229 - learning_rate: 0.0036\n",
            "Epoch 2/42\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5899 - loss: 0.6473\n",
            "Epoch 2: val_loss improved from 0.62294 to 0.42745, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5919 - loss: 0.6463 - val_accuracy: 0.8019 - val_loss: 0.4274 - learning_rate: 0.0036\n",
            "Epoch 3/42\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6764 - loss: 0.5614\n",
            "Epoch 3: val_loss improved from 0.42745 to 0.38755, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6765 - loss: 0.5613 - val_accuracy: 0.8221 - val_loss: 0.3876 - learning_rate: 0.0036\n",
            "Epoch 4/42\n",
            "\u001b[1m283/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7471 - loss: 0.5015\n",
            "Epoch 4: val_loss improved from 0.38755 to 0.35173, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7471 - loss: 0.5013 - val_accuracy: 0.8373 - val_loss: 0.3517 - learning_rate: 0.0036\n",
            "Epoch 5/42\n",
            "\u001b[1m283/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7582 - loss: 0.4700\n",
            "Epoch 5: val_loss did not improve from 0.35173\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7585 - loss: 0.4697 - val_accuracy: 0.7976 - val_loss: 0.4221 - learning_rate: 0.0036\n",
            "Epoch 6/42\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7851 - loss: 0.4360\n",
            "Epoch 6: val_loss did not improve from 0.35173\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7852 - loss: 0.4358 - val_accuracy: 0.8170 - val_loss: 0.3758 - learning_rate: 0.0036\n",
            "Epoch 7/42\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7809 - loss: 0.4445\n",
            "Epoch 7: val_loss did not improve from 0.35173\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7812 - loss: 0.4441 - val_accuracy: 0.8280 - val_loss: 0.3789 - learning_rate: 0.0036\n",
            "Epoch 8/42\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7826 - loss: 0.4392\n",
            "Epoch 8: val_loss improved from 0.35173 to 0.31111, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7827 - loss: 0.4392 - val_accuracy: 0.8609 - val_loss: 0.3111 - learning_rate: 0.0036\n",
            "Epoch 9/42\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7785 - loss: 0.4445\n",
            "Epoch 9: val_loss improved from 0.31111 to 0.30492, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7790 - loss: 0.4437 - val_accuracy: 0.8600 - val_loss: 0.3049 - learning_rate: 0.0036\n",
            "Epoch 10/42\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7988 - loss: 0.4014\n",
            "Epoch 10: val_loss did not improve from 0.30492\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.4013 - val_accuracy: 0.8499 - val_loss: 0.3131 - learning_rate: 0.0036\n",
            "Epoch 11/42\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8007 - loss: 0.4041\n",
            "Epoch 11: val_loss did not improve from 0.30492\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8010 - loss: 0.4038 - val_accuracy: 0.8449 - val_loss: 0.3583 - learning_rate: 0.0036\n",
            "Epoch 12/42\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8050 - loss: 0.3859\n",
            "Epoch 12: val_loss did not improve from 0.30492\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8052 - loss: 0.3860 - val_accuracy: 0.8196 - val_loss: 0.3594 - learning_rate: 0.0036\n",
            "Epoch 13/42\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7966 - loss: 0.4081\n",
            "Epoch 13: val_loss improved from 0.30492 to 0.30159, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7969 - loss: 0.4075 - val_accuracy: 0.8702 - val_loss: 0.3016 - learning_rate: 0.0036\n",
            "Epoch 14/42\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8144 - loss: 0.3797\n",
            "Epoch 14: val_loss improved from 0.30159 to 0.29611, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8145 - loss: 0.3796 - val_accuracy: 0.8727 - val_loss: 0.2961 - learning_rate: 0.0036\n",
            "Epoch 15/42\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8027 - loss: 0.3858\n",
            "Epoch 15: val_loss did not improve from 0.29611\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.3855 - val_accuracy: 0.8702 - val_loss: 0.3017 - learning_rate: 0.0036\n",
            "Epoch 16/42\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8184 - loss: 0.3766\n",
            "Epoch 16: val_loss did not improve from 0.29611\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8184 - loss: 0.3765 - val_accuracy: 0.8626 - val_loss: 0.3208 - learning_rate: 0.0036\n",
            "Epoch 17/42\n",
            "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8273 - loss: 0.3595\n",
            "Epoch 17: val_loss did not improve from 0.29611\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8274 - loss: 0.3595 - val_accuracy: 0.8288 - val_loss: 0.4515 - learning_rate: 0.0036\n",
            "Epoch 18/42\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8160 - loss: 0.3712\n",
            "Epoch 18: val_loss did not improve from 0.29611\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8167 - loss: 0.3705 - val_accuracy: 0.8524 - val_loss: 0.3546 - learning_rate: 0.0036\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:49:18,788] Trial 1 finished with value: -0.2961065471172333 and parameters: {'epochs': 42, 'batch_size': 16, 'learning_rate': 0.0035684395449399535, 'stop_patience': 4, 'reduce_lr_factor': 0.4014357262255418, 'reduce_lr_patience': 5}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/29\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5635 - loss: 0.6937\n",
            "Epoch 1: val_loss improved from inf to 0.68339, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5635 - loss: 0.6937 - val_accuracy: 0.5801 - val_loss: 0.6834 - learning_rate: 0.0093\n",
            "Epoch 2/29\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5697 - loss: 0.6843\n",
            "Epoch 2: val_loss did not improve from 0.68339\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5693 - loss: 0.6843 - val_accuracy: 0.5801 - val_loss: 0.6839 - learning_rate: 0.0093\n",
            "Epoch 3/29\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5718 - loss: 0.6846\n",
            "Epoch 3: val_loss improved from 0.68339 to 0.68248, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5718 - loss: 0.6846 - val_accuracy: 0.5801 - val_loss: 0.6825 - learning_rate: 0.0093\n",
            "Epoch 4/29\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5718 - loss: 0.6841\n",
            "Epoch 4: val_loss improved from 0.68248 to 0.68181, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.5718 - loss: 0.6841 - val_accuracy: 0.5801 - val_loss: 0.6818 - learning_rate: 0.0093\n",
            "Epoch 5/29\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5691 - loss: 0.6832\n",
            "Epoch 5: val_loss improved from 0.68181 to 0.67367, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5690 - loss: 0.6832 - val_accuracy: 0.5801 - val_loss: 0.6737 - learning_rate: 0.0093\n",
            "Epoch 6/29\n",
            "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5802 - loss: 0.6557\n",
            "Epoch 6: val_loss improved from 0.67367 to 0.57611, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.5804 - loss: 0.6556 - val_accuracy: 0.6914 - val_loss: 0.5761 - learning_rate: 0.0093\n",
            "Epoch 7/29\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6496 - loss: 0.6127\n",
            "Epoch 7: val_loss improved from 0.57611 to 0.41791, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6497 - loss: 0.6125 - val_accuracy: 0.8103 - val_loss: 0.4179 - learning_rate: 0.0093\n",
            "Epoch 8/29\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7112 - loss: 0.5403\n",
            "Epoch 8: val_loss did not improve from 0.41791\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7112 - loss: 0.5398 - val_accuracy: 0.7951 - val_loss: 0.4949 - learning_rate: 0.0093\n",
            "Epoch 9/29\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7230 - loss: 0.5099\n",
            "Epoch 9: val_loss did not improve from 0.41791\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7230 - loss: 0.5099 - val_accuracy: 0.7445 - val_loss: 0.4754 - learning_rate: 0.0093\n",
            "Epoch 10/29\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7494 - loss: 0.4983\n",
            "Epoch 10: val_loss did not improve from 0.41791\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7497 - loss: 0.4977 - val_accuracy: 0.8086 - val_loss: 0.4286 - learning_rate: 0.0093\n",
            "Epoch 11/29\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7491 - loss: 0.5008\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.002889281097508373.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.41791\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7494 - loss: 0.5002 - val_accuracy: 0.7175 - val_loss: 0.4968 - learning_rate: 0.0093\n",
            "Epoch 12/29\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7734 - loss: 0.4682\n",
            "Epoch 12: val_loss did not improve from 0.41791\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7737 - loss: 0.4677 - val_accuracy: 0.8078 - val_loss: 0.4655 - learning_rate: 0.0029\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:49:57,224] Trial 2 finished with value: -0.41791102290153503 and parameters: {'epochs': 29, 'batch_size': 16, 'learning_rate': 0.009300502346771544, 'stop_patience': 5, 'reduce_lr_factor': 0.31065861737178957, 'reduce_lr_patience': 4}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/34\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5703 - loss: 0.6933\n",
            "Epoch 1: val_loss improved from inf to 0.74562, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5700 - loss: 0.6932 - val_accuracy: 0.4325 - val_loss: 0.7456 - learning_rate: 0.0092\n",
            "Epoch 2/34\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5639 - loss: 0.6771\n",
            "Epoch 2: val_loss improved from 0.74562 to 0.67763, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5621 - loss: 0.6765 - val_accuracy: 0.5995 - val_loss: 0.6776 - learning_rate: 0.0092\n",
            "Epoch 3/34\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6000 - loss: 0.6452\n",
            "Epoch 3: val_loss improved from 0.67763 to 0.46827, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6006 - loss: 0.6445 - val_accuracy: 0.8212 - val_loss: 0.4683 - learning_rate: 0.0092\n",
            "Epoch 4/34\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6571 - loss: 0.5975\n",
            "Epoch 4: val_loss did not improve from 0.46827\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6563 - loss: 0.5989 - val_accuracy: 0.7504 - val_loss: 0.5328 - learning_rate: 0.0092\n",
            "Epoch 5/34\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6633 - loss: 0.5835\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.002074749973203994.\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.46827\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6655 - loss: 0.5822 - val_accuracy: 0.6636 - val_loss: 0.5660 - learning_rate: 0.0092\n",
            "Epoch 6/34\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7427 - loss: 0.5106\n",
            "Epoch 6: val_loss improved from 0.46827 to 0.45672, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7447 - loss: 0.5084 - val_accuracy: 0.7884 - val_loss: 0.4567 - learning_rate: 0.0021\n",
            "Epoch 7/34\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7712 - loss: 0.4705\n",
            "Epoch 7: val_loss did not improve from 0.45672\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7725 - loss: 0.4688 - val_accuracy: 0.7799 - val_loss: 0.5105 - learning_rate: 0.0021\n",
            "Epoch 8/34\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7874 - loss: 0.4522\n",
            "Epoch 8: val_loss improved from 0.45672 to 0.45324, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7895 - loss: 0.4493 - val_accuracy: 0.8221 - val_loss: 0.4532 - learning_rate: 0.0021\n",
            "Epoch 9/34\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7943 - loss: 0.4347\n",
            "Epoch 9: val_loss did not improve from 0.45324\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7954 - loss: 0.4336 - val_accuracy: 0.7926 - val_loss: 0.6015 - learning_rate: 0.0021\n",
            "Epoch 10/34\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7941 - loss: 0.4198\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00046793837439417884.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.45324\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7950 - loss: 0.4191 - val_accuracy: 0.8019 - val_loss: 0.6106 - learning_rate: 0.0021\n",
            "Epoch 11/34\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4052\n",
            "Epoch 11: val_loss did not improve from 0.45324\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8124 - loss: 0.4036 - val_accuracy: 0.7993 - val_loss: 0.6088 - learning_rate: 4.6794e-04\n",
            "Epoch 12/34\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8340 - loss: 0.3722\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00010553865786635803.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.45324\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8340 - loss: 0.3724 - val_accuracy: 0.7909 - val_loss: 0.6770 - learning_rate: 4.6794e-04\n",
            "Epoch 13/34\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8381 - loss: 0.3680\n",
            "Epoch 13: val_loss did not improve from 0.45324\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8379 - loss: 0.3683 - val_accuracy: 0.7951 - val_loss: 0.6407 - learning_rate: 1.0554e-04\n",
            "Epoch 14/34\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8391 - loss: 0.3712\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.3803152795430983e-05.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.45324\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8387 - loss: 0.3715 - val_accuracy: 0.8002 - val_loss: 0.6209 - learning_rate: 1.0554e-04\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:50:10,837] Trial 3 finished with value: -0.45323851704597473 and parameters: {'epochs': 34, 'batch_size': 64, 'learning_rate': 0.009199047770357507, 'stop_patience': 6, 'reduce_lr_factor': 0.2255396530962299, 'reduce_lr_patience': 2}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/22\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5533 - loss: 0.6887\n",
            "Epoch 1: val_loss improved from inf to 0.75600, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5535 - loss: 0.6882 - val_accuracy: 0.5194 - val_loss: 0.7560 - learning_rate: 0.0049\n",
            "Epoch 2/22\n",
            "\u001b[1m136/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5696 - loss: 0.6685\n",
            "Epoch 2: val_loss improved from 0.75600 to 0.50450, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5725 - loss: 0.6666 - val_accuracy: 0.7563 - val_loss: 0.5045 - learning_rate: 0.0049\n",
            "Epoch 3/22\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6374 - loss: 0.6144\n",
            "Epoch 3: val_loss did not improve from 0.50450\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6383 - loss: 0.6138 - val_accuracy: 0.5472 - val_loss: 0.6034 - learning_rate: 0.0049\n",
            "Epoch 4/22\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7087 - loss: 0.5371\n",
            "Epoch 4: val_loss improved from 0.50450 to 0.43473, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7084 - loss: 0.5367 - val_accuracy: 0.8440 - val_loss: 0.4347 - learning_rate: 0.0049\n",
            "Epoch 5/22\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7255 - loss: 0.5113\n",
            "Epoch 5: val_loss improved from 0.43473 to 0.37965, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7263 - loss: 0.5102 - val_accuracy: 0.8246 - val_loss: 0.3796 - learning_rate: 0.0049\n",
            "Epoch 6/22\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7597 - loss: 0.4611\n",
            "Epoch 6: val_loss did not improve from 0.37965\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7598 - loss: 0.4610 - val_accuracy: 0.7648 - val_loss: 0.4480 - learning_rate: 0.0049\n",
            "Epoch 7/22\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7632 - loss: 0.4571\n",
            "Epoch 7: val_loss improved from 0.37965 to 0.30602, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7645 - loss: 0.4558 - val_accuracy: 0.8735 - val_loss: 0.3060 - learning_rate: 0.0049\n",
            "Epoch 8/22\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7712 - loss: 0.4650\n",
            "Epoch 8: val_loss did not improve from 0.30602\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7715 - loss: 0.4635 - val_accuracy: 0.7867 - val_loss: 0.4206 - learning_rate: 0.0049\n",
            "Epoch 9/22\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.4187\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.001971388873286571.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.30602\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7850 - loss: 0.4184 - val_accuracy: 0.8010 - val_loss: 0.3619 - learning_rate: 0.0049\n",
            "Epoch 10/22\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8096 - loss: 0.3867\n",
            "Epoch 10: val_loss did not improve from 0.30602\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.3868 - val_accuracy: 0.8179 - val_loss: 0.3563 - learning_rate: 0.0020\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:50:24,105] Trial 4 finished with value: -0.3060208857059479 and parameters: {'epochs': 22, 'batch_size': 32, 'learning_rate': 0.004862365289611238, 'stop_patience': 3, 'reduce_lr_factor': 0.40543824793806216, 'reduce_lr_patience': 2}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/21\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5653 - loss: 0.6908\n",
            "Epoch 1: val_loss improved from inf to 0.68359, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5652 - loss: 0.6908 - val_accuracy: 0.5801 - val_loss: 0.6836 - learning_rate: 0.0071\n",
            "Epoch 2/21\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5706 - loss: 0.6820\n",
            "Epoch 2: val_loss did not improve from 0.68359\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5706 - loss: 0.6820 - val_accuracy: 0.4469 - val_loss: 0.7343 - learning_rate: 0.0071\n",
            "Epoch 3/21\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5663 - loss: 0.6449\n",
            "Epoch 3: val_loss improved from 0.68359 to 0.48682, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5671 - loss: 0.6446 - val_accuracy: 0.8255 - val_loss: 0.4868 - learning_rate: 0.0071\n",
            "Epoch 4/21\n",
            "\u001b[1m283/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6616 - loss: 0.5808\n",
            "Epoch 4: val_loss improved from 0.48682 to 0.40071, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6633 - loss: 0.5794 - val_accuracy: 0.8314 - val_loss: 0.4007 - learning_rate: 0.0071\n",
            "Epoch 5/21\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7265 - loss: 0.5263\n",
            "Epoch 5: val_loss improved from 0.40071 to 0.37842, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7267 - loss: 0.5259 - val_accuracy: 0.8229 - val_loss: 0.3784 - learning_rate: 0.0071\n",
            "Epoch 6/21\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7448 - loss: 0.4905\n",
            "Epoch 6: val_loss did not improve from 0.37842\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7450 - loss: 0.4903 - val_accuracy: 0.8482 - val_loss: 0.3805 - learning_rate: 0.0071\n",
            "Epoch 7/21\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7528 - loss: 0.4891\n",
            "Epoch 7: val_loss improved from 0.37842 to 0.33022, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7534 - loss: 0.4881 - val_accuracy: 0.8406 - val_loss: 0.3302 - learning_rate: 0.0071\n",
            "Epoch 8/21\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7676 - loss: 0.4551\n",
            "Epoch 8: val_loss did not improve from 0.33022\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7677 - loss: 0.4550 - val_accuracy: 0.6627 - val_loss: 0.6138 - learning_rate: 0.0071\n",
            "Epoch 9/21\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7803 - loss: 0.4400\n",
            "Epoch 9: val_loss improved from 0.33022 to 0.31389, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7805 - loss: 0.4398 - val_accuracy: 0.8668 - val_loss: 0.3139 - learning_rate: 0.0071\n",
            "Epoch 10/21\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7753 - loss: 0.4374\n",
            "Epoch 10: val_loss improved from 0.31389 to 0.30986, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7756 - loss: 0.4370 - val_accuracy: 0.8642 - val_loss: 0.3099 - learning_rate: 0.0071\n",
            "Epoch 11/21\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7921 - loss: 0.4178\n",
            "Epoch 11: val_loss improved from 0.30986 to 0.30948, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.4177 - val_accuracy: 0.8668 - val_loss: 0.3095 - learning_rate: 0.0071\n",
            "Epoch 12/21\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.4263\n",
            "Epoch 12: val_loss did not improve from 0.30948\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 0.4258 - val_accuracy: 0.8533 - val_loss: 0.3102 - learning_rate: 0.0071\n",
            "Epoch 13/21\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7917 - loss: 0.4181\n",
            "Epoch 13: val_loss did not improve from 0.30948\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7920 - loss: 0.4178 - val_accuracy: 0.8137 - val_loss: 0.4105 - learning_rate: 0.0071\n",
            "Epoch 14/21\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.4071\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0019472902840926972.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.30948\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7960 - loss: 0.4068 - val_accuracy: 0.8583 - val_loss: 0.3494 - learning_rate: 0.0071\n",
            "Epoch 15/21\n",
            "\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8426 - loss: 0.3560\n",
            "Epoch 15: val_loss did not improve from 0.30948\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.3551 - val_accuracy: 0.8592 - val_loss: 0.4021 - learning_rate: 0.0019\n",
            "Epoch 16/21\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8523 - loss: 0.3263\n",
            "Epoch 16: val_loss did not improve from 0.30948\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8522 - loss: 0.3264 - val_accuracy: 0.8702 - val_loss: 0.3139 - learning_rate: 0.0019\n",
            "Epoch 17/21\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8590 - loss: 0.3188\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005342917242425767.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.30948\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.3190 - val_accuracy: 0.8642 - val_loss: 0.3107 - learning_rate: 0.0019\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:50:59,558] Trial 5 finished with value: -0.30948150157928467 and parameters: {'epochs': 21, 'batch_size': 16, 'learning_rate': 0.007097132819228273, 'stop_patience': 6, 'reduce_lr_factor': 0.2743770325877627, 'reduce_lr_patience': 3}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5562 - loss: 0.6922\n",
            "Epoch 1: val_loss improved from inf to 0.69004, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5566 - loss: 0.6915 - val_accuracy: 0.5379 - val_loss: 0.6900 - learning_rate: 0.0054\n",
            "Epoch 2/14\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6035 - loss: 0.6447\n",
            "Epoch 2: val_loss improved from 0.69004 to 0.63366, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6066 - loss: 0.6422 - val_accuracy: 0.7218 - val_loss: 0.6337 - learning_rate: 0.0054\n",
            "Epoch 3/14\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6728 - loss: 0.5773\n",
            "Epoch 3: val_loss improved from 0.63366 to 0.44200, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6757 - loss: 0.5732 - val_accuracy: 0.7985 - val_loss: 0.4420 - learning_rate: 0.0054\n",
            "Epoch 4/14\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7369 - loss: 0.5142\n",
            "Epoch 4: val_loss improved from 0.44200 to 0.40151, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7371 - loss: 0.5139 - val_accuracy: 0.7985 - val_loss: 0.4015 - learning_rate: 0.0054\n",
            "Epoch 5/14\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7650 - loss: 0.4706\n",
            "Epoch 5: val_loss improved from 0.40151 to 0.39749, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7653 - loss: 0.4698 - val_accuracy: 0.8086 - val_loss: 0.3975 - learning_rate: 0.0054\n",
            "Epoch 6/14\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7503 - loss: 0.4976\n",
            "Epoch 6: val_loss did not improve from 0.39749\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7509 - loss: 0.4963 - val_accuracy: 0.7530 - val_loss: 0.4665 - learning_rate: 0.0054\n",
            "Epoch 7/14\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7780 - loss: 0.4551\n",
            "Epoch 7: val_loss did not improve from 0.39749\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7783 - loss: 0.4538 - val_accuracy: 0.8027 - val_loss: 0.4115 - learning_rate: 0.0054\n",
            "Epoch 8/14\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7730 - loss: 0.4448\n",
            "Epoch 8: val_loss improved from 0.39749 to 0.35713, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7729 - loss: 0.4446 - val_accuracy: 0.8491 - val_loss: 0.3571 - learning_rate: 0.0054\n",
            "Epoch 9/14\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7998 - loss: 0.4339\n",
            "Epoch 9: val_loss improved from 0.35713 to 0.32969, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7991 - loss: 0.4346 - val_accuracy: 0.8465 - val_loss: 0.3297 - learning_rate: 0.0054\n",
            "Epoch 10/14\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7888 - loss: 0.4101\n",
            "Epoch 10: val_loss did not improve from 0.32969\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7890 - loss: 0.4100 - val_accuracy: 0.7960 - val_loss: 0.3618 - learning_rate: 0.0054\n",
            "Epoch 11/14\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8009 - loss: 0.3976 \n",
            "Epoch 11: val_loss did not improve from 0.32969\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8006 - loss: 0.3983 - val_accuracy: 0.8162 - val_loss: 0.3608 - learning_rate: 0.0054\n",
            "Epoch 12/14\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8235 - loss: 0.3851\n",
            "Epoch 12: val_loss did not improve from 0.32969\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8227 - loss: 0.3858 - val_accuracy: 0.8002 - val_loss: 0.3727 - learning_rate: 0.0054\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:51:14,324] Trial 6 finished with value: -0.32968708872795105 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 0.005382325576398161, 'stop_patience': 3, 'reduce_lr_factor': 0.46154740219618173, 'reduce_lr_patience': 5}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/21\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5553 - loss: 0.6923\n",
            "Epoch 1: val_loss improved from inf to 0.68166, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5553 - loss: 0.6923 - val_accuracy: 0.5801 - val_loss: 0.6817 - learning_rate: 0.0097\n",
            "Epoch 2/21\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5721 - loss: 0.6846\n",
            "Epoch 2: val_loss did not improve from 0.68166\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5718 - loss: 0.6846 - val_accuracy: 0.5801 - val_loss: 0.6865 - learning_rate: 0.0097\n",
            "Epoch 3/21\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5723 - loss: 0.6711\n",
            "Epoch 3: val_loss improved from 0.68166 to 0.68022, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5722 - loss: 0.6711 - val_accuracy: 0.5801 - val_loss: 0.6802 - learning_rate: 0.0097\n",
            "Epoch 4/21\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5968 - loss: 0.6283\n",
            "Epoch 4: val_loss improved from 0.68022 to 0.47112, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5980 - loss: 0.6275 - val_accuracy: 0.8044 - val_loss: 0.4711 - learning_rate: 0.0097\n",
            "Epoch 5/21\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6697 - loss: 0.6043\n",
            "Epoch 5: val_loss did not improve from 0.47112\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6703 - loss: 0.6036 - val_accuracy: 0.7909 - val_loss: 0.6329 - learning_rate: 0.0097\n",
            "Epoch 6/21\n",
            "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6991 - loss: 0.5750\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0010762414695294354.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.47112\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6992 - loss: 0.5748 - val_accuracy: 0.8078 - val_loss: 0.5479 - learning_rate: 0.0097\n",
            "Epoch 7/21\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7531 - loss: 0.5130\n",
            "Epoch 7: val_loss did not improve from 0.47112\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7536 - loss: 0.5126 - val_accuracy: 0.7968 - val_loss: 0.4745 - learning_rate: 0.0011\n",
            "Epoch 8/21\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7814 - loss: 0.4692\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00011921041350875316.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.47112\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7818 - loss: 0.4688 - val_accuracy: 0.8179 - val_loss: 0.4742 - learning_rate: 0.0011\n",
            "Epoch 9/21\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7956 - loss: 0.4490\n",
            "Epoch 9: val_loss did not improve from 0.47112\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7959 - loss: 0.4488 - val_accuracy: 0.8204 - val_loss: 0.4779 - learning_rate: 1.1921e-04\n",
            "Epoch 10/21\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8056 - loss: 0.4493\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.3204399212490038e-05.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.47112\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8056 - loss: 0.4492 - val_accuracy: 0.8196 - val_loss: 0.4754 - learning_rate: 1.1921e-04\n",
            "Epoch 11/21\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8110 - loss: 0.4446\n",
            "Epoch 11: val_loss did not improve from 0.47112\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8110 - loss: 0.4446 - val_accuracy: 0.8196 - val_loss: 0.4754 - learning_rate: 1.3204e-05\n",
            "Epoch 12/21\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8102 - loss: 0.4427\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.4625916715216365e-06.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.47112\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8102 - loss: 0.4425 - val_accuracy: 0.8187 - val_loss: 0.4759 - learning_rate: 1.3204e-05\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:51:57,153] Trial 7 finished with value: -0.4711209535598755 and parameters: {'epochs': 21, 'batch_size': 16, 'learning_rate': 0.009716396714229353, 'stop_patience': 8, 'reduce_lr_factor': 0.11076548773840456, 'reduce_lr_patience': 2}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/22\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5646 - loss: 0.6910\n",
            "Epoch 1: val_loss improved from inf to 0.68407, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5645 - loss: 0.6910 - val_accuracy: 0.5801 - val_loss: 0.6841 - learning_rate: 0.0081\n",
            "Epoch 2/22\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5718 - loss: 0.6851\n",
            "Epoch 2: val_loss improved from 0.68407 to 0.68324, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5718 - loss: 0.6851 - val_accuracy: 0.5801 - val_loss: 0.6832 - learning_rate: 0.0081\n",
            "Epoch 3/22\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5718 - loss: 0.6845\n",
            "Epoch 3: val_loss improved from 0.68324 to 0.68247, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5718 - loss: 0.6845 - val_accuracy: 0.5801 - val_loss: 0.6825 - learning_rate: 0.0081\n",
            "Epoch 4/22\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5721 - loss: 0.6842\n",
            "Epoch 4: val_loss did not improve from 0.68247\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5718 - loss: 0.6843 - val_accuracy: 0.5801 - val_loss: 0.6825 - learning_rate: 0.0081\n",
            "Epoch 5/22\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5721 - loss: 0.6841\n",
            "Epoch 5: val_loss improved from 0.68247 to 0.68102, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5717 - loss: 0.6842 - val_accuracy: 0.5801 - val_loss: 0.6810 - learning_rate: 0.0081\n",
            "Epoch 6/22\n",
            "\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5728 - loss: 0.6843\n",
            "Epoch 6: val_loss did not improve from 0.68102\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5725 - loss: 0.6843 - val_accuracy: 0.5396 - val_loss: 0.7775 - learning_rate: 0.0081\n",
            "Epoch 7/22\n",
            "\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5983 - loss: 0.6789\n",
            "Epoch 7: val_loss improved from 0.68102 to 0.68046, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5980 - loss: 0.6791 - val_accuracy: 0.5801 - val_loss: 0.6805 - learning_rate: 0.0081\n",
            "Epoch 8/22\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5730 - loss: 0.6828\n",
            "Epoch 8: val_loss improved from 0.68046 to 0.67403, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5729 - loss: 0.6828 - val_accuracy: 0.5953 - val_loss: 0.6740 - learning_rate: 0.0081\n",
            "Epoch 9/22\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6028 - loss: 0.6706\n",
            "Epoch 9: val_loss improved from 0.67403 to 0.61815, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6028 - loss: 0.6706 - val_accuracy: 0.6745 - val_loss: 0.6182 - learning_rate: 0.0081\n",
            "Epoch 10/22\n",
            "\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6253 - loss: 0.6552\n",
            "Epoch 10: val_loss improved from 0.61815 to 0.56809, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6255 - loss: 0.6548 - val_accuracy: 0.7841 - val_loss: 0.5681 - learning_rate: 0.0081\n",
            "Epoch 11/22\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6767 - loss: 0.5940\n",
            "Epoch 11: val_loss improved from 0.56809 to 0.46365, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6769 - loss: 0.5938 - val_accuracy: 0.8010 - val_loss: 0.4636 - learning_rate: 0.0081\n",
            "Epoch 12/22\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6964 - loss: 0.5485\n",
            "Epoch 12: val_loss did not improve from 0.46365\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6968 - loss: 0.5481 - val_accuracy: 0.7184 - val_loss: 0.6035 - learning_rate: 0.0081\n",
            "Epoch 13/22\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7301 - loss: 0.5151\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0031122918786525297.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.46365\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7303 - loss: 0.5150 - val_accuracy: 0.7622 - val_loss: 0.5395 - learning_rate: 0.0081\n",
            "Epoch 14/22\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7716 - loss: 0.4635\n",
            "Epoch 14: val_loss improved from 0.46365 to 0.43010, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7722 - loss: 0.4630 - val_accuracy: 0.8128 - val_loss: 0.4301 - learning_rate: 0.0031\n",
            "Epoch 15/22\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7791 - loss: 0.4425\n",
            "Epoch 15: val_loss did not improve from 0.43010\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7795 - loss: 0.4422 - val_accuracy: 0.8153 - val_loss: 0.4503 - learning_rate: 0.0031\n",
            "Epoch 16/22\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7843 - loss: 0.4440\n",
            "Epoch 16: val_loss improved from 0.43010 to 0.42759, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7844 - loss: 0.4438 - val_accuracy: 0.8145 - val_loss: 0.4276 - learning_rate: 0.0031\n",
            "Epoch 17/22\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7841 - loss: 0.4356\n",
            "Epoch 17: val_loss improved from 0.42759 to 0.40754, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7843 - loss: 0.4354 - val_accuracy: 0.8229 - val_loss: 0.4075 - learning_rate: 0.0031\n",
            "Epoch 18/22\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7844 - loss: 0.4235\n",
            "Epoch 18: val_loss did not improve from 0.40754\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7844 - loss: 0.4235 - val_accuracy: 0.8440 - val_loss: 0.4139 - learning_rate: 0.0031\n",
            "Epoch 19/22\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7934 - loss: 0.4144\n",
            "Epoch 19: val_loss improved from 0.40754 to 0.38954, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7937 - loss: 0.4142 - val_accuracy: 0.8347 - val_loss: 0.3895 - learning_rate: 0.0031\n",
            "Epoch 20/22\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7864 - loss: 0.4168\n",
            "Epoch 20: val_loss did not improve from 0.38954\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7872 - loss: 0.4161 - val_accuracy: 0.8373 - val_loss: 0.4029 - learning_rate: 0.0031\n",
            "Epoch 21/22\n",
            "\u001b[1m282/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7833 - loss: 0.4316\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0011998817700675764.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.38954\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7844 - loss: 0.4302 - val_accuracy: 0.8390 - val_loss: 0.4201 - learning_rate: 0.0031\n",
            "Epoch 22/22\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8092 - loss: 0.3914\n",
            "Epoch 22: val_loss did not improve from 0.38954\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8097 - loss: 0.3909 - val_accuracy: 0.8390 - val_loss: 0.4330 - learning_rate: 0.0012\n",
            "Restoring model weights from the end of the best epoch: 19.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:52:49,013] Trial 8 finished with value: -0.3895404636859894 and parameters: {'epochs': 22, 'batch_size': 16, 'learning_rate': 0.008072762753459396, 'stop_patience': 4, 'reduce_lr_factor': 0.3855299573393449, 'reduce_lr_patience': 2}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5607 - loss: 0.6821\n",
            "Epoch 1: val_loss improved from inf to 1.19222, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5614 - loss: 0.6816 - val_accuracy: 0.4806 - val_loss: 1.1922 - learning_rate: 0.0041\n",
            "Epoch 2/14\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6301 - loss: 0.6149\n",
            "Epoch 2: val_loss improved from 1.19222 to 0.39303, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6303 - loss: 0.6147 - val_accuracy: 0.8331 - val_loss: 0.3930 - learning_rate: 0.0041\n",
            "Epoch 3/14\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7010 - loss: 0.5464\n",
            "Epoch 3: val_loss improved from 0.39303 to 0.35087, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7014 - loss: 0.5460 - val_accuracy: 0.8423 - val_loss: 0.3509 - learning_rate: 0.0041\n",
            "Epoch 4/14\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7435 - loss: 0.5060\n",
            "Epoch 4: val_loss did not improve from 0.35087\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7436 - loss: 0.5058 - val_accuracy: 0.8263 - val_loss: 0.3851 - learning_rate: 0.0041\n",
            "Epoch 5/14\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7531 - loss: 0.4677\n",
            "Epoch 5: val_loss did not improve from 0.35087\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7529 - loss: 0.4679 - val_accuracy: 0.8432 - val_loss: 0.3679 - learning_rate: 0.0041\n",
            "Epoch 6/14\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7562 - loss: 0.4750\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0016246546021504555.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.35087\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7565 - loss: 0.4746 - val_accuracy: 0.8390 - val_loss: 0.4304 - learning_rate: 0.0041\n",
            "Epoch 7/14\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7809 - loss: 0.4311\n",
            "Epoch 7: val_loss improved from 0.35087 to 0.30944, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7810 - loss: 0.4309 - val_accuracy: 0.8524 - val_loss: 0.3094 - learning_rate: 0.0016\n",
            "Epoch 8/14\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8142 - loss: 0.4007\n",
            "Epoch 8: val_loss improved from 0.30944 to 0.30401, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8142 - loss: 0.4006 - val_accuracy: 0.8634 - val_loss: 0.3040 - learning_rate: 0.0016\n",
            "Epoch 9/14\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8168 - loss: 0.3833\n",
            "Epoch 9: val_loss did not improve from 0.30401\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8170 - loss: 0.3830 - val_accuracy: 0.8752 - val_loss: 0.3075 - learning_rate: 0.0016\n",
            "Epoch 10/14\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8255 - loss: 0.3665\n",
            "Epoch 10: val_loss did not improve from 0.30401\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8257 - loss: 0.3664 - val_accuracy: 0.8668 - val_loss: 0.3094 - learning_rate: 0.0016\n",
            "Epoch 11/14\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8277 - loss: 0.3590\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0006409047735073112.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.30401\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8279 - loss: 0.3589 - val_accuracy: 0.8575 - val_loss: 0.3080 - learning_rate: 0.0016\n",
            "Epoch 12/14\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8580 - loss: 0.3202\n",
            "Epoch 12: val_loss did not improve from 0.30401\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8581 - loss: 0.3201 - val_accuracy: 0.8617 - val_loss: 0.3259 - learning_rate: 6.4090e-04\n",
            "Epoch 13/14\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8644 - loss: 0.3033\n",
            "Epoch 13: val_loss did not improve from 0.30401\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8643 - loss: 0.3034 - val_accuracy: 0.8575 - val_loss: 0.3476 - learning_rate: 6.4090e-04\n",
            "Epoch 14/14\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8645 - loss: 0.3009\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00025282845660106677.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.30401\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8644 - loss: 0.3011 - val_accuracy: 0.8524 - val_loss: 0.3578 - learning_rate: 6.4090e-04\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:53:15,328] Trial 9 finished with value: -0.3040103614330292 and parameters: {'epochs': 14, 'batch_size': 16, 'learning_rate': 0.004118400412047983, 'stop_patience': 9, 'reduce_lr_factor': 0.3944867801202606, 'reduce_lr_patience': 3}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5544 - loss: 0.6874\n",
            "Epoch 1: val_loss improved from inf to 0.59896, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5552 - loss: 0.6870 - val_accuracy: 0.6838 - val_loss: 0.5990 - learning_rate: 5.7104e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6197 - loss: 0.6408\n",
            "Epoch 2: val_loss improved from 0.59896 to 0.45085, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6198 - loss: 0.6407 - val_accuracy: 0.8229 - val_loss: 0.4509 - learning_rate: 5.7104e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6971 - loss: 0.5670\n",
            "Epoch 3: val_loss did not improve from 0.45085\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6972 - loss: 0.5668 - val_accuracy: 0.7513 - val_loss: 0.4947 - learning_rate: 5.7104e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7383 - loss: 0.5124\n",
            "Epoch 4: val_loss improved from 0.45085 to 0.36963, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7383 - loss: 0.5124 - val_accuracy: 0.8322 - val_loss: 0.3696 - learning_rate: 5.7104e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7557 - loss: 0.4839\n",
            "Epoch 5: val_loss improved from 0.36963 to 0.35468, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7560 - loss: 0.4836 - val_accuracy: 0.8288 - val_loss: 0.3547 - learning_rate: 5.7104e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7638 - loss: 0.4589\n",
            "Epoch 6: val_loss improved from 0.35468 to 0.31508, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7640 - loss: 0.4588 - val_accuracy: 0.8567 - val_loss: 0.3151 - learning_rate: 5.7104e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7825 - loss: 0.4468\n",
            "Epoch 7: val_loss did not improve from 0.31508\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7826 - loss: 0.4465 - val_accuracy: 0.8406 - val_loss: 0.3876 - learning_rate: 5.7104e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7975 - loss: 0.4216\n",
            "Epoch 8: val_loss did not improve from 0.31508\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.4218 - val_accuracy: 0.8516 - val_loss: 0.3249 - learning_rate: 5.7104e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8019 - loss: 0.4038\n",
            "Epoch 9: val_loss did not improve from 0.31508\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8020 - loss: 0.4037 - val_accuracy: 0.8415 - val_loss: 0.3753 - learning_rate: 5.7104e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.3989\n",
            "Epoch 10: val_loss did not improve from 0.31508\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7987 - loss: 0.3991 - val_accuracy: 0.8583 - val_loss: 0.3196 - learning_rate: 5.7104e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8144 - loss: 0.3868\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002819817581191621.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.31508\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8144 - loss: 0.3868 - val_accuracy: 0.8524 - val_loss: 0.3352 - learning_rate: 5.7104e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8325 - loss: 0.3662\n",
            "Epoch 12: val_loss improved from 0.31508 to 0.30034, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8330 - loss: 0.3658 - val_accuracy: 0.8676 - val_loss: 0.3003 - learning_rate: 2.8198e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8494 - loss: 0.3481\n",
            "Epoch 13: val_loss did not improve from 0.30034\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8494 - loss: 0.3481 - val_accuracy: 0.8710 - val_loss: 0.3158 - learning_rate: 2.8198e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8436 - loss: 0.3495\n",
            "Epoch 14: val_loss did not improve from 0.30034\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8436 - loss: 0.3494 - val_accuracy: 0.8710 - val_loss: 0.3228 - learning_rate: 2.8198e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8444 - loss: 0.3451\n",
            "Epoch 15: val_loss did not improve from 0.30034\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8445 - loss: 0.3453 - val_accuracy: 0.8659 - val_loss: 0.3128 - learning_rate: 2.8198e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8515 - loss: 0.3363\n",
            "Epoch 16: val_loss did not improve from 0.30034\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8513 - loss: 0.3366 - val_accuracy: 0.8718 - val_loss: 0.3076 - learning_rate: 2.8198e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8459 - loss: 0.3347\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00013924433530266629.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.30034\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8459 - loss: 0.3349 - val_accuracy: 0.8676 - val_loss: 0.3272 - learning_rate: 2.8198e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8662 - loss: 0.3231\n",
            "Epoch 18: val_loss did not improve from 0.30034\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8663 - loss: 0.3231 - val_accuracy: 0.8744 - val_loss: 0.3212 - learning_rate: 1.3924e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8598 - loss: 0.3221\n",
            "Epoch 19: val_loss did not improve from 0.30034\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8599 - loss: 0.3221 - val_accuracy: 0.8676 - val_loss: 0.3207 - learning_rate: 1.3924e-04\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:53:41,933] Trial 10 finished with value: -0.3003368675708771 and parameters: {'epochs': 50, 'batch_size': 32, 'learning_rate': 0.0005710373038373649, 'stop_patience': 7, 'reduce_lr_factor': 0.49380620385474017, 'reduce_lr_patience': 5}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/48\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5465 - loss: 0.6887\n",
            "Epoch 1: val_loss improved from inf to 0.67068, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5469 - loss: 0.6886 - val_accuracy: 0.6788 - val_loss: 0.6707 - learning_rate: 2.8850e-04\n",
            "Epoch 2/48\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5865 - loss: 0.6619\n",
            "Epoch 2: val_loss improved from 0.67068 to 0.53582, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5868 - loss: 0.6617 - val_accuracy: 0.7698 - val_loss: 0.5358 - learning_rate: 2.8850e-04\n",
            "Epoch 3/48\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6695 - loss: 0.6037\n",
            "Epoch 3: val_loss improved from 0.53582 to 0.41512, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6703 - loss: 0.6030 - val_accuracy: 0.8238 - val_loss: 0.4151 - learning_rate: 2.8850e-04\n",
            "Epoch 4/48\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7198 - loss: 0.5416\n",
            "Epoch 4: val_loss did not improve from 0.41512\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7200 - loss: 0.5414 - val_accuracy: 0.8035 - val_loss: 0.4347 - learning_rate: 2.8850e-04\n",
            "Epoch 5/48\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7547 - loss: 0.4972\n",
            "Epoch 5: val_loss did not improve from 0.41512\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7547 - loss: 0.4971 - val_accuracy: 0.8196 - val_loss: 0.4214 - learning_rate: 2.8850e-04\n",
            "Epoch 6/48\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7588 - loss: 0.4815\n",
            "Epoch 6: val_loss improved from 0.41512 to 0.38338, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7590 - loss: 0.4813 - val_accuracy: 0.8280 - val_loss: 0.3834 - learning_rate: 2.8850e-04\n",
            "Epoch 7/48\n",
            "\u001b[1m136/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7810 - loss: 0.4528\n",
            "Epoch 7: val_loss did not improve from 0.38338\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4528 - val_accuracy: 0.8339 - val_loss: 0.3849 - learning_rate: 2.8850e-04\n",
            "Epoch 8/48\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7884 - loss: 0.4378\n",
            "Epoch 8: val_loss improved from 0.38338 to 0.36775, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7885 - loss: 0.4376 - val_accuracy: 0.8398 - val_loss: 0.3677 - learning_rate: 2.8850e-04\n",
            "Epoch 9/48\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7880 - loss: 0.4340\n",
            "Epoch 9: val_loss improved from 0.36775 to 0.36031, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7883 - loss: 0.4337 - val_accuracy: 0.8423 - val_loss: 0.3603 - learning_rate: 2.8850e-04\n",
            "Epoch 10/48\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.4211\n",
            "Epoch 10: val_loss improved from 0.36031 to 0.33962, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7984 - loss: 0.4210 - val_accuracy: 0.8482 - val_loss: 0.3396 - learning_rate: 2.8850e-04\n",
            "Epoch 11/48\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8017 - loss: 0.4081\n",
            "Epoch 11: val_loss did not improve from 0.33962\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8021 - loss: 0.4081 - val_accuracy: 0.8541 - val_loss: 0.3537 - learning_rate: 2.8850e-04\n",
            "Epoch 12/48\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8133 - loss: 0.3985\n",
            "Epoch 12: val_loss did not improve from 0.33962\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8132 - loss: 0.3985 - val_accuracy: 0.8524 - val_loss: 0.3470 - learning_rate: 2.8850e-04\n",
            "Epoch 13/48\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8140 - loss: 0.3888\n",
            "Epoch 13: val_loss improved from 0.33962 to 0.33321, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8141 - loss: 0.3890 - val_accuracy: 0.8642 - val_loss: 0.3332 - learning_rate: 2.8850e-04\n",
            "Epoch 14/48\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8149 - loss: 0.3872\n",
            "Epoch 14: val_loss improved from 0.33321 to 0.32104, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8149 - loss: 0.3874 - val_accuracy: 0.8659 - val_loss: 0.3210 - learning_rate: 2.8850e-04\n",
            "Epoch 15/48\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8178 - loss: 0.3762\n",
            "Epoch 15: val_loss did not improve from 0.32104\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8178 - loss: 0.3762 - val_accuracy: 0.8676 - val_loss: 0.3315 - learning_rate: 2.8850e-04\n",
            "Epoch 16/48\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8303 - loss: 0.3740\n",
            "Epoch 16: val_loss did not improve from 0.32104\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8300 - loss: 0.3744 - val_accuracy: 0.8642 - val_loss: 0.3316 - learning_rate: 2.8850e-04\n",
            "Epoch 17/48\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8329 - loss: 0.3685\n",
            "Epoch 17: val_loss did not improve from 0.32104\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8329 - loss: 0.3685 - val_accuracy: 0.8583 - val_loss: 0.3314 - learning_rate: 2.8850e-04\n",
            "Epoch 18/48\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8380 - loss: 0.3599\n",
            "Epoch 18: val_loss did not improve from 0.32104\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8376 - loss: 0.3602 - val_accuracy: 0.8651 - val_loss: 0.3291 - learning_rate: 2.8850e-04\n",
            "Epoch 19/48\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8359 - loss: 0.3632\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001416847911575334.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.32104\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8358 - loss: 0.3634 - val_accuracy: 0.8634 - val_loss: 0.3375 - learning_rate: 2.8850e-04\n",
            "Epoch 20/48\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.3403\n",
            "Epoch 20: val_loss did not improve from 0.32104\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8588 - loss: 0.3403 - val_accuracy: 0.8592 - val_loss: 0.3470 - learning_rate: 1.4168e-04\n",
            "Epoch 21/48\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8418 - loss: 0.3429\n",
            "Epoch 21: val_loss did not improve from 0.32104\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 0.3428 - val_accuracy: 0.8651 - val_loss: 0.3371 - learning_rate: 1.4168e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:54:10,685] Trial 11 finished with value: -0.3210367262363434 and parameters: {'epochs': 48, 'batch_size': 32, 'learning_rate': 0.000288495002800162, 'stop_patience': 7, 'reduce_lr_factor': 0.49111695926165655, 'reduce_lr_patience': 5}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5626 - loss: 0.6854\n",
            "Epoch 1: val_loss improved from inf to 0.59642, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.5625 - loss: 0.6853 - val_accuracy: 0.6880 - val_loss: 0.5964 - learning_rate: 6.5023e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6097 - loss: 0.6457\n",
            "Epoch 2: val_loss improved from 0.59642 to 0.48768, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6100 - loss: 0.6455 - val_accuracy: 0.7690 - val_loss: 0.4877 - learning_rate: 6.5023e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6855 - loss: 0.5711\n",
            "Epoch 3: val_loss improved from 0.48768 to 0.38784, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6859 - loss: 0.5706 - val_accuracy: 0.8280 - val_loss: 0.3878 - learning_rate: 6.5023e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7242 - loss: 0.5125\n",
            "Epoch 4: val_loss did not improve from 0.38784\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7244 - loss: 0.5123 - val_accuracy: 0.8280 - val_loss: 0.4088 - learning_rate: 6.5023e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7702 - loss: 0.4654\n",
            "Epoch 5: val_loss did not improve from 0.38784\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7707 - loss: 0.4647 - val_accuracy: 0.8255 - val_loss: 0.4265 - learning_rate: 6.5023e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7700 - loss: 0.4598\n",
            "Epoch 6: val_loss did not improve from 0.38784\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7705 - loss: 0.4588 - val_accuracy: 0.7976 - val_loss: 0.5447 - learning_rate: 6.5023e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7893 - loss: 0.4272\n",
            "Epoch 7: val_loss did not improve from 0.38784\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7897 - loss: 0.4267 - val_accuracy: 0.8347 - val_loss: 0.4027 - learning_rate: 6.5023e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7928 - loss: 0.4194\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00032310611618658686.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.38784\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4188 - val_accuracy: 0.8331 - val_loss: 0.4269 - learning_rate: 6.5023e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8216 - loss: 0.3876\n",
            "Epoch 9: val_loss improved from 0.38784 to 0.30784, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8220 - loss: 0.3871 - val_accuracy: 0.8693 - val_loss: 0.3078 - learning_rate: 3.2311e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8380 - loss: 0.3690\n",
            "Epoch 10: val_loss did not improve from 0.30784\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8378 - loss: 0.3692 - val_accuracy: 0.8651 - val_loss: 0.3110 - learning_rate: 3.2311e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8416 - loss: 0.3619\n",
            "Epoch 11: val_loss did not improve from 0.30784\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8416 - loss: 0.3618 - val_accuracy: 0.8659 - val_loss: 0.3237 - learning_rate: 3.2311e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8419 - loss: 0.3632\n",
            "Epoch 12: val_loss did not improve from 0.30784\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8420 - loss: 0.3630 - val_accuracy: 0.8567 - val_loss: 0.3581 - learning_rate: 3.2311e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8507 - loss: 0.3549\n",
            "Epoch 13: val_loss did not improve from 0.30784\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8506 - loss: 0.3549 - val_accuracy: 0.8592 - val_loss: 0.3323 - learning_rate: 3.2311e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8488 - loss: 0.3485\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00016055369761184618.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.30784\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8487 - loss: 0.3486 - val_accuracy: 0.8567 - val_loss: 0.3640 - learning_rate: 3.2311e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8633 - loss: 0.3259\n",
            "Epoch 15: val_loss did not improve from 0.30784\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8633 - loss: 0.3258 - val_accuracy: 0.8524 - val_loss: 0.3548 - learning_rate: 1.6055e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8571 - loss: 0.3226\n",
            "Epoch 16: val_loss did not improve from 0.30784\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8574 - loss: 0.3224 - val_accuracy: 0.8567 - val_loss: 0.3392 - learning_rate: 1.6055e-04\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:54:33,053] Trial 12 finished with value: -0.3078356385231018 and parameters: {'epochs': 50, 'batch_size': 32, 'learning_rate': 0.0006502345763045482, 'stop_patience': 7, 'reduce_lr_factor': 0.4969070037168626, 'reduce_lr_patience': 5}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/41\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5695 - loss: 0.6850\n",
            "Epoch 1: val_loss improved from inf to 0.54239, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5695 - loss: 0.6847 - val_accuracy: 0.8162 - val_loss: 0.5424 - learning_rate: 0.0019\n",
            "Epoch 2/41\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6617 - loss: 0.6068\n",
            "Epoch 2: val_loss improved from 0.54239 to 0.43906, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6628 - loss: 0.6053 - val_accuracy: 0.7926 - val_loss: 0.4391 - learning_rate: 0.0019\n",
            "Epoch 3/41\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6845 - loss: 0.5518\n",
            "Epoch 3: val_loss did not improve from 0.43906\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6856 - loss: 0.5505 - val_accuracy: 0.7530 - val_loss: 0.5333 - learning_rate: 0.0019\n",
            "Epoch 4/41\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7538 - loss: 0.4746\n",
            "Epoch 4: val_loss improved from 0.43906 to 0.36179, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7550 - loss: 0.4731 - val_accuracy: 0.8457 - val_loss: 0.3618 - learning_rate: 0.0019\n",
            "Epoch 5/41\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7553 - loss: 0.4737\n",
            "Epoch 5: val_loss improved from 0.36179 to 0.31443, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7572 - loss: 0.4717 - val_accuracy: 0.8634 - val_loss: 0.3144 - learning_rate: 0.0019\n",
            "Epoch 6/41\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7811 - loss: 0.4404\n",
            "Epoch 6: val_loss did not improve from 0.31443\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7820 - loss: 0.4385 - val_accuracy: 0.8482 - val_loss: 0.3382 - learning_rate: 0.0019\n",
            "Epoch 7/41\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.4123\n",
            "Epoch 7: val_loss improved from 0.31443 to 0.30486, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7937 - loss: 0.4123 - val_accuracy: 0.8752 - val_loss: 0.3049 - learning_rate: 0.0019\n",
            "Epoch 8/41\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7859 - loss: 0.4358\n",
            "Epoch 8: val_loss did not improve from 0.30486\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7870 - loss: 0.4339 - val_accuracy: 0.8567 - val_loss: 0.3236 - learning_rate: 0.0019\n",
            "Epoch 9/41\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7918 - loss: 0.4235\n",
            "Epoch 9: val_loss did not improve from 0.30486\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7928 - loss: 0.4217 - val_accuracy: 0.8457 - val_loss: 0.3402 - learning_rate: 0.0019\n",
            "Epoch 10/41\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8047 - loss: 0.3975\n",
            "Epoch 10: val_loss did not improve from 0.30486\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8048 - loss: 0.3974 - val_accuracy: 0.8474 - val_loss: 0.3979 - learning_rate: 0.0019\n",
            "Epoch 11/41\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7989 - loss: 0.3931\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0006241441559160108.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.30486\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7994 - loss: 0.3929 - val_accuracy: 0.8246 - val_loss: 0.4322 - learning_rate: 0.0019\n",
            "Epoch 12/41\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8394 - loss: 0.3450\n",
            "Epoch 12: val_loss did not improve from 0.30486\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8398 - loss: 0.3447 - val_accuracy: 0.8533 - val_loss: 0.4120 - learning_rate: 6.2414e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:54:48,683] Trial 13 finished with value: -0.304857462644577 and parameters: {'epochs': 41, 'batch_size': 32, 'learning_rate': 0.0018681750058041908, 'stop_patience': 5, 'reduce_lr_factor': 0.3340929827826515, 'reduce_lr_patience': 4}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/42\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5475 - loss: 0.6853\n",
            "Epoch 1: val_loss improved from inf to 0.51961, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.5479 - loss: 0.6850 - val_accuracy: 0.7310 - val_loss: 0.5196 - learning_rate: 0.0022\n",
            "Epoch 2/42\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6494 - loss: 0.6124\n",
            "Epoch 2: val_loss improved from 0.51961 to 0.40703, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6507 - loss: 0.6109 - val_accuracy: 0.8027 - val_loss: 0.4070 - learning_rate: 0.0022\n",
            "Epoch 3/42\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7077 - loss: 0.5607\n",
            "Epoch 3: val_loss improved from 0.40703 to 0.35310, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7082 - loss: 0.5600 - val_accuracy: 0.8432 - val_loss: 0.3531 - learning_rate: 0.0022\n",
            "Epoch 4/42\n",
            "\u001b[1m136/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7688 - loss: 0.4704\n",
            "Epoch 4: val_loss did not improve from 0.35310\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7684 - loss: 0.4703 - val_accuracy: 0.8314 - val_loss: 0.3538 - learning_rate: 0.0022\n",
            "Epoch 5/42\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7523 - loss: 0.4651\n",
            "Epoch 5: val_loss did not improve from 0.35310\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7528 - loss: 0.4646 - val_accuracy: 0.8221 - val_loss: 0.3991 - learning_rate: 0.0022\n",
            "Epoch 6/42\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7965 - loss: 0.4274\n",
            "Epoch 6: val_loss improved from 0.35310 to 0.33177, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7967 - loss: 0.4268 - val_accuracy: 0.8592 - val_loss: 0.3318 - learning_rate: 0.0022\n",
            "Epoch 7/42\n",
            "\u001b[1m136/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7797 - loss: 0.4467\n",
            "Epoch 7: val_loss did not improve from 0.33177\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 0.4442 - val_accuracy: 0.8272 - val_loss: 0.4692 - learning_rate: 0.0022\n",
            "Epoch 8/42\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7844 - loss: 0.4570\n",
            "Epoch 8: val_loss did not improve from 0.33177\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7860 - loss: 0.4535 - val_accuracy: 0.8339 - val_loss: 0.4105 - learning_rate: 0.0022\n",
            "Epoch 9/42\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7890 - loss: 0.4485\n",
            "Epoch 9: val_loss improved from 0.33177 to 0.32077, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7898 - loss: 0.4468 - val_accuracy: 0.8533 - val_loss: 0.3208 - learning_rate: 0.0022\n",
            "Epoch 10/42\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 0.4297\n",
            "Epoch 10: val_loss did not improve from 0.32077\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7959 - loss: 0.4279 - val_accuracy: 0.8390 - val_loss: 0.3687 - learning_rate: 0.0022\n",
            "Epoch 11/42\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7930 - loss: 0.4103\n",
            "Epoch 11: val_loss did not improve from 0.32077\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7938 - loss: 0.4093 - val_accuracy: 0.8322 - val_loss: 0.4548 - learning_rate: 0.0022\n",
            "Epoch 12/42\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8015 - loss: 0.4026\n",
            "Epoch 12: val_loss did not improve from 0.32077\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8017 - loss: 0.4023 - val_accuracy: 0.8111 - val_loss: 0.4203 - learning_rate: 0.0022\n",
            "Epoch 13/42\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8140 - loss: 0.3830\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007663994557305537.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.32077\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8142 - loss: 0.3829 - val_accuracy: 0.8179 - val_loss: 0.3964 - learning_rate: 0.0022\n",
            "Epoch 14/42\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8337 - loss: 0.3535\n",
            "Epoch 14: val_loss did not improve from 0.32077\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8340 - loss: 0.3531 - val_accuracy: 0.8339 - val_loss: 0.5560 - learning_rate: 7.6640e-04\n",
            "Epoch 15/42\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 0.3110\n",
            "Epoch 15: val_loss did not improve from 0.32077\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8655 - loss: 0.3112 - val_accuracy: 0.8373 - val_loss: 0.5755 - learning_rate: 7.6640e-04\n",
            "Epoch 16/42\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8697 - loss: 0.3059\n",
            "Epoch 16: val_loss did not improve from 0.32077\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8692 - loss: 0.3066 - val_accuracy: 0.8255 - val_loss: 0.6445 - learning_rate: 7.6640e-04\n",
            "Epoch 17/42\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8679 - loss: 0.3099\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002642057454215363.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.32077\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8677 - loss: 0.3098 - val_accuracy: 0.8364 - val_loss: 0.5728 - learning_rate: 7.6640e-04\n",
            "Epoch 18/42\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8783 - loss: 0.2848\n",
            "Epoch 18: val_loss did not improve from 0.32077\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8781 - loss: 0.2850 - val_accuracy: 0.8196 - val_loss: 0.7654 - learning_rate: 2.6421e-04\n",
            "Epoch 19/42\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8760 - loss: 0.2884\n",
            "Epoch 19: val_loss did not improve from 0.32077\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8761 - loss: 0.2883 - val_accuracy: 0.8170 - val_loss: 0.7740 - learning_rate: 2.6421e-04\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:55:11,870] Trial 14 finished with value: -0.32076773047447205 and parameters: {'epochs': 42, 'batch_size': 32, 'learning_rate': 0.002223146607842878, 'stop_patience': 10, 'reduce_lr_factor': 0.3447363529746765, 'reduce_lr_patience': 4}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/36\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5456 - loss: 0.6863\n",
            "Epoch 1: val_loss improved from inf to 0.56663, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5460 - loss: 0.6862 - val_accuracy: 0.7901 - val_loss: 0.5666 - learning_rate: 0.0020\n",
            "Epoch 2/36\n",
            "\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6104 - loss: 0.6358\n",
            "Epoch 2: val_loss improved from 0.56663 to 0.38949, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6116 - loss: 0.6349 - val_accuracy: 0.8465 - val_loss: 0.3895 - learning_rate: 0.0020\n",
            "Epoch 3/36\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7094 - loss: 0.5397\n",
            "Epoch 3: val_loss improved from 0.38949 to 0.33218, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7100 - loss: 0.5391 - val_accuracy: 0.8558 - val_loss: 0.3322 - learning_rate: 0.0020\n",
            "Epoch 4/36\n",
            "\u001b[1m283/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.5037\n",
            "Epoch 4: val_loss improved from 0.33218 to 0.31859, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7368 - loss: 0.5028 - val_accuracy: 0.8482 - val_loss: 0.3186 - learning_rate: 0.0020\n",
            "Epoch 5/36\n",
            "\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7804 - loss: 0.4516\n",
            "Epoch 5: val_loss improved from 0.31859 to 0.31442, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7803 - loss: 0.4514 - val_accuracy: 0.8575 - val_loss: 0.3144 - learning_rate: 0.0020\n",
            "Epoch 6/36\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.4344\n",
            "Epoch 6: val_loss did not improve from 0.31442\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.4344 - val_accuracy: 0.8390 - val_loss: 0.3494 - learning_rate: 0.0020\n",
            "Epoch 7/36\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7793 - loss: 0.4339\n",
            "Epoch 7: val_loss improved from 0.31442 to 0.31218, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7795 - loss: 0.4337 - val_accuracy: 0.8583 - val_loss: 0.3122 - learning_rate: 0.0020\n",
            "Epoch 8/36\n",
            "\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7984 - loss: 0.4069\n",
            "Epoch 8: val_loss improved from 0.31218 to 0.30871, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7983 - loss: 0.4072 - val_accuracy: 0.8592 - val_loss: 0.3087 - learning_rate: 0.0020\n",
            "Epoch 9/36\n",
            "\u001b[1m283/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8101 - loss: 0.3866\n",
            "Epoch 9: val_loss did not improve from 0.30871\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8103 - loss: 0.3865 - val_accuracy: 0.8499 - val_loss: 0.3139 - learning_rate: 0.0020\n",
            "Epoch 10/36\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.4104\n",
            "Epoch 10: val_loss improved from 0.30871 to 0.30191, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4094 - val_accuracy: 0.8567 - val_loss: 0.3019 - learning_rate: 0.0020\n",
            "Epoch 11/36\n",
            "\u001b[1m283/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8018 - loss: 0.3941\n",
            "Epoch 11: val_loss did not improve from 0.30191\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8023 - loss: 0.3935 - val_accuracy: 0.8491 - val_loss: 0.3144 - learning_rate: 0.0020\n",
            "Epoch 12/36\n",
            "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.3830\n",
            "Epoch 12: val_loss did not improve from 0.30191\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8109 - loss: 0.3829 - val_accuracy: 0.8406 - val_loss: 0.3607 - learning_rate: 0.0020\n",
            "Epoch 13/36\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8207 - loss: 0.3653\n",
            "Epoch 13: val_loss did not improve from 0.30191\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8208 - loss: 0.3653 - val_accuracy: 0.8406 - val_loss: 0.3829 - learning_rate: 0.0020\n",
            "Epoch 14/36\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8336 - loss: 0.3496\n",
            "Epoch 14: val_loss did not improve from 0.30191\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8337 - loss: 0.3497 - val_accuracy: 0.8331 - val_loss: 0.4021 - learning_rate: 0.0020\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:55:42,685] Trial 15 finished with value: -0.30190813541412354 and parameters: {'epochs': 36, 'batch_size': 16, 'learning_rate': 0.001992519257104267, 'stop_patience': 4, 'reduce_lr_factor': 0.4348297912674576, 'reduce_lr_patience': 5}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/46\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5608 - loss: 0.6877\n",
            "Epoch 1: val_loss improved from inf to 0.61967, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5608 - loss: 0.6874 - val_accuracy: 0.5801 - val_loss: 0.6197 - learning_rate: 0.0061\n",
            "Epoch 2/46\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6041 - loss: 0.6442\n",
            "Epoch 2: val_loss improved from 0.61967 to 0.48318, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6045 - loss: 0.6439 - val_accuracy: 0.8196 - val_loss: 0.4832 - learning_rate: 0.0061\n",
            "Epoch 3/46\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6816 - loss: 0.5838\n",
            "Epoch 3: val_loss did not improve from 0.48318\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6815 - loss: 0.5836 - val_accuracy: 0.5776 - val_loss: 0.8587 - learning_rate: 0.0061\n",
            "Epoch 4/46\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7214 - loss: 0.5298\n",
            "Epoch 4: val_loss improved from 0.48318 to 0.33671, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7217 - loss: 0.5292 - val_accuracy: 0.8474 - val_loss: 0.3367 - learning_rate: 0.0061\n",
            "Epoch 5/46\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7505 - loss: 0.4902\n",
            "Epoch 5: val_loss did not improve from 0.33671\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7505 - loss: 0.4897 - val_accuracy: 0.8398 - val_loss: 0.3421 - learning_rate: 0.0061\n",
            "Epoch 6/46\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7609 - loss: 0.4625\n",
            "Epoch 6: val_loss did not improve from 0.33671\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7606 - loss: 0.4629 - val_accuracy: 0.8398 - val_loss: 0.3441 - learning_rate: 0.0061\n",
            "Epoch 7/46\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7660 - loss: 0.4566\n",
            "Epoch 7: val_loss did not improve from 0.33671\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7670 - loss: 0.4558 - val_accuracy: 0.8145 - val_loss: 0.4015 - learning_rate: 0.0061\n",
            "Epoch 8/46\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7669 - loss: 0.4537\n",
            "Epoch 8: val_loss improved from 0.33671 to 0.32479, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7671 - loss: 0.4535 - val_accuracy: 0.8465 - val_loss: 0.3248 - learning_rate: 0.0061\n",
            "Epoch 9/46\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7939 - loss: 0.4268\n",
            "Epoch 9: val_loss improved from 0.32479 to 0.31889, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7940 - loss: 0.4266 - val_accuracy: 0.8541 - val_loss: 0.3189 - learning_rate: 0.0061\n",
            "Epoch 10/46\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7769 - loss: 0.4283\n",
            "Epoch 10: val_loss did not improve from 0.31889\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 0.4277 - val_accuracy: 0.8398 - val_loss: 0.3377 - learning_rate: 0.0061\n",
            "Epoch 11/46\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7850 - loss: 0.4243\n",
            "Epoch 11: val_loss did not improve from 0.31889\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7856 - loss: 0.4236 - val_accuracy: 0.8196 - val_loss: 0.4312 - learning_rate: 0.0061\n",
            "Epoch 12/46\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7747 - loss: 0.4302\n",
            "Epoch 12: val_loss did not improve from 0.31889\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7757 - loss: 0.4293 - val_accuracy: 0.8010 - val_loss: 0.5318 - learning_rate: 0.0061\n",
            "Epoch 13/46\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7892 - loss: 0.4298\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0015391477659361496.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.31889\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7896 - loss: 0.4289 - val_accuracy: 0.7799 - val_loss: 0.6021 - learning_rate: 0.0061\n",
            "Epoch 14/46\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.3452\n",
            "Epoch 14: val_loss did not improve from 0.31889\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8471 - loss: 0.3452 - val_accuracy: 0.8381 - val_loss: 0.5163 - learning_rate: 0.0015\n",
            "Epoch 15/46\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8506 - loss: 0.3348\n",
            "Epoch 15: val_loss did not improve from 0.31889\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8508 - loss: 0.3346 - val_accuracy: 0.8179 - val_loss: 0.5904 - learning_rate: 0.0015\n",
            "Epoch 16/46\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8569 - loss: 0.3161\n",
            "Epoch 16: val_loss did not improve from 0.31889\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.3161 - val_accuracy: 0.8069 - val_loss: 0.7341 - learning_rate: 0.0015\n",
            "Epoch 17/46\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8703 - loss: 0.3183\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0003906952217171745.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.31889\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8699 - loss: 0.3182 - val_accuracy: 0.8128 - val_loss: 0.7326 - learning_rate: 0.0015\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:56:05,228] Trial 16 finished with value: -0.31888577342033386 and parameters: {'epochs': 46, 'batch_size': 32, 'learning_rate': 0.006063488354246374, 'stop_patience': 8, 'reduce_lr_factor': 0.25383866294809765, 'reduce_lr_patience': 4}. Best is trial 1 with value: -0.2961065471172333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/37\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5535 - loss: 0.6889\n",
            "Epoch 1: val_loss improved from inf to 0.64387, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5535 - loss: 0.6888 - val_accuracy: 0.5818 - val_loss: 0.6439 - learning_rate: 0.0031\n",
            "Epoch 2/37\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5938 - loss: 0.6415\n",
            "Epoch 2: val_loss improved from 0.64387 to 0.43093, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5946 - loss: 0.6411 - val_accuracy: 0.8052 - val_loss: 0.4309 - learning_rate: 0.0031\n",
            "Epoch 3/37\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6763 - loss: 0.5685\n",
            "Epoch 3: val_loss improved from 0.43093 to 0.34811, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6771 - loss: 0.5679 - val_accuracy: 0.8457 - val_loss: 0.3481 - learning_rate: 0.0031\n",
            "Epoch 4/37\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7365 - loss: 0.5035\n",
            "Epoch 4: val_loss did not improve from 0.34811\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7366 - loss: 0.5034 - val_accuracy: 0.8516 - val_loss: 0.3659 - learning_rate: 0.0031\n",
            "Epoch 5/37\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7594 - loss: 0.4651\n",
            "Epoch 5: val_loss improved from 0.34811 to 0.30166, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7594 - loss: 0.4650 - val_accuracy: 0.8583 - val_loss: 0.3017 - learning_rate: 0.0031\n",
            "Epoch 6/37\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7732 - loss: 0.4416\n",
            "Epoch 6: val_loss did not improve from 0.30166\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7735 - loss: 0.4411 - val_accuracy: 0.8390 - val_loss: 0.3647 - learning_rate: 0.0031\n",
            "Epoch 7/37\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7844 - loss: 0.4193\n",
            "Epoch 7: val_loss did not improve from 0.30166\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7846 - loss: 0.4192 - val_accuracy: 0.8575 - val_loss: 0.3113 - learning_rate: 0.0031\n",
            "Epoch 8/37\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7798 - loss: 0.4341\n",
            "Epoch 8: val_loss improved from 0.30166 to 0.30006, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7799 - loss: 0.4340 - val_accuracy: 0.8634 - val_loss: 0.3001 - learning_rate: 0.0031\n",
            "Epoch 9/37\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.4134\n",
            "Epoch 9: val_loss did not improve from 0.30006\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7986 - loss: 0.4131 - val_accuracy: 0.8752 - val_loss: 0.3092 - learning_rate: 0.0031\n",
            "Epoch 10/37\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7977 - loss: 0.4201\n",
            "Epoch 10: val_loss did not improve from 0.30006\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7976 - loss: 0.4197 - val_accuracy: 0.8524 - val_loss: 0.3057 - learning_rate: 0.0031\n",
            "Epoch 11/37\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8022 - loss: 0.4074\n",
            "Epoch 11: val_loss improved from 0.30006 to 0.29738, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8023 - loss: 0.4074 - val_accuracy: 0.8744 - val_loss: 0.2974 - learning_rate: 0.0031\n",
            "Epoch 12/37\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8058 - loss: 0.3974\n",
            "Epoch 12: val_loss did not improve from 0.29738\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8059 - loss: 0.3973 - val_accuracy: 0.8676 - val_loss: 0.3857 - learning_rate: 0.0031\n",
            "Epoch 13/37\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8053 - loss: 0.3970\n",
            "Epoch 13: val_loss improved from 0.29738 to 0.29266, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8056 - loss: 0.3966 - val_accuracy: 0.8744 - val_loss: 0.2927 - learning_rate: 0.0031\n",
            "Epoch 14/37\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8015 - loss: 0.4017\n",
            "Epoch 14: val_loss did not improve from 0.29266\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.4017 - val_accuracy: 0.8668 - val_loss: 0.3165 - learning_rate: 0.0031\n",
            "Epoch 15/37\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.3793\n",
            "Epoch 15: val_loss did not improve from 0.29266\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8103 - loss: 0.3793 - val_accuracy: 0.8693 - val_loss: 0.3114 - learning_rate: 0.0031\n",
            "Epoch 16/37\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8145 - loss: 0.3688\n",
            "Epoch 16: val_loss improved from 0.29266 to 0.28911, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8146 - loss: 0.3688 - val_accuracy: 0.8685 - val_loss: 0.2891 - learning_rate: 0.0031\n",
            "Epoch 17/37\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8069 - loss: 0.3768\n",
            "Epoch 17: val_loss did not improve from 0.28911\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8071 - loss: 0.3767 - val_accuracy: 0.8592 - val_loss: 0.3138 - learning_rate: 0.0031\n",
            "Epoch 18/37\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8180 - loss: 0.3737\n",
            "Epoch 18: val_loss did not improve from 0.28911\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8185 - loss: 0.3732 - val_accuracy: 0.8769 - val_loss: 0.2914 - learning_rate: 0.0031\n",
            "Epoch 19/37\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8179 - loss: 0.3761\n",
            "Epoch 19: val_loss improved from 0.28911 to 0.28150, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8180 - loss: 0.3760 - val_accuracy: 0.8744 - val_loss: 0.2815 - learning_rate: 0.0031\n",
            "Epoch 20/37\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8162 - loss: 0.3648\n",
            "Epoch 20: val_loss did not improve from 0.28150\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8168 - loss: 0.3645 - val_accuracy: 0.8794 - val_loss: 0.2850 - learning_rate: 0.0031\n",
            "Epoch 21/37\n",
            "\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8215 - loss: 0.3738\n",
            "Epoch 21: val_loss improved from 0.28150 to 0.28107, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8220 - loss: 0.3730 - val_accuracy: 0.8752 - val_loss: 0.2811 - learning_rate: 0.0031\n",
            "Epoch 22/37\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8173 - loss: 0.3822\n",
            "Epoch 22: val_loss did not improve from 0.28107\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8177 - loss: 0.3817 - val_accuracy: 0.8541 - val_loss: 0.3119 - learning_rate: 0.0031\n",
            "Epoch 23/37\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8251 - loss: 0.3687\n",
            "Epoch 23: val_loss did not improve from 0.28107\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8253 - loss: 0.3683 - val_accuracy: 0.8761 - val_loss: 0.2830 - learning_rate: 0.0031\n",
            "Epoch 24/37\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8294 - loss: 0.3636\n",
            "Epoch 24: val_loss did not improve from 0.28107\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8295 - loss: 0.3634 - val_accuracy: 0.8685 - val_loss: 0.2885 - learning_rate: 0.0031\n",
            "Epoch 25/37\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.3463\n",
            "Epoch 25: val_loss did not improve from 0.28107\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8398 - loss: 0.3462 - val_accuracy: 0.8735 - val_loss: 0.3082 - learning_rate: 0.0031\n",
            "Epoch 26/37\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8260 - loss: 0.3620\n",
            "Epoch 26: val_loss improved from 0.28107 to 0.28009, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8263 - loss: 0.3616 - val_accuracy: 0.8786 - val_loss: 0.2801 - learning_rate: 0.0031\n",
            "Epoch 27/37\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8364 - loss: 0.3544\n",
            "Epoch 27: val_loss did not improve from 0.28009\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8366 - loss: 0.3541 - val_accuracy: 0.8803 - val_loss: 0.2867 - learning_rate: 0.0031\n",
            "Epoch 28/37\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8318 - loss: 0.3519\n",
            "Epoch 28: val_loss did not improve from 0.28009\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8320 - loss: 0.3518 - val_accuracy: 0.8693 - val_loss: 0.2966 - learning_rate: 0.0031\n",
            "Epoch 29/37\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8311 - loss: 0.3494\n",
            "Epoch 29: val_loss did not improve from 0.28009\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8312 - loss: 0.3493 - val_accuracy: 0.8777 - val_loss: 0.2849 - learning_rate: 0.0031\n",
            "Epoch 30/37\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8401 - loss: 0.3288\n",
            "Epoch 30: val_loss did not improve from 0.28009\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8402 - loss: 0.3286 - val_accuracy: 0.8786 - val_loss: 0.3019 - learning_rate: 0.0031\n",
            "Epoch 31/37\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8332 - loss: 0.3390\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005283109568708786.\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.28009\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8335 - loss: 0.3388 - val_accuracy: 0.8735 - val_loss: 0.2829 - learning_rate: 0.0031\n",
            "Epoch 31: early stopping\n",
            "Restoring model weights from the end of the best epoch: 26.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:57:11,396] Trial 17 finished with value: -0.2800886034965515 and parameters: {'epochs': 37, 'batch_size': 16, 'learning_rate': 0.003141698145764422, 'stop_patience': 5, 'reduce_lr_factor': 0.16816095122299263, 'reduce_lr_patience': 5}. Best is trial 17 with value: -0.2800886034965515.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5637 - loss: 0.6883\n",
            "Epoch 1: val_loss improved from inf to 0.58366, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5637 - loss: 0.6881 - val_accuracy: 0.6239 - val_loss: 0.5837 - learning_rate: 0.0031\n",
            "Epoch 2/30\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5903 - loss: 0.6698\n",
            "Epoch 2: val_loss improved from 0.58366 to 0.47465, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5910 - loss: 0.6691 - val_accuracy: 0.7681 - val_loss: 0.4746 - learning_rate: 0.0031\n",
            "Epoch 3/30\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6903 - loss: 0.5655\n",
            "Epoch 3: val_loss improved from 0.47465 to 0.43939, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6903 - loss: 0.5655 - val_accuracy: 0.8196 - val_loss: 0.4394 - learning_rate: 0.0031\n",
            "Epoch 4/30\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7232 - loss: 0.5220\n",
            "Epoch 4: val_loss improved from 0.43939 to 0.37156, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7233 - loss: 0.5219 - val_accuracy: 0.8356 - val_loss: 0.3716 - learning_rate: 0.0031\n",
            "Epoch 5/30\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7550 - loss: 0.4793\n",
            "Epoch 5: val_loss did not improve from 0.37156\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7552 - loss: 0.4790 - val_accuracy: 0.8002 - val_loss: 0.4376 - learning_rate: 0.0031\n",
            "Epoch 6/30\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7726 - loss: 0.4598\n",
            "Epoch 6: val_loss did not improve from 0.37156\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7726 - loss: 0.4597 - val_accuracy: 0.8221 - val_loss: 0.3803 - learning_rate: 0.0031\n",
            "Epoch 7/30\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7779 - loss: 0.4382\n",
            "Epoch 7: val_loss did not improve from 0.37156\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7782 - loss: 0.4379 - val_accuracy: 0.7639 - val_loss: 0.4774 - learning_rate: 0.0031\n",
            "Epoch 8/30\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.4057\n",
            "Epoch 8: val_loss did not improve from 0.37156\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8064 - loss: 0.4058 - val_accuracy: 0.7673 - val_loss: 0.5862 - learning_rate: 0.0031\n",
            "Epoch 9/30\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8072 - loss: 0.4022\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005002037273908632.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.37156\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8072 - loss: 0.4022 - val_accuracy: 0.7816 - val_loss: 0.7096 - learning_rate: 0.0031\n",
            "Epoch 9: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:57:33,023] Trial 18 finished with value: -0.37156176567077637 and parameters: {'epochs': 30, 'batch_size': 16, 'learning_rate': 0.0031455490449621166, 'stop_patience': 5, 'reduce_lr_factor': 0.1590195321906063, 'reduce_lr_patience': 5}. Best is trial 17 with value: -0.2800886034965515.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/36\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5613 - loss: 0.6849\n",
            "Epoch 1: val_loss improved from inf to 0.71565, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5613 - loss: 0.6846 - val_accuracy: 0.5978 - val_loss: 0.7156 - learning_rate: 0.0029\n",
            "Epoch 2/36\n",
            "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6028 - loss: 0.6398\n",
            "Epoch 2: val_loss improved from 0.71565 to 0.45911, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6031 - loss: 0.6396 - val_accuracy: 0.8035 - val_loss: 0.4591 - learning_rate: 0.0029\n",
            "Epoch 3/36\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6971 - loss: 0.5610\n",
            "Epoch 3: val_loss improved from 0.45911 to 0.38685, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6972 - loss: 0.5607 - val_accuracy: 0.8364 - val_loss: 0.3868 - learning_rate: 0.0029\n",
            "Epoch 4/36\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7283 - loss: 0.5132\n",
            "Epoch 4: val_loss improved from 0.38685 to 0.37697, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7283 - loss: 0.5131 - val_accuracy: 0.8449 - val_loss: 0.3770 - learning_rate: 0.0029\n",
            "Epoch 5/36\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7745 - loss: 0.4628\n",
            "Epoch 5: val_loss improved from 0.37697 to 0.35332, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7744 - loss: 0.4628 - val_accuracy: 0.8398 - val_loss: 0.3533 - learning_rate: 0.0029\n",
            "Epoch 6/36\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7775 - loss: 0.4376\n",
            "Epoch 6: val_loss improved from 0.35332 to 0.32760, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7774 - loss: 0.4378 - val_accuracy: 0.8516 - val_loss: 0.3276 - learning_rate: 0.0029\n",
            "Epoch 7/36\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7726 - loss: 0.4696\n",
            "Epoch 7: val_loss did not improve from 0.32760\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7727 - loss: 0.4692 - val_accuracy: 0.8415 - val_loss: 0.3744 - learning_rate: 0.0029\n",
            "Epoch 8/36\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7854 - loss: 0.4204\n",
            "Epoch 8: val_loss did not improve from 0.32760\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7854 - loss: 0.4204 - val_accuracy: 0.8423 - val_loss: 0.3330 - learning_rate: 0.0029\n",
            "Epoch 9/36\n",
            "\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7710 - loss: 0.4355\n",
            "Epoch 9: val_loss did not improve from 0.32760\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7717 - loss: 0.4352 - val_accuracy: 0.8305 - val_loss: 0.3604 - learning_rate: 0.0029\n",
            "Epoch 10/36\n",
            "\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8087 - loss: 0.4155\n",
            "Epoch 10: val_loss improved from 0.32760 to 0.32026, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.4152 - val_accuracy: 0.8626 - val_loss: 0.3203 - learning_rate: 0.0029\n",
            "Epoch 11/36\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7861 - loss: 0.4307\n",
            "Epoch 11: val_loss did not improve from 0.32026\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7865 - loss: 0.4304 - val_accuracy: 0.8347 - val_loss: 0.3604 - learning_rate: 0.0029\n",
            "Epoch 12/36\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8062 - loss: 0.3875\n",
            "Epoch 12: val_loss did not improve from 0.32026\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8062 - loss: 0.3877 - val_accuracy: 0.7909 - val_loss: 0.4320 - learning_rate: 0.0029\n",
            "Epoch 13/36\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8198 - loss: 0.3809\n",
            "Epoch 13: val_loss did not improve from 0.32026\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8199 - loss: 0.3809 - val_accuracy: 0.8255 - val_loss: 0.4851 - learning_rate: 0.0029\n",
            "Epoch 14/36\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8177 - loss: 0.3903\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.000549185228959875.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.32026\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8178 - loss: 0.3902 - val_accuracy: 0.8322 - val_loss: 0.4772 - learning_rate: 0.0029\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:58:04,766] Trial 19 finished with value: -0.3202648162841797 and parameters: {'epochs': 36, 'batch_size': 16, 'learning_rate': 0.0029233878598301528, 'stop_patience': 4, 'reduce_lr_factor': 0.18785917787589418, 'reduce_lr_patience': 4}. Best is trial 17 with value: -0.2800886034965515.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/39\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5662 - loss: 0.6891\n",
            "Epoch 1: val_loss improved from inf to 0.68435, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5658 - loss: 0.6891 - val_accuracy: 0.5691 - val_loss: 0.6843 - learning_rate: 0.0044\n",
            "Epoch 2/39\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5745 - loss: 0.6674\n",
            "Epoch 2: val_loss did not improve from 0.68435\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5747 - loss: 0.6670 - val_accuracy: 0.4865 - val_loss: 0.6947 - learning_rate: 0.0044\n",
            "Epoch 3/39\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6389 - loss: 0.6024\n",
            "Epoch 3: val_loss improved from 0.68435 to 0.40418, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6398 - loss: 0.6018 - val_accuracy: 0.8153 - val_loss: 0.4042 - learning_rate: 0.0044\n",
            "Epoch 4/39\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6971 - loss: 0.5451\n",
            "Epoch 4: val_loss improved from 0.40418 to 0.36396, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6976 - loss: 0.5446 - val_accuracy: 0.8398 - val_loss: 0.3640 - learning_rate: 0.0044\n",
            "Epoch 5/39\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7451 - loss: 0.4896\n",
            "Epoch 5: val_loss did not improve from 0.36396\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7450 - loss: 0.4895 - val_accuracy: 0.8052 - val_loss: 0.5228 - learning_rate: 0.0044\n",
            "Epoch 6/39\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7666 - loss: 0.4552\n",
            "Epoch 6: val_loss did not improve from 0.36396\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7666 - loss: 0.4552 - val_accuracy: 0.8010 - val_loss: 0.4559 - learning_rate: 0.0044\n",
            "Epoch 7/39\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7752 - loss: 0.4445\n",
            "Epoch 7: val_loss improved from 0.36396 to 0.35695, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7753 - loss: 0.4445 - val_accuracy: 0.8432 - val_loss: 0.3570 - learning_rate: 0.0044\n",
            "Epoch 8/39\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.4158\n",
            "Epoch 8: val_loss improved from 0.35695 to 0.30566, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7937 - loss: 0.4157 - val_accuracy: 0.8516 - val_loss: 0.3057 - learning_rate: 0.0044\n",
            "Epoch 9/39\n",
            "\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7847 - loss: 0.4253\n",
            "Epoch 9: val_loss improved from 0.30566 to 0.30067, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4249 - val_accuracy: 0.8642 - val_loss: 0.3007 - learning_rate: 0.0044\n",
            "Epoch 10/39\n",
            "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.3886\n",
            "Epoch 10: val_loss did not improve from 0.30067\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.3886 - val_accuracy: 0.8204 - val_loss: 0.4445 - learning_rate: 0.0044\n",
            "Epoch 11/39\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.3824\n",
            "Epoch 11: val_loss did not improve from 0.30067\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8188 - loss: 0.3826 - val_accuracy: 0.8583 - val_loss: 0.3100 - learning_rate: 0.0044\n",
            "Epoch 12/39\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8045 - loss: 0.3993\n",
            "Epoch 12: val_loss did not improve from 0.30067\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8046 - loss: 0.3992 - val_accuracy: 0.8516 - val_loss: 0.3443 - learning_rate: 0.0044\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:58:34,015] Trial 20 finished with value: -0.300666868686676 and parameters: {'epochs': 39, 'batch_size': 16, 'learning_rate': 0.004401868276883011, 'stop_patience': 3, 'reduce_lr_factor': 0.1144473797040462, 'reduce_lr_patience': 5}. Best is trial 17 with value: -0.2800886034965515.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/46\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5568 - loss: 0.6867\n",
            "Epoch 1: val_loss improved from inf to 0.54288, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5570 - loss: 0.6865 - val_accuracy: 0.7673 - val_loss: 0.5429 - learning_rate: 0.0012\n",
            "Epoch 2/46\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6288 - loss: 0.6293\n",
            "Epoch 2: val_loss improved from 0.54288 to 0.45540, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6298 - loss: 0.6283 - val_accuracy: 0.7757 - val_loss: 0.4554 - learning_rate: 0.0012\n",
            "Epoch 3/46\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7261 - loss: 0.5240\n",
            "Epoch 3: val_loss did not improve from 0.45540\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7261 - loss: 0.5239 - val_accuracy: 0.7791 - val_loss: 0.4753 - learning_rate: 0.0012\n",
            "Epoch 4/46\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7615 - loss: 0.4641\n",
            "Epoch 4: val_loss improved from 0.45540 to 0.32478, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7616 - loss: 0.4641 - val_accuracy: 0.8541 - val_loss: 0.3248 - learning_rate: 0.0012\n",
            "Epoch 5/46\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7711 - loss: 0.4432\n",
            "Epoch 5: val_loss improved from 0.32478 to 0.31199, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4431 - val_accuracy: 0.8676 - val_loss: 0.3120 - learning_rate: 0.0012\n",
            "Epoch 6/46\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7785 - loss: 0.4306\n",
            "Epoch 6: val_loss did not improve from 0.31199\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7786 - loss: 0.4306 - val_accuracy: 0.7968 - val_loss: 0.4378 - learning_rate: 0.0012\n",
            "Epoch 7/46\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7799 - loss: 0.4310\n",
            "Epoch 7: val_loss did not improve from 0.31199\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7803 - loss: 0.4305 - val_accuracy: 0.8499 - val_loss: 0.3240 - learning_rate: 0.0012\n",
            "Epoch 8/46\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 0.4130\n",
            "Epoch 8: val_loss did not improve from 0.31199\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7840 - loss: 0.4129 - val_accuracy: 0.8575 - val_loss: 0.3173 - learning_rate: 0.0012\n",
            "Epoch 9/46\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.3953\n",
            "Epoch 9: val_loss improved from 0.31199 to 0.30307, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8050 - loss: 0.3953 - val_accuracy: 0.8617 - val_loss: 0.3031 - learning_rate: 0.0012\n",
            "Epoch 10/46\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8044 - loss: 0.3851\n",
            "Epoch 10: val_loss did not improve from 0.30307\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8045 - loss: 0.3852 - val_accuracy: 0.8524 - val_loss: 0.3421 - learning_rate: 0.0012\n",
            "Epoch 11/46\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.3904\n",
            "Epoch 11: val_loss did not improve from 0.30307\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8056 - loss: 0.3904 - val_accuracy: 0.8212 - val_loss: 0.4049 - learning_rate: 0.0012\n",
            "Epoch 12/46\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8012 - loss: 0.3970\n",
            "Epoch 12: val_loss did not improve from 0.30307\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8014 - loss: 0.3967 - val_accuracy: 0.8297 - val_loss: 0.3613 - learning_rate: 0.0012\n",
            "Epoch 13/46\n",
            "\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8128 - loss: 0.3736\n",
            "Epoch 13: val_loss did not improve from 0.30307\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8135 - loss: 0.3733 - val_accuracy: 0.8390 - val_loss: 0.3273 - learning_rate: 0.0012\n",
            "Epoch 14/46\n",
            "\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7985 - loss: 0.3849\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00045358131826418475.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.30307\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7994 - loss: 0.3840 - val_accuracy: 0.8449 - val_loss: 0.3369 - learning_rate: 0.0012\n",
            "Epoch 15/46\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8383 - loss: 0.3366\n",
            "Epoch 15: val_loss did not improve from 0.30307\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 0.3364 - val_accuracy: 0.8508 - val_loss: 0.3559 - learning_rate: 4.5358e-04\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:59:09,164] Trial 21 finished with value: -0.30307063460350037 and parameters: {'epochs': 46, 'batch_size': 16, 'learning_rate': 0.0012438242403280584, 'stop_patience': 6, 'reduce_lr_factor': 0.3646667253856996, 'reduce_lr_patience': 5}. Best is trial 17 with value: -0.2800886034965515.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5470 - loss: 0.6900\n",
            "Epoch 1: val_loss improved from inf to 0.66356, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5472 - loss: 0.6899 - val_accuracy: 0.5700 - val_loss: 0.6636 - learning_rate: 0.0061\n",
            "Epoch 2/45\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5584 - loss: 0.6679\n",
            "Epoch 2: val_loss did not improve from 0.66356\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5599 - loss: 0.6671 - val_accuracy: 0.6602 - val_loss: 0.6839 - learning_rate: 0.0061\n",
            "Epoch 3/45\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6191 - loss: 0.6272\n",
            "Epoch 3: val_loss improved from 0.66356 to 0.41059, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6202 - loss: 0.6261 - val_accuracy: 0.8263 - val_loss: 0.4106 - learning_rate: 0.0061\n",
            "Epoch 4/45\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7186 - loss: 0.5357\n",
            "Epoch 4: val_loss did not improve from 0.41059\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7197 - loss: 0.5339 - val_accuracy: 0.7386 - val_loss: 0.4719 - learning_rate: 0.0061\n",
            "Epoch 5/45\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7316 - loss: 0.4928\n",
            "Epoch 5: val_loss did not improve from 0.41059\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7320 - loss: 0.4923 - val_accuracy: 0.6990 - val_loss: 0.5735 - learning_rate: 0.0061\n",
            "Epoch 6/45\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7704 - loss: 0.4551\n",
            "Epoch 6: val_loss improved from 0.41059 to 0.34081, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7707 - loss: 0.4549 - val_accuracy: 0.8449 - val_loss: 0.3408 - learning_rate: 0.0061\n",
            "Epoch 7/45\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7734 - loss: 0.4505\n",
            "Epoch 7: val_loss did not improve from 0.34081\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7735 - loss: 0.4504 - val_accuracy: 0.7774 - val_loss: 0.4692 - learning_rate: 0.0061\n",
            "Epoch 8/45\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7855 - loss: 0.4274\n",
            "Epoch 8: val_loss did not improve from 0.34081\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7857 - loss: 0.4272 - val_accuracy: 0.8094 - val_loss: 0.3964 - learning_rate: 0.0061\n",
            "Epoch 9/45\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.4497\n",
            "Epoch 9: val_loss improved from 0.34081 to 0.33693, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7762 - loss: 0.4490 - val_accuracy: 0.8457 - val_loss: 0.3369 - learning_rate: 0.0061\n",
            "Epoch 10/45\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7884 - loss: 0.4089\n",
            "Epoch 10: val_loss improved from 0.33693 to 0.33294, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7896 - loss: 0.4080 - val_accuracy: 0.8364 - val_loss: 0.3329 - learning_rate: 0.0061\n",
            "Epoch 11/45\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8022 - loss: 0.4017\n",
            "Epoch 11: val_loss did not improve from 0.33294\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8025 - loss: 0.4016 - val_accuracy: 0.8212 - val_loss: 0.4057 - learning_rate: 0.0061\n",
            "Epoch 12/45\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8178 - loss: 0.3854\n",
            "Epoch 12: val_loss did not improve from 0.33294\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8178 - loss: 0.3855 - val_accuracy: 0.6594 - val_loss: 0.6512 - learning_rate: 0.0061\n",
            "Epoch 13/45\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8103 - loss: 0.3919\n",
            "Epoch 13: val_loss did not improve from 0.33294\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8111 - loss: 0.3912 - val_accuracy: 0.7850 - val_loss: 0.8037 - learning_rate: 0.0061\n",
            "Epoch 14/45\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8122 - loss: 0.3938\n",
            "Epoch 14: val_loss did not improve from 0.33294\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8126 - loss: 0.3933 - val_accuracy: 0.7993 - val_loss: 0.4951 - learning_rate: 0.0061\n",
            "Epoch 15/45\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8235 - loss: 0.3860\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0027276071615737543.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.33294\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8235 - loss: 0.3859 - val_accuracy: 0.7715 - val_loss: 0.7104 - learning_rate: 0.0061\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:59:27,969] Trial 22 finished with value: -0.3329354524612427 and parameters: {'epochs': 45, 'batch_size': 32, 'learning_rate': 0.006096841576034697, 'stop_patience': 5, 'reduce_lr_factor': 0.4473803430728341, 'reduce_lr_patience': 5}. Best is trial 17 with value: -0.2800886034965515.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/38\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5636 - loss: 0.6904\n",
            "Epoch 1: val_loss improved from inf to 0.66980, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5632 - loss: 0.6902 - val_accuracy: 0.5801 - val_loss: 0.6698 - learning_rate: 7.4342e-05\n",
            "Epoch 2/38\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5714 - loss: 0.6863\n",
            "Epoch 2: val_loss improved from 0.66980 to 0.66030, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5711 - loss: 0.6863 - val_accuracy: 0.5801 - val_loss: 0.6603 - learning_rate: 7.4342e-05\n",
            "Epoch 3/38\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5750 - loss: 0.6819\n",
            "Epoch 3: val_loss improved from 0.66030 to 0.65475, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5747 - loss: 0.6819 - val_accuracy: 0.5919 - val_loss: 0.6547 - learning_rate: 7.4342e-05\n",
            "Epoch 4/38\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5752 - loss: 0.6777\n",
            "Epoch 4: val_loss improved from 0.65475 to 0.64157, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5748 - loss: 0.6777 - val_accuracy: 0.6509 - val_loss: 0.6416 - learning_rate: 7.4342e-05\n",
            "Epoch 5/38\n",
            "\u001b[1m64/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5870 - loss: 0.6730\n",
            "Epoch 5: val_loss improved from 0.64157 to 0.63629, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5853 - loss: 0.6729 - val_accuracy: 0.7521 - val_loss: 0.6363 - learning_rate: 7.4342e-05\n",
            "Epoch 6/38\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6040 - loss: 0.6652\n",
            "Epoch 6: val_loss improved from 0.63629 to 0.62455, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6025 - loss: 0.6651 - val_accuracy: 0.7673 - val_loss: 0.6245 - learning_rate: 7.4342e-05\n",
            "Epoch 7/38\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6093 - loss: 0.6559\n",
            "Epoch 7: val_loss improved from 0.62455 to 0.62335, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6091 - loss: 0.6559 - val_accuracy: 0.7209 - val_loss: 0.6234 - learning_rate: 7.4342e-05\n",
            "Epoch 8/38\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6224 - loss: 0.6474\n",
            "Epoch 8: val_loss did not improve from 0.62335\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6222 - loss: 0.6473 - val_accuracy: 0.6931 - val_loss: 0.6235 - learning_rate: 7.4342e-05\n",
            "Epoch 9/38\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6426 - loss: 0.6346\n",
            "Epoch 9: val_loss improved from 0.62335 to 0.58002, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6422 - loss: 0.6345 - val_accuracy: 0.7437 - val_loss: 0.5800 - learning_rate: 7.4342e-05\n",
            "Epoch 10/38\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6587 - loss: 0.6168\n",
            "Epoch 10: val_loss improved from 0.58002 to 0.51631, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6589 - loss: 0.6166 - val_accuracy: 0.7909 - val_loss: 0.5163 - learning_rate: 7.4342e-05\n",
            "Epoch 11/38\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6789 - loss: 0.6010\n",
            "Epoch 11: val_loss did not improve from 0.51631\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6791 - loss: 0.6008 - val_accuracy: 0.7774 - val_loss: 0.5204 - learning_rate: 7.4342e-05\n",
            "Epoch 12/38\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7041 - loss: 0.5842\n",
            "Epoch 12: val_loss improved from 0.51631 to 0.50110, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7042 - loss: 0.5841 - val_accuracy: 0.7825 - val_loss: 0.5011 - learning_rate: 7.4342e-05\n",
            "Epoch 13/38\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7154 - loss: 0.5691\n",
            "Epoch 13: val_loss improved from 0.50110 to 0.47206, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7153 - loss: 0.5690 - val_accuracy: 0.7901 - val_loss: 0.4721 - learning_rate: 7.4342e-05\n",
            "Epoch 14/38\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7161 - loss: 0.5585\n",
            "Epoch 14: val_loss did not improve from 0.47206\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7164 - loss: 0.5583 - val_accuracy: 0.7901 - val_loss: 0.4819 - learning_rate: 7.4342e-05\n",
            "Epoch 15/38\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7440 - loss: 0.5375\n",
            "Epoch 15: val_loss improved from 0.47206 to 0.46273, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7439 - loss: 0.5375 - val_accuracy: 0.8019 - val_loss: 0.4627 - learning_rate: 7.4342e-05\n",
            "Epoch 16/38\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7524 - loss: 0.5244\n",
            "Epoch 16: val_loss did not improve from 0.46273\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7522 - loss: 0.5245 - val_accuracy: 0.7917 - val_loss: 0.4822 - learning_rate: 7.4342e-05\n",
            "Epoch 17/38\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7458 - loss: 0.5161\n",
            "Epoch 17: val_loss did not improve from 0.46273\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7458 - loss: 0.5161 - val_accuracy: 0.7985 - val_loss: 0.4666 - learning_rate: 7.4342e-05\n",
            "Epoch 18/38\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7650 - loss: 0.5040\n",
            "Epoch 18: val_loss did not improve from 0.46273\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7648 - loss: 0.5040 - val_accuracy: 0.7993 - val_loss: 0.4805 - learning_rate: 7.4342e-05\n",
            "Epoch 19/38\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7699 - loss: 0.4931\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.3521597234889636e-05.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.46273\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7697 - loss: 0.4932 - val_accuracy: 0.8019 - val_loss: 0.4857 - learning_rate: 7.4342e-05\n",
            "Epoch 20/38\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7684 - loss: 0.4892\n",
            "Epoch 20: val_loss improved from 0.46273 to 0.41609, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7686 - loss: 0.4892 - val_accuracy: 0.8145 - val_loss: 0.4161 - learning_rate: 1.3522e-05\n",
            "Epoch 21/38\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7796 - loss: 0.4825\n",
            "Epoch 21: val_loss did not improve from 0.41609\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7796 - loss: 0.4825 - val_accuracy: 0.8111 - val_loss: 0.4277 - learning_rate: 1.3522e-05\n",
            "Epoch 22/38\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7823 - loss: 0.4770\n",
            "Epoch 22: val_loss did not improve from 0.41609\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7816 - loss: 0.4776 - val_accuracy: 0.8120 - val_loss: 0.4279 - learning_rate: 1.3522e-05\n",
            "Epoch 23/38\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7774 - loss: 0.4816\n",
            "Epoch 23: val_loss did not improve from 0.41609\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7771 - loss: 0.4817 - val_accuracy: 0.8128 - val_loss: 0.4281 - learning_rate: 1.3522e-05\n",
            "Epoch 24/38\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4835\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 2.4593734957737034e-06.\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.41609\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7713 - loss: 0.4834 - val_accuracy: 0.8120 - val_loss: 0.4223 - learning_rate: 1.3522e-05\n",
            "Epoch 25/38\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7801 - loss: 0.4784\n",
            "Epoch 25: val_loss improved from 0.41609 to 0.41108, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7801 - loss: 0.4784 - val_accuracy: 0.8128 - val_loss: 0.4111 - learning_rate: 2.4594e-06\n",
            "Epoch 26/38\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7805 - loss: 0.4788\n",
            "Epoch 26: val_loss improved from 0.41108 to 0.40900, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7804 - loss: 0.4788 - val_accuracy: 0.8145 - val_loss: 0.4090 - learning_rate: 2.4594e-06\n",
            "Epoch 27/38\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7721 - loss: 0.4808\n",
            "Epoch 27: val_loss did not improve from 0.40900\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7723 - loss: 0.4809 - val_accuracy: 0.8128 - val_loss: 0.4110 - learning_rate: 2.4594e-06\n",
            "Epoch 28/38\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7846 - loss: 0.4747\n",
            "Epoch 28: val_loss did not improve from 0.40900\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7844 - loss: 0.4747 - val_accuracy: 0.8128 - val_loss: 0.4112 - learning_rate: 2.4594e-06\n",
            "Epoch 29/38\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.4705\n",
            "Epoch 29: val_loss did not improve from 0.40900\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7924 - loss: 0.4709 - val_accuracy: 0.8137 - val_loss: 0.4124 - learning_rate: 2.4594e-06\n",
            "Epoch 30/38\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7860 - loss: 0.4795\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.40900\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7853 - loss: 0.4793 - val_accuracy: 0.8145 - val_loss: 0.4100 - learning_rate: 2.4594e-06\n",
            "Epoch 31/38\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7765 - loss: 0.4786\n",
            "Epoch 31: val_loss did not improve from 0.40900\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7767 - loss: 0.4785 - val_accuracy: 0.8145 - val_loss: 0.4091 - learning_rate: 1.0000e-06\n",
            "Epoch 32/38\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7828 - loss: 0.4786\n",
            "Epoch 32: val_loss did not improve from 0.40900\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7827 - loss: 0.4786 - val_accuracy: 0.8145 - val_loss: 0.4099 - learning_rate: 1.0000e-06\n",
            "Epoch 33/38\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7780 - loss: 0.4808\n",
            "Epoch 33: val_loss did not improve from 0.40900\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7778 - loss: 0.4808 - val_accuracy: 0.8137 - val_loss: 0.4111 - learning_rate: 1.0000e-06\n",
            "Epoch 33: early stopping\n",
            "Restoring model weights from the end of the best epoch: 26.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 13:59:55,312] Trial 23 finished with value: -0.4090004563331604 and parameters: {'epochs': 38, 'batch_size': 64, 'learning_rate': 7.434153284365842e-05, 'stop_patience': 7, 'reduce_lr_factor': 0.18188484073899663, 'reduce_lr_patience': 4}. Best is trial 17 with value: -0.2800886034965515.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5674 - loss: 0.6836\n",
            "Epoch 1: val_loss improved from inf to 0.67174, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5674 - loss: 0.6834 - val_accuracy: 0.5675 - val_loss: 0.6717 - learning_rate: 0.0027\n",
            "Epoch 2/50\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6204 - loss: 0.6253\n",
            "Epoch 2: val_loss improved from 0.67174 to 0.40421, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6215 - loss: 0.6245 - val_accuracy: 0.8288 - val_loss: 0.4042 - learning_rate: 0.0027\n",
            "Epoch 3/50\n",
            "\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6962 - loss: 0.5417\n",
            "Epoch 3: val_loss did not improve from 0.40421\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6973 - loss: 0.5405 - val_accuracy: 0.7976 - val_loss: 0.4336 - learning_rate: 0.0027\n",
            "Epoch 4/50\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7411 - loss: 0.4923\n",
            "Epoch 4: val_loss improved from 0.40421 to 0.34404, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7416 - loss: 0.4921 - val_accuracy: 0.8347 - val_loss: 0.3440 - learning_rate: 0.0027\n",
            "Epoch 5/50\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7517 - loss: 0.4714\n",
            "Epoch 5: val_loss did not improve from 0.34404\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7518 - loss: 0.4714 - val_accuracy: 0.8398 - val_loss: 0.3455 - learning_rate: 0.0027\n",
            "Epoch 6/50\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7630 - loss: 0.4424\n",
            "Epoch 6: val_loss did not improve from 0.34404\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7632 - loss: 0.4423 - val_accuracy: 0.8305 - val_loss: 0.3475 - learning_rate: 0.0027\n",
            "Epoch 7/50\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7681 - loss: 0.4319\n",
            "Epoch 7: val_loss improved from 0.34404 to 0.32875, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7683 - loss: 0.4319 - val_accuracy: 0.8499 - val_loss: 0.3288 - learning_rate: 0.0027\n",
            "Epoch 8/50\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7831 - loss: 0.4124\n",
            "Epoch 8: val_loss improved from 0.32875 to 0.31166, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7834 - loss: 0.4124 - val_accuracy: 0.8592 - val_loss: 0.3117 - learning_rate: 0.0027\n",
            "Epoch 9/50\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7681 - loss: 0.4188\n",
            "Epoch 9: val_loss improved from 0.31166 to 0.28367, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7687 - loss: 0.4186 - val_accuracy: 0.8769 - val_loss: 0.2837 - learning_rate: 0.0027\n",
            "Epoch 10/50\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.3952\n",
            "Epoch 10: val_loss improved from 0.28367 to 0.26838, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.3952 - val_accuracy: 0.8853 - val_loss: 0.2684 - learning_rate: 0.0027\n",
            "Epoch 11/50\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8159 - loss: 0.3720\n",
            "Epoch 11: val_loss did not improve from 0.26838\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.3720 - val_accuracy: 0.8718 - val_loss: 0.2926 - learning_rate: 0.0027\n",
            "Epoch 12/50\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8181 - loss: 0.3726\n",
            "Epoch 12: val_loss did not improve from 0.26838\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8181 - loss: 0.3727 - val_accuracy: 0.8676 - val_loss: 0.3178 - learning_rate: 0.0027\n",
            "Epoch 13/50\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8215 - loss: 0.3627\n",
            "Epoch 13: val_loss did not improve from 0.26838\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8215 - loss: 0.3628 - val_accuracy: 0.8567 - val_loss: 0.3443 - learning_rate: 0.0027\n",
            "Epoch 14/50\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8161 - loss: 0.3736\n",
            "Epoch 14: val_loss did not improve from 0.26838\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8162 - loss: 0.3736 - val_accuracy: 0.8457 - val_loss: 0.3338 - learning_rate: 0.0027\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:00:28,706] Trial 24 finished with value: -0.2683771252632141 and parameters: {'epochs': 50, 'batch_size': 16, 'learning_rate': 0.002678169468879813, 'stop_patience': 4, 'reduce_lr_factor': 0.29431686816170216, 'reduce_lr_patience': 5}. Best is trial 24 with value: -0.2683771252632141.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5626 - loss: 0.6897\n",
            "Epoch 1: val_loss improved from inf to 0.67788, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5624 - loss: 0.6896 - val_accuracy: 0.6998 - val_loss: 0.6779 - learning_rate: 0.0026\n",
            "Epoch 2/32\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5866 - loss: 0.6570\n",
            "Epoch 2: val_loss improved from 0.67788 to 0.43030, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5866 - loss: 0.6569 - val_accuracy: 0.8145 - val_loss: 0.4303 - learning_rate: 0.0026\n",
            "Epoch 3/32\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6710 - loss: 0.5930\n",
            "Epoch 3: val_loss improved from 0.43030 to 0.37815, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6711 - loss: 0.5928 - val_accuracy: 0.8364 - val_loss: 0.3782 - learning_rate: 0.0026\n",
            "Epoch 4/32\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7088 - loss: 0.5308\n",
            "Epoch 4: val_loss improved from 0.37815 to 0.33864, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7088 - loss: 0.5307 - val_accuracy: 0.8541 - val_loss: 0.3386 - learning_rate: 0.0026\n",
            "Epoch 5/32\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7570 - loss: 0.4814\n",
            "Epoch 5: val_loss improved from 0.33864 to 0.31847, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.4812 - val_accuracy: 0.8558 - val_loss: 0.3185 - learning_rate: 0.0026\n",
            "Epoch 6/32\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7767 - loss: 0.4564\n",
            "Epoch 6: val_loss did not improve from 0.31847\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7767 - loss: 0.4562 - val_accuracy: 0.8499 - val_loss: 0.3291 - learning_rate: 0.0026\n",
            "Epoch 7/32\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.4203\n",
            "Epoch 7: val_loss improved from 0.31847 to 0.29833, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7982 - loss: 0.4205 - val_accuracy: 0.8710 - val_loss: 0.2983 - learning_rate: 0.0026\n",
            "Epoch 8/32\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.4346\n",
            "Epoch 8: val_loss did not improve from 0.29833\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.4346 - val_accuracy: 0.8558 - val_loss: 0.3236 - learning_rate: 0.0026\n",
            "Epoch 9/32\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7911 - loss: 0.4150\n",
            "Epoch 9: val_loss did not improve from 0.29833\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7913 - loss: 0.4148 - val_accuracy: 0.8415 - val_loss: 0.3608 - learning_rate: 0.0026\n",
            "Epoch 10/32\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7955 - loss: 0.4300\n",
            "Epoch 10: val_loss improved from 0.29833 to 0.29257, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7955 - loss: 0.4299 - val_accuracy: 0.8769 - val_loss: 0.2926 - learning_rate: 0.0026\n",
            "Epoch 11/32\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8139 - loss: 0.3933\n",
            "Epoch 11: val_loss did not improve from 0.29257\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8138 - loss: 0.3933 - val_accuracy: 0.8626 - val_loss: 0.3030 - learning_rate: 0.0026\n",
            "Epoch 12/32\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8080 - loss: 0.3923\n",
            "Epoch 12: val_loss did not improve from 0.29257\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.3921 - val_accuracy: 0.8516 - val_loss: 0.3213 - learning_rate: 0.0026\n",
            "Epoch 13/32\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.4013\n",
            "Epoch 13: val_loss did not improve from 0.29257\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8035 - loss: 0.4012 - val_accuracy: 0.8642 - val_loss: 0.3052 - learning_rate: 0.0026\n",
            "Epoch 14/32\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8147 - loss: 0.3681\n",
            "Epoch 14: val_loss did not improve from 0.29257\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8149 - loss: 0.3680 - val_accuracy: 0.8634 - val_loss: 0.3239 - learning_rate: 0.0026\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:01:00,269] Trial 25 finished with value: -0.2925732433795929 and parameters: {'epochs': 32, 'batch_size': 16, 'learning_rate': 0.002646505434198699, 'stop_patience': 4, 'reduce_lr_factor': 0.2329787900652953, 'reduce_lr_patience': 5}. Best is trial 24 with value: -0.2683771252632141.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/28\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5622 - loss: 0.6847\n",
            "Epoch 1: val_loss improved from inf to 0.57707, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5622 - loss: 0.6846 - val_accuracy: 0.6518 - val_loss: 0.5771 - learning_rate: 0.0025\n",
            "Epoch 2/28\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6182 - loss: 0.6265\n",
            "Epoch 2: val_loss improved from 0.57707 to 0.39192, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6185 - loss: 0.6263 - val_accuracy: 0.8263 - val_loss: 0.3919 - learning_rate: 0.0025\n",
            "Epoch 3/28\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7156 - loss: 0.5307\n",
            "Epoch 3: val_loss improved from 0.39192 to 0.34801, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7158 - loss: 0.5305 - val_accuracy: 0.8322 - val_loss: 0.3480 - learning_rate: 0.0025\n",
            "Epoch 4/28\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7421 - loss: 0.4998\n",
            "Epoch 4: val_loss did not improve from 0.34801\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7422 - loss: 0.4994 - val_accuracy: 0.8246 - val_loss: 0.3904 - learning_rate: 0.0025\n",
            "Epoch 5/28\n",
            "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7637 - loss: 0.4583\n",
            "Epoch 5: val_loss improved from 0.34801 to 0.32588, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7638 - loss: 0.4583 - val_accuracy: 0.8592 - val_loss: 0.3259 - learning_rate: 0.0025\n",
            "Epoch 6/28\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7720 - loss: 0.4671\n",
            "Epoch 6: val_loss improved from 0.32588 to 0.32269, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7723 - loss: 0.4665 - val_accuracy: 0.8508 - val_loss: 0.3227 - learning_rate: 0.0025\n",
            "Epoch 7/28\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7895 - loss: 0.4337\n",
            "Epoch 7: val_loss did not improve from 0.32269\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7899 - loss: 0.4331 - val_accuracy: 0.8533 - val_loss: 0.3240 - learning_rate: 0.0025\n",
            "Epoch 8/28\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7804 - loss: 0.4314\n",
            "Epoch 8: val_loss did not improve from 0.32269\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7805 - loss: 0.4313 - val_accuracy: 0.8103 - val_loss: 0.4402 - learning_rate: 0.0025\n",
            "Epoch 9/28\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8003 - loss: 0.4167\n",
            "Epoch 9: val_loss did not improve from 0.32269\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8004 - loss: 0.4166 - val_accuracy: 0.8263 - val_loss: 0.4915 - learning_rate: 0.0025\n",
            "Epoch 10/28\n",
            "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7991 - loss: 0.4076\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005612093324013007.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.32269\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.4075 - val_accuracy: 0.8297 - val_loss: 0.4414 - learning_rate: 0.0025\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:01:23,819] Trial 26 finished with value: -0.3226897716522217 and parameters: {'epochs': 28, 'batch_size': 16, 'learning_rate': 0.002490109941441152, 'stop_patience': 4, 'reduce_lr_factor': 0.22537531800068647, 'reduce_lr_patience': 4}. Best is trial 24 with value: -0.2683771252632141.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5518 - loss: 0.6854\n",
            "Epoch 1: val_loss improved from inf to 0.53445, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5522 - loss: 0.6851 - val_accuracy: 0.7943 - val_loss: 0.5345 - learning_rate: 0.0017\n",
            "Epoch 2/26\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6066 - loss: 0.6351\n",
            "Epoch 2: val_loss improved from 0.53445 to 0.42435, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6072 - loss: 0.6347 - val_accuracy: 0.8229 - val_loss: 0.4244 - learning_rate: 0.0017\n",
            "Epoch 3/26\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7038 - loss: 0.5571\n",
            "Epoch 3: val_loss improved from 0.42435 to 0.37783, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7045 - loss: 0.5562 - val_accuracy: 0.8153 - val_loss: 0.3778 - learning_rate: 0.0017\n",
            "Epoch 4/26\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7434 - loss: 0.4866\n",
            "Epoch 4: val_loss improved from 0.37783 to 0.34515, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7433 - loss: 0.4865 - val_accuracy: 0.8432 - val_loss: 0.3451 - learning_rate: 0.0017\n",
            "Epoch 5/26\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7614 - loss: 0.4576\n",
            "Epoch 5: val_loss improved from 0.34515 to 0.32392, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7616 - loss: 0.4574 - val_accuracy: 0.8465 - val_loss: 0.3239 - learning_rate: 0.0017\n",
            "Epoch 6/26\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7773 - loss: 0.4270\n",
            "Epoch 6: val_loss improved from 0.32392 to 0.32356, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7774 - loss: 0.4270 - val_accuracy: 0.8533 - val_loss: 0.3236 - learning_rate: 0.0017\n",
            "Epoch 7/26\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7836 - loss: 0.4247\n",
            "Epoch 7: val_loss did not improve from 0.32356\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7838 - loss: 0.4245 - val_accuracy: 0.8508 - val_loss: 0.3313 - learning_rate: 0.0017\n",
            "Epoch 8/26\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7952 - loss: 0.4048\n",
            "Epoch 8: val_loss did not improve from 0.32356\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4047 - val_accuracy: 0.8170 - val_loss: 0.4085 - learning_rate: 0.0017\n",
            "Epoch 9/26\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.3893\n",
            "Epoch 9: val_loss did not improve from 0.32356\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.3894 - val_accuracy: 0.8187 - val_loss: 0.3915 - learning_rate: 0.0017\n",
            "Epoch 10/26\n",
            "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7982 - loss: 0.3983\n",
            "Epoch 10: val_loss did not improve from 0.32356\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7983 - loss: 0.3982 - val_accuracy: 0.8246 - val_loss: 0.4180 - learning_rate: 0.0017\n",
            "Epoch 11/26\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.3928\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00046119247600657294.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.32356\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8035 - loss: 0.3927 - val_accuracy: 0.8128 - val_loss: 0.4686 - learning_rate: 0.0017\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:01:50,471] Trial 27 finished with value: -0.3235626518726349 and parameters: {'epochs': 26, 'batch_size': 16, 'learning_rate': 0.0016505159632287454, 'stop_patience': 5, 'reduce_lr_factor': 0.2794232177814445, 'reduce_lr_patience': 5}. Best is trial 24 with value: -0.2683771252632141.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/33\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5666 - loss: 0.6884\n",
            "Epoch 1: val_loss improved from inf to 0.81299, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5663 - loss: 0.6883 - val_accuracy: 0.4545 - val_loss: 0.8130 - learning_rate: 0.0040\n",
            "Epoch 2/33\n",
            "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6073 - loss: 0.6419\n",
            "Epoch 2: val_loss improved from 0.81299 to 0.43230, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6075 - loss: 0.6417 - val_accuracy: 0.8111 - val_loss: 0.4323 - learning_rate: 0.0040\n",
            "Epoch 3/33\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6809 - loss: 0.5745\n",
            "Epoch 3: val_loss improved from 0.43230 to 0.37424, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6812 - loss: 0.5742 - val_accuracy: 0.8423 - val_loss: 0.3742 - learning_rate: 0.0040\n",
            "Epoch 4/33\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6830 - loss: 0.5470\n",
            "Epoch 4: val_loss improved from 0.37424 to 0.33377, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6835 - loss: 0.5467 - val_accuracy: 0.8558 - val_loss: 0.3338 - learning_rate: 0.0040\n",
            "Epoch 5/33\n",
            "\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7337 - loss: 0.5054\n",
            "Epoch 5: val_loss did not improve from 0.33377\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7344 - loss: 0.5048 - val_accuracy: 0.8415 - val_loss: 0.3642 - learning_rate: 0.0040\n",
            "Epoch 6/33\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7620 - loss: 0.4643\n",
            "Epoch 6: val_loss did not improve from 0.33377\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7617 - loss: 0.4645 - val_accuracy: 0.7395 - val_loss: 0.4511 - learning_rate: 0.0040\n",
            "Epoch 7/33\n",
            "\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7510 - loss: 0.4754\n",
            "Epoch 7: val_loss improved from 0.33377 to 0.30614, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7516 - loss: 0.4748 - val_accuracy: 0.8617 - val_loss: 0.3061 - learning_rate: 0.0040\n",
            "Epoch 8/33\n",
            "\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7686 - loss: 0.4400\n",
            "Epoch 8: val_loss did not improve from 0.30614\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7690 - loss: 0.4398 - val_accuracy: 0.8347 - val_loss: 0.3738 - learning_rate: 0.0040\n",
            "Epoch 9/33\n",
            "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7851 - loss: 0.4248\n",
            "Epoch 9: val_loss did not improve from 0.30614\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7852 - loss: 0.4247 - val_accuracy: 0.8567 - val_loss: 0.3152 - learning_rate: 0.0040\n",
            "Epoch 10/33\n",
            "\u001b[1m282/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7805 - loss: 0.4264\n",
            "Epoch 10: val_loss did not improve from 0.30614\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4259 - val_accuracy: 0.8600 - val_loss: 0.3261 - learning_rate: 0.0040\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:02:14,878] Trial 28 finished with value: -0.3061427175998688 and parameters: {'epochs': 33, 'batch_size': 16, 'learning_rate': 0.00396155724603266, 'stop_patience': 3, 'reduce_lr_factor': 0.21960292025932926, 'reduce_lr_patience': 4}. Best is trial 24 with value: -0.2683771252632141.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/33\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5669 - loss: 0.6856\n",
            "Epoch 1: val_loss improved from inf to 0.68596, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5666 - loss: 0.6853 - val_accuracy: 0.5101 - val_loss: 0.6860 - learning_rate: 0.0029\n",
            "Epoch 2/33\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5957 - loss: 0.6541\n",
            "Epoch 2: val_loss improved from 0.68596 to 0.60286, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5968 - loss: 0.6529 - val_accuracy: 0.6737 - val_loss: 0.6029 - learning_rate: 0.0029\n",
            "Epoch 3/33\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6504 - loss: 0.5927\n",
            "Epoch 3: val_loss improved from 0.60286 to 0.37634, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6513 - loss: 0.5921 - val_accuracy: 0.8153 - val_loss: 0.3763 - learning_rate: 0.0029\n",
            "Epoch 4/33\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7347 - loss: 0.5272\n",
            "Epoch 4: val_loss improved from 0.37634 to 0.35641, saving model to BEST_CNN_SEQ_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7308 - loss: 0.5306 - val_accuracy: 0.8322 - val_loss: 0.3564 - learning_rate: 0.0029\n",
            "Epoch 5/33\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7611 - loss: 0.4905\n",
            "Epoch 5: val_loss did not improve from 0.35641\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7599 - loss: 0.4902 - val_accuracy: 0.7428 - val_loss: 0.4848 - learning_rate: 0.0029\n",
            "Epoch 6/33\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7684 - loss: 0.4637\n",
            "Epoch 6: val_loss did not improve from 0.35641\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7687 - loss: 0.4632 - val_accuracy: 0.8373 - val_loss: 0.3855 - learning_rate: 0.0029\n",
            "Epoch 7/33\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7513 - loss: 0.5081\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0004220520353076953.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.35641\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7533 - loss: 0.5041 - val_accuracy: 0.8314 - val_loss: 0.3870 - learning_rate: 0.0029\n",
            "Epoch 8/33\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8224 - loss: 0.3916\n",
            "Epoch 8: val_loss did not improve from 0.35641\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8230 - loss: 0.3909 - val_accuracy: 0.8516 - val_loss: 0.3596 - learning_rate: 4.2205e-04\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:02:23,284] Trial 29 finished with value: -0.3564065098762512 and parameters: {'epochs': 33, 'batch_size': 64, 'learning_rate': 0.0028644274380458493, 'stop_patience': 4, 'reduce_lr_factor': 0.1473425493245902, 'reduce_lr_patience': 3}. Best is trial 24 with value: -0.2683771252632141.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Melhor combinação encontrada:\n",
            "trial                  24.000000\n",
            "epochs                 50.000000\n",
            "batch_size             16.000000\n",
            "learning_rate           0.002678\n",
            "stop_patience           4.000000\n",
            "reduce_lr_factor        0.294317\n",
            "reduce_lr_patience      5.000000\n",
            "recall_Compra(1)        0.865462\n",
            "recall_Vende(0)         0.899709\n",
            "precision_Compra(1)     0.862000\n",
            "precision_Vende(0)      0.902332\n",
            "macro_recall            0.882586\n",
            "accuracy                0.885329\n",
            "f1_macro                0.882373\n",
            "f1_weighted             0.885360\n",
            "min_val_loss            0.268377\n",
            "Name: 0, dtype: float64\n",
            "🔍 Hiperparâmetros: {'epochs': 50, 'batch_size': 16, 'learning_rate': 0.002678169468879813, 'stop_patience': 4, 'reduce_lr_factor': 0.29431686816170216, 'reduce_lr_patience': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_ram_model, best_ram_history, df_results, best_ram_metrics, best_ram_y_pred = train_model(\n",
        "    model_fn=model_cnn_ramificado,\n",
        "    model_path = \"BEST_CNN_RAM_CSNA3.keras\",\n",
        "    X_train=[X_train1, X_train2],\n",
        "    y_train=y_train,\n",
        "    X_test=[X_test1, X_test2],\n",
        "    y_test=y_test,\n",
        "    prob=0.5,\n",
        "    n_trials=30,\n",
        "    metric_to_optimize=metric_optimization\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5a51SQ3m1jR1",
        "outputId": "51222d85-245c-4449-ce28-0104a86014ef"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:02:23,311] A new study created in memory with name: no-name-ed894a4e-450b-4412-b14e-2ed7b219b6a2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5737 - loss: 0.6799\n",
            "Epoch 1: val_loss improved from inf to 0.45187, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5741 - loss: 0.6796 - val_accuracy: 0.8550 - val_loss: 0.4519 - learning_rate: 0.0024\n",
            "Epoch 2/25\n",
            "\u001b[1m280/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6908 - loss: 0.5659\n",
            "Epoch 2: val_loss did not improve from 0.45187\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6922 - loss: 0.5642 - val_accuracy: 0.7901 - val_loss: 0.4628 - learning_rate: 0.0024\n",
            "Epoch 3/25\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7466 - loss: 0.4989\n",
            "Epoch 3: val_loss improved from 0.45187 to 0.37260, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7470 - loss: 0.4984 - val_accuracy: 0.8524 - val_loss: 0.3726 - learning_rate: 0.0024\n",
            "Epoch 4/25\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7577 - loss: 0.4723\n",
            "Epoch 4: val_loss improved from 0.37260 to 0.37254, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7584 - loss: 0.4712 - val_accuracy: 0.8600 - val_loss: 0.3725 - learning_rate: 0.0024\n",
            "Epoch 5/25\n",
            "\u001b[1m278/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7651 - loss: 0.4449\n",
            "Epoch 5: val_loss did not improve from 0.37254\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7660 - loss: 0.4441 - val_accuracy: 0.8398 - val_loss: 0.4659 - learning_rate: 0.0024\n",
            "Epoch 6/25\n",
            "\u001b[1m283/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7894 - loss: 0.4216\n",
            "Epoch 6: val_loss improved from 0.37254 to 0.31530, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7897 - loss: 0.4209 - val_accuracy: 0.8803 - val_loss: 0.3153 - learning_rate: 0.0024\n",
            "Epoch 7/25\n",
            "\u001b[1m278/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7788 - loss: 0.4412\n",
            "Epoch 7: val_loss did not improve from 0.31530\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7798 - loss: 0.4393 - val_accuracy: 0.8676 - val_loss: 0.3713 - learning_rate: 0.0024\n",
            "Epoch 8/25\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.3912\n",
            "Epoch 8: val_loss did not improve from 0.31530\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.3912 - val_accuracy: 0.8575 - val_loss: 0.3593 - learning_rate: 0.0024\n",
            "Epoch 9/25\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7913 - loss: 0.4068\n",
            "Epoch 9: val_loss did not improve from 0.31530\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7917 - loss: 0.4063 - val_accuracy: 0.8583 - val_loss: 0.3939 - learning_rate: 0.0024\n",
            "Epoch 10/25\n",
            "\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8060 - loss: 0.3867\n",
            "Epoch 10: val_loss did not improve from 0.31530\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8060 - loss: 0.3866 - val_accuracy: 0.8516 - val_loss: 0.4580 - learning_rate: 0.0024\n",
            "Epoch 11/25\n",
            "\u001b[1m280/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8146 - loss: 0.3721\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0011549745222152689.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.31530\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8149 - loss: 0.3720 - val_accuracy: 0.8524 - val_loss: 0.4426 - learning_rate: 0.0024\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:02:39,370] Trial 0 finished with value: -0.3153038024902344 and parameters: {'epochs': 25, 'batch_size': 16, 'learning_rate': 0.0023611941287638772, 'stop_patience': 5, 'reduce_lr_factor': 0.4891484602323072, 'reduce_lr_patience': 5}. Best is trial 0 with value: -0.3153038024902344.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/39\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5734 - loss: 0.6754\n",
            "Epoch 1: val_loss improved from inf to 0.43938, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5743 - loss: 0.6747 - val_accuracy: 0.8373 - val_loss: 0.4394 - learning_rate: 0.0023\n",
            "Epoch 2/39\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7183 - loss: 0.5630\n",
            "Epoch 2: val_loss improved from 0.43938 to 0.35925, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7185 - loss: 0.5625 - val_accuracy: 0.8457 - val_loss: 0.3593 - learning_rate: 0.0023\n",
            "Epoch 3/39\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7271 - loss: 0.5142\n",
            "Epoch 3: val_loss improved from 0.35925 to 0.35084, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7283 - loss: 0.5130 - val_accuracy: 0.8541 - val_loss: 0.3508 - learning_rate: 0.0023\n",
            "Epoch 4/39\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7700 - loss: 0.4673\n",
            "Epoch 4: val_loss did not improve from 0.35084\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7701 - loss: 0.4670 - val_accuracy: 0.8516 - val_loss: 0.3559 - learning_rate: 0.0023\n",
            "Epoch 5/39\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7633 - loss: 0.4520\n",
            "Epoch 5: val_loss did not improve from 0.35084\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7644 - loss: 0.4513 - val_accuracy: 0.8541 - val_loss: 0.3789 - learning_rate: 0.0023\n",
            "Epoch 6/39\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7789 - loss: 0.4355\n",
            "Epoch 6: val_loss improved from 0.35084 to 0.30180, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7804 - loss: 0.4341 - val_accuracy: 0.8761 - val_loss: 0.3018 - learning_rate: 0.0023\n",
            "Epoch 7/39\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7848 - loss: 0.4233\n",
            "Epoch 7: val_loss improved from 0.30180 to 0.29035, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7855 - loss: 0.4229 - val_accuracy: 0.8735 - val_loss: 0.2903 - learning_rate: 0.0023\n",
            "Epoch 8/39\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7911 - loss: 0.4191\n",
            "Epoch 8: val_loss did not improve from 0.29035\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7918 - loss: 0.4184 - val_accuracy: 0.8600 - val_loss: 0.3045 - learning_rate: 0.0023\n",
            "Epoch 9/39\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.4012\n",
            "Epoch 9: val_loss improved from 0.29035 to 0.28780, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8030 - loss: 0.3996 - val_accuracy: 0.8752 - val_loss: 0.2878 - learning_rate: 0.0023\n",
            "Epoch 10/39\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8102 - loss: 0.3771\n",
            "Epoch 10: val_loss improved from 0.28780 to 0.27377, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8108 - loss: 0.3775 - val_accuracy: 0.8845 - val_loss: 0.2738 - learning_rate: 0.0023\n",
            "Epoch 11/39\n",
            "\u001b[1m62/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8231 - loss: 0.3636\n",
            "Epoch 11: val_loss did not improve from 0.27377\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8233 - loss: 0.3644 - val_accuracy: 0.8803 - val_loss: 0.2805 - learning_rate: 0.0023\n",
            "Epoch 12/39\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8187 - loss: 0.3722\n",
            "Epoch 12: val_loss did not improve from 0.27377\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8187 - loss: 0.3724 - val_accuracy: 0.8761 - val_loss: 0.2865 - learning_rate: 0.0023\n",
            "Epoch 13/39\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8243 - loss: 0.3714\n",
            "Epoch 13: val_loss did not improve from 0.27377\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8242 - loss: 0.3716 - val_accuracy: 0.8617 - val_loss: 0.3247 - learning_rate: 0.0023\n",
            "Epoch 14/39\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8211 - loss: 0.3743\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0010839665074420456.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.27377\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8212 - loss: 0.3741 - val_accuracy: 0.8702 - val_loss: 0.2980 - learning_rate: 0.0023\n",
            "Epoch 15/39\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.3501\n",
            "Epoch 15: val_loss did not improve from 0.27377\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8435 - loss: 0.3494 - val_accuracy: 0.8727 - val_loss: 0.3250 - learning_rate: 0.0011\n",
            "Epoch 16/39\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.3439\n",
            "Epoch 16: val_loss did not improve from 0.27377\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8421 - loss: 0.3433 - val_accuracy: 0.8777 - val_loss: 0.3263 - learning_rate: 0.0011\n",
            "Epoch 17/39\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8507 - loss: 0.3322\n",
            "Epoch 17: val_loss did not improve from 0.27377\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8513 - loss: 0.3318 - val_accuracy: 0.8744 - val_loss: 0.3266 - learning_rate: 0.0011\n",
            "Epoch 18/39\n",
            "\u001b[1m64/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8593 - loss: 0.3322\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005133325189645047.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.27377\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8591 - loss: 0.3313 - val_accuracy: 0.8718 - val_loss: 0.3490 - learning_rate: 0.0011\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:02:52,388] Trial 1 finished with value: -0.2737700939178467 and parameters: {'epochs': 39, 'batch_size': 64, 'learning_rate': 0.002288932236178897, 'stop_patience': 8, 'reduce_lr_factor': 0.4735686365111972, 'reduce_lr_patience': 4}. Best is trial 1 with value: -0.2737700939178467.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/11\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5913 - loss: 0.6718\n",
            "Epoch 1: val_loss improved from inf to 0.38629, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5916 - loss: 0.6715 - val_accuracy: 0.8499 - val_loss: 0.3863 - learning_rate: 0.0032\n",
            "Epoch 2/11\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7244 - loss: 0.5496\n",
            "Epoch 2: val_loss improved from 0.38629 to 0.35110, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7250 - loss: 0.5489 - val_accuracy: 0.8398 - val_loss: 0.3511 - learning_rate: 0.0032\n",
            "Epoch 3/11\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7647 - loss: 0.4789\n",
            "Epoch 3: val_loss did not improve from 0.35110\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7646 - loss: 0.4788 - val_accuracy: 0.8524 - val_loss: 0.3590 - learning_rate: 0.0032\n",
            "Epoch 4/11\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.4637\n",
            "Epoch 4: val_loss did not improve from 0.35110\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7739 - loss: 0.4637 - val_accuracy: 0.8575 - val_loss: 0.3560 - learning_rate: 0.0032\n",
            "Epoch 5/11\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7839 - loss: 0.4288\n",
            "Epoch 5: val_loss did not improve from 0.35110\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 0.4289 - val_accuracy: 0.8288 - val_loss: 0.4472 - learning_rate: 0.0032\n",
            "Epoch 6/11\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7970 - loss: 0.4197\n",
            "Epoch 6: val_loss improved from 0.35110 to 0.28684, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7968 - loss: 0.4197 - val_accuracy: 0.8769 - val_loss: 0.2868 - learning_rate: 0.0032\n",
            "Epoch 7/11\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7887 - loss: 0.4146\n",
            "Epoch 7: val_loss did not improve from 0.28684\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7887 - loss: 0.4146 - val_accuracy: 0.8752 - val_loss: 0.3142 - learning_rate: 0.0032\n",
            "Epoch 8/11\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4025\n",
            "Epoch 8: val_loss did not improve from 0.28684\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8045 - loss: 0.4028 - val_accuracy: 0.8583 - val_loss: 0.3352 - learning_rate: 0.0032\n",
            "Epoch 9/11\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7810 - loss: 0.4095\n",
            "Epoch 9: val_loss did not improve from 0.28684\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7813 - loss: 0.4094 - val_accuracy: 0.8777 - val_loss: 0.3057 - learning_rate: 0.0032\n",
            "Epoch 10/11\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8099 - loss: 0.3916\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.000980332605911832.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.28684\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.3922 - val_accuracy: 0.8642 - val_loss: 0.3114 - learning_rate: 0.0032\n",
            "Epoch 11/11\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8342 - loss: 0.3604\n",
            "Epoch 11: val_loss improved from 0.28684 to 0.28005, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8346 - loss: 0.3600 - val_accuracy: 0.8862 - val_loss: 0.2800 - learning_rate: 9.8033e-04\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:03:06,665] Trial 2 finished with value: -0.28004616498947144 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 0.003159932188898459, 'stop_patience': 7, 'reduce_lr_factor': 0.3102385041336635, 'reduce_lr_patience': 4}. Best is trial 1 with value: -0.2737700939178467.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/34\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5763 - loss: 0.6769\n",
            "Epoch 1: val_loss improved from inf to 0.40481, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5770 - loss: 0.6763 - val_accuracy: 0.8609 - val_loss: 0.4048 - learning_rate: 0.0052\n",
            "Epoch 2/34\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7187 - loss: 0.5579\n",
            "Epoch 2: val_loss improved from 0.40481 to 0.31590, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7191 - loss: 0.5566 - val_accuracy: 0.8685 - val_loss: 0.3159 - learning_rate: 0.0052\n",
            "Epoch 3/34\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7633 - loss: 0.4754\n",
            "Epoch 3: val_loss did not improve from 0.31590\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7634 - loss: 0.4752 - val_accuracy: 0.7639 - val_loss: 0.6011 - learning_rate: 0.0052\n",
            "Epoch 4/34\n",
            "\u001b[1m136/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7653 - loss: 0.4702\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.002016524687629163.\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.31590\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7656 - loss: 0.4687 - val_accuracy: 0.8600 - val_loss: 0.3657 - learning_rate: 0.0052\n",
            "Epoch 5/34\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7813 - loss: 0.4233\n",
            "Epoch 5: val_loss improved from 0.31590 to 0.27492, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7825 - loss: 0.4218 - val_accuracy: 0.8820 - val_loss: 0.2749 - learning_rate: 0.0020\n",
            "Epoch 6/34\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.3718\n",
            "Epoch 6: val_loss did not improve from 0.27492\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8175 - loss: 0.3718 - val_accuracy: 0.8836 - val_loss: 0.2765 - learning_rate: 0.0020\n",
            "Epoch 7/34\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8344 - loss: 0.3672\n",
            "Epoch 7: val_loss improved from 0.27492 to 0.27162, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8329 - loss: 0.3684 - val_accuracy: 0.8862 - val_loss: 0.2716 - learning_rate: 0.0020\n",
            "Epoch 8/34\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8135 - loss: 0.3736\n",
            "Epoch 8: val_loss did not improve from 0.27162\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8136 - loss: 0.3736 - val_accuracy: 0.8887 - val_loss: 0.2821 - learning_rate: 0.0020\n",
            "Epoch 9/34\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.3579\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0007849355981548402.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.27162\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8239 - loss: 0.3579 - val_accuracy: 0.8879 - val_loss: 0.2742 - learning_rate: 0.0020\n",
            "Epoch 10/34\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8566 - loss: 0.3295\n",
            "Epoch 10: val_loss did not improve from 0.27162\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8561 - loss: 0.3300 - val_accuracy: 0.8786 - val_loss: 0.3031 - learning_rate: 7.8494e-04\n",
            "Epoch 11/34\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8523 - loss: 0.3318\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0003055374785835807.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.27162\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8525 - loss: 0.3316 - val_accuracy: 0.8761 - val_loss: 0.2982 - learning_rate: 7.8494e-04\n",
            "Epoch 12/34\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8645 - loss: 0.3151\n",
            "Epoch 12: val_loss did not improve from 0.27162\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8647 - loss: 0.3150 - val_accuracy: 0.8651 - val_loss: 0.3922 - learning_rate: 3.0554e-04\n",
            "Epoch 13/34\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8754 - loss: 0.3064\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00011893096943937582.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.27162\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8753 - loss: 0.3064 - val_accuracy: 0.8575 - val_loss: 0.4047 - learning_rate: 3.0554e-04\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:03:25,999] Trial 3 finished with value: -0.2716202735900879 and parameters: {'epochs': 34, 'batch_size': 32, 'learning_rate': 0.005180516786047501, 'stop_patience': 6, 'reduce_lr_factor': 0.389251649312201, 'reduce_lr_patience': 2}. Best is trial 3 with value: -0.2716202735900879.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/39\n",
            "\u001b[1m64/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5493 - loss: 0.6940\n",
            "Epoch 1: val_loss improved from inf to 0.45530, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5522 - loss: 0.6906 - val_accuracy: 0.8474 - val_loss: 0.4553 - learning_rate: 0.0062\n",
            "Epoch 2/39\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6751 - loss: 0.5840\n",
            "Epoch 2: val_loss did not improve from 0.45530\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6764 - loss: 0.5827 - val_accuracy: 0.7943 - val_loss: 0.4619 - learning_rate: 0.0062\n",
            "Epoch 3/39\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7287 - loss: 0.5150\n",
            "Epoch 3: val_loss did not improve from 0.45530\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7291 - loss: 0.5145 - val_accuracy: 0.7605 - val_loss: 0.4942 - learning_rate: 0.0062\n",
            "Epoch 4/39\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7706 - loss: 0.4503\n",
            "Epoch 4: val_loss improved from 0.45530 to 0.30759, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7705 - loss: 0.4504 - val_accuracy: 0.8592 - val_loss: 0.3076 - learning_rate: 0.0062\n",
            "Epoch 5/39\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7614 - loss: 0.4519\n",
            "Epoch 5: val_loss did not improve from 0.30759\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7625 - loss: 0.4506 - val_accuracy: 0.8440 - val_loss: 0.3721 - learning_rate: 0.0062\n",
            "Epoch 6/39\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7885 - loss: 0.4270\n",
            "Epoch 6: val_loss did not improve from 0.30759\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7891 - loss: 0.4257 - val_accuracy: 0.8693 - val_loss: 0.3201 - learning_rate: 0.0062\n",
            "Epoch 7/39\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7967 - loss: 0.4109\n",
            "Epoch 7: val_loss did not improve from 0.30759\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7969 - loss: 0.4106 - val_accuracy: 0.8482 - val_loss: 0.3365 - learning_rate: 0.0062\n",
            "Epoch 8/39\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.3996\n",
            "Epoch 8: val_loss improved from 0.30759 to 0.29661, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8072 - loss: 0.3998 - val_accuracy: 0.8659 - val_loss: 0.2966 - learning_rate: 0.0062\n",
            "Epoch 9/39\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8115 - loss: 0.3818\n",
            "Epoch 9: val_loss did not improve from 0.29661\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.3824 - val_accuracy: 0.8567 - val_loss: 0.3060 - learning_rate: 0.0062\n",
            "Epoch 10/39\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8005 - loss: 0.3947\n",
            "Epoch 10: val_loss did not improve from 0.29661\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8007 - loss: 0.3950 - val_accuracy: 0.8449 - val_loss: 0.3663 - learning_rate: 0.0062\n",
            "Epoch 11/39\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.3803\n",
            "Epoch 11: val_loss did not improve from 0.29661\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8109 - loss: 0.3791 - val_accuracy: 0.8626 - val_loss: 0.3168 - learning_rate: 0.0062\n",
            "Epoch 12/39\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8288 - loss: 0.3635\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.002519356058511668.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.29661\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8279 - loss: 0.3645 - val_accuracy: 0.8659 - val_loss: 0.4205 - learning_rate: 0.0062\n",
            "Epoch 13/39\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8494 - loss: 0.3417\n",
            "Epoch 13: val_loss did not improve from 0.29661\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8497 - loss: 0.3414 - val_accuracy: 0.8432 - val_loss: 0.4437 - learning_rate: 0.0025\n",
            "Epoch 14/39\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8505 - loss: 0.3268\n",
            "Epoch 14: val_loss did not improve from 0.29661\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8507 - loss: 0.3267 - val_accuracy: 0.8516 - val_loss: 0.4857 - learning_rate: 0.0025\n",
            "Epoch 15/39\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8507 - loss: 0.3467\n",
            "Epoch 15: val_loss did not improve from 0.29661\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8514 - loss: 0.3454 - val_accuracy: 0.8465 - val_loss: 0.4855 - learning_rate: 0.0025\n",
            "Epoch 16/39\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8559 - loss: 0.3268\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0010162632717007985.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.29661\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8567 - loss: 0.3262 - val_accuracy: 0.8499 - val_loss: 0.4497 - learning_rate: 0.0025\n",
            "Epoch 17/39\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8587 - loss: 0.3169\n",
            "Epoch 17: val_loss did not improve from 0.29661\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8602 - loss: 0.3156 - val_accuracy: 0.8440 - val_loss: 0.4695 - learning_rate: 0.0010\n",
            "Epoch 18/39\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8818 - loss: 0.2926\n",
            "Epoch 18: val_loss did not improve from 0.29661\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8818 - loss: 0.2925 - val_accuracy: 0.8457 - val_loss: 0.5673 - learning_rate: 0.0010\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:03:38,635] Trial 4 finished with value: -0.29660919308662415 and parameters: {'epochs': 39, 'batch_size': 64, 'learning_rate': 0.006245581510880467, 'stop_patience': 10, 'reduce_lr_factor': 0.40338214871855815, 'reduce_lr_patience': 4}. Best is trial 3 with value: -0.2716202735900879.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5838 - loss: 0.6875\n",
            "Epoch 1: val_loss improved from inf to 0.35161, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5845 - loss: 0.6861 - val_accuracy: 0.8659 - val_loss: 0.3516 - learning_rate: 0.0073\n",
            "Epoch 2/50\n",
            "\u001b[1m281/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6747 - loss: 0.5858\n",
            "Epoch 2: val_loss did not improve from 0.35161\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6756 - loss: 0.5850 - val_accuracy: 0.8196 - val_loss: 0.3849 - learning_rate: 0.0073\n",
            "Epoch 3/50\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7573 - loss: 0.4848\n",
            "Epoch 3: val_loss improved from 0.35161 to 0.32441, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7568 - loss: 0.4850 - val_accuracy: 0.8710 - val_loss: 0.3244 - learning_rate: 0.0073\n",
            "Epoch 4/50\n",
            "\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7629 - loss: 0.4596\n",
            "Epoch 4: val_loss did not improve from 0.32441\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7629 - loss: 0.4596 - val_accuracy: 0.7951 - val_loss: 0.4044 - learning_rate: 0.0073\n",
            "Epoch 5/50\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7655 - loss: 0.4598\n",
            "Epoch 5: val_loss did not improve from 0.32441\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7656 - loss: 0.4596 - val_accuracy: 0.8212 - val_loss: 0.4212 - learning_rate: 0.0073\n",
            "Epoch 6/50\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7861 - loss: 0.4222\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009337867914199269.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.32441\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7859 - loss: 0.4226 - val_accuracy: 0.6476 - val_loss: 0.7251 - learning_rate: 0.0073\n",
            "Epoch 7/50\n",
            "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8181 - loss: 0.3809\n",
            "Epoch 7: val_loss did not improve from 0.32441\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8183 - loss: 0.3807 - val_accuracy: 0.8423 - val_loss: 0.3395 - learning_rate: 9.3379e-04\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:03:50,478] Trial 5 finished with value: -0.3244090676307678 and parameters: {'epochs': 50, 'batch_size': 16, 'learning_rate': 0.007324083702131285, 'stop_patience': 4, 'reduce_lr_factor': 0.1274953739770974, 'reduce_lr_patience': 3}. Best is trial 3 with value: -0.2716202735900879.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5772 - loss: 0.6858\n",
            "Epoch 1: val_loss improved from inf to 0.51578, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5779 - loss: 0.6851 - val_accuracy: 0.7546 - val_loss: 0.5158 - learning_rate: 0.0076\n",
            "Epoch 2/13\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6787 - loss: 0.5878\n",
            "Epoch 2: val_loss did not improve from 0.51578\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6803 - loss: 0.5860 - val_accuracy: 0.7648 - val_loss: 0.5507 - learning_rate: 0.0076\n",
            "Epoch 3/13\n",
            "\u001b[1m131/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.5142\n",
            "Epoch 3: val_loss improved from 0.51578 to 0.31085, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7352 - loss: 0.5119 - val_accuracy: 0.8668 - val_loss: 0.3108 - learning_rate: 0.0076\n",
            "Epoch 4/13\n",
            "\u001b[1m136/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7753 - loss: 0.4459\n",
            "Epoch 4: val_loss did not improve from 0.31085\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7747 - loss: 0.4462 - val_accuracy: 0.8255 - val_loss: 0.4203 - learning_rate: 0.0076\n",
            "Epoch 5/13\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7501 - loss: 0.4593\n",
            "Epoch 5: val_loss did not improve from 0.31085\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7503 - loss: 0.4592 - val_accuracy: 0.8305 - val_loss: 0.5044 - learning_rate: 0.0076\n",
            "Epoch 6/13\n",
            "\u001b[1m135/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7891 - loss: 0.4326\n",
            "Epoch 6: val_loss did not improve from 0.31085\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7892 - loss: 0.4310 - val_accuracy: 0.8373 - val_loss: 0.4097 - learning_rate: 0.0076\n",
            "Epoch 7/13\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7969 - loss: 0.4050\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0025495961122037653.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.31085\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7961 - loss: 0.4058 - val_accuracy: 0.8524 - val_loss: 0.3612 - learning_rate: 0.0076\n",
            "Epoch 8/13\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8164 - loss: 0.3663\n",
            "Epoch 8: val_loss did not improve from 0.31085\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.3658 - val_accuracy: 0.8524 - val_loss: 0.3445 - learning_rate: 0.0025\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:04:00,522] Trial 6 finished with value: -0.310845285654068 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 0.00764629343133679, 'stop_patience': 5, 'reduce_lr_factor': 0.33344209876694986, 'reduce_lr_patience': 4}. Best is trial 3 with value: -0.2716202735900879.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/34\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5900 - loss: 0.6764\n",
            "Epoch 1: val_loss improved from inf to 0.44577, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5923 - loss: 0.6740 - val_accuracy: 0.7892 - val_loss: 0.4458 - learning_rate: 0.0055\n",
            "Epoch 2/34\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7006 - loss: 0.5566\n",
            "Epoch 2: val_loss improved from 0.44577 to 0.29612, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7010 - loss: 0.5563 - val_accuracy: 0.8836 - val_loss: 0.2961 - learning_rate: 0.0055\n",
            "Epoch 3/34\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7473 - loss: 0.4859\n",
            "Epoch 3: val_loss improved from 0.29612 to 0.29416, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7472 - loss: 0.4860 - val_accuracy: 0.8693 - val_loss: 0.2942 - learning_rate: 0.0055\n",
            "Epoch 4/34\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7689 - loss: 0.4444\n",
            "Epoch 4: val_loss did not improve from 0.29416\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7680 - loss: 0.4449 - val_accuracy: 0.8735 - val_loss: 0.3275 - learning_rate: 0.0055\n",
            "Epoch 5/34\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7837 - loss: 0.4289\n",
            "Epoch 5: val_loss did not improve from 0.29416\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7842 - loss: 0.4284 - val_accuracy: 0.8761 - val_loss: 0.3097 - learning_rate: 0.0055\n",
            "Epoch 6/34\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7917 - loss: 0.4239\n",
            "Epoch 6: val_loss improved from 0.29416 to 0.29062, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7915 - loss: 0.4237 - val_accuracy: 0.8769 - val_loss: 0.2906 - learning_rate: 0.0055\n",
            "Epoch 7/34\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7794 - loss: 0.4378\n",
            "Epoch 7: val_loss did not improve from 0.29062\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7804 - loss: 0.4362 - val_accuracy: 0.8508 - val_loss: 0.4030 - learning_rate: 0.0055\n",
            "Epoch 8/34\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8045 - loss: 0.3959\n",
            "Epoch 8: val_loss did not improve from 0.29062\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8047 - loss: 0.3955 - val_accuracy: 0.8710 - val_loss: 0.3468 - learning_rate: 0.0055\n",
            "Epoch 9/34\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7979 - loss: 0.4024\n",
            "Epoch 9: val_loss did not improve from 0.29062\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.4020 - val_accuracy: 0.8524 - val_loss: 0.3993 - learning_rate: 0.0055\n",
            "Epoch 10/34\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8152 - loss: 0.3849\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0006674165525565713.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.29062\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8153 - loss: 0.3849 - val_accuracy: 0.8314 - val_loss: 0.6673 - learning_rate: 0.0055\n",
            "Epoch 11/34\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8578 - loss: 0.3459\n",
            "Epoch 11: val_loss did not improve from 0.29062\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8577 - loss: 0.3456 - val_accuracy: 0.8457 - val_loss: 0.5235 - learning_rate: 6.6742e-04\n",
            "Epoch 12/34\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8723 - loss: 0.3223\n",
            "Epoch 12: val_loss did not improve from 0.29062\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8723 - loss: 0.3222 - val_accuracy: 0.8440 - val_loss: 0.4912 - learning_rate: 6.6742e-04\n",
            "Epoch 13/34\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8746 - loss: 0.3138\n",
            "Epoch 13: val_loss did not improve from 0.29062\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8746 - loss: 0.3136 - val_accuracy: 0.8457 - val_loss: 0.5352 - learning_rate: 6.6742e-04\n",
            "Epoch 14/34\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8731 - loss: 0.3091\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 8.080761668020937e-05.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.29062\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8732 - loss: 0.3090 - val_accuracy: 0.8474 - val_loss: 0.5050 - learning_rate: 6.6742e-04\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:04:16,678] Trial 7 finished with value: -0.2906169295310974 and parameters: {'epochs': 34, 'batch_size': 32, 'learning_rate': 0.005512411637230668, 'stop_patience': 8, 'reduce_lr_factor': 0.12107523678102812, 'reduce_lr_patience': 4}. Best is trial 3 with value: -0.2716202735900879.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/44\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6025 - loss: 0.6809\n",
            "Epoch 1: val_loss improved from inf to 0.38188, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6031 - loss: 0.6798 - val_accuracy: 0.8609 - val_loss: 0.3819 - learning_rate: 0.0055\n",
            "Epoch 2/44\n",
            "\u001b[1m283/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7043 - loss: 0.5658\n",
            "Epoch 2: val_loss improved from 0.38188 to 0.37366, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7048 - loss: 0.5649 - val_accuracy: 0.8331 - val_loss: 0.3737 - learning_rate: 0.0055\n",
            "Epoch 3/44\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7388 - loss: 0.4972\n",
            "Epoch 3: val_loss improved from 0.37366 to 0.28464, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7389 - loss: 0.4970 - val_accuracy: 0.8744 - val_loss: 0.2846 - learning_rate: 0.0055\n",
            "Epoch 4/44\n",
            "\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7574 - loss: 0.4593\n",
            "Epoch 4: val_loss did not improve from 0.28464\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7579 - loss: 0.4589 - val_accuracy: 0.8710 - val_loss: 0.3086 - learning_rate: 0.0055\n",
            "Epoch 5/44\n",
            "\u001b[1m280/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7752 - loss: 0.4458\n",
            "Epoch 5: val_loss did not improve from 0.28464\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7752 - loss: 0.4455 - val_accuracy: 0.8398 - val_loss: 0.4443 - learning_rate: 0.0055\n",
            "Epoch 6/44\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7879 - loss: 0.4083\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0018140404296795142.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.28464\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7881 - loss: 0.4082 - val_accuracy: 0.8676 - val_loss: 0.3435 - learning_rate: 0.0055\n",
            "Epoch 7/44\n",
            "\u001b[1m282/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8206 - loss: 0.3698\n",
            "Epoch 7: val_loss did not improve from 0.28464\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.3692 - val_accuracy: 0.8516 - val_loss: 0.3792 - learning_rate: 0.0018\n",
            "Epoch 8/44\n",
            "\u001b[1m283/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8334 - loss: 0.3420\n",
            "Epoch 8: val_loss did not improve from 0.28464\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8338 - loss: 0.3419 - val_accuracy: 0.8583 - val_loss: 0.4222 - learning_rate: 0.0018\n",
            "Epoch 9/44\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8373 - loss: 0.3406\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005988920725763077.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.28464\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8376 - loss: 0.3405 - val_accuracy: 0.8583 - val_loss: 0.3723 - learning_rate: 0.0018\n",
            "Epoch 10/44\n",
            "\u001b[1m281/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8528 - loss: 0.3242\n",
            "Epoch 10: val_loss did not improve from 0.28464\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3235 - val_accuracy: 0.8449 - val_loss: 0.4399 - learning_rate: 5.9889e-04\n",
            "Epoch 11/44\n",
            "\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8827 - loss: 0.3024\n",
            "Epoch 11: val_loss did not improve from 0.28464\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8824 - loss: 0.3027 - val_accuracy: 0.8423 - val_loss: 0.4932 - learning_rate: 5.9889e-04\n",
            "Epoch 12/44\n",
            "\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8783 - loss: 0.2935\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00019771978853742262.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.28464\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8781 - loss: 0.2938 - val_accuracy: 0.8432 - val_loss: 0.5321 - learning_rate: 5.9889e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:04:35,084] Trial 8 finished with value: -0.2846392095088959 and parameters: {'epochs': 44, 'batch_size': 16, 'learning_rate': 0.005494717596813478, 'stop_patience': 9, 'reduce_lr_factor': 0.33014261913470944, 'reduce_lr_patience': 3}. Best is trial 3 with value: -0.2716202735900879.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/46\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5714 - loss: 0.6757\n",
            "Epoch 1: val_loss improved from inf to 0.52463, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5722 - loss: 0.6752 - val_accuracy: 0.7487 - val_loss: 0.5246 - learning_rate: 0.0020\n",
            "Epoch 2/46\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6945 - loss: 0.5700\n",
            "Epoch 2: val_loss improved from 0.52463 to 0.38147, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6953 - loss: 0.5688 - val_accuracy: 0.8280 - val_loss: 0.3815 - learning_rate: 0.0020\n",
            "Epoch 3/46\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7522 - loss: 0.4955\n",
            "Epoch 3: val_loss improved from 0.38147 to 0.33289, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7518 - loss: 0.4954 - val_accuracy: 0.8567 - val_loss: 0.3329 - learning_rate: 0.0020\n",
            "Epoch 4/46\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7953 - loss: 0.4396\n",
            "Epoch 4: val_loss improved from 0.33289 to 0.30157, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7946 - loss: 0.4399 - val_accuracy: 0.8634 - val_loss: 0.3016 - learning_rate: 0.0020\n",
            "Epoch 5/46\n",
            "\u001b[1m136/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.4334\n",
            "Epoch 5: val_loss improved from 0.30157 to 0.27689, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7904 - loss: 0.4335 - val_accuracy: 0.8744 - val_loss: 0.2769 - learning_rate: 0.0020\n",
            "Epoch 6/46\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4084\n",
            "Epoch 6: val_loss improved from 0.27689 to 0.27266, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8046 - loss: 0.4084 - val_accuracy: 0.8769 - val_loss: 0.2727 - learning_rate: 0.0020\n",
            "Epoch 7/46\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8081 - loss: 0.3928\n",
            "Epoch 7: val_loss did not improve from 0.27266\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.3931 - val_accuracy: 0.8744 - val_loss: 0.3087 - learning_rate: 0.0020\n",
            "Epoch 8/46\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8162 - loss: 0.3936\n",
            "Epoch 8: val_loss did not improve from 0.27266\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8158 - loss: 0.3937 - val_accuracy: 0.8853 - val_loss: 0.2743 - learning_rate: 0.0020\n",
            "Epoch 9/46\n",
            "\u001b[1m134/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8173 - loss: 0.3837\n",
            "Epoch 9: val_loss did not improve from 0.27266\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8170 - loss: 0.3839 - val_accuracy: 0.8853 - val_loss: 0.2804 - learning_rate: 0.0020\n",
            "Epoch 10/46\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8288 - loss: 0.3721\n",
            "Epoch 10: val_loss improved from 0.27266 to 0.25887, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8279 - loss: 0.3727 - val_accuracy: 0.8820 - val_loss: 0.2589 - learning_rate: 0.0020\n",
            "Epoch 11/46\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8280 - loss: 0.3660\n",
            "Epoch 11: val_loss did not improve from 0.25887\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8273 - loss: 0.3665 - val_accuracy: 0.8777 - val_loss: 0.2923 - learning_rate: 0.0020\n",
            "Epoch 12/46\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8249 - loss: 0.3655\n",
            "Epoch 12: val_loss did not improve from 0.25887\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8242 - loss: 0.3664 - val_accuracy: 0.8845 - val_loss: 0.2679 - learning_rate: 0.0020\n",
            "Epoch 13/46\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8360 - loss: 0.3535\n",
            "Epoch 13: val_loss did not improve from 0.25887\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8354 - loss: 0.3540 - val_accuracy: 0.8820 - val_loss: 0.2794 - learning_rate: 0.0020\n",
            "Epoch 14/46\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8359 - loss: 0.3563\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008616304668784714.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.25887\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8358 - loss: 0.3564 - val_accuracy: 0.8752 - val_loss: 0.3176 - learning_rate: 0.0020\n",
            "Epoch 15/46\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8519 - loss: 0.3340\n",
            "Epoch 15: val_loss did not improve from 0.25887\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8519 - loss: 0.3339 - val_accuracy: 0.8820 - val_loss: 0.2760 - learning_rate: 8.6163e-04\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:04:52,195] Trial 9 finished with value: -0.25887417793273926 and parameters: {'epochs': 46, 'batch_size': 32, 'learning_rate': 0.002033526410365415, 'stop_patience': 5, 'reduce_lr_factor': 0.423712475391115, 'reduce_lr_patience': 4}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4895 - loss: 0.6985\n",
            "Epoch 1: val_loss improved from inf to 0.67340, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4912 - loss: 0.6983 - val_accuracy: 0.6973 - val_loss: 0.6734 - learning_rate: 2.2884e-05\n",
            "Epoch 2/26\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5841 - loss: 0.6870\n",
            "Epoch 2: val_loss improved from 0.67340 to 0.65226, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5839 - loss: 0.6870 - val_accuracy: 0.6012 - val_loss: 0.6523 - learning_rate: 2.2884e-05\n",
            "Epoch 3/26\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6026 - loss: 0.6830\n",
            "Epoch 3: val_loss improved from 0.65226 to 0.63769, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6023 - loss: 0.6829 - val_accuracy: 0.6197 - val_loss: 0.6377 - learning_rate: 2.2884e-05\n",
            "Epoch 4/26\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6069 - loss: 0.6791\n",
            "Epoch 4: val_loss improved from 0.63769 to 0.62949, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6064 - loss: 0.6792 - val_accuracy: 0.6619 - val_loss: 0.6295 - learning_rate: 2.2884e-05\n",
            "Epoch 5/26\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6215 - loss: 0.6746\n",
            "Epoch 5: val_loss improved from 0.62949 to 0.62220, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6206 - loss: 0.6747 - val_accuracy: 0.6712 - val_loss: 0.6222 - learning_rate: 2.2884e-05\n",
            "Epoch 6/26\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6155 - loss: 0.6732\n",
            "Epoch 6: val_loss improved from 0.62220 to 0.61289, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6150 - loss: 0.6732 - val_accuracy: 0.6906 - val_loss: 0.6129 - learning_rate: 2.2884e-05\n",
            "Epoch 7/26\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6251 - loss: 0.6681\n",
            "Epoch 7: val_loss improved from 0.61289 to 0.60519, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6245 - loss: 0.6682 - val_accuracy: 0.7201 - val_loss: 0.6052 - learning_rate: 2.2884e-05\n",
            "Epoch 8/26\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6370 - loss: 0.6637\n",
            "Epoch 8: val_loss improved from 0.60519 to 0.59731, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6362 - loss: 0.6636 - val_accuracy: 0.7555 - val_loss: 0.5973 - learning_rate: 2.2884e-05\n",
            "Epoch 9/26\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6384 - loss: 0.6610\n",
            "Epoch 9: val_loss improved from 0.59731 to 0.59003, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6378 - loss: 0.6610 - val_accuracy: 0.7825 - val_loss: 0.5900 - learning_rate: 2.2884e-05\n",
            "Epoch 10/26\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6392 - loss: 0.6588\n",
            "Epoch 10: val_loss improved from 0.59003 to 0.58306, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6393 - loss: 0.6588 - val_accuracy: 0.8221 - val_loss: 0.5831 - learning_rate: 2.2884e-05\n",
            "Epoch 11/26\n",
            "\u001b[1m134/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6615 - loss: 0.6516\n",
            "Epoch 11: val_loss improved from 0.58306 to 0.57232, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6603 - loss: 0.6516 - val_accuracy: 0.8449 - val_loss: 0.5723 - learning_rate: 2.2884e-05\n",
            "Epoch 12/26\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6703 - loss: 0.6481\n",
            "Epoch 12: val_loss improved from 0.57232 to 0.56395, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6697 - loss: 0.6482 - val_accuracy: 0.8457 - val_loss: 0.5640 - learning_rate: 2.2884e-05\n",
            "Epoch 13/26\n",
            "\u001b[1m136/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6743 - loss: 0.6443\n",
            "Epoch 13: val_loss improved from 0.56395 to 0.55420, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6729 - loss: 0.6444 - val_accuracy: 0.8482 - val_loss: 0.5542 - learning_rate: 2.2884e-05\n",
            "Epoch 14/26\n",
            "\u001b[1m135/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6672 - loss: 0.6409\n",
            "Epoch 14: val_loss improved from 0.55420 to 0.54604, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6663 - loss: 0.6410 - val_accuracy: 0.8457 - val_loss: 0.5460 - learning_rate: 2.2884e-05\n",
            "Epoch 15/26\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6804 - loss: 0.6367\n",
            "Epoch 15: val_loss improved from 0.54604 to 0.53707, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6798 - loss: 0.6367 - val_accuracy: 0.8474 - val_loss: 0.5371 - learning_rate: 2.2884e-05\n",
            "Epoch 16/26\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6898 - loss: 0.6316\n",
            "Epoch 16: val_loss improved from 0.53707 to 0.52987, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6895 - loss: 0.6316 - val_accuracy: 0.8499 - val_loss: 0.5299 - learning_rate: 2.2884e-05\n",
            "Epoch 17/26\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6873 - loss: 0.6280\n",
            "Epoch 17: val_loss improved from 0.52987 to 0.52609, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6869 - loss: 0.6279 - val_accuracy: 0.8432 - val_loss: 0.5261 - learning_rate: 2.2884e-05\n",
            "Epoch 18/26\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6964 - loss: 0.6230\n",
            "Epoch 18: val_loss improved from 0.52609 to 0.51487, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6962 - loss: 0.6231 - val_accuracy: 0.8474 - val_loss: 0.5149 - learning_rate: 2.2884e-05\n",
            "Epoch 19/26\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6986 - loss: 0.6222\n",
            "Epoch 19: val_loss improved from 0.51487 to 0.50902, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6980 - loss: 0.6221 - val_accuracy: 0.8491 - val_loss: 0.5090 - learning_rate: 2.2884e-05\n",
            "Epoch 20/26\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6972 - loss: 0.6148\n",
            "Epoch 20: val_loss improved from 0.50902 to 0.50602, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6966 - loss: 0.6149 - val_accuracy: 0.8406 - val_loss: 0.5060 - learning_rate: 2.2884e-05\n",
            "Epoch 21/26\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7083 - loss: 0.6116\n",
            "Epoch 21: val_loss improved from 0.50602 to 0.49541, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7078 - loss: 0.6116 - val_accuracy: 0.8474 - val_loss: 0.4954 - learning_rate: 2.2884e-05\n",
            "Epoch 22/26\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7118 - loss: 0.6076\n",
            "Epoch 22: val_loss improved from 0.49541 to 0.49131, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7114 - loss: 0.6076 - val_accuracy: 0.8406 - val_loss: 0.4913 - learning_rate: 2.2884e-05\n",
            "Epoch 23/26\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7140 - loss: 0.6037\n",
            "Epoch 23: val_loss improved from 0.49131 to 0.48960, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7133 - loss: 0.6039 - val_accuracy: 0.8373 - val_loss: 0.4896 - learning_rate: 2.2884e-05\n",
            "Epoch 24/26\n",
            "\u001b[1m136/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7207 - loss: 0.5972\n",
            "Epoch 24: val_loss improved from 0.48960 to 0.48092, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7200 - loss: 0.5975 - val_accuracy: 0.8398 - val_loss: 0.4809 - learning_rate: 2.2884e-05\n",
            "Epoch 25/26\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7117 - loss: 0.6002\n",
            "Epoch 25: val_loss improved from 0.48092 to 0.47462, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7116 - loss: 0.6002 - val_accuracy: 0.8406 - val_loss: 0.4746 - learning_rate: 2.2884e-05\n",
            "Epoch 26/26\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.5957\n",
            "Epoch 26: val_loss improved from 0.47462 to 0.47376, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7293 - loss: 0.5957 - val_accuracy: 0.8381 - val_loss: 0.4738 - learning_rate: 2.2884e-05\n",
            "Restoring model weights from the end of the best epoch: 26.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:05:22,126] Trial 10 finished with value: -0.4737597703933716 and parameters: {'epochs': 26, 'batch_size': 32, 'learning_rate': 2.288366057145129e-05, 'stop_patience': 3, 'reduce_lr_factor': 0.21984265008375076, 'reduce_lr_patience': 5}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5665 - loss: 0.6846\n",
            "Epoch 1: val_loss improved from inf to 0.76293, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5679 - loss: 0.6832 - val_accuracy: 0.6349 - val_loss: 0.7629 - learning_rate: 0.0096\n",
            "Epoch 2/50\n",
            "\u001b[1m135/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7087 - loss: 0.5669\n",
            "Epoch 2: val_loss improved from 0.76293 to 0.44534, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7091 - loss: 0.5664 - val_accuracy: 0.8609 - val_loss: 0.4453 - learning_rate: 0.0096\n",
            "Epoch 3/50\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7588 - loss: 0.4854\n",
            "Epoch 3: val_loss did not improve from 0.44534\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7584 - loss: 0.4850 - val_accuracy: 0.8137 - val_loss: 0.6356 - learning_rate: 0.0096\n",
            "Epoch 4/50\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7555 - loss: 0.4572\n",
            "Epoch 4: val_loss improved from 0.44534 to 0.29667, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7557 - loss: 0.4572 - val_accuracy: 0.8676 - val_loss: 0.2967 - learning_rate: 0.0096\n",
            "Epoch 5/50\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7412 - loss: 0.4667\n",
            "Epoch 5: val_loss did not improve from 0.29667\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7421 - loss: 0.4656 - val_accuracy: 0.7884 - val_loss: 0.6210 - learning_rate: 0.0096\n",
            "Epoch 6/50\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7765 - loss: 0.4304\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.003911759793125971.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.29667\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7767 - loss: 0.4304 - val_accuracy: 0.7901 - val_loss: 0.9011 - learning_rate: 0.0096\n",
            "Epoch 7/50\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8078 - loss: 0.3943\n",
            "Epoch 7: val_loss did not improve from 0.29667\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8079 - loss: 0.3937 - val_accuracy: 0.8423 - val_loss: 0.3496 - learning_rate: 0.0039\n",
            "Epoch 8/50\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.3627\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0015923702808250315.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.29667\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8240 - loss: 0.3632 - val_accuracy: 0.8415 - val_loss: 0.4051 - learning_rate: 0.0039\n",
            "Epoch 9/50\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8356 - loss: 0.3450\n",
            "Epoch 9: val_loss did not improve from 0.29667\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8361 - loss: 0.3447 - val_accuracy: 0.8499 - val_loss: 0.3885 - learning_rate: 0.0016\n",
            "Epoch 9: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:05:33,961] Trial 11 finished with value: -0.29667428135871887 and parameters: {'epochs': 50, 'batch_size': 32, 'learning_rate': 0.00960948845595496, 'stop_patience': 5, 'reduce_lr_factor': 0.4070726223427491, 'reduce_lr_patience': 2}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5927 - loss: 0.6760\n",
            "Epoch 1: val_loss improved from inf to 0.38910, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5942 - loss: 0.6746 - val_accuracy: 0.8592 - val_loss: 0.3891 - learning_rate: 0.0035\n",
            "Epoch 2/32\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6877 - loss: 0.5617\n",
            "Epoch 2: val_loss did not improve from 0.38910\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6889 - loss: 0.5607 - val_accuracy: 0.8170 - val_loss: 0.4118 - learning_rate: 0.0035\n",
            "Epoch 3/32\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7246 - loss: 0.5114\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0013984132036259378.\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.38910\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7249 - loss: 0.5110 - val_accuracy: 0.7841 - val_loss: 0.5297 - learning_rate: 0.0035\n",
            "Epoch 4/32\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7988 - loss: 0.4210\n",
            "Epoch 4: val_loss improved from 0.38910 to 0.31995, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7991 - loss: 0.4202 - val_accuracy: 0.8651 - val_loss: 0.3200 - learning_rate: 0.0014\n",
            "Epoch 5/32\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.3872\n",
            "Epoch 5: val_loss improved from 0.31995 to 0.31486, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.3873 - val_accuracy: 0.8744 - val_loss: 0.3149 - learning_rate: 0.0014\n",
            "Epoch 6/32\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8332 - loss: 0.3739\n",
            "Epoch 6: val_loss improved from 0.31486 to 0.29610, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8328 - loss: 0.3741 - val_accuracy: 0.8777 - val_loss: 0.2961 - learning_rate: 0.0014\n",
            "Epoch 7/32\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8343 - loss: 0.3632\n",
            "Epoch 7: val_loss improved from 0.29610 to 0.28173, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8335 - loss: 0.3638 - val_accuracy: 0.8853 - val_loss: 0.2817 - learning_rate: 0.0014\n",
            "Epoch 8/32\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.3549\n",
            "Epoch 8: val_loss did not improve from 0.28173\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8361 - loss: 0.3550 - val_accuracy: 0.8803 - val_loss: 0.3263 - learning_rate: 0.0014\n",
            "Epoch 9/32\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3527\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.000565643439280683.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.28173\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8445 - loss: 0.3527 - val_accuracy: 0.8803 - val_loss: 0.2835 - learning_rate: 0.0014\n",
            "Epoch 10/32\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8607 - loss: 0.3232\n",
            "Epoch 10: val_loss did not improve from 0.28173\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8605 - loss: 0.3235 - val_accuracy: 0.8609 - val_loss: 0.3699 - learning_rate: 5.6564e-04\n",
            "Epoch 11/32\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8564 - loss: 0.3313\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00022879681676652455.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.28173\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 0.3307 - val_accuracy: 0.8769 - val_loss: 0.3127 - learning_rate: 5.6564e-04\n",
            "Epoch 12/32\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8663 - loss: 0.3213\n",
            "Epoch 12: val_loss did not improve from 0.28173\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.3211 - val_accuracy: 0.8600 - val_loss: 0.4256 - learning_rate: 2.2880e-04\n",
            "Epoch 13/32\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8814 - loss: 0.3072\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.254590944194187e-05.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.28173\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8811 - loss: 0.3075 - val_accuracy: 0.8583 - val_loss: 0.4240 - learning_rate: 2.2880e-04\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:05:48,986] Trial 12 finished with value: -0.2817336320877075 and parameters: {'epochs': 32, 'batch_size': 32, 'learning_rate': 0.003457229933869494, 'stop_patience': 6, 'reduce_lr_factor': 0.4044894853261797, 'reduce_lr_patience': 2}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/19\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5651 - loss: 0.6885\n",
            "Epoch 1: val_loss improved from inf to 0.63449, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5655 - loss: 0.6884 - val_accuracy: 0.6981 - val_loss: 0.6345 - learning_rate: 8.9821e-05\n",
            "Epoch 2/19\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6210 - loss: 0.6708\n",
            "Epoch 2: val_loss improved from 0.63449 to 0.60151, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6206 - loss: 0.6707 - val_accuracy: 0.8238 - val_loss: 0.6015 - learning_rate: 8.9821e-05\n",
            "Epoch 3/19\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6462 - loss: 0.6527\n",
            "Epoch 3: val_loss improved from 0.60151 to 0.57413, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6455 - loss: 0.6526 - val_accuracy: 0.8280 - val_loss: 0.5741 - learning_rate: 8.9821e-05\n",
            "Epoch 4/19\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6627 - loss: 0.6386\n",
            "Epoch 4: val_loss improved from 0.57413 to 0.55852, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6622 - loss: 0.6387 - val_accuracy: 0.8120 - val_loss: 0.5585 - learning_rate: 8.9821e-05\n",
            "Epoch 5/19\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6830 - loss: 0.6250\n",
            "Epoch 5: val_loss improved from 0.55852 to 0.53786, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6825 - loss: 0.6248 - val_accuracy: 0.8111 - val_loss: 0.5379 - learning_rate: 8.9821e-05\n",
            "Epoch 6/19\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7023 - loss: 0.6066\n",
            "Epoch 6: val_loss improved from 0.53786 to 0.52593, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7019 - loss: 0.6066 - val_accuracy: 0.8027 - val_loss: 0.5259 - learning_rate: 8.9821e-05\n",
            "Epoch 7/19\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7168 - loss: 0.5922\n",
            "Epoch 7: val_loss improved from 0.52593 to 0.50885, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7168 - loss: 0.5922 - val_accuracy: 0.8010 - val_loss: 0.5088 - learning_rate: 8.9821e-05\n",
            "Epoch 8/19\n",
            "\u001b[1m136/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7342 - loss: 0.5791\n",
            "Epoch 8: val_loss improved from 0.50885 to 0.48983, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7339 - loss: 0.5791 - val_accuracy: 0.8069 - val_loss: 0.4898 - learning_rate: 8.9821e-05\n",
            "Epoch 9/19\n",
            "\u001b[1m134/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7412 - loss: 0.5632\n",
            "Epoch 9: val_loss improved from 0.48983 to 0.48201, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7410 - loss: 0.5633 - val_accuracy: 0.8002 - val_loss: 0.4820 - learning_rate: 8.9821e-05\n",
            "Epoch 10/19\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7528 - loss: 0.5526\n",
            "Epoch 10: val_loss improved from 0.48201 to 0.47284, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7525 - loss: 0.5527 - val_accuracy: 0.8002 - val_loss: 0.4728 - learning_rate: 8.9821e-05\n",
            "Epoch 11/19\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7669 - loss: 0.5359\n",
            "Epoch 11: val_loss improved from 0.47284 to 0.44597, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7669 - loss: 0.5359 - val_accuracy: 0.8187 - val_loss: 0.4460 - learning_rate: 8.9821e-05\n",
            "Epoch 12/19\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7661 - loss: 0.5296\n",
            "Epoch 12: val_loss improved from 0.44597 to 0.43253, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7660 - loss: 0.5296 - val_accuracy: 0.8263 - val_loss: 0.4325 - learning_rate: 8.9821e-05\n",
            "Epoch 13/19\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7780 - loss: 0.5142\n",
            "Epoch 13: val_loss did not improve from 0.43253\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7779 - loss: 0.5142 - val_accuracy: 0.8238 - val_loss: 0.4333 - learning_rate: 8.9821e-05\n",
            "Epoch 14/19\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.5039\n",
            "Epoch 14: val_loss improved from 0.43253 to 0.41148, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7926 - loss: 0.5039 - val_accuracy: 0.8339 - val_loss: 0.4115 - learning_rate: 8.9821e-05\n",
            "Epoch 15/19\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7879 - loss: 0.4950\n",
            "Epoch 15: val_loss did not improve from 0.41148\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7879 - loss: 0.4950 - val_accuracy: 0.8322 - val_loss: 0.4178 - learning_rate: 8.9821e-05\n",
            "Epoch 16/19\n",
            "\u001b[1m136/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7888 - loss: 0.4850\n",
            "Epoch 16: val_loss did not improve from 0.41148\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7888 - loss: 0.4851 - val_accuracy: 0.8322 - val_loss: 0.4175 - learning_rate: 8.9821e-05\n",
            "Epoch 17/19\n",
            "\u001b[1m134/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7975 - loss: 0.4774\n",
            "Epoch 17: val_loss improved from 0.41148 to 0.39561, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7971 - loss: 0.4776 - val_accuracy: 0.8364 - val_loss: 0.3956 - learning_rate: 8.9821e-05\n",
            "Epoch 18/19\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.4691\n",
            "Epoch 18: val_loss improved from 0.39561 to 0.39490, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8035 - loss: 0.4691 - val_accuracy: 0.8373 - val_loss: 0.3949 - learning_rate: 8.9821e-05\n",
            "Epoch 19/19\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8111 - loss: 0.4591\n",
            "Epoch 19: val_loss did not improve from 0.39490\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8106 - loss: 0.4593 - val_accuracy: 0.8305 - val_loss: 0.4261 - learning_rate: 8.9821e-05\n",
            "Restoring model weights from the end of the best epoch: 18.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:06:13,136] Trial 13 finished with value: -0.39490076899528503 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 8.982054548587522e-05, 'stop_patience': 6, 'reduce_lr_factor': 0.24052313846058773, 'reduce_lr_patience': 3}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/42\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5667 - loss: 0.6872\n",
            "Epoch 1: val_loss improved from inf to 0.44549, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5709 - loss: 0.6841 - val_accuracy: 0.8465 - val_loss: 0.4455 - learning_rate: 0.0039\n",
            "Epoch 2/42\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7060 - loss: 0.5696\n",
            "Epoch 2: val_loss improved from 0.44549 to 0.33863, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7072 - loss: 0.5674 - val_accuracy: 0.8550 - val_loss: 0.3386 - learning_rate: 0.0039\n",
            "Epoch 3/42\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7601 - loss: 0.4809\n",
            "Epoch 3: val_loss did not improve from 0.33863\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7599 - loss: 0.4810 - val_accuracy: 0.8052 - val_loss: 0.4130 - learning_rate: 0.0039\n",
            "Epoch 4/42\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7685 - loss: 0.4540\n",
            "Epoch 4: val_loss improved from 0.33863 to 0.29818, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7686 - loss: 0.4538 - val_accuracy: 0.8668 - val_loss: 0.2982 - learning_rate: 0.0039\n",
            "Epoch 5/42\n",
            "\u001b[1m64/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7650 - loss: 0.4473\n",
            "Epoch 5: val_loss improved from 0.29818 to 0.28313, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7676 - loss: 0.4450 - val_accuracy: 0.8761 - val_loss: 0.2831 - learning_rate: 0.0039\n",
            "Epoch 6/42\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7728 - loss: 0.4325\n",
            "Epoch 6: val_loss did not improve from 0.28313\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7739 - loss: 0.4316 - val_accuracy: 0.8432 - val_loss: 0.3733 - learning_rate: 0.0039\n",
            "Epoch 7/42\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8008 - loss: 0.4026\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0017211010707286214.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.28313\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7990 - loss: 0.4048 - val_accuracy: 0.8440 - val_loss: 0.3789 - learning_rate: 0.0039\n",
            "Epoch 8/42\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8289 - loss: 0.3791\n",
            "Epoch 8: val_loss did not improve from 0.28313\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8289 - loss: 0.3787 - val_accuracy: 0.8727 - val_loss: 0.3388 - learning_rate: 0.0017\n",
            "Epoch 9/42\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8267 - loss: 0.3751\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0007622200197337854.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.28313\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8271 - loss: 0.3745 - val_accuracy: 0.8794 - val_loss: 0.2976 - learning_rate: 0.0017\n",
            "Epoch 10/42\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8277 - loss: 0.3620\n",
            "Epoch 10: val_loss did not improve from 0.28313\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8291 - loss: 0.3605 - val_accuracy: 0.8533 - val_loss: 0.4584 - learning_rate: 7.6222e-04\n",
            "Epoch 11/42\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8645 - loss: 0.3311\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0003375625891144055.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.28313\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8643 - loss: 0.3310 - val_accuracy: 0.8592 - val_loss: 0.4295 - learning_rate: 7.6222e-04\n",
            "Epoch 12/42\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8677 - loss: 0.3244\n",
            "Epoch 12: val_loss did not improve from 0.28313\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8673 - loss: 0.3243 - val_accuracy: 0.8685 - val_loss: 0.3556 - learning_rate: 3.3756e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:06:22,928] Trial 14 finished with value: -0.28313350677490234 and parameters: {'epochs': 42, 'batch_size': 64, 'learning_rate': 0.003886264874651091, 'stop_patience': 7, 'reduce_lr_factor': 0.4428676579780913, 'reduce_lr_patience': 2}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5907 - loss: 0.6743\n",
            "Epoch 1: val_loss improved from inf to 0.44796, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5918 - loss: 0.6734 - val_accuracy: 0.8381 - val_loss: 0.4480 - learning_rate: 0.0011\n",
            "Epoch 2/35\n",
            "\u001b[1m135/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7011 - loss: 0.5845\n",
            "Epoch 2: val_loss improved from 0.44796 to 0.36256, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7026 - loss: 0.5823 - val_accuracy: 0.8449 - val_loss: 0.3626 - learning_rate: 0.0011\n",
            "Epoch 3/35\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7386 - loss: 0.5136\n",
            "Epoch 3: val_loss improved from 0.36256 to 0.35393, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7391 - loss: 0.5129 - val_accuracy: 0.8482 - val_loss: 0.3539 - learning_rate: 0.0011\n",
            "Epoch 4/35\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7736 - loss: 0.4648\n",
            "Epoch 4: val_loss did not improve from 0.35393\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7734 - loss: 0.4648 - val_accuracy: 0.8297 - val_loss: 0.4352 - learning_rate: 0.0011\n",
            "Epoch 5/35\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7920 - loss: 0.4394\n",
            "Epoch 5: val_loss improved from 0.35393 to 0.31839, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7920 - loss: 0.4394 - val_accuracy: 0.8609 - val_loss: 0.3184 - learning_rate: 0.0011\n",
            "Epoch 6/35\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.4219\n",
            "Epoch 6: val_loss did not improve from 0.31839\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7994 - loss: 0.4219 - val_accuracy: 0.8626 - val_loss: 0.3460 - learning_rate: 0.0011\n",
            "Epoch 7/35\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8072 - loss: 0.4045\n",
            "Epoch 7: val_loss did not improve from 0.31839\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8072 - loss: 0.4045 - val_accuracy: 0.8592 - val_loss: 0.3580 - learning_rate: 0.0011\n",
            "Epoch 8/35\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8151 - loss: 0.3925\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0004062675682495795.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.31839\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8146 - loss: 0.3927 - val_accuracy: 0.8575 - val_loss: 0.3608 - learning_rate: 0.0011\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:06:34,228] Trial 15 finished with value: -0.3183938264846802 and parameters: {'epochs': 35, 'batch_size': 32, 'learning_rate': 0.0010743563890948044, 'stop_patience': 3, 'reduce_lr_factor': 0.37814972503725447, 'reduce_lr_patience': 3}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5789 - loss: 0.6824\n",
            "Epoch 1: val_loss improved from inf to 0.40933, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5805 - loss: 0.6810 - val_accuracy: 0.8390 - val_loss: 0.4093 - learning_rate: 0.0043\n",
            "Epoch 2/45\n",
            "\u001b[1m134/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7200 - loss: 0.5509\n",
            "Epoch 2: val_loss improved from 0.40933 to 0.39762, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7219 - loss: 0.5481 - val_accuracy: 0.8406 - val_loss: 0.3976 - learning_rate: 0.0043\n",
            "Epoch 3/45\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7347 - loss: 0.5117\n",
            "Epoch 3: val_loss did not improve from 0.39762\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7358 - loss: 0.5103 - val_accuracy: 0.8229 - val_loss: 0.4444 - learning_rate: 0.0043\n",
            "Epoch 4/45\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7632 - loss: 0.4633\n",
            "Epoch 4: val_loss improved from 0.39762 to 0.34724, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7631 - loss: 0.4634 - val_accuracy: 0.8592 - val_loss: 0.3472 - learning_rate: 0.0043\n",
            "Epoch 5/45\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7848 - loss: 0.4278\n",
            "Epoch 5: val_loss did not improve from 0.34724\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7842 - loss: 0.4284 - val_accuracy: 0.8499 - val_loss: 0.3662 - learning_rate: 0.0043\n",
            "Epoch 6/45\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7903 - loss: 0.4138\n",
            "Epoch 6: val_loss did not improve from 0.34724\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 0.4137 - val_accuracy: 0.8457 - val_loss: 0.5116 - learning_rate: 0.0043\n",
            "Epoch 7/45\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7896 - loss: 0.4036\n",
            "Epoch 7: val_loss improved from 0.34724 to 0.32797, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7895 - loss: 0.4037 - val_accuracy: 0.8702 - val_loss: 0.3280 - learning_rate: 0.0043\n",
            "Epoch 8/45\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8044 - loss: 0.3876\n",
            "Epoch 8: val_loss did not improve from 0.32797\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8042 - loss: 0.3878 - val_accuracy: 0.8609 - val_loss: 0.3601 - learning_rate: 0.0043\n",
            "Epoch 9/45\n",
            "\u001b[1m133/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8039 - loss: 0.4014\n",
            "Epoch 9: val_loss did not improve from 0.32797\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8036 - loss: 0.4011 - val_accuracy: 0.8642 - val_loss: 0.4588 - learning_rate: 0.0043\n",
            "Epoch 10/45\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8276 - loss: 0.3636\n",
            "Epoch 10: val_loss did not improve from 0.32797\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8270 - loss: 0.3647 - val_accuracy: 0.8550 - val_loss: 0.4141 - learning_rate: 0.0043\n",
            "Epoch 11/45\n",
            "\u001b[1m146/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8030 - loss: 0.3959\n",
            "Epoch 11: val_loss did not improve from 0.32797\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.3958 - val_accuracy: 0.8449 - val_loss: 0.5579 - learning_rate: 0.0043\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:06:49,303] Trial 16 finished with value: -0.3279690146446228 and parameters: {'epochs': 45, 'batch_size': 32, 'learning_rate': 0.004334114584557123, 'stop_patience': 4, 'reduce_lr_factor': 0.36336491960006756, 'reduce_lr_patience': 5}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/28\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5740 - loss: 0.6758\n",
            "Epoch 1: val_loss improved from inf to 0.44424, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5758 - loss: 0.6745 - val_accuracy: 0.8415 - val_loss: 0.4442 - learning_rate: 0.0017\n",
            "Epoch 2/28\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6993 - loss: 0.5692\n",
            "Epoch 2: val_loss improved from 0.44424 to 0.34990, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6994 - loss: 0.5691 - val_accuracy: 0.8592 - val_loss: 0.3499 - learning_rate: 0.0017\n",
            "Epoch 3/28\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7554 - loss: 0.4906\n",
            "Epoch 3: val_loss improved from 0.34990 to 0.31063, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7554 - loss: 0.4905 - val_accuracy: 0.8668 - val_loss: 0.3106 - learning_rate: 0.0017\n",
            "Epoch 4/28\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7817 - loss: 0.4430\n",
            "Epoch 4: val_loss improved from 0.31063 to 0.30705, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7816 - loss: 0.4431 - val_accuracy: 0.8600 - val_loss: 0.3070 - learning_rate: 0.0017\n",
            "Epoch 5/28\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: 0.4240\n",
            "Epoch 5: val_loss did not improve from 0.30705\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.4241 - val_accuracy: 0.8693 - val_loss: 0.3116 - learning_rate: 0.0017\n",
            "Epoch 6/28\n",
            "\u001b[1m135/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.4032\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00041016573030284737.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.30705\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.4043 - val_accuracy: 0.8676 - val_loss: 0.3256 - learning_rate: 0.0017\n",
            "Epoch 7/28\n",
            "\u001b[1m135/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8315 - loss: 0.3765\n",
            "Epoch 7: val_loss improved from 0.30705 to 0.28701, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8314 - loss: 0.3760 - val_accuracy: 0.8845 - val_loss: 0.2870 - learning_rate: 4.1017e-04\n",
            "Epoch 8/28\n",
            "\u001b[1m133/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.3642\n",
            "Epoch 8: val_loss did not improve from 0.28701\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8378 - loss: 0.3639 - val_accuracy: 0.8794 - val_loss: 0.3074 - learning_rate: 4.1017e-04\n",
            "Epoch 9/28\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8382 - loss: 0.3583\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010152073519528535.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.28701\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8384 - loss: 0.3581 - val_accuracy: 0.8853 - val_loss: 0.2901 - learning_rate: 4.1017e-04\n",
            "Epoch 10/28\n",
            "\u001b[1m133/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8534 - loss: 0.3472\n",
            "Epoch 10: val_loss did not improve from 0.28701\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8537 - loss: 0.3467 - val_accuracy: 0.8668 - val_loss: 0.3624 - learning_rate: 1.0152e-04\n",
            "Epoch 11/28\n",
            "\u001b[1m133/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.3321\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.512755049991953e-05.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.28701\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8716 - loss: 0.3325 - val_accuracy: 0.8600 - val_loss: 0.3819 - learning_rate: 1.0152e-04\n",
            "Epoch 12/28\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8732 - loss: 0.3315\n",
            "Epoch 12: val_loss did not improve from 0.28701\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8725 - loss: 0.3315 - val_accuracy: 0.8702 - val_loss: 0.3574 - learning_rate: 2.5128e-05\n",
            "Epoch 13/28\n",
            "\u001b[1m143/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8704 - loss: 0.3316\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.21935780849361e-06.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.28701\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8702 - loss: 0.3317 - val_accuracy: 0.8676 - val_loss: 0.3626 - learning_rate: 2.5128e-05\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:07:05,665] Trial 17 finished with value: -0.2870078682899475 and parameters: {'epochs': 28, 'batch_size': 32, 'learning_rate': 0.0016571582661099827, 'stop_patience': 6, 'reduce_lr_factor': 0.2475115032701272, 'reduce_lr_patience': 2}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/21\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5797 - loss: 0.6803\n",
            "Epoch 1: val_loss improved from inf to 0.37657, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5821 - loss: 0.6781 - val_accuracy: 0.8541 - val_loss: 0.3766 - learning_rate: 0.0076\n",
            "Epoch 2/21\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7194 - loss: 0.5404\n",
            "Epoch 2: val_loss improved from 0.37657 to 0.32935, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7201 - loss: 0.5389 - val_accuracy: 0.8499 - val_loss: 0.3294 - learning_rate: 0.0076\n",
            "Epoch 3/21\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7500 - loss: 0.4797\n",
            "Epoch 3: val_loss did not improve from 0.32935\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7501 - loss: 0.4798 - val_accuracy: 0.8314 - val_loss: 0.4111 - learning_rate: 0.0076\n",
            "Epoch 4/21\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7506 - loss: 0.4717\n",
            "Epoch 4: val_loss did not improve from 0.32935\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7516 - loss: 0.4705 - val_accuracy: 0.8668 - val_loss: 0.3349 - learning_rate: 0.0076\n",
            "Epoch 5/21\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7765 - loss: 0.4432\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0033630335622098838.\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.32935\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7779 - loss: 0.4417 - val_accuracy: 0.8499 - val_loss: 0.3547 - learning_rate: 0.0076\n",
            "Epoch 6/21\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8109 - loss: 0.3883\n",
            "Epoch 6: val_loss improved from 0.32935 to 0.28462, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8109 - loss: 0.3886 - val_accuracy: 0.8870 - val_loss: 0.2846 - learning_rate: 0.0034\n",
            "Epoch 7/21\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8122 - loss: 0.3897\n",
            "Epoch 7: val_loss improved from 0.28462 to 0.27822, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8133 - loss: 0.3879 - val_accuracy: 0.8752 - val_loss: 0.2782 - learning_rate: 0.0034\n",
            "Epoch 8/21\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.3699\n",
            "Epoch 8: val_loss did not improve from 0.27822\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8253 - loss: 0.3690 - val_accuracy: 0.8777 - val_loss: 0.2824 - learning_rate: 0.0034\n",
            "Epoch 9/21\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8365 - loss: 0.3507\n",
            "Epoch 9: val_loss did not improve from 0.27822\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8366 - loss: 0.3507 - val_accuracy: 0.8794 - val_loss: 0.2797 - learning_rate: 0.0034\n",
            "Epoch 10/21\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8375 - loss: 0.3463\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0014974547360357938.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.27822\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 0.3476 - val_accuracy: 0.8761 - val_loss: 0.2934 - learning_rate: 0.0034\n",
            "Epoch 11/21\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8352 - loss: 0.3486\n",
            "Epoch 11: val_loss did not improve from 0.27822\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8367 - loss: 0.3473 - val_accuracy: 0.8482 - val_loss: 0.3932 - learning_rate: 0.0015\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:07:14,993] Trial 18 finished with value: -0.27822187542915344 and parameters: {'epochs': 21, 'batch_size': 64, 'learning_rate': 0.007552812383666452, 'stop_patience': 4, 'reduce_lr_factor': 0.4452690481512958, 'reduce_lr_patience': 3}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/38\n",
            "\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5595 - loss: 0.6983\n",
            "Epoch 1: val_loss improved from inf to 0.63304, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5597 - loss: 0.6977 - val_accuracy: 0.5801 - val_loss: 0.6330 - learning_rate: 0.0096\n",
            "Epoch 2/38\n",
            "\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6271 - loss: 0.6146\n",
            "Epoch 2: val_loss improved from 0.63304 to 0.34602, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6279 - loss: 0.6141 - val_accuracy: 0.8727 - val_loss: 0.3460 - learning_rate: 0.0096\n",
            "Epoch 3/38\n",
            "\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7130 - loss: 0.5228\n",
            "Epoch 3: val_loss improved from 0.34602 to 0.27825, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7136 - loss: 0.5222 - val_accuracy: 0.8803 - val_loss: 0.2782 - learning_rate: 0.0096\n",
            "Epoch 4/38\n",
            "\u001b[1m283/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7280 - loss: 0.5016\n",
            "Epoch 4: val_loss did not improve from 0.27825\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7292 - loss: 0.5004 - val_accuracy: 0.8465 - val_loss: 0.3606 - learning_rate: 0.0096\n",
            "Epoch 5/38\n",
            "\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.4704\n",
            "Epoch 5: val_loss did not improve from 0.27825\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7430 - loss: 0.4705 - val_accuracy: 0.7605 - val_loss: 0.5316 - learning_rate: 0.0096\n",
            "Epoch 6/38\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7664 - loss: 0.4605\n",
            "Epoch 6: val_loss did not improve from 0.27825\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7665 - loss: 0.4603 - val_accuracy: 0.8440 - val_loss: 0.3406 - learning_rate: 0.0096\n",
            "Epoch 7/38\n",
            "\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7711 - loss: 0.4340\n",
            "Epoch 7: val_loss did not improve from 0.27825\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7712 - loss: 0.4339 - val_accuracy: 0.8314 - val_loss: 0.5379 - learning_rate: 0.0096\n",
            "Epoch 8/38\n",
            "\u001b[1m279/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7614 - loss: 0.4421\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0026790230615063504.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.27825\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7624 - loss: 0.4415 - val_accuracy: 0.8339 - val_loss: 0.4166 - learning_rate: 0.0096\n",
            "Epoch 9/38\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8201 - loss: 0.3777\n",
            "Epoch 9: val_loss did not improve from 0.27825\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8205 - loss: 0.3773 - val_accuracy: 0.8567 - val_loss: 0.3065 - learning_rate: 0.0027\n",
            "Epoch 10/38\n",
            "\u001b[1m280/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8493 - loss: 0.3432\n",
            "Epoch 10: val_loss did not improve from 0.27825\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8492 - loss: 0.3435 - val_accuracy: 0.8457 - val_loss: 0.3156 - learning_rate: 0.0027\n",
            "Epoch 11/38\n",
            "\u001b[1m280/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8500 - loss: 0.3300\n",
            "Epoch 11: val_loss did not improve from 0.27825\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8501 - loss: 0.3302 - val_accuracy: 0.8693 - val_loss: 0.2990 - learning_rate: 0.0027\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:07:34,315] Trial 19 finished with value: -0.2782479226589203 and parameters: {'epochs': 38, 'batch_size': 16, 'learning_rate': 0.009602037258876307, 'stop_patience': 8, 'reduce_lr_factor': 0.27900569320847074, 'reduce_lr_patience': 5}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5617 - loss: 0.6945\n",
            "Epoch 1: val_loss improved from inf to 0.47413, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5630 - loss: 0.6925 - val_accuracy: 0.8465 - val_loss: 0.4741 - learning_rate: 0.0047\n",
            "Epoch 2/45\n",
            "\u001b[1m136/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6875 - loss: 0.5893\n",
            "Epoch 2: val_loss improved from 0.47413 to 0.36740, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6881 - loss: 0.5881 - val_accuracy: 0.8499 - val_loss: 0.3674 - learning_rate: 0.0047\n",
            "Epoch 3/45\n",
            "\u001b[1m133/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.5089\n",
            "Epoch 3: val_loss did not improve from 0.36740\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7330 - loss: 0.5070 - val_accuracy: 0.8204 - val_loss: 0.4004 - learning_rate: 0.0047\n",
            "Epoch 4/45\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7596 - loss: 0.4691\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.002128689102637383.\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.36740\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7593 - loss: 0.4691 - val_accuracy: 0.8272 - val_loss: 0.4488 - learning_rate: 0.0047\n",
            "Epoch 5/45\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7863 - loss: 0.4281\n",
            "Epoch 5: val_loss improved from 0.36740 to 0.28225, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7862 - loss: 0.4273 - val_accuracy: 0.8777 - val_loss: 0.2822 - learning_rate: 0.0021\n",
            "Epoch 6/45\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8058 - loss: 0.3850\n",
            "Epoch 6: val_loss did not improve from 0.28225\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.3858 - val_accuracy: 0.8735 - val_loss: 0.3154 - learning_rate: 0.0021\n",
            "Epoch 7/45\n",
            "\u001b[1m134/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.3734\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009648846014186548.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.28225\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.3743 - val_accuracy: 0.8786 - val_loss: 0.3253 - learning_rate: 0.0021\n",
            "Epoch 8/45\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8353 - loss: 0.3559\n",
            "Epoch 8: val_loss did not improve from 0.28225\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8354 - loss: 0.3558 - val_accuracy: 0.8744 - val_loss: 0.2882 - learning_rate: 9.6488e-04\n",
            "Epoch 9/45\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8487 - loss: 0.3416\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00043735944720390315.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.28225\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8489 - loss: 0.3415 - val_accuracy: 0.8567 - val_loss: 0.3348 - learning_rate: 9.6488e-04\n",
            "Epoch 10/45\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8675 - loss: 0.3191\n",
            "Epoch 10: val_loss did not improve from 0.28225\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8674 - loss: 0.3191 - val_accuracy: 0.8482 - val_loss: 0.4287 - learning_rate: 4.3736e-04\n",
            "Epoch 11/45\n",
            "\u001b[1m136/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8647 - loss: 0.3222\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00019824472911787768.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.28225\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8650 - loss: 0.3218 - val_accuracy: 0.8516 - val_loss: 0.4207 - learning_rate: 4.3736e-04\n",
            "Epoch 12/45\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8776 - loss: 0.3160\n",
            "Epoch 12: val_loss did not improve from 0.28225\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8771 - loss: 0.3159 - val_accuracy: 0.8499 - val_loss: 0.4245 - learning_rate: 1.9824e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:07:46,348] Trial 20 finished with value: -0.2822488248348236 and parameters: {'epochs': 45, 'batch_size': 32, 'learning_rate': 0.004696227322695055, 'stop_patience': 7, 'reduce_lr_factor': 0.4532764359903439, 'reduce_lr_patience': 2}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/38\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5938 - loss: 0.6672\n",
            "Epoch 1: val_loss improved from inf to 0.44338, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5953 - loss: 0.6658 - val_accuracy: 0.8187 - val_loss: 0.4434 - learning_rate: 0.0025\n",
            "Epoch 2/38\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7268 - loss: 0.5534\n",
            "Epoch 2: val_loss did not improve from 0.44338\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7268 - loss: 0.5522 - val_accuracy: 0.8120 - val_loss: 0.4444 - learning_rate: 0.0025\n",
            "Epoch 3/38\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7375 - loss: 0.5031\n",
            "Epoch 3: val_loss improved from 0.44338 to 0.32001, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7398 - loss: 0.5015 - val_accuracy: 0.8600 - val_loss: 0.3200 - learning_rate: 0.0025\n",
            "Epoch 4/38\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7644 - loss: 0.4702\n",
            "Epoch 4: val_loss improved from 0.32001 to 0.31254, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7658 - loss: 0.4688 - val_accuracy: 0.8685 - val_loss: 0.3125 - learning_rate: 0.0025\n",
            "Epoch 5/38\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7837 - loss: 0.4393\n",
            "Epoch 5: val_loss improved from 0.31254 to 0.30599, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7839 - loss: 0.4393 - val_accuracy: 0.8718 - val_loss: 0.3060 - learning_rate: 0.0025\n",
            "Epoch 6/38\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7817 - loss: 0.4268\n",
            "Epoch 6: val_loss did not improve from 0.30599\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7821 - loss: 0.4269 - val_accuracy: 0.8693 - val_loss: 0.3335 - learning_rate: 0.0025\n",
            "Epoch 7/38\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7933 - loss: 0.4148\n",
            "Epoch 7: val_loss did not improve from 0.30599\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7938 - loss: 0.4142 - val_accuracy: 0.8600 - val_loss: 0.3310 - learning_rate: 0.0025\n",
            "Epoch 8/38\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 0.3969\n",
            "Epoch 8: val_loss did not improve from 0.30599\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8026 - loss: 0.3974 - val_accuracy: 0.8600 - val_loss: 0.3220 - learning_rate: 0.0025\n",
            "Epoch 9/38\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7963 - loss: 0.4090\n",
            "Epoch 9: val_loss improved from 0.30599 to 0.30114, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7964 - loss: 0.4088 - val_accuracy: 0.8626 - val_loss: 0.3011 - learning_rate: 0.0025\n",
            "Epoch 10/38\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8027 - loss: 0.3963\n",
            "Epoch 10: val_loss improved from 0.30114 to 0.28613, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8038 - loss: 0.3956 - val_accuracy: 0.8786 - val_loss: 0.2861 - learning_rate: 0.0025\n",
            "Epoch 11/38\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8066 - loss: 0.3883\n",
            "Epoch 11: val_loss improved from 0.28613 to 0.27669, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8069 - loss: 0.3881 - val_accuracy: 0.8836 - val_loss: 0.2767 - learning_rate: 0.0025\n",
            "Epoch 12/38\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8060 - loss: 0.3843\n",
            "Epoch 12: val_loss did not improve from 0.27669\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8063 - loss: 0.3842 - val_accuracy: 0.8659 - val_loss: 0.3157 - learning_rate: 0.0025\n",
            "Epoch 13/38\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8085 - loss: 0.3942\n",
            "Epoch 13: val_loss did not improve from 0.27669\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8096 - loss: 0.3927 - val_accuracy: 0.8600 - val_loss: 0.3309 - learning_rate: 0.0025\n",
            "Epoch 14/38\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8155 - loss: 0.3820\n",
            "Epoch 14: val_loss improved from 0.27669 to 0.27031, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8156 - loss: 0.3817 - val_accuracy: 0.8879 - val_loss: 0.2703 - learning_rate: 0.0025\n",
            "Epoch 15/38\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8274 - loss: 0.3594\n",
            "Epoch 15: val_loss did not improve from 0.27031\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8273 - loss: 0.3600 - val_accuracy: 0.8845 - val_loss: 0.2795 - learning_rate: 0.0025\n",
            "Epoch 16/38\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8365 - loss: 0.3485\n",
            "Epoch 16: val_loss did not improve from 0.27031\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8363 - loss: 0.3490 - val_accuracy: 0.8735 - val_loss: 0.2999 - learning_rate: 0.0025\n",
            "Epoch 17/38\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8105 - loss: 0.3847\n",
            "Epoch 17: val_loss did not improve from 0.27031\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8107 - loss: 0.3847 - val_accuracy: 0.8870 - val_loss: 0.2707 - learning_rate: 0.0025\n",
            "Epoch 18/38\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8202 - loss: 0.3656\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0012045565733248603.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.27031\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8208 - loss: 0.3653 - val_accuracy: 0.8870 - val_loss: 0.2790 - learning_rate: 0.0025\n",
            "Epoch 19/38\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8561 - loss: 0.3210\n",
            "Epoch 19: val_loss did not improve from 0.27031\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8563 - loss: 0.3214 - val_accuracy: 0.8718 - val_loss: 0.3285 - learning_rate: 0.0012\n",
            "Epoch 20/38\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8506 - loss: 0.3351\n",
            "Epoch 20: val_loss did not improve from 0.27031\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8512 - loss: 0.3342 - val_accuracy: 0.8794 - val_loss: 0.3190 - learning_rate: 0.0012\n",
            "Epoch 21/38\n",
            "\u001b[1m63/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8448 - loss: 0.3344\n",
            "Epoch 21: val_loss did not improve from 0.27031\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8467 - loss: 0.3328 - val_accuracy: 0.8702 - val_loss: 0.3872 - learning_rate: 0.0012\n",
            "Epoch 22/38\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8500 - loss: 0.3344\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005890961507797242.\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.27031\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8510 - loss: 0.3328 - val_accuracy: 0.8718 - val_loss: 0.3460 - learning_rate: 0.0012\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:08:02,567] Trial 21 finished with value: -0.27030840516090393 and parameters: {'epochs': 38, 'batch_size': 64, 'learning_rate': 0.002463021541868752, 'stop_patience': 8, 'reduce_lr_factor': 0.48905644941499343, 'reduce_lr_patience': 4}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/31\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5798 - loss: 0.6804\n",
            "Epoch 1: val_loss improved from inf to 0.43324, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5821 - loss: 0.6788 - val_accuracy: 0.8609 - val_loss: 0.4332 - learning_rate: 0.0030\n",
            "Epoch 2/31\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7047 - loss: 0.5739\n",
            "Epoch 2: val_loss improved from 0.43324 to 0.35024, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7053 - loss: 0.5729 - val_accuracy: 0.8516 - val_loss: 0.3502 - learning_rate: 0.0030\n",
            "Epoch 3/31\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7310 - loss: 0.5177\n",
            "Epoch 3: val_loss improved from 0.35024 to 0.34591, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7319 - loss: 0.5168 - val_accuracy: 0.8491 - val_loss: 0.3459 - learning_rate: 0.0030\n",
            "Epoch 4/31\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7779 - loss: 0.4513\n",
            "Epoch 4: val_loss improved from 0.34591 to 0.33453, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7778 - loss: 0.4511 - val_accuracy: 0.8558 - val_loss: 0.3345 - learning_rate: 0.0030\n",
            "Epoch 5/31\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7900 - loss: 0.4342\n",
            "Epoch 5: val_loss improved from 0.33453 to 0.30326, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7899 - loss: 0.4341 - val_accuracy: 0.8744 - val_loss: 0.3033 - learning_rate: 0.0030\n",
            "Epoch 6/31\n",
            "\u001b[1m64/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7924 - loss: 0.4089\n",
            "Epoch 6: val_loss did not improve from 0.30326\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7929 - loss: 0.4102 - val_accuracy: 0.8777 - val_loss: 0.3036 - learning_rate: 0.0030\n",
            "Epoch 7/31\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8084 - loss: 0.3967\n",
            "Epoch 7: val_loss did not improve from 0.30326\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.3969 - val_accuracy: 0.8524 - val_loss: 0.3469 - learning_rate: 0.0030\n",
            "Epoch 8/31\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8048 - loss: 0.3948\n",
            "Epoch 8: val_loss did not improve from 0.30326\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8046 - loss: 0.3946 - val_accuracy: 0.7901 - val_loss: 0.6283 - learning_rate: 0.0030\n",
            "Epoch 9/31\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7910 - loss: 0.4120\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0014801371375467596.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.30326\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7939 - loss: 0.4091 - val_accuracy: 0.8153 - val_loss: 0.4627 - learning_rate: 0.0030\n",
            "Epoch 10/31\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8201 - loss: 0.3775\n",
            "Epoch 10: val_loss did not improve from 0.30326\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8207 - loss: 0.3765 - val_accuracy: 0.8718 - val_loss: 0.3595 - learning_rate: 0.0015\n",
            "Epoch 11/31\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8362 - loss: 0.3586\n",
            "Epoch 11: val_loss did not improve from 0.30326\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8369 - loss: 0.3579 - val_accuracy: 0.8685 - val_loss: 0.3758 - learning_rate: 0.0015\n",
            "Epoch 12/31\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 0.3621\n",
            "Epoch 12: val_loss did not improve from 0.30326\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8366 - loss: 0.3608 - val_accuracy: 0.8744 - val_loss: 0.3559 - learning_rate: 0.0015\n",
            "Epoch 13/31\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8365 - loss: 0.3511\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007394274434013626.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.30326\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8376 - loss: 0.3500 - val_accuracy: 0.8761 - val_loss: 0.3255 - learning_rate: 0.0015\n",
            "Epoch 14/31\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 0.3397\n",
            "Epoch 14: val_loss did not improve from 0.30326\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8497 - loss: 0.3386 - val_accuracy: 0.8609 - val_loss: 0.4407 - learning_rate: 7.3943e-04\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:08:14,856] Trial 22 finished with value: -0.30325737595558167 and parameters: {'epochs': 31, 'batch_size': 64, 'learning_rate': 0.0029628408796121123, 'stop_patience': 9, 'reduce_lr_factor': 0.4995668551251531, 'reduce_lr_patience': 4}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/36\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5774 - loss: 0.6796\n",
            "Epoch 1: val_loss improved from inf to 0.49023, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5828 - loss: 0.6766 - val_accuracy: 0.8246 - val_loss: 0.4902 - learning_rate: 0.0013\n",
            "Epoch 2/36\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6886 - loss: 0.5920\n",
            "Epoch 2: val_loss improved from 0.49023 to 0.35931, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6899 - loss: 0.5903 - val_accuracy: 0.8533 - val_loss: 0.3593 - learning_rate: 0.0013\n",
            "Epoch 3/36\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7647 - loss: 0.5164\n",
            "Epoch 3: val_loss did not improve from 0.35931\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7634 - loss: 0.5161 - val_accuracy: 0.8288 - val_loss: 0.3708 - learning_rate: 0.0013\n",
            "Epoch 4/36\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7686 - loss: 0.4750\n",
            "Epoch 4: val_loss improved from 0.35931 to 0.33390, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7685 - loss: 0.4747 - val_accuracy: 0.8642 - val_loss: 0.3339 - learning_rate: 0.0013\n",
            "Epoch 5/36\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7957 - loss: 0.4409\n",
            "Epoch 5: val_loss did not improve from 0.33390\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7947 - loss: 0.4411 - val_accuracy: 0.8406 - val_loss: 0.4035 - learning_rate: 0.0013\n",
            "Epoch 6/36\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.4432\n",
            "Epoch 6: val_loss improved from 0.33390 to 0.30091, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7852 - loss: 0.4420 - val_accuracy: 0.8626 - val_loss: 0.3009 - learning_rate: 0.0013\n",
            "Epoch 7/36\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.4189\n",
            "Epoch 7: val_loss did not improve from 0.30091\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.4176 - val_accuracy: 0.8626 - val_loss: 0.3101 - learning_rate: 0.0013\n",
            "Epoch 8/36\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8012 - loss: 0.4129\n",
            "Epoch 8: val_loss improved from 0.30091 to 0.28984, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8013 - loss: 0.4128 - val_accuracy: 0.8676 - val_loss: 0.2898 - learning_rate: 0.0013\n",
            "Epoch 9/36\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7963 - loss: 0.4159\n",
            "Epoch 9: val_loss improved from 0.28984 to 0.28894, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7969 - loss: 0.4150 - val_accuracy: 0.8752 - val_loss: 0.2889 - learning_rate: 0.0013\n",
            "Epoch 10/36\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.3967\n",
            "Epoch 10: val_loss did not improve from 0.28894\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8043 - loss: 0.3956 - val_accuracy: 0.8761 - val_loss: 0.2928 - learning_rate: 0.0013\n",
            "Epoch 11/36\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8166 - loss: 0.3862\n",
            "Epoch 11: val_loss improved from 0.28894 to 0.28628, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8170 - loss: 0.3860 - val_accuracy: 0.8786 - val_loss: 0.2863 - learning_rate: 0.0013\n",
            "Epoch 12/36\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8286 - loss: 0.3690\n",
            "Epoch 12: val_loss did not improve from 0.28628\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8286 - loss: 0.3688 - val_accuracy: 0.8794 - val_loss: 0.2865 - learning_rate: 0.0013\n",
            "Epoch 13/36\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8199 - loss: 0.3924\n",
            "Epoch 13: val_loss did not improve from 0.28628\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.3909 - val_accuracy: 0.8820 - val_loss: 0.2926 - learning_rate: 0.0013\n",
            "Epoch 14/36\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8206 - loss: 0.3737\n",
            "Epoch 14: val_loss did not improve from 0.28628\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8215 - loss: 0.3728 - val_accuracy: 0.8828 - val_loss: 0.2868 - learning_rate: 0.0013\n",
            "Epoch 15/36\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8242 - loss: 0.3720\n",
            "Epoch 15: val_loss improved from 0.28628 to 0.27662, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8248 - loss: 0.3714 - val_accuracy: 0.8828 - val_loss: 0.2766 - learning_rate: 0.0013\n",
            "Epoch 16/36\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8270 - loss: 0.3691\n",
            "Epoch 16: val_loss did not improve from 0.27662\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8279 - loss: 0.3679 - val_accuracy: 0.8803 - val_loss: 0.2835 - learning_rate: 0.0013\n",
            "Epoch 17/36\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8282 - loss: 0.3670\n",
            "Epoch 17: val_loss did not improve from 0.27662\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8285 - loss: 0.3665 - val_accuracy: 0.8836 - val_loss: 0.2837 - learning_rate: 0.0013\n",
            "Epoch 18/36\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8318 - loss: 0.3561\n",
            "Epoch 18: val_loss did not improve from 0.27662\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8322 - loss: 0.3559 - val_accuracy: 0.8803 - val_loss: 0.2911 - learning_rate: 0.0013\n",
            "Epoch 19/36\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8216 - loss: 0.3670\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005729383948094444.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.27662\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8225 - loss: 0.3655 - val_accuracy: 0.8659 - val_loss: 0.3187 - learning_rate: 0.0013\n",
            "Epoch 20/36\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8433 - loss: 0.3519\n",
            "Epoch 20: val_loss did not improve from 0.27662\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8446 - loss: 0.3505 - val_accuracy: 0.8744 - val_loss: 0.3705 - learning_rate: 5.7294e-04\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:08:29,499] Trial 23 finished with value: -0.2766205072402954 and parameters: {'epochs': 36, 'batch_size': 64, 'learning_rate': 0.0013390550402811799, 'stop_patience': 5, 'reduce_lr_factor': 0.42786770378330774, 'reduce_lr_patience': 4}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/41\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6003 - loss: 0.6787\n",
            "Epoch 1: val_loss improved from inf to 0.60264, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6011 - loss: 0.6778 - val_accuracy: 0.7175 - val_loss: 0.6026 - learning_rate: 8.5855e-04\n",
            "Epoch 2/41\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6916 - loss: 0.6031\n",
            "Epoch 2: val_loss improved from 0.60264 to 0.38452, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6924 - loss: 0.6013 - val_accuracy: 0.8499 - val_loss: 0.3845 - learning_rate: 8.5855e-04\n",
            "Epoch 3/41\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7441 - loss: 0.5334\n",
            "Epoch 3: val_loss improved from 0.38452 to 0.33928, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7435 - loss: 0.5329 - val_accuracy: 0.8567 - val_loss: 0.3393 - learning_rate: 8.5855e-04\n",
            "Epoch 4/41\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7810 - loss: 0.4889\n",
            "Epoch 4: val_loss improved from 0.33928 to 0.33753, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7807 - loss: 0.4883 - val_accuracy: 0.8567 - val_loss: 0.3375 - learning_rate: 8.5855e-04\n",
            "Epoch 5/41\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7868 - loss: 0.4573\n",
            "Epoch 5: val_loss improved from 0.33753 to 0.32309, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7866 - loss: 0.4571 - val_accuracy: 0.8600 - val_loss: 0.3231 - learning_rate: 8.5855e-04\n",
            "Epoch 6/41\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7943 - loss: 0.4376\n",
            "Epoch 6: val_loss did not improve from 0.32309\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7941 - loss: 0.4374 - val_accuracy: 0.8592 - val_loss: 0.3426 - learning_rate: 8.5855e-04\n",
            "Epoch 7/41\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.4281\n",
            "Epoch 7: val_loss improved from 0.32309 to 0.31077, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8040 - loss: 0.4268 - val_accuracy: 0.8668 - val_loss: 0.3108 - learning_rate: 8.5855e-04\n",
            "Epoch 8/41\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8200 - loss: 0.4011\n",
            "Epoch 8: val_loss did not improve from 0.31077\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8195 - loss: 0.4013 - val_accuracy: 0.8676 - val_loss: 0.3146 - learning_rate: 8.5855e-04\n",
            "Epoch 9/41\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.4041\n",
            "Epoch 9: val_loss did not improve from 0.31077\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8060 - loss: 0.4035 - val_accuracy: 0.8718 - val_loss: 0.3207 - learning_rate: 8.5855e-04\n",
            "Epoch 10/41\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8161 - loss: 0.3935\n",
            "Epoch 10: val_loss improved from 0.31077 to 0.29895, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8163 - loss: 0.3933 - val_accuracy: 0.8668 - val_loss: 0.2990 - learning_rate: 8.5855e-04\n",
            "Epoch 11/41\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8133 - loss: 0.3927\n",
            "Epoch 11: val_loss improved from 0.29895 to 0.29724, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8142 - loss: 0.3915 - val_accuracy: 0.8744 - val_loss: 0.2972 - learning_rate: 8.5855e-04\n",
            "Epoch 12/41\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8211 - loss: 0.3814\n",
            "Epoch 12: val_loss did not improve from 0.29724\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8218 - loss: 0.3809 - val_accuracy: 0.8794 - val_loss: 0.3083 - learning_rate: 8.5855e-04\n",
            "Epoch 13/41\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8322 - loss: 0.3805\n",
            "Epoch 13: val_loss improved from 0.29724 to 0.28488, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8322 - loss: 0.3797 - val_accuracy: 0.8744 - val_loss: 0.2849 - learning_rate: 8.5855e-04\n",
            "Epoch 14/41\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8200 - loss: 0.3839\n",
            "Epoch 14: val_loss did not improve from 0.28488\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8210 - loss: 0.3827 - val_accuracy: 0.8786 - val_loss: 0.2853 - learning_rate: 8.5855e-04\n",
            "Epoch 15/41\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8151 - loss: 0.3758\n",
            "Epoch 15: val_loss did not improve from 0.28488\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8171 - loss: 0.3744 - val_accuracy: 0.8803 - val_loss: 0.2857 - learning_rate: 8.5855e-04\n",
            "Epoch 16/41\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8323 - loss: 0.3646\n",
            "Epoch 16: val_loss improved from 0.28488 to 0.28202, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8328 - loss: 0.3641 - val_accuracy: 0.8786 - val_loss: 0.2820 - learning_rate: 8.5855e-04\n",
            "Epoch 17/41\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8226 - loss: 0.3693\n",
            "Epoch 17: val_loss did not improve from 0.28202\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8247 - loss: 0.3674 - val_accuracy: 0.8803 - val_loss: 0.2845 - learning_rate: 8.5855e-04\n",
            "Epoch 18/41\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8308 - loss: 0.3610\n",
            "Epoch 18: val_loss improved from 0.28202 to 0.28177, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8315 - loss: 0.3604 - val_accuracy: 0.8845 - val_loss: 0.2818 - learning_rate: 8.5855e-04\n",
            "Epoch 19/41\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8365 - loss: 0.3561\n",
            "Epoch 19: val_loss did not improve from 0.28177\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8368 - loss: 0.3558 - val_accuracy: 0.8786 - val_loss: 0.2939 - learning_rate: 8.5855e-04\n",
            "Epoch 20/41\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8346 - loss: 0.3674\n",
            "Epoch 20: val_loss improved from 0.28177 to 0.27795, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8353 - loss: 0.3663 - val_accuracy: 0.8853 - val_loss: 0.2780 - learning_rate: 8.5855e-04\n",
            "Epoch 21/41\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8300 - loss: 0.3623\n",
            "Epoch 21: val_loss did not improve from 0.27795\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8306 - loss: 0.3618 - val_accuracy: 0.8794 - val_loss: 0.3032 - learning_rate: 8.5855e-04\n",
            "Epoch 22/41\n",
            "\u001b[1m64/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8422 - loss: 0.3497\n",
            "Epoch 22: val_loss did not improve from 0.27795\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8423 - loss: 0.3492 - val_accuracy: 0.8803 - val_loss: 0.2847 - learning_rate: 8.5855e-04\n",
            "Epoch 23/41\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8324 - loss: 0.3618\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00032165889295977926.\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.27795\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8336 - loss: 0.3603 - val_accuracy: 0.8803 - val_loss: 0.3066 - learning_rate: 8.5855e-04\n",
            "Epoch 24/41\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8475 - loss: 0.3416\n",
            "Epoch 24: val_loss did not improve from 0.27795\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8495 - loss: 0.3402 - val_accuracy: 0.8727 - val_loss: 0.3528 - learning_rate: 3.2166e-04\n",
            "Epoch 25/41\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8639 - loss: 0.3209\n",
            "Epoch 25: val_loss did not improve from 0.27795\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8640 - loss: 0.3210 - val_accuracy: 0.8702 - val_loss: 0.3649 - learning_rate: 3.2166e-04\n",
            "Epoch 26/41\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8783 - loss: 0.3138\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00012051098245752589.\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.27795\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8771 - loss: 0.3145 - val_accuracy: 0.8685 - val_loss: 0.3706 - learning_rate: 3.2166e-04\n",
            "Epoch 26: early stopping\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:08:48,778] Trial 24 finished with value: -0.27795475721359253 and parameters: {'epochs': 41, 'batch_size': 64, 'learning_rate': 0.0008585478000320522, 'stop_patience': 6, 'reduce_lr_factor': 0.3746546093404952, 'reduce_lr_patience': 3}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/46\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5689 - loss: 0.6813\n",
            "Epoch 1: val_loss improved from inf to 0.42086, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5744 - loss: 0.6775 - val_accuracy: 0.8583 - val_loss: 0.4209 - learning_rate: 0.0023\n",
            "Epoch 2/46\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7162 - loss: 0.5624\n",
            "Epoch 2: val_loss improved from 0.42086 to 0.41686, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7166 - loss: 0.5612 - val_accuracy: 0.8187 - val_loss: 0.4169 - learning_rate: 0.0023\n",
            "Epoch 3/46\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7407 - loss: 0.5078\n",
            "Epoch 3: val_loss improved from 0.41686 to 0.32281, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7418 - loss: 0.5065 - val_accuracy: 0.8600 - val_loss: 0.3228 - learning_rate: 0.0023\n",
            "Epoch 4/46\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7640 - loss: 0.4736\n",
            "Epoch 4: val_loss improved from 0.32281 to 0.32125, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7651 - loss: 0.4719 - val_accuracy: 0.8685 - val_loss: 0.3213 - learning_rate: 0.0023\n",
            "Epoch 5/46\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7812 - loss: 0.4450\n",
            "Epoch 5: val_loss improved from 0.32125 to 0.30456, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7814 - loss: 0.4448 - val_accuracy: 0.8702 - val_loss: 0.3046 - learning_rate: 0.0023\n",
            "Epoch 6/46\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7714 - loss: 0.4387\n",
            "Epoch 6: val_loss improved from 0.30456 to 0.29309, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7728 - loss: 0.4377 - val_accuracy: 0.8676 - val_loss: 0.2931 - learning_rate: 0.0023\n",
            "Epoch 7/46\n",
            "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7961 - loss: 0.4108\n",
            "Epoch 7: val_loss did not improve from 0.29309\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7967 - loss: 0.4100 - val_accuracy: 0.8617 - val_loss: 0.3595 - learning_rate: 0.0023\n",
            "Epoch 8/46\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8023 - loss: 0.4023\n",
            "Epoch 8: val_loss improved from 0.29309 to 0.29188, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8027 - loss: 0.4020 - val_accuracy: 0.8845 - val_loss: 0.2919 - learning_rate: 0.0023\n",
            "Epoch 9/46\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7984 - loss: 0.4046\n",
            "Epoch 9: val_loss improved from 0.29188 to 0.28810, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7997 - loss: 0.4030 - val_accuracy: 0.8836 - val_loss: 0.2881 - learning_rate: 0.0023\n",
            "Epoch 10/46\n",
            "\u001b[1m64/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 0.4003\n",
            "Epoch 10: val_loss did not improve from 0.28810\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8000 - loss: 0.3988 - val_accuracy: 0.8659 - val_loss: 0.2970 - learning_rate: 0.0023\n",
            "Epoch 11/46\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8110 - loss: 0.3883\n",
            "Epoch 11: val_loss improved from 0.28810 to 0.28230, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8117 - loss: 0.3873 - val_accuracy: 0.8845 - val_loss: 0.2823 - learning_rate: 0.0023\n",
            "Epoch 12/46\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8231 - loss: 0.3623\n",
            "Epoch 12: val_loss did not improve from 0.28230\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8232 - loss: 0.3623 - val_accuracy: 0.8744 - val_loss: 0.3061 - learning_rate: 0.0023\n",
            "Epoch 13/46\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8274 - loss: 0.3574\n",
            "Epoch 13: val_loss improved from 0.28230 to 0.27912, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8275 - loss: 0.3575 - val_accuracy: 0.8820 - val_loss: 0.2791 - learning_rate: 0.0023\n",
            "Epoch 14/46\n",
            "\u001b[1m63/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8275 - loss: 0.3563\n",
            "Epoch 14: val_loss did not improve from 0.27912\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8273 - loss: 0.3576 - val_accuracy: 0.8845 - val_loss: 0.2842 - learning_rate: 0.0023\n",
            "Epoch 15/46\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8175 - loss: 0.3735\n",
            "Epoch 15: val_loss did not improve from 0.27912\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8177 - loss: 0.3733 - val_accuracy: 0.8735 - val_loss: 0.3127 - learning_rate: 0.0023\n",
            "Epoch 16/46\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.3725\n",
            "Epoch 16: val_loss did not improve from 0.27912\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8169 - loss: 0.3724 - val_accuracy: 0.8676 - val_loss: 0.3060 - learning_rate: 0.0023\n",
            "Epoch 17/46\n",
            "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8325 - loss: 0.3654\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.001069572435427969.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.27912\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8326 - loss: 0.3652 - val_accuracy: 0.8845 - val_loss: 0.2828 - learning_rate: 0.0023\n",
            "Epoch 18/46\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8503 - loss: 0.3373\n",
            "Epoch 18: val_loss did not improve from 0.27912\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8509 - loss: 0.3363 - val_accuracy: 0.8744 - val_loss: 0.3660 - learning_rate: 0.0011\n",
            "Epoch 19/46\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 0.3281\n",
            "Epoch 19: val_loss did not improve from 0.27912\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8574 - loss: 0.3280 - val_accuracy: 0.8516 - val_loss: 0.4337 - learning_rate: 0.0011\n",
            "Epoch 20/46\n",
            "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8529 - loss: 0.3314\n",
            "Epoch 20: val_loss did not improve from 0.27912\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8536 - loss: 0.3307 - val_accuracy: 0.8735 - val_loss: 0.4245 - learning_rate: 0.0011\n",
            "Epoch 21/46\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8600 - loss: 0.3236\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00050020746452564.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.27912\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8606 - loss: 0.3228 - val_accuracy: 0.8668 - val_loss: 0.4182 - learning_rate: 0.0011\n",
            "Epoch 22/46\n",
            "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8718 - loss: 0.3115\n",
            "Epoch 22: val_loss did not improve from 0.27912\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8720 - loss: 0.3112 - val_accuracy: 0.8617 - val_loss: 0.4834 - learning_rate: 5.0021e-04\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:09:05,709] Trial 25 finished with value: -0.2791193127632141 and parameters: {'epochs': 46, 'batch_size': 64, 'learning_rate': 0.002287021323430773, 'stop_patience': 9, 'reduce_lr_factor': 0.4676705029101216, 'reduce_lr_patience': 4}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/47\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6046 - loss: 0.6764\n",
            "Epoch 1: val_loss improved from inf to 0.71559, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6051 - loss: 0.6757 - val_accuracy: 0.6214 - val_loss: 0.7156 - learning_rate: 0.0064\n",
            "Epoch 2/47\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6990 - loss: 0.5664\n",
            "Epoch 2: val_loss improved from 0.71559 to 0.34617, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7006 - loss: 0.5644 - val_accuracy: 0.8491 - val_loss: 0.3462 - learning_rate: 0.0064\n",
            "Epoch 3/47\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7476 - loss: 0.4989\n",
            "Epoch 3: val_loss did not improve from 0.34617\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7478 - loss: 0.4981 - val_accuracy: 0.8415 - val_loss: 0.4303 - learning_rate: 0.0064\n",
            "Epoch 4/47\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7594 - loss: 0.4637\n",
            "Epoch 4: val_loss did not improve from 0.34617\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7598 - loss: 0.4632 - val_accuracy: 0.8474 - val_loss: 0.3772 - learning_rate: 0.0064\n",
            "Epoch 5/47\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7779 - loss: 0.4365\n",
            "Epoch 5: val_loss did not improve from 0.34617\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7775 - loss: 0.4367 - val_accuracy: 0.8516 - val_loss: 0.4384 - learning_rate: 0.0064\n",
            "Epoch 6/47\n",
            "\u001b[1m147/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7965 - loss: 0.4271\n",
            "Epoch 6: val_loss improved from 0.34617 to 0.33956, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7963 - loss: 0.4270 - val_accuracy: 0.8592 - val_loss: 0.3396 - learning_rate: 0.0064\n",
            "Epoch 7/47\n",
            "\u001b[1m135/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7997 - loss: 0.4034\n",
            "Epoch 7: val_loss improved from 0.33956 to 0.32797, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.4044 - val_accuracy: 0.8651 - val_loss: 0.3280 - learning_rate: 0.0064\n",
            "Epoch 8/47\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7845 - loss: 0.4084\n",
            "Epoch 8: val_loss did not improve from 0.32797\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7843 - loss: 0.4089 - val_accuracy: 0.8272 - val_loss: 0.5892 - learning_rate: 0.0064\n",
            "Epoch 9/47\n",
            "\u001b[1m137/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.3980\n",
            "Epoch 9: val_loss did not improve from 0.32797\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.3976 - val_accuracy: 0.7698 - val_loss: 1.1346 - learning_rate: 0.0064\n",
            "Epoch 10/47\n",
            "\u001b[1m136/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8333 - loss: 0.3754\n",
            "Epoch 10: val_loss did not improve from 0.32797\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8329 - loss: 0.3759 - val_accuracy: 0.8432 - val_loss: 0.4127 - learning_rate: 0.0064\n",
            "Epoch 11/47\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8073 - loss: 0.3834\n",
            "Epoch 11: val_loss did not improve from 0.32797\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.3839 - val_accuracy: 0.8314 - val_loss: 0.4525 - learning_rate: 0.0064\n",
            "Epoch 12/47\n",
            "\u001b[1m142/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8180 - loss: 0.3618\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.002708567515499835.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.32797\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8178 - loss: 0.3623 - val_accuracy: 0.8145 - val_loss: 0.8034 - learning_rate: 0.0064\n",
            "Epoch 13/47\n",
            "\u001b[1m140/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8365 - loss: 0.3445\n",
            "Epoch 13: val_loss did not improve from 0.32797\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8365 - loss: 0.3448 - val_accuracy: 0.8398 - val_loss: 0.4061 - learning_rate: 0.0027\n",
            "Epoch 14/47\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3269\n",
            "Epoch 14: val_loss did not improve from 0.32797\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8551 - loss: 0.3285 - val_accuracy: 0.8356 - val_loss: 0.3957 - learning_rate: 0.0027\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:09:21,445] Trial 26 finished with value: -0.32797062397003174 and parameters: {'epochs': 47, 'batch_size': 32, 'learning_rate': 0.0063708486548626235, 'stop_patience': 7, 'reduce_lr_factor': 0.42515019954911293, 'reduce_lr_patience': 5}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/42\n",
            "\u001b[1m141/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5724 - loss: 0.6841\n",
            "Epoch 1: val_loss improved from inf to 0.43249, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5738 - loss: 0.6827 - val_accuracy: 0.8541 - val_loss: 0.4325 - learning_rate: 0.0039\n",
            "Epoch 2/42\n",
            "\u001b[1m133/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6790 - loss: 0.5785\n",
            "Epoch 2: val_loss improved from 0.43249 to 0.32500, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6816 - loss: 0.5762 - val_accuracy: 0.8617 - val_loss: 0.3250 - learning_rate: 0.0039\n",
            "Epoch 3/42\n",
            "\u001b[1m135/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7382 - loss: 0.4976\n",
            "Epoch 3: val_loss improved from 0.32500 to 0.31776, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7384 - loss: 0.4977 - val_accuracy: 0.8676 - val_loss: 0.3178 - learning_rate: 0.0039\n",
            "Epoch 4/42\n",
            "\u001b[1m148/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7613 - loss: 0.4637\n",
            "Epoch 4: val_loss did not improve from 0.31776\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7613 - loss: 0.4636 - val_accuracy: 0.8634 - val_loss: 0.3347 - learning_rate: 0.0039\n",
            "Epoch 5/42\n",
            "\u001b[1m136/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7896 - loss: 0.4366\n",
            "Epoch 5: val_loss improved from 0.31776 to 0.29170, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7903 - loss: 0.4355 - val_accuracy: 0.8811 - val_loss: 0.2917 - learning_rate: 0.0039\n",
            "Epoch 6/42\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.4126\n",
            "Epoch 6: val_loss did not improve from 0.29170\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 0.4126 - val_accuracy: 0.8550 - val_loss: 0.3293 - learning_rate: 0.0039\n",
            "Epoch 7/42\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8033 - loss: 0.3898\n",
            "Epoch 7: val_loss did not improve from 0.29170\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.3897 - val_accuracy: 0.8642 - val_loss: 0.3301 - learning_rate: 0.0039\n",
            "Epoch 8/42\n",
            "\u001b[1m134/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8079 - loss: 0.3889\n",
            "Epoch 8: val_loss improved from 0.29170 to 0.27506, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8071 - loss: 0.3905 - val_accuracy: 0.8862 - val_loss: 0.2751 - learning_rate: 0.0039\n",
            "Epoch 9/42\n",
            "\u001b[1m133/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8056 - loss: 0.3908\n",
            "Epoch 9: val_loss did not improve from 0.27506\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8050 - loss: 0.3917 - val_accuracy: 0.8693 - val_loss: 0.3122 - learning_rate: 0.0039\n",
            "Epoch 10/42\n",
            "\u001b[1m144/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8270 - loss: 0.3671\n",
            "Epoch 10: val_loss did not improve from 0.27506\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8270 - loss: 0.3672 - val_accuracy: 0.8516 - val_loss: 0.5388 - learning_rate: 0.0039\n",
            "Epoch 11/42\n",
            "\u001b[1m133/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8196 - loss: 0.3715\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.001369145322911696.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.27506\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8195 - loss: 0.3721 - val_accuracy: 0.8642 - val_loss: 0.3764 - learning_rate: 0.0039\n",
            "Epoch 12/42\n",
            "\u001b[1m133/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8484 - loss: 0.3467\n",
            "Epoch 12: val_loss did not improve from 0.27506\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 0.3461 - val_accuracy: 0.8727 - val_loss: 0.2901 - learning_rate: 0.0014\n",
            "Epoch 13/42\n",
            "\u001b[1m134/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.3257\n",
            "Epoch 13: val_loss did not improve from 0.27506\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 0.3261 - val_accuracy: 0.8626 - val_loss: 0.3050 - learning_rate: 0.0014\n",
            "Epoch 14/42\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8610 - loss: 0.3211\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0004840829522127752.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.27506\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8608 - loss: 0.3214 - val_accuracy: 0.8761 - val_loss: 0.2861 - learning_rate: 0.0014\n",
            "Epoch 15/42\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8715 - loss: 0.3137\n",
            "Epoch 15: val_loss did not improve from 0.27506\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8715 - loss: 0.3131 - val_accuracy: 0.8432 - val_loss: 0.5108 - learning_rate: 4.8408e-04\n",
            "Epoch 16/42\n",
            "\u001b[1m145/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8764 - loss: 0.3023\n",
            "Epoch 16: val_loss did not improve from 0.27506\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8764 - loss: 0.3021 - val_accuracy: 0.8390 - val_loss: 0.5177 - learning_rate: 4.8408e-04\n",
            "Epoch 17/42\n",
            "\u001b[1m138/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8794 - loss: 0.3003\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001711551739324877.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.27506\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8793 - loss: 0.3001 - val_accuracy: 0.8415 - val_loss: 0.5162 - learning_rate: 4.8408e-04\n",
            "Epoch 18/42\n",
            "\u001b[1m139/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8893 - loss: 0.2897\n",
            "Epoch 18: val_loss did not improve from 0.27506\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8891 - loss: 0.2895 - val_accuracy: 0.8457 - val_loss: 0.4920 - learning_rate: 1.7116e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:09:44,544] Trial 27 finished with value: -0.27505508065223694 and parameters: {'epochs': 42, 'batch_size': 32, 'learning_rate': 0.0038723919861385096, 'stop_patience': 10, 'reduce_lr_factor': 0.35356578638959424, 'reduce_lr_patience': 3}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/33\n",
            "\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5619 - loss: 0.6843\n",
            "Epoch 1: val_loss improved from inf to 0.45455, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5625 - loss: 0.6839 - val_accuracy: 0.7884 - val_loss: 0.4545 - learning_rate: 0.0052\n",
            "Epoch 2/33\n",
            "\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7072 - loss: 0.5593\n",
            "Epoch 2: val_loss improved from 0.45455 to 0.30284, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7076 - loss: 0.5584 - val_accuracy: 0.8718 - val_loss: 0.3028 - learning_rate: 0.0052\n",
            "Epoch 3/33\n",
            "\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7541 - loss: 0.4661\n",
            "Epoch 3: val_loss did not improve from 0.30284\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7539 - loss: 0.4664 - val_accuracy: 0.8676 - val_loss: 0.3346 - learning_rate: 0.0052\n",
            "Epoch 4/33\n",
            "\u001b[1m279/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7665 - loss: 0.4533\n",
            "Epoch 4: val_loss did not improve from 0.30284\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7668 - loss: 0.4534 - val_accuracy: 0.8592 - val_loss: 0.3853 - learning_rate: 0.0052\n",
            "Epoch 5/33\n",
            "\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7913 - loss: 0.4245\n",
            "Epoch 5: val_loss did not improve from 0.30284\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7913 - loss: 0.4245 - val_accuracy: 0.8482 - val_loss: 0.4480 - learning_rate: 0.0052\n",
            "Epoch 6/33\n",
            "\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.4157\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009250237907565038.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.30284\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8005 - loss: 0.4157 - val_accuracy: 0.8440 - val_loss: 0.4795 - learning_rate: 0.0052\n",
            "Epoch 7/33\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8271 - loss: 0.3669\n",
            "Epoch 7: val_loss did not improve from 0.30284\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8274 - loss: 0.3665 - val_accuracy: 0.8626 - val_loss: 0.3524 - learning_rate: 9.2502e-04\n",
            "Epoch 8/33\n",
            "\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8551 - loss: 0.3351\n",
            "Epoch 8: val_loss did not improve from 0.30284\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8551 - loss: 0.3351 - val_accuracy: 0.8651 - val_loss: 0.3242 - learning_rate: 9.2502e-04\n",
            "Epoch 9/33\n",
            "\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8609 - loss: 0.3297\n",
            "Epoch 9: val_loss did not improve from 0.30284\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8608 - loss: 0.3297 - val_accuracy: 0.8516 - val_loss: 0.3632 - learning_rate: 9.2502e-04\n",
            "Epoch 10/33\n",
            "\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8628 - loss: 0.3203\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00016386961804150174.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.30284\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8628 - loss: 0.3203 - val_accuracy: 0.8541 - val_loss: 0.3851 - learning_rate: 9.2502e-04\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:10:03,055] Trial 28 finished with value: -0.30283647775650024 and parameters: {'epochs': 33, 'batch_size': 16, 'learning_rate': 0.005221645443704961, 'stop_patience': 8, 'reduce_lr_factor': 0.1771517843797719, 'reduce_lr_patience': 4}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/29\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5692 - loss: 0.6809\n",
            "Epoch 1: val_loss improved from inf to 0.48594, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5724 - loss: 0.6786 - val_accuracy: 0.8449 - val_loss: 0.4859 - learning_rate: 0.0018\n",
            "Epoch 2/29\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6865 - loss: 0.5840\n",
            "Epoch 2: val_loss improved from 0.48594 to 0.35843, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6872 - loss: 0.5830 - val_accuracy: 0.8533 - val_loss: 0.3584 - learning_rate: 0.0018\n",
            "Epoch 3/29\n",
            "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7463 - loss: 0.5161\n",
            "Epoch 3: val_loss improved from 0.35843 to 0.33863, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7471 - loss: 0.5147 - val_accuracy: 0.8541 - val_loss: 0.3386 - learning_rate: 0.0018\n",
            "Epoch 4/29\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7602 - loss: 0.4763\n",
            "Epoch 4: val_loss improved from 0.33863 to 0.32381, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7618 - loss: 0.4750 - val_accuracy: 0.8609 - val_loss: 0.3238 - learning_rate: 0.0018\n",
            "Epoch 5/29\n",
            "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7618 - loss: 0.4559\n",
            "Epoch 5: val_loss did not improve from 0.32381\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7642 - loss: 0.4544 - val_accuracy: 0.8516 - val_loss: 0.3392 - learning_rate: 0.0018\n",
            "Epoch 6/29\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7749 - loss: 0.4401\n",
            "Epoch 6: val_loss did not improve from 0.32381\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7771 - loss: 0.4380 - val_accuracy: 0.8693 - val_loss: 0.3285 - learning_rate: 0.0018\n",
            "Epoch 7/29\n",
            "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7747 - loss: 0.4306\n",
            "Epoch 7: val_loss improved from 0.32381 to 0.30825, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7763 - loss: 0.4288 - val_accuracy: 0.8634 - val_loss: 0.3083 - learning_rate: 0.0018\n",
            "Epoch 8/29\n",
            "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7993 - loss: 0.4081\n",
            "Epoch 8: val_loss improved from 0.30825 to 0.29233, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7999 - loss: 0.4080 - val_accuracy: 0.8718 - val_loss: 0.2923 - learning_rate: 0.0018\n",
            "Epoch 9/29\n",
            "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7975 - loss: 0.4118\n",
            "Epoch 9: val_loss improved from 0.29233 to 0.28367, saving model to BEST_CNN_RAM_CSNA3.keras\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7981 - loss: 0.4111 - val_accuracy: 0.8735 - val_loss: 0.2837 - learning_rate: 0.0018\n",
            "Epoch 10/29\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8197 - loss: 0.3855\n",
            "Epoch 10: val_loss did not improve from 0.28367\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8198 - loss: 0.3855 - val_accuracy: 0.8761 - val_loss: 0.2878 - learning_rate: 0.0018\n",
            "Epoch 11/29\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.3864\n",
            "Epoch 11: val_loss did not improve from 0.28367\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8121 - loss: 0.3863 - val_accuracy: 0.8761 - val_loss: 0.3097 - learning_rate: 0.0018\n",
            "Epoch 12/29\n",
            "\u001b[1m64/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8182 - loss: 0.3672\n",
            "Epoch 12: val_loss did not improve from 0.28367\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8189 - loss: 0.3674 - val_accuracy: 0.8761 - val_loss: 0.2959 - learning_rate: 0.0018\n",
            "Epoch 13/29\n",
            "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8113 - loss: 0.3790\n",
            "Epoch 13: val_loss did not improve from 0.28367\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 0.3782 - val_accuracy: 0.8777 - val_loss: 0.2929 - learning_rate: 0.0018\n",
            "Epoch 14/29\n",
            "\u001b[1m64/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8134 - loss: 0.3842\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008548096812334773.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.28367\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8152 - loss: 0.3821 - val_accuracy: 0.8744 - val_loss: 0.3002 - learning_rate: 0.0018\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:10:14,269] Trial 29 finished with value: -0.2836689054965973 and parameters: {'epochs': 29, 'batch_size': 64, 'learning_rate': 0.0017501136995559223, 'stop_patience': 5, 'reduce_lr_factor': 0.48843094780821084, 'reduce_lr_patience': 5}. Best is trial 9 with value: -0.25887417793273926.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Melhor combinação encontrada:\n",
            "trial                   9.000000\n",
            "epochs                 46.000000\n",
            "batch_size             32.000000\n",
            "learning_rate           0.002034\n",
            "stop_patience           5.000000\n",
            "reduce_lr_factor        0.423712\n",
            "reduce_lr_patience      4.000000\n",
            "recall_Compra(1)        0.843373\n",
            "recall_Vende(0)         0.909884\n",
            "precision_Compra(1)     0.871369\n",
            "precision_Vende(0)      0.889205\n",
            "macro_recall            0.876629\n",
            "accuracy                0.881956\n",
            "f1_macro                0.878284\n",
            "f1_weighted             0.881671\n",
            "min_val_loss            0.258874\n",
            "Name: 0, dtype: float64\n",
            "🔍 Hiperparâmetros: {'epochs': 46, 'batch_size': 32, 'learning_rate': 0.002033526410365415, 'stop_patience': 5, 'reduce_lr_factor': 0.423712475391115, 'reduce_lr_patience': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_history([best_seq_history, best_ram_history], titles=titles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "RKw_2Kqx1poR",
        "outputId": "350f575f-64e3-407c-e8fd-d0a51f148e82"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix([best_seq_metrics, best_ram_metrics], titles=titles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "OckV8CEy1qu_",
        "outputId": "fdb99795-eb08-4ee8-cbe1-364ec80b67d2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_classification_reports(\n",
        "    metrics_list=[best_seq_metrics, best_ram_metrics],\n",
        "    titles=titles\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQxzFp901wB-",
        "outputId": "5ca576c7-22be-4ed6-97a2-eaa0720f2767"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "📊 Relatório de Classificação - Modelo Sequencial\n",
            "==================================================\n",
            "\n",
            "Vende (0):\n",
            "Precision: 0.90\n",
            "Recall:    0.90\n",
            "F1-Score:  0.90\n",
            "\n",
            "Compra (1):\n",
            "Precision: 0.86\n",
            "Recall:    0.87\n",
            "F1-Score:  0.86\n",
            "\n",
            "Médias:\n",
            "Acurácia:  0.89\n",
            "Precision: 0.88\n",
            "Recall:    0.88\n",
            "F1-Score:  0.88\n",
            "\n",
            "\n",
            "==================================================\n",
            "📊 Relatório de Classificação - Modelo Ramificado\n",
            "==================================================\n",
            "\n",
            "Vende (0):\n",
            "Precision: 0.89\n",
            "Recall:    0.91\n",
            "F1-Score:  0.90\n",
            "\n",
            "Compra (1):\n",
            "Precision: 0.87\n",
            "Recall:    0.84\n",
            "F1-Score:  0.86\n",
            "\n",
            "Médias:\n",
            "Acurácia:  0.88\n",
            "Precision: 0.88\n",
            "Recall:    0.88\n",
            "F1-Score:  0.88\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultado_backtest = run_backtest(\n",
        "    predictions=best_seq_y_pred,\n",
        "    prices=prices,\n",
        "    capital=10000,\n",
        "    model_name=\"CNN Sequencial\",\n",
        "    stock_name=\"CSAN3\",\n",
        "    metrics = best_seq_metrics,\n",
        "    cdi_df = cdi,\n",
        "    metric_optimization=metric_optimization\n",
        ")\n",
        "\n",
        "resultado_backtest = run_backtest(\n",
        "    predictions=best_ram_y_pred,\n",
        "    prices=prices,\n",
        "    capital=10000,\n",
        "    model_name=\"CNN Ramificado\",\n",
        "    stock_name=\"CSAN3\",\n",
        "    metrics = best_ram_metrics,\n",
        "    cdi_df=cdi,\n",
        "    metric_optimization=metric_optimization\n",
        ")\n",
        "\n",
        "resultado_backtest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "9pyEgrr71yqN",
        "outputId": "dd1535c5-27ba-44a7-a800-be33744a7eea"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-cadec49cf654>:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  preco_atual = prices[i]\n",
            "<ipython-input-17-cadec49cf654>:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  preco_atual = prices[i]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Data          Modelo   Ação Métrica de Otimização  \\\n",
              "0  2025-04-13 14:10:15.041119  CNN Sequencial  CSAN3              val_loss   \n",
              "1  2025-04-13 14:10:15.069407  CNN Ramificado  CSAN3              val_loss   \n",
              "\n",
              "   Acurácia  Precision    Recall        F1      Matriz de Confusão  \\\n",
              "0  0.885329   0.882166  0.882586  0.882373  [[619, 69], [67, 431]]   \n",
              "1  0.881956   0.880287  0.876629  0.878284  [[626, 62], [78, 420]]   \n",
              "\n",
              "   Saldo Inicial  Saldo Final  Total de Ações   Lucro Total   Lucro (%)  \\\n",
              "0          10000     3.640817           990.0   9467.040666   94.670407   \n",
              "1          10000     8.435907          1065.0  10946.335745  109.463357   \n",
              "\n",
              "   Lucro (%) CDI  \n",
              "0       42.26921  \n",
              "1       42.26921  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8363f855-5397-471a-bc71-526e23da681b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Ação</th>\n",
              "      <th>Métrica de Otimização</th>\n",
              "      <th>Acurácia</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Matriz de Confusão</th>\n",
              "      <th>Saldo Inicial</th>\n",
              "      <th>Saldo Final</th>\n",
              "      <th>Total de Ações</th>\n",
              "      <th>Lucro Total</th>\n",
              "      <th>Lucro (%)</th>\n",
              "      <th>Lucro (%) CDI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-04-13 14:10:15.041119</td>\n",
              "      <td>CNN Sequencial</td>\n",
              "      <td>CSAN3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.885329</td>\n",
              "      <td>0.882166</td>\n",
              "      <td>0.882586</td>\n",
              "      <td>0.882373</td>\n",
              "      <td>[[619, 69], [67, 431]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>3.640817</td>\n",
              "      <td>990.0</td>\n",
              "      <td>9467.040666</td>\n",
              "      <td>94.670407</td>\n",
              "      <td>42.26921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-04-13 14:10:15.069407</td>\n",
              "      <td>CNN Ramificado</td>\n",
              "      <td>CSAN3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.881956</td>\n",
              "      <td>0.880287</td>\n",
              "      <td>0.876629</td>\n",
              "      <td>0.878284</td>\n",
              "      <td>[[626, 62], [78, 420]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>8.435907</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>10946.335745</td>\n",
              "      <td>109.463357</td>\n",
              "      <td>42.26921</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8363f855-5397-471a-bc71-526e23da681b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8363f855-5397-471a-bc71-526e23da681b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8363f855-5397-471a-bc71-526e23da681b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c43a304c-41f0-404c-8b06-27ff06b4874b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c43a304c-41f0-404c-8b06-27ff06b4874b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c43a304c-41f0-404c-8b06-27ff06b4874b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_90ba02ea-93a3-444c-8720-9aef74705df8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('resultado_backtest')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_90ba02ea-93a3-444c-8720-9aef74705df8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('resultado_backtest');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "resultado_backtest",
              "summary": "{\n  \"name\": \"resultado_backtest\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Data\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2025-04-13 14:10:15.069407\",\n          \"2025-04-13 14:10:15.041119\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"CNN Ramificado\",\n          \"CNN Sequencial\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\\u00e7\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"CSAN3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"M\\u00e9trica de Otimiza\\u00e7\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"val_loss\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Acur\\u00e1cia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0023848458050136877,\n        \"min\": 0.8819561551433389,\n        \"max\": 0.8853288364249579,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8819561551433389\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0013288380042733516,\n        \"min\": 0.8802869200301773,\n        \"max\": 0.8821661807580174,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8802869200301773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004212212047030451,\n        \"min\": 0.876628607453068,\n        \"max\": 0.8825855748575698,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.876628607453068\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002891442099417192,\n        \"min\": 0.8782840722495895,\n        \"max\": 0.8823731888814018,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8782840722495895\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Matriz de Confus\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Saldo Inicial\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 10000,\n        \"max\": 10000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          10000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Saldo Final\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.3906407957801274,\n        \"min\": 3.640817165378394,\n        \"max\": 8.435907363906153,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          8.435907363906153\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total de A\\u00e7\\u00f5es\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 53.033008588991066,\n        \"min\": 990.0,\n        \"max\": 1065.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1065.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lucro Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1046.0195815631482,\n        \"min\": 9467.040666103368,\n        \"max\": 10946.335744857803,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          10946.335744857803\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lucro (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.460195815631483,\n        \"min\": 94.67040666103368,\n        \"max\": 109.46335744857802,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          109.46335744857802\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lucro (%) CDI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.105427357601002e-15,\n        \"min\": 42.2692096209317,\n        \"max\": 42.269209620931704,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          42.269209620931704\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFRwtJ8lwrbn"
      },
      "source": [
        "### PETR4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "imy0lLWAw4Ds"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, features = preprocess_data(pe_train, pe_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "janela_curta = features[:7]\n",
        "janela_longa = features[7:]\n",
        "X_train1, X_test1, X_train2, X_test2, y_train, y_test, features = preprocess_data(pe_train, pe_test, split_features=[janela_curta,janela_longa])"
      ],
      "metadata": {
        "id": "uNKK3Ea16Gld"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prices = pe_test.set_index(\"Date\")[\"Close\"]\n",
        "titles = [\"Modelo Sequencial\", \"Modelo Ramificado\"]\n",
        "metric_optimization = 'val_loss'"
      ],
      "metadata": {
        "id": "tBZnJ-uA6JUI"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_seq_model, best_seq_history, df_results, best_seq_metrics, best_seq_y_pred = train_model(\n",
        "    model_fn=model_cnn_sequencial,\n",
        "    model_path = \"BEST_CNN_SEQ_PETR4.keras\",\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    prob=0.5,\n",
        "    n_trials=30,\n",
        "    metric_to_optimize=metric_optimization\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcYGvA-46MGs",
        "outputId": "1de1177f-6b9c-44e6-c81a-f5f1d92314ba"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:37:38,806] A new study created in memory with name: no-name-aa683edf-4a3a-4bcd-8f8a-b21afa5f7e7c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/48\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5491 - loss: 0.6960\n",
            "Epoch 1: val_loss improved from inf to 0.69770, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5491 - loss: 0.6959 - val_accuracy: 0.4830 - val_loss: 0.6977 - learning_rate: 0.0086\n",
            "Epoch 2/48\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5583 - loss: 0.6869\n",
            "Epoch 2: val_loss did not improve from 0.69770\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5581 - loss: 0.6869 - val_accuracy: 0.4830 - val_loss: 0.7017 - learning_rate: 0.0086\n",
            "Epoch 3/48\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5600 - loss: 0.6864\n",
            "Epoch 3: val_loss did not improve from 0.69770\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5600 - loss: 0.6864 - val_accuracy: 0.4830 - val_loss: 0.7015 - learning_rate: 0.0086\n",
            "Epoch 4/48\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5603 - loss: 0.6863\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0029794015778826653.\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.69770\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5600 - loss: 0.6863 - val_accuracy: 0.4830 - val_loss: 0.7011 - learning_rate: 0.0086\n",
            "Epoch 5/48\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5603 - loss: 0.6847\n",
            "Epoch 5: val_loss improved from 0.69770 to 0.68341, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5602 - loss: 0.6845 - val_accuracy: 0.5445 - val_loss: 0.6834 - learning_rate: 0.0030\n",
            "Epoch 6/48\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6504 - loss: 0.6061\n",
            "Epoch 6: val_loss improved from 0.68341 to 0.57643, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6507 - loss: 0.6058 - val_accuracy: 0.7398 - val_loss: 0.5764 - learning_rate: 0.0030\n",
            "Epoch 7/48\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7035 - loss: 0.5532\n",
            "Epoch 7: val_loss improved from 0.57643 to 0.53601, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7039 - loss: 0.5527 - val_accuracy: 0.7656 - val_loss: 0.5360 - learning_rate: 0.0030\n",
            "Epoch 8/48\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7172 - loss: 0.5341\n",
            "Epoch 8: val_loss did not improve from 0.53601\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7173 - loss: 0.5340 - val_accuracy: 0.7373 - val_loss: 0.6020 - learning_rate: 0.0030\n",
            "Epoch 9/48\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7222 - loss: 0.5222\n",
            "Epoch 9: val_loss improved from 0.53601 to 0.51073, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7222 - loss: 0.5223 - val_accuracy: 0.7822 - val_loss: 0.5107 - learning_rate: 0.0030\n",
            "Epoch 10/48\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7256 - loss: 0.5179\n",
            "Epoch 10: val_loss improved from 0.51073 to 0.49348, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7257 - loss: 0.5179 - val_accuracy: 0.7905 - val_loss: 0.4935 - learning_rate: 0.0030\n",
            "Epoch 11/48\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7265 - loss: 0.5082\n",
            "Epoch 11: val_loss did not improve from 0.49348\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7270 - loss: 0.5083 - val_accuracy: 0.7880 - val_loss: 0.5035 - learning_rate: 0.0030\n",
            "Epoch 12/48\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.5049\n",
            "Epoch 12: val_loss did not improve from 0.49348\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7349 - loss: 0.5049 - val_accuracy: 0.7889 - val_loss: 0.5066 - learning_rate: 0.0030\n",
            "Epoch 13/48\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7375 - loss: 0.5057\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0010325041053513245.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.49348\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7377 - loss: 0.5057 - val_accuracy: 0.7706 - val_loss: 0.5391 - learning_rate: 0.0030\n",
            "Epoch 14/48\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7619 - loss: 0.4809\n",
            "Epoch 14: val_loss did not improve from 0.49348\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7621 - loss: 0.4808 - val_accuracy: 0.7864 - val_loss: 0.5240 - learning_rate: 0.0010\n",
            "Epoch 15/48\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7787 - loss: 0.4617\n",
            "Epoch 15: val_loss did not improve from 0.49348\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7789 - loss: 0.4618 - val_accuracy: 0.7930 - val_loss: 0.5185 - learning_rate: 0.0010\n",
            "Epoch 16/48\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7931 - loss: 0.4501\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00035781171495491724.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.49348\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7933 - loss: 0.4501 - val_accuracy: 0.7922 - val_loss: 0.5330 - learning_rate: 0.0010\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:38:14,524] Trial 0 finished with value: -0.4934810698032379 and parameters: {'epochs': 48, 'batch_size': 16, 'learning_rate': 0.008597383679239045, 'stop_patience': 6, 'reduce_lr_factor': 0.3465474880396096, 'reduce_lr_patience': 3}. Best is trial 0 with value: -0.4934810698032379.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/27\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5471 - loss: 0.6958\n",
            "Epoch 1: val_loss improved from inf to 0.74184, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5474 - loss: 0.6955 - val_accuracy: 0.5486 - val_loss: 0.7418 - learning_rate: 0.0040\n",
            "Epoch 2/27\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5918 - loss: 0.6550\n",
            "Epoch 2: val_loss did not improve from 0.74184\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5931 - loss: 0.6542 - val_accuracy: 0.6126 - val_loss: 0.8541 - learning_rate: 0.0040\n",
            "Epoch 3/27\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6703 - loss: 0.5911\n",
            "Epoch 3: val_loss improved from 0.74184 to 0.49201, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6704 - loss: 0.5911 - val_accuracy: 0.7448 - val_loss: 0.4920 - learning_rate: 0.0040\n",
            "Epoch 4/27\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7086 - loss: 0.5415\n",
            "Epoch 4: val_loss did not improve from 0.49201\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7087 - loss: 0.5415 - val_accuracy: 0.7199 - val_loss: 0.5561 - learning_rate: 0.0040\n",
            "Epoch 5/27\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7230 - loss: 0.5201\n",
            "Epoch 5: val_loss did not improve from 0.49201\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7232 - loss: 0.5197 - val_accuracy: 0.6949 - val_loss: 0.5801 - learning_rate: 0.0040\n",
            "Epoch 6/27\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7391 - loss: 0.4858\n",
            "Epoch 6: val_loss did not improve from 0.49201\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7393 - loss: 0.4856 - val_accuracy: 0.6791 - val_loss: 0.6012 - learning_rate: 0.0040\n",
            "Epoch 7/27\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7563 - loss: 0.4681\n",
            "Epoch 7: val_loss improved from 0.49201 to 0.42757, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7563 - loss: 0.4681 - val_accuracy: 0.8071 - val_loss: 0.4276 - learning_rate: 0.0040\n",
            "Epoch 8/27\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7590 - loss: 0.4647\n",
            "Epoch 8: val_loss improved from 0.42757 to 0.42195, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7595 - loss: 0.4645 - val_accuracy: 0.8171 - val_loss: 0.4219 - learning_rate: 0.0040\n",
            "Epoch 9/27\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7721 - loss: 0.4418\n",
            "Epoch 9: val_loss did not improve from 0.42195\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7719 - loss: 0.4421 - val_accuracy: 0.8005 - val_loss: 0.4606 - learning_rate: 0.0040\n",
            "Epoch 10/27\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7760 - loss: 0.4370\n",
            "Epoch 10: val_loss did not improve from 0.42195\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7762 - loss: 0.4369 - val_accuracy: 0.7997 - val_loss: 0.4538 - learning_rate: 0.0040\n",
            "Epoch 11/27\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7965 - loss: 0.4436\n",
            "Epoch 11: val_loss did not improve from 0.42195\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4434 - val_accuracy: 0.7348 - val_loss: 0.5009 - learning_rate: 0.0040\n",
            "Epoch 12/27\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8011 - loss: 0.4151\n",
            "Epoch 12: val_loss improved from 0.42195 to 0.42011, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8011 - loss: 0.4151 - val_accuracy: 0.8263 - val_loss: 0.4201 - learning_rate: 0.0040\n",
            "Epoch 13/27\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8075 - loss: 0.4194\n",
            "Epoch 13: val_loss did not improve from 0.42011\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.4194 - val_accuracy: 0.8038 - val_loss: 0.4340 - learning_rate: 0.0040\n",
            "Epoch 14/27\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8078 - loss: 0.4071\n",
            "Epoch 14: val_loss did not improve from 0.42011\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.4073 - val_accuracy: 0.8080 - val_loss: 0.4674 - learning_rate: 0.0040\n",
            "Epoch 15/27\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8091 - loss: 0.3998\n",
            "Epoch 15: val_loss improved from 0.42011 to 0.41972, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.3999 - val_accuracy: 0.8188 - val_loss: 0.4197 - learning_rate: 0.0040\n",
            "Epoch 16/27\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8131 - loss: 0.3945\n",
            "Epoch 16: val_loss did not improve from 0.41972\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8130 - loss: 0.3946 - val_accuracy: 0.7415 - val_loss: 0.4644 - learning_rate: 0.0040\n",
            "Epoch 17/27\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8148 - loss: 0.3839\n",
            "Epoch 17: val_loss did not improve from 0.41972\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8147 - loss: 0.3841 - val_accuracy: 0.7490 - val_loss: 0.5707 - learning_rate: 0.0040\n",
            "Epoch 18/27\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8173 - loss: 0.3827\n",
            "Epoch 18: val_loss did not improve from 0.41972\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8169 - loss: 0.3833 - val_accuracy: 0.7315 - val_loss: 0.6339 - learning_rate: 0.0040\n",
            "Epoch 19/27\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8181 - loss: 0.3881\n",
            "Epoch 19: val_loss did not improve from 0.41972\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8181 - loss: 0.3881 - val_accuracy: 0.6392 - val_loss: 0.9933 - learning_rate: 0.0040\n",
            "Epoch 20/27\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8157 - loss: 0.3996\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0015904976988568484.\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.41972\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8156 - loss: 0.3992 - val_accuracy: 0.7781 - val_loss: 0.4519 - learning_rate: 0.0040\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:38:56,111] Trial 1 finished with value: -0.41971808671951294 and parameters: {'epochs': 27, 'batch_size': 16, 'learning_rate': 0.003954965345974381, 'stop_patience': 5, 'reduce_lr_factor': 0.40215213947363804, 'reduce_lr_patience': 5}. Best is trial 1 with value: -0.41971808671951294.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5696 - loss: 0.6812\n",
            "Epoch 1: val_loss improved from inf to 0.96957, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5704 - loss: 0.6808 - val_accuracy: 0.5544 - val_loss: 0.9696 - learning_rate: 0.0011\n",
            "Epoch 2/45\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6544 - loss: 0.6136\n",
            "Epoch 2: val_loss improved from 0.96957 to 0.56595, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6551 - loss: 0.6129 - val_accuracy: 0.7265 - val_loss: 0.5659 - learning_rate: 0.0011\n",
            "Epoch 3/45\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6989 - loss: 0.5494\n",
            "Epoch 3: val_loss improved from 0.56595 to 0.49191, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6992 - loss: 0.5491 - val_accuracy: 0.7664 - val_loss: 0.4919 - learning_rate: 0.0011\n",
            "Epoch 4/45\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7421 - loss: 0.5042\n",
            "Epoch 4: val_loss did not improve from 0.49191\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7426 - loss: 0.5037 - val_accuracy: 0.7149 - val_loss: 0.5328 - learning_rate: 0.0011\n",
            "Epoch 5/45\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7647 - loss: 0.4618\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005328578218999464.\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.49191\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7650 - loss: 0.4616 - val_accuracy: 0.7706 - val_loss: 0.5759 - learning_rate: 0.0011\n",
            "Epoch 6/45\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7894 - loss: 0.4234\n",
            "Epoch 6: val_loss improved from 0.49191 to 0.40978, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7895 - loss: 0.4232 - val_accuracy: 0.8263 - val_loss: 0.4098 - learning_rate: 5.3286e-04\n",
            "Epoch 7/45\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8168 - loss: 0.3761\n",
            "Epoch 7: val_loss did not improve from 0.40978\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8168 - loss: 0.3761 - val_accuracy: 0.8238 - val_loss: 0.4174 - learning_rate: 5.3286e-04\n",
            "Epoch 8/45\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8251 - loss: 0.3674\n",
            "Epoch 8: val_loss improved from 0.40978 to 0.40846, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8251 - loss: 0.3677 - val_accuracy: 0.8304 - val_loss: 0.4085 - learning_rate: 5.3286e-04\n",
            "Epoch 9/45\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.3713\n",
            "Epoch 9: val_loss improved from 0.40846 to 0.38819, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8247 - loss: 0.3713 - val_accuracy: 0.8387 - val_loss: 0.3882 - learning_rate: 5.3286e-04\n",
            "Epoch 10/45\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8425 - loss: 0.3476\n",
            "Epoch 10: val_loss improved from 0.38819 to 0.38717, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8421 - loss: 0.3481 - val_accuracy: 0.8346 - val_loss: 0.3872 - learning_rate: 5.3286e-04\n",
            "Epoch 11/45\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8470 - loss: 0.3441\n",
            "Epoch 11: val_loss did not improve from 0.38717\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8468 - loss: 0.3444 - val_accuracy: 0.8313 - val_loss: 0.3904 - learning_rate: 5.3286e-04\n",
            "Epoch 12/45\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8471 - loss: 0.3408\n",
            "Epoch 12: val_loss improved from 0.38717 to 0.38609, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8468 - loss: 0.3413 - val_accuracy: 0.8379 - val_loss: 0.3861 - learning_rate: 5.3286e-04\n",
            "Epoch 13/45\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8523 - loss: 0.3333\n",
            "Epoch 13: val_loss improved from 0.38609 to 0.38152, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8521 - loss: 0.3336 - val_accuracy: 0.8337 - val_loss: 0.3815 - learning_rate: 5.3286e-04\n",
            "Epoch 14/45\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8499 - loss: 0.3326\n",
            "Epoch 14: val_loss improved from 0.38152 to 0.37208, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8496 - loss: 0.3329 - val_accuracy: 0.8313 - val_loss: 0.3721 - learning_rate: 5.3286e-04\n",
            "Epoch 15/45\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8533 - loss: 0.3258\n",
            "Epoch 15: val_loss did not improve from 0.37208\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8532 - loss: 0.3259 - val_accuracy: 0.8313 - val_loss: 0.3801 - learning_rate: 5.3286e-04\n",
            "Epoch 16/45\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8577 - loss: 0.3212\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00025329112054797405.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.37208\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 0.3215 - val_accuracy: 0.8213 - val_loss: 0.4143 - learning_rate: 5.3286e-04\n",
            "Epoch 17/45\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8676 - loss: 0.2980\n",
            "Epoch 17: val_loss did not improve from 0.37208\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8674 - loss: 0.2982 - val_accuracy: 0.8329 - val_loss: 0.3884 - learning_rate: 2.5329e-04\n",
            "Epoch 18/45\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8691 - loss: 0.2971\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00012040058254202598.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.37208\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8690 - loss: 0.2972 - val_accuracy: 0.8313 - val_loss: 0.3899 - learning_rate: 2.5329e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:39:36,934] Trial 2 finished with value: -0.3720824718475342 and parameters: {'epochs': 45, 'batch_size': 16, 'learning_rate': 0.001120992598403538, 'stop_patience': 4, 'reduce_lr_factor': 0.4753446437596067, 'reduce_lr_patience': 2}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/17\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5562 - loss: 0.6926\n",
            "Epoch 1: val_loss improved from inf to 0.76872, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5565 - loss: 0.6921 - val_accuracy: 0.5345 - val_loss: 0.7687 - learning_rate: 0.0056\n",
            "Epoch 2/17\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6027 - loss: 0.6612\n",
            "Epoch 2: val_loss did not improve from 0.76872\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6037 - loss: 0.6603 - val_accuracy: 0.5711 - val_loss: 1.4675 - learning_rate: 0.0056\n",
            "Epoch 3/17\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6691 - loss: 0.5843\n",
            "Epoch 3: val_loss improved from 0.76872 to 0.48087, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6704 - loss: 0.5827 - val_accuracy: 0.7997 - val_loss: 0.4809 - learning_rate: 0.0056\n",
            "Epoch 4/17\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7074 - loss: 0.5394\n",
            "Epoch 4: val_loss did not improve from 0.48087\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7085 - loss: 0.5387 - val_accuracy: 0.6500 - val_loss: 0.6303 - learning_rate: 0.0056\n",
            "Epoch 5/17\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7349 - loss: 0.5103\n",
            "Epoch 5: val_loss improved from 0.48087 to 0.47593, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7351 - loss: 0.5097 - val_accuracy: 0.8105 - val_loss: 0.4759 - learning_rate: 0.0056\n",
            "Epoch 6/17\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7513 - loss: 0.4613\n",
            "Epoch 6: val_loss did not improve from 0.47593\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7515 - loss: 0.4615 - val_accuracy: 0.6866 - val_loss: 0.7293 - learning_rate: 0.0056\n",
            "Epoch 7/17\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7857 - loss: 0.4280\n",
            "Epoch 7: val_loss did not improve from 0.47593\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4288 - val_accuracy: 0.7889 - val_loss: 0.4927 - learning_rate: 0.0056\n",
            "Epoch 8/17\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7906 - loss: 0.4266\n",
            "Epoch 8: val_loss improved from 0.47593 to 0.44065, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7905 - loss: 0.4266 - val_accuracy: 0.8113 - val_loss: 0.4406 - learning_rate: 0.0056\n",
            "Epoch 9/17\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7978 - loss: 0.4198\n",
            "Epoch 9: val_loss did not improve from 0.44065\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7971 - loss: 0.4208 - val_accuracy: 0.8022 - val_loss: 0.4571 - learning_rate: 0.0056\n",
            "Epoch 10/17\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.4079\n",
            "Epoch 10: val_loss did not improve from 0.44065\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.4082 - val_accuracy: 0.7531 - val_loss: 0.5119 - learning_rate: 0.0056\n",
            "Epoch 11/17\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7842 - loss: 0.4257\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0012362013895208703.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.44065\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7843 - loss: 0.4259 - val_accuracy: 0.8146 - val_loss: 0.4591 - learning_rate: 0.0056\n",
            "Epoch 12/17\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8343 - loss: 0.3680\n",
            "Epoch 12: val_loss improved from 0.44065 to 0.42591, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8346 - loss: 0.3677 - val_accuracy: 0.8180 - val_loss: 0.4259 - learning_rate: 0.0012\n",
            "Epoch 13/17\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8481 - loss: 0.3428\n",
            "Epoch 13: val_loss improved from 0.42591 to 0.42573, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8482 - loss: 0.3427 - val_accuracy: 0.8229 - val_loss: 0.4257 - learning_rate: 0.0012\n",
            "Epoch 14/17\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8537 - loss: 0.3334\n",
            "Epoch 14: val_loss did not improve from 0.42573\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8534 - loss: 0.3337 - val_accuracy: 0.7997 - val_loss: 0.4522 - learning_rate: 0.0012\n",
            "Epoch 15/17\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 0.3267\n",
            "Epoch 15: val_loss improved from 0.42573 to 0.41633, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8582 - loss: 0.3267 - val_accuracy: 0.8221 - val_loss: 0.4163 - learning_rate: 0.0012\n",
            "Epoch 16/17\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8534 - loss: 0.3231\n",
            "Epoch 16: val_loss did not improve from 0.41633\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8534 - loss: 0.3233 - val_accuracy: 0.8155 - val_loss: 0.4240 - learning_rate: 0.0012\n",
            "Epoch 17/17\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8461 - loss: 0.3266\n",
            "Epoch 17: val_loss did not improve from 0.41633\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8463 - loss: 0.3264 - val_accuracy: 0.8022 - val_loss: 0.4359 - learning_rate: 0.0012\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:40:01,317] Trial 3 finished with value: -0.4163287281990051 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.005577338159082833, 'stop_patience': 4, 'reduce_lr_factor': 0.22164720973584298, 'reduce_lr_patience': 3}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/37\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5545 - loss: 0.6889\n",
            "Epoch 1: val_loss improved from inf to 1.55128, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5578 - loss: 0.6870 - val_accuracy: 0.5503 - val_loss: 1.5513 - learning_rate: 0.0052\n",
            "Epoch 2/37\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6465 - loss: 0.6274\n",
            "Epoch 2: val_loss improved from 1.55128 to 0.46589, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6476 - loss: 0.6251 - val_accuracy: 0.7922 - val_loss: 0.4659 - learning_rate: 0.0052\n",
            "Epoch 3/37\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6965 - loss: 0.5578\n",
            "Epoch 3: val_loss improved from 0.46589 to 0.45225, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6960 - loss: 0.5584 - val_accuracy: 0.8030 - val_loss: 0.4522 - learning_rate: 0.0052\n",
            "Epoch 4/37\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7296 - loss: 0.5083\n",
            "Epoch 4: val_loss improved from 0.45225 to 0.44569, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7293 - loss: 0.5081 - val_accuracy: 0.8146 - val_loss: 0.4457 - learning_rate: 0.0052\n",
            "Epoch 5/37\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7313 - loss: 0.5028\n",
            "Epoch 5: val_loss improved from 0.44569 to 0.44316, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7316 - loss: 0.5030 - val_accuracy: 0.8138 - val_loss: 0.4432 - learning_rate: 0.0052\n",
            "Epoch 6/37\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7174 - loss: 0.5011\n",
            "Epoch 6: val_loss did not improve from 0.44316\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7186 - loss: 0.5005 - val_accuracy: 0.7357 - val_loss: 0.6127 - learning_rate: 0.0052\n",
            "Epoch 7/37\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7434 - loss: 0.4707\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0016331998413634168.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.44316\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7440 - loss: 0.4718 - val_accuracy: 0.7814 - val_loss: 0.4744 - learning_rate: 0.0052\n",
            "Epoch 8/37\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7954 - loss: 0.4246\n",
            "Epoch 8: val_loss improved from 0.44316 to 0.40851, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7953 - loss: 0.4247 - val_accuracy: 0.8279 - val_loss: 0.4085 - learning_rate: 0.0016\n",
            "Epoch 9/37\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7990 - loss: 0.4026\n",
            "Epoch 9: val_loss did not improve from 0.40851\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7994 - loss: 0.4024 - val_accuracy: 0.7963 - val_loss: 0.4496 - learning_rate: 0.0016\n",
            "Epoch 10/37\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8126 - loss: 0.3890\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005127064926558656.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.40851\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8122 - loss: 0.3894 - val_accuracy: 0.8130 - val_loss: 0.4167 - learning_rate: 0.0016\n",
            "Epoch 11/37\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8379 - loss: 0.3679\n",
            "Epoch 11: val_loss did not improve from 0.40851\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8387 - loss: 0.3667 - val_accuracy: 0.8213 - val_loss: 0.4097 - learning_rate: 5.1271e-04\n",
            "Epoch 12/37\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8369 - loss: 0.3541\n",
            "Epoch 12: val_loss improved from 0.40851 to 0.40151, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8371 - loss: 0.3541 - val_accuracy: 0.8271 - val_loss: 0.4015 - learning_rate: 5.1271e-04\n",
            "Epoch 13/37\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8472 - loss: 0.3462\n",
            "Epoch 13: val_loss improved from 0.40151 to 0.40096, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8472 - loss: 0.3465 - val_accuracy: 0.8279 - val_loss: 0.4010 - learning_rate: 5.1271e-04\n",
            "Epoch 14/37\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8518 - loss: 0.3405\n",
            "Epoch 14: val_loss did not improve from 0.40096\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8516 - loss: 0.3406 - val_accuracy: 0.8229 - val_loss: 0.4129 - learning_rate: 5.1271e-04\n",
            "Epoch 15/37\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8543 - loss: 0.3356\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00016095270359161738.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.40096\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8541 - loss: 0.3356 - val_accuracy: 0.8204 - val_loss: 0.4177 - learning_rate: 5.1271e-04\n",
            "Epoch 16/37\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8598 - loss: 0.3264\n",
            "Epoch 16: val_loss did not improve from 0.40096\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8598 - loss: 0.3263 - val_accuracy: 0.8296 - val_loss: 0.4060 - learning_rate: 1.6095e-04\n",
            "Epoch 17/37\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8610 - loss: 0.3226\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 5.0527495876231454e-05.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.40096\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8610 - loss: 0.3227 - val_accuracy: 0.8279 - val_loss: 0.4102 - learning_rate: 1.6095e-04\n",
            "Epoch 18/37\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8628 - loss: 0.3168\n",
            "Epoch 18: val_loss did not improve from 0.40096\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8627 - loss: 0.3174 - val_accuracy: 0.8337 - val_loss: 0.4063 - learning_rate: 5.0527e-05\n",
            "Epoch 19/37\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8595 - loss: 0.3213\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.5861974520505155e-05.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.40096\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8596 - loss: 0.3217 - val_accuracy: 0.8371 - val_loss: 0.4052 - learning_rate: 5.0527e-05\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:40:16,248] Trial 4 finished with value: -0.4009556174278259 and parameters: {'epochs': 37, 'batch_size': 64, 'learning_rate': 0.005202473214491373, 'stop_patience': 6, 'reduce_lr_factor': 0.3139275873262975, 'reduce_lr_patience': 2}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/21\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5667 - loss: 0.6827\n",
            "Epoch 1: val_loss improved from inf to 0.64330, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5676 - loss: 0.6820 - val_accuracy: 0.6060 - val_loss: 0.6433 - learning_rate: 8.4482e-04\n",
            "Epoch 2/21\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6685 - loss: 0.5934\n",
            "Epoch 2: val_loss improved from 0.64330 to 0.57955, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6691 - loss: 0.5930 - val_accuracy: 0.6484 - val_loss: 0.5796 - learning_rate: 8.4482e-04\n",
            "Epoch 3/21\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7119 - loss: 0.5442\n",
            "Epoch 3: val_loss did not improve from 0.57955\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7123 - loss: 0.5438 - val_accuracy: 0.6841 - val_loss: 0.6676 - learning_rate: 8.4482e-04\n",
            "Epoch 4/21\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7336 - loss: 0.5197\n",
            "Epoch 4: val_loss improved from 0.57955 to 0.52411, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7337 - loss: 0.5194 - val_accuracy: 0.7323 - val_loss: 0.5241 - learning_rate: 8.4482e-04\n",
            "Epoch 5/21\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7665 - loss: 0.4645\n",
            "Epoch 5: val_loss improved from 0.52411 to 0.49948, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7666 - loss: 0.4644 - val_accuracy: 0.7531 - val_loss: 0.4995 - learning_rate: 8.4482e-04\n",
            "Epoch 6/21\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7789 - loss: 0.4437\n",
            "Epoch 6: val_loss did not improve from 0.49948\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7789 - loss: 0.4436 - val_accuracy: 0.7190 - val_loss: 0.7165 - learning_rate: 8.4482e-04\n",
            "Epoch 7/21\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7774 - loss: 0.4404\n",
            "Epoch 7: val_loss did not improve from 0.49948\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7777 - loss: 0.4402 - val_accuracy: 0.7664 - val_loss: 0.5522 - learning_rate: 8.4482e-04\n",
            "Epoch 8/21\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7953 - loss: 0.4235\n",
            "Epoch 8: val_loss improved from 0.49948 to 0.46186, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7953 - loss: 0.4234 - val_accuracy: 0.8055 - val_loss: 0.4619 - learning_rate: 8.4482e-04\n",
            "Epoch 9/21\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8120 - loss: 0.3973\n",
            "Epoch 9: val_loss did not improve from 0.46186\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.3973 - val_accuracy: 0.7781 - val_loss: 0.5981 - learning_rate: 8.4482e-04\n",
            "Epoch 10/21\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8001 - loss: 0.3987\n",
            "Epoch 10: val_loss did not improve from 0.46186\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8002 - loss: 0.3988 - val_accuracy: 0.7664 - val_loss: 0.5732 - learning_rate: 8.4482e-04\n",
            "Epoch 11/21\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8131 - loss: 0.3804\n",
            "Epoch 11: val_loss improved from 0.46186 to 0.45271, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8134 - loss: 0.3804 - val_accuracy: 0.8163 - val_loss: 0.4527 - learning_rate: 8.4482e-04\n",
            "Epoch 12/21\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.3721\n",
            "Epoch 12: val_loss improved from 0.45271 to 0.42608, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8252 - loss: 0.3721 - val_accuracy: 0.8213 - val_loss: 0.4261 - learning_rate: 8.4482e-04\n",
            "Epoch 13/21\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8204 - loss: 0.3743\n",
            "Epoch 13: val_loss improved from 0.42608 to 0.39778, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8204 - loss: 0.3743 - val_accuracy: 0.8304 - val_loss: 0.3978 - learning_rate: 8.4482e-04\n",
            "Epoch 14/21\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8389 - loss: 0.3557\n",
            "Epoch 14: val_loss did not improve from 0.39778\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8387 - loss: 0.3560 - val_accuracy: 0.7830 - val_loss: 0.5223 - learning_rate: 8.4482e-04\n",
            "Epoch 15/21\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8420 - loss: 0.3475\n",
            "Epoch 15: val_loss improved from 0.39778 to 0.38816, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8419 - loss: 0.3478 - val_accuracy: 0.8346 - val_loss: 0.3882 - learning_rate: 8.4482e-04\n",
            "Epoch 16/21\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8383 - loss: 0.3422\n",
            "Epoch 16: val_loss did not improve from 0.38816\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8384 - loss: 0.3422 - val_accuracy: 0.7988 - val_loss: 0.5261 - learning_rate: 8.4482e-04\n",
            "Epoch 17/21\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8363 - loss: 0.3528\n",
            "Epoch 17: val_loss did not improve from 0.38816\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 0.3528 - val_accuracy: 0.8238 - val_loss: 0.4049 - learning_rate: 8.4482e-04\n",
            "Epoch 18/21\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8441 - loss: 0.3496\n",
            "Epoch 18: val_loss did not improve from 0.38816\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8441 - loss: 0.3496 - val_accuracy: 0.8071 - val_loss: 0.4053 - learning_rate: 8.4482e-04\n",
            "Epoch 19/21\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8531 - loss: 0.3416\n",
            "Epoch 19: val_loss did not improve from 0.38816\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8531 - loss: 0.3416 - val_accuracy: 0.8337 - val_loss: 0.3914 - learning_rate: 8.4482e-04\n",
            "Epoch 20/21\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.3349\n",
            "Epoch 20: val_loss improved from 0.38816 to 0.37869, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8518 - loss: 0.3350 - val_accuracy: 0.8337 - val_loss: 0.3787 - learning_rate: 8.4482e-04\n",
            "Epoch 21/21\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8525 - loss: 0.3261\n",
            "Epoch 21: val_loss did not improve from 0.37869\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8524 - loss: 0.3264 - val_accuracy: 0.8288 - val_loss: 0.4192 - learning_rate: 8.4482e-04\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:41:01,926] Trial 5 finished with value: -0.37868744134902954 and parameters: {'epochs': 21, 'batch_size': 16, 'learning_rate': 0.0008448170541277142, 'stop_patience': 7, 'reduce_lr_factor': 0.4652961326519476, 'reduce_lr_patience': 5}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/47\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5556 - loss: 0.6863\n",
            "Epoch 1: val_loss improved from inf to 0.64037, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5559 - loss: 0.6858 - val_accuracy: 0.6559 - val_loss: 0.6404 - learning_rate: 7.6991e-04\n",
            "Epoch 2/47\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6103 - loss: 0.6543\n",
            "Epoch 2: val_loss did not improve from 0.64037\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6125 - loss: 0.6526 - val_accuracy: 0.5894 - val_loss: 1.0607 - learning_rate: 7.6991e-04\n",
            "Epoch 3/47\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6685 - loss: 0.5841\n",
            "Epoch 3: val_loss improved from 0.64037 to 0.48421, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6691 - loss: 0.5837 - val_accuracy: 0.7889 - val_loss: 0.4842 - learning_rate: 7.6991e-04\n",
            "Epoch 4/47\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7100 - loss: 0.5497\n",
            "Epoch 4: val_loss did not improve from 0.48421\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7100 - loss: 0.5502 - val_accuracy: 0.7091 - val_loss: 0.5742 - learning_rate: 7.6991e-04\n",
            "Epoch 5/47\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7624 - loss: 0.5074\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00026722103618929326.\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.48421\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7612 - loss: 0.5082 - val_accuracy: 0.7573 - val_loss: 0.4847 - learning_rate: 7.6991e-04\n",
            "Epoch 6/47\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7887 - loss: 0.4658\n",
            "Epoch 6: val_loss did not improve from 0.48421\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7886 - loss: 0.4657 - val_accuracy: 0.7631 - val_loss: 0.5158 - learning_rate: 2.6722e-04\n",
            "Epoch 7/47\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7860 - loss: 0.4508\n",
            "Epoch 7: val_loss improved from 0.48421 to 0.47170, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7863 - loss: 0.4510 - val_accuracy: 0.7739 - val_loss: 0.4717 - learning_rate: 2.6722e-04\n",
            "Epoch 8/47\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4352\n",
            "Epoch 8: val_loss did not improve from 0.47170\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8002 - loss: 0.4360 - val_accuracy: 0.7265 - val_loss: 0.5447 - learning_rate: 2.6722e-04\n",
            "Epoch 9/47\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.4209\n",
            "Epoch 9: val_loss improved from 0.47170 to 0.45897, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8107 - loss: 0.4214 - val_accuracy: 0.7905 - val_loss: 0.4590 - learning_rate: 2.6722e-04\n",
            "Epoch 10/47\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8025 - loss: 0.4167\n",
            "Epoch 10: val_loss did not improve from 0.45897\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8036 - loss: 0.4170 - val_accuracy: 0.7548 - val_loss: 0.5142 - learning_rate: 2.6722e-04\n",
            "Epoch 11/47\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8173 - loss: 0.4066\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.274685688120494e-05.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.45897\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8171 - loss: 0.4074 - val_accuracy: 0.7614 - val_loss: 0.4846 - learning_rate: 2.6722e-04\n",
            "Epoch 12/47\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8346 - loss: 0.3964\n",
            "Epoch 12: val_loss improved from 0.45897 to 0.43417, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8346 - loss: 0.3964 - val_accuracy: 0.8229 - val_loss: 0.4342 - learning_rate: 9.2747e-05\n",
            "Epoch 13/47\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8377 - loss: 0.3826\n",
            "Epoch 13: val_loss did not improve from 0.43417\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8372 - loss: 0.3832 - val_accuracy: 0.8121 - val_loss: 0.4349 - learning_rate: 9.2747e-05\n",
            "Epoch 14/47\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8434 - loss: 0.3766\n",
            "Epoch 14: val_loss improved from 0.43417 to 0.42913, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8434 - loss: 0.3769 - val_accuracy: 0.8221 - val_loss: 0.4291 - learning_rate: 9.2747e-05\n",
            "Epoch 15/47\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8301 - loss: 0.3818\n",
            "Epoch 15: val_loss did not improve from 0.42913\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8306 - loss: 0.3819 - val_accuracy: 0.8163 - val_loss: 0.4335 - learning_rate: 9.2747e-05\n",
            "Epoch 16/47\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8356 - loss: 0.3767\n",
            "Epoch 16: val_loss improved from 0.42913 to 0.42896, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8358 - loss: 0.3770 - val_accuracy: 0.8180 - val_loss: 0.4290 - learning_rate: 9.2747e-05\n",
            "Epoch 17/47\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8395 - loss: 0.3699\n",
            "Epoch 17: val_loss did not improve from 0.42896\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8400 - loss: 0.3706 - val_accuracy: 0.8047 - val_loss: 0.4429 - learning_rate: 9.2747e-05\n",
            "Epoch 18/47\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8426 - loss: 0.3673\n",
            "Epoch 18: val_loss improved from 0.42896 to 0.42391, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8424 - loss: 0.3677 - val_accuracy: 0.8204 - val_loss: 0.4239 - learning_rate: 9.2747e-05\n",
            "Epoch 19/47\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8440 - loss: 0.3672\n",
            "Epoch 19: val_loss did not improve from 0.42391\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8440 - loss: 0.3673 - val_accuracy: 0.8146 - val_loss: 0.4351 - learning_rate: 9.2747e-05\n",
            "Epoch 20/47\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8449 - loss: 0.3632\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.2190502350539654e-05.\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.42391\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8450 - loss: 0.3634 - val_accuracy: 0.8088 - val_loss: 0.4395 - learning_rate: 9.2747e-05\n",
            "Epoch 21/47\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8473 - loss: 0.3596\n",
            "Epoch 21: val_loss did not improve from 0.42391\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8478 - loss: 0.3602 - val_accuracy: 0.8155 - val_loss: 0.4348 - learning_rate: 3.2191e-05\n",
            "Epoch 22/47\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8508 - loss: 0.3561\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.1172652990631757e-05.\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.42391\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8506 - loss: 0.3569 - val_accuracy: 0.8171 - val_loss: 0.4327 - learning_rate: 3.2191e-05\n",
            "Epoch 23/47\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8460 - loss: 0.3549\n",
            "Epoch 23: val_loss improved from 0.42391 to 0.41770, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8465 - loss: 0.3553 - val_accuracy: 0.8246 - val_loss: 0.4177 - learning_rate: 1.1173e-05\n",
            "Epoch 24/47\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8571 - loss: 0.3520\n",
            "Epoch 24: val_loss improved from 0.41770 to 0.41688, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8571 - loss: 0.3525 - val_accuracy: 0.8279 - val_loss: 0.4169 - learning_rate: 1.1173e-05\n",
            "Epoch 25/47\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8549 - loss: 0.3500\n",
            "Epoch 25: val_loss did not improve from 0.41688\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8547 - loss: 0.3508 - val_accuracy: 0.8263 - val_loss: 0.4203 - learning_rate: 1.1173e-05\n",
            "Epoch 26/47\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8616 - loss: 0.3492\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 3.8777951791883445e-06.\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.41688\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8613 - loss: 0.3499 - val_accuracy: 0.8246 - val_loss: 0.4243 - learning_rate: 1.1173e-05\n",
            "Epoch 27/47\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8536 - loss: 0.3479\n",
            "Epoch 27: val_loss did not improve from 0.41688\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8536 - loss: 0.3481 - val_accuracy: 0.8238 - val_loss: 0.4248 - learning_rate: 3.8778e-06\n",
            "Epoch 28/47\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8472 - loss: 0.3531\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.345901971726311e-06.\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.41688\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8478 - loss: 0.3536 - val_accuracy: 0.8254 - val_loss: 0.4239 - learning_rate: 3.8778e-06\n",
            "Epoch 29/47\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8573 - loss: 0.3548\n",
            "Epoch 29: val_loss did not improve from 0.41688\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8572 - loss: 0.3549 - val_accuracy: 0.8246 - val_loss: 0.4234 - learning_rate: 1.3459e-06\n",
            "Epoch 30/47\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8522 - loss: 0.3497\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.41688\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8521 - loss: 0.3507 - val_accuracy: 0.8254 - val_loss: 0.4227 - learning_rate: 1.3459e-06\n",
            "Epoch 31/47\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8520 - loss: 0.3536\n",
            "Epoch 31: val_loss did not improve from 0.41688\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8523 - loss: 0.3540 - val_accuracy: 0.8263 - val_loss: 0.4226 - learning_rate: 1.0000e-06\n",
            "Epoch 31: early stopping\n",
            "Restoring model weights from the end of the best epoch: 24.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:41:24,522] Trial 6 finished with value: -0.4168836176395416 and parameters: {'epochs': 47, 'batch_size': 64, 'learning_rate': 0.0007699138004934441, 'stop_patience': 7, 'reduce_lr_factor': 0.3470791712043476, 'reduce_lr_patience': 2}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5601 - loss: 0.6893\n",
            "Epoch 1: val_loss improved from inf to 0.67065, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5603 - loss: 0.6891 - val_accuracy: 0.5786 - val_loss: 0.6707 - learning_rate: 0.0022\n",
            "Epoch 2/13\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6351 - loss: 0.6283\n",
            "Epoch 2: val_loss improved from 0.67065 to 0.55114, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6358 - loss: 0.6275 - val_accuracy: 0.7082 - val_loss: 0.5511 - learning_rate: 0.0022\n",
            "Epoch 3/13\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6848 - loss: 0.5553\n",
            "Epoch 3: val_loss did not improve from 0.55114\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6854 - loss: 0.5549 - val_accuracy: 0.6683 - val_loss: 0.6850 - learning_rate: 0.0022\n",
            "Epoch 4/13\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.5167\n",
            "Epoch 4: val_loss improved from 0.55114 to 0.51990, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7264 - loss: 0.5165 - val_accuracy: 0.7332 - val_loss: 0.5199 - learning_rate: 0.0022\n",
            "Epoch 5/13\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7461 - loss: 0.4863\n",
            "Epoch 5: val_loss improved from 0.51990 to 0.44117, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7463 - loss: 0.4860 - val_accuracy: 0.7889 - val_loss: 0.4412 - learning_rate: 0.0022\n",
            "Epoch 6/13\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7725 - loss: 0.4395\n",
            "Epoch 6: val_loss did not improve from 0.44117\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7727 - loss: 0.4397 - val_accuracy: 0.7290 - val_loss: 0.6601 - learning_rate: 0.0022\n",
            "Epoch 7/13\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7715 - loss: 0.4517\n",
            "Epoch 7: val_loss did not improve from 0.44117\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7716 - loss: 0.4516 - val_accuracy: 0.7938 - val_loss: 0.5118 - learning_rate: 0.0022\n",
            "Epoch 8/13\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7749 - loss: 0.4382\n",
            "Epoch 8: val_loss did not improve from 0.44117\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7749 - loss: 0.4389 - val_accuracy: 0.7980 - val_loss: 0.6223 - learning_rate: 0.0022\n",
            "Epoch 9/13\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7799 - loss: 0.4365\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009612071431532194.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.44117\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7804 - loss: 0.4362 - val_accuracy: 0.7307 - val_loss: 0.6005 - learning_rate: 0.0022\n",
            "Epoch 10/13\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.4137\n",
            "Epoch 10: val_loss improved from 0.44117 to 0.40332, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7928 - loss: 0.4130 - val_accuracy: 0.8329 - val_loss: 0.4033 - learning_rate: 9.6121e-04\n",
            "Epoch 11/13\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.3648\n",
            "Epoch 11: val_loss improved from 0.40332 to 0.39852, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8254 - loss: 0.3648 - val_accuracy: 0.8304 - val_loss: 0.3985 - learning_rate: 9.6121e-04\n",
            "Epoch 12/13\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8444 - loss: 0.3499\n",
            "Epoch 12: val_loss improved from 0.39852 to 0.39473, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8443 - loss: 0.3500 - val_accuracy: 0.8329 - val_loss: 0.3947 - learning_rate: 9.6121e-04\n",
            "Epoch 13/13\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8455 - loss: 0.3363\n",
            "Epoch 13: val_loss did not improve from 0.39473\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8455 - loss: 0.3365 - val_accuracy: 0.8321 - val_loss: 0.4145 - learning_rate: 9.6121e-04\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:41:47,984] Trial 7 finished with value: -0.3947293758392334 and parameters: {'epochs': 13, 'batch_size': 16, 'learning_rate': 0.0022150100075120716, 'stop_patience': 8, 'reduce_lr_factor': 0.4339515820138957, 'reduce_lr_patience': 4}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5581 - loss: 0.6864\n",
            "Epoch 1: val_loss improved from inf to 0.59666, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5582 - loss: 0.6863 - val_accuracy: 0.7431 - val_loss: 0.5967 - learning_rate: 0.0011\n",
            "Epoch 2/45\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6335 - loss: 0.6315\n",
            "Epoch 2: val_loss improved from 0.59666 to 0.49224, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6360 - loss: 0.6292 - val_accuracy: 0.7872 - val_loss: 0.4922 - learning_rate: 0.0011\n",
            "Epoch 3/45\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7177 - loss: 0.5516\n",
            "Epoch 3: val_loss improved from 0.49224 to 0.47854, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7179 - loss: 0.5510 - val_accuracy: 0.7914 - val_loss: 0.4785 - learning_rate: 0.0011\n",
            "Epoch 4/45\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7356 - loss: 0.4986\n",
            "Epoch 4: val_loss improved from 0.47854 to 0.46403, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7362 - loss: 0.4983 - val_accuracy: 0.8121 - val_loss: 0.4640 - learning_rate: 0.0011\n",
            "Epoch 5/45\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7699 - loss: 0.4632\n",
            "Epoch 5: val_loss improved from 0.46403 to 0.43368, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7707 - loss: 0.4630 - val_accuracy: 0.7922 - val_loss: 0.4337 - learning_rate: 0.0011\n",
            "Epoch 6/45\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7560 - loss: 0.4735\n",
            "Epoch 6: val_loss did not improve from 0.43368\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7575 - loss: 0.4724 - val_accuracy: 0.7049 - val_loss: 0.6404 - learning_rate: 0.0011\n",
            "Epoch 7/45\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7962 - loss: 0.4229\n",
            "Epoch 7: val_loss improved from 0.43368 to 0.39109, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7962 - loss: 0.4229 - val_accuracy: 0.8379 - val_loss: 0.3911 - learning_rate: 0.0011\n",
            "Epoch 8/45\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.4031\n",
            "Epoch 8: val_loss did not improve from 0.39109\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8055 - loss: 0.4046 - val_accuracy: 0.8071 - val_loss: 0.4738 - learning_rate: 0.0011\n",
            "Epoch 9/45\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8224 - loss: 0.3853\n",
            "Epoch 9: val_loss did not improve from 0.39109\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8223 - loss: 0.3854 - val_accuracy: 0.8337 - val_loss: 0.4025 - learning_rate: 0.0011\n",
            "Epoch 10/45\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.3842\n",
            "Epoch 10: val_loss did not improve from 0.39109\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8138 - loss: 0.3849 - val_accuracy: 0.8271 - val_loss: 0.3949 - learning_rate: 0.0011\n",
            "Epoch 11/45\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8212 - loss: 0.3868\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0003010880161280662.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.39109\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8217 - loss: 0.3858 - val_accuracy: 0.8263 - val_loss: 0.3913 - learning_rate: 0.0011\n",
            "Epoch 12/45\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 0.3608\n",
            "Epoch 12: val_loss did not improve from 0.39109\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8398 - loss: 0.3592 - val_accuracy: 0.8387 - val_loss: 0.3967 - learning_rate: 3.0109e-04\n",
            "Epoch 13/45\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8609 - loss: 0.3302\n",
            "Epoch 13: val_loss did not improve from 0.39109\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8599 - loss: 0.3311 - val_accuracy: 0.8379 - val_loss: 0.3942 - learning_rate: 3.0109e-04\n",
            "Epoch 14/45\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8495 - loss: 0.3331\n",
            "Epoch 14: val_loss did not improve from 0.39109\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8495 - loss: 0.3332 - val_accuracy: 0.8354 - val_loss: 0.3945 - learning_rate: 3.0109e-04\n",
            "Epoch 15/45\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8594 - loss: 0.3197\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 7.982038172488956e-05.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.39109\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8587 - loss: 0.3208 - val_accuracy: 0.8337 - val_loss: 0.4033 - learning_rate: 3.0109e-04\n",
            "Epoch 16/45\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8691 - loss: 0.3090\n",
            "Epoch 16: val_loss did not improve from 0.39109\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8690 - loss: 0.3088 - val_accuracy: 0.8429 - val_loss: 0.3963 - learning_rate: 7.9820e-05\n",
            "Epoch 17/45\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8747 - loss: 0.3019\n",
            "Epoch 17: val_loss did not improve from 0.39109\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8747 - loss: 0.3019 - val_accuracy: 0.8454 - val_loss: 0.3930 - learning_rate: 7.9820e-05\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:42:02,639] Trial 8 finished with value: -0.39109376072883606 and parameters: {'epochs': 45, 'batch_size': 64, 'learning_rate': 0.0011357247881677516, 'stop_patience': 10, 'reduce_lr_factor': 0.26510648381087787, 'reduce_lr_patience': 4}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/43\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5573 - loss: 0.6872\n",
            "Epoch 1: val_loss improved from inf to 0.58946, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5577 - loss: 0.6870 - val_accuracy: 0.6841 - val_loss: 0.5895 - learning_rate: 0.0038\n",
            "Epoch 2/43\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6261 - loss: 0.6486\n",
            "Epoch 2: val_loss improved from 0.58946 to 0.52305, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6262 - loss: 0.6488 - val_accuracy: 0.7614 - val_loss: 0.5230 - learning_rate: 0.0038\n",
            "Epoch 3/43\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6996 - loss: 0.5629\n",
            "Epoch 3: val_loss did not improve from 0.52305\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6989 - loss: 0.5632 - val_accuracy: 0.6467 - val_loss: 0.6368 - learning_rate: 0.0038\n",
            "Epoch 4/43\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7081 - loss: 0.5341\n",
            "Epoch 4: val_loss improved from 0.52305 to 0.44050, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7084 - loss: 0.5344 - val_accuracy: 0.8063 - val_loss: 0.4405 - learning_rate: 0.0038\n",
            "Epoch 5/43\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7090 - loss: 0.5211\n",
            "Epoch 5: val_loss did not improve from 0.44050\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7111 - loss: 0.5203 - val_accuracy: 0.8121 - val_loss: 0.4424 - learning_rate: 0.0038\n",
            "Epoch 6/43\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7470 - loss: 0.4824\n",
            "Epoch 6: val_loss did not improve from 0.44050\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7472 - loss: 0.4839 - val_accuracy: 0.6085 - val_loss: 0.8162 - learning_rate: 0.0038\n",
            "Epoch 7/43\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7544 - loss: 0.4867\n",
            "Epoch 7: val_loss did not improve from 0.44050\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7545 - loss: 0.4865 - val_accuracy: 0.7598 - val_loss: 0.4901 - learning_rate: 0.0038\n",
            "Epoch 8/43\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7713 - loss: 0.4453\n",
            "Epoch 8: val_loss did not improve from 0.44050\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7712 - loss: 0.4455 - val_accuracy: 0.7955 - val_loss: 0.4558 - learning_rate: 0.0038\n",
            "Epoch 9/43\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7770 - loss: 0.4459\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.000506981293525839.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.44050\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7768 - loss: 0.4463 - val_accuracy: 0.6941 - val_loss: 0.6063 - learning_rate: 0.0038\n",
            "Epoch 10/43\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.3944\n",
            "Epoch 10: val_loss improved from 0.44050 to 0.41122, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8140 - loss: 0.3941 - val_accuracy: 0.8246 - val_loss: 0.4112 - learning_rate: 5.0698e-04\n",
            "Epoch 11/43\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8290 - loss: 0.3763\n",
            "Epoch 11: val_loss did not improve from 0.41122\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8290 - loss: 0.3763 - val_accuracy: 0.8296 - val_loss: 0.4136 - learning_rate: 5.0698e-04\n",
            "Epoch 12/43\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8446 - loss: 0.3568\n",
            "Epoch 12: val_loss did not improve from 0.41122\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8446 - loss: 0.3567 - val_accuracy: 0.8304 - val_loss: 0.4125 - learning_rate: 5.0698e-04\n",
            "Epoch 13/43\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8562 - loss: 0.3456\n",
            "Epoch 13: val_loss did not improve from 0.41122\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8547 - loss: 0.3465 - val_accuracy: 0.8196 - val_loss: 0.4237 - learning_rate: 5.0698e-04\n",
            "Epoch 14/43\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8502 - loss: 0.3433\n",
            "Epoch 14: val_loss improved from 0.41122 to 0.40979, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8501 - loss: 0.3434 - val_accuracy: 0.8313 - val_loss: 0.4098 - learning_rate: 5.0698e-04\n",
            "Epoch 15/43\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8492 - loss: 0.3372\n",
            "Epoch 15: val_loss improved from 0.40979 to 0.40746, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8490 - loss: 0.3375 - val_accuracy: 0.8288 - val_loss: 0.4075 - learning_rate: 5.0698e-04\n",
            "Epoch 16/43\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8597 - loss: 0.3285\n",
            "Epoch 16: val_loss did not improve from 0.40746\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8596 - loss: 0.3286 - val_accuracy: 0.8238 - val_loss: 0.4175 - learning_rate: 5.0698e-04\n",
            "Epoch 17/43\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8479 - loss: 0.3337\n",
            "Epoch 17: val_loss did not improve from 0.40746\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8480 - loss: 0.3337 - val_accuracy: 0.8271 - val_loss: 0.4116 - learning_rate: 5.0698e-04\n",
            "Epoch 18/43\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8577 - loss: 0.3292\n",
            "Epoch 18: val_loss did not improve from 0.40746\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8577 - loss: 0.3292 - val_accuracy: 0.8229 - val_loss: 0.4150 - learning_rate: 5.0698e-04\n",
            "Epoch 19/43\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8602 - loss: 0.3221\n",
            "Epoch 19: val_loss did not improve from 0.40746\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8601 - loss: 0.3222 - val_accuracy: 0.8288 - val_loss: 0.4108 - learning_rate: 5.0698e-04\n",
            "Epoch 20/43\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8566 - loss: 0.3225\n",
            "Epoch 20: val_loss improved from 0.40746 to 0.40289, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8566 - loss: 0.3226 - val_accuracy: 0.8371 - val_loss: 0.4029 - learning_rate: 5.0698e-04\n",
            "Epoch 21/43\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8574 - loss: 0.3223\n",
            "Epoch 21: val_loss did not improve from 0.40289\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8576 - loss: 0.3223 - val_accuracy: 0.8346 - val_loss: 0.4113 - learning_rate: 5.0698e-04\n",
            "Epoch 22/43\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8648 - loss: 0.3157\n",
            "Epoch 22: val_loss improved from 0.40289 to 0.40042, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8644 - loss: 0.3164 - val_accuracy: 0.8246 - val_loss: 0.4004 - learning_rate: 5.0698e-04\n",
            "Epoch 23/43\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8616 - loss: 0.3156\n",
            "Epoch 23: val_loss did not improve from 0.40042\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8617 - loss: 0.3157 - val_accuracy: 0.8296 - val_loss: 0.4022 - learning_rate: 5.0698e-04\n",
            "Epoch 24/43\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8605 - loss: 0.3170\n",
            "Epoch 24: val_loss did not improve from 0.40042\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8603 - loss: 0.3168 - val_accuracy: 0.8329 - val_loss: 0.4048 - learning_rate: 5.0698e-04\n",
            "Epoch 25/43\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8606 - loss: 0.3149\n",
            "Epoch 25: val_loss did not improve from 0.40042\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8606 - loss: 0.3149 - val_accuracy: 0.8263 - val_loss: 0.4122 - learning_rate: 5.0698e-04\n",
            "Epoch 26/43\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8624 - loss: 0.3125\n",
            "Epoch 26: val_loss did not improve from 0.40042\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8629 - loss: 0.3121 - val_accuracy: 0.8337 - val_loss: 0.4068 - learning_rate: 5.0698e-04\n",
            "Epoch 27/43\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8629 - loss: 0.3053\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 6.84054613084499e-05.\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.40042\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8631 - loss: 0.3053 - val_accuracy: 0.8304 - val_loss: 0.4200 - learning_rate: 5.0698e-04\n",
            "Epoch 28/43\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8778 - loss: 0.2960\n",
            "Epoch 28: val_loss improved from 0.40042 to 0.40035, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8778 - loss: 0.2960 - val_accuracy: 0.8362 - val_loss: 0.4003 - learning_rate: 6.8405e-05\n",
            "Epoch 29/43\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8736 - loss: 0.2901\n",
            "Epoch 29: val_loss did not improve from 0.40035\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8736 - loss: 0.2902 - val_accuracy: 0.8371 - val_loss: 0.4038 - learning_rate: 6.8405e-05\n",
            "Epoch 30/43\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8720 - loss: 0.2918\n",
            "Epoch 30: val_loss did not improve from 0.40035\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8720 - loss: 0.2918 - val_accuracy: 0.8346 - val_loss: 0.4020 - learning_rate: 6.8405e-05\n",
            "Epoch 31/43\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8739 - loss: 0.2876\n",
            "Epoch 31: val_loss did not improve from 0.40035\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8738 - loss: 0.2880 - val_accuracy: 0.8362 - val_loss: 0.4024 - learning_rate: 6.8405e-05\n",
            "Epoch 32/43\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8707 - loss: 0.2918\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 9.22974348677268e-06.\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.40035\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8713 - loss: 0.2917 - val_accuracy: 0.8371 - val_loss: 0.4061 - learning_rate: 6.8405e-05\n",
            "Epoch 33/43\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8754 - loss: 0.2853\n",
            "Epoch 33: val_loss did not improve from 0.40035\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8754 - loss: 0.2854 - val_accuracy: 0.8379 - val_loss: 0.4070 - learning_rate: 9.2297e-06\n",
            "Epoch 34/43\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8720 - loss: 0.2906\n",
            "Epoch 34: val_loss did not improve from 0.40035\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8720 - loss: 0.2906 - val_accuracy: 0.8371 - val_loss: 0.4077 - learning_rate: 9.2297e-06\n",
            "Epoch 35/43\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8752 - loss: 0.2869\n",
            "Epoch 35: val_loss did not improve from 0.40035\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8751 - loss: 0.2870 - val_accuracy: 0.8379 - val_loss: 0.4073 - learning_rate: 9.2297e-06\n",
            "Epoch 36/43\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8700 - loss: 0.2883\n",
            "Epoch 36: val_loss did not improve from 0.40035\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8701 - loss: 0.2883 - val_accuracy: 0.8371 - val_loss: 0.4074 - learning_rate: 9.2297e-06\n",
            "Epoch 37/43\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8737 - loss: 0.2870\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.2453415405118475e-06.\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.40035\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8738 - loss: 0.2871 - val_accuracy: 0.8379 - val_loss: 0.4081 - learning_rate: 9.2297e-06\n",
            "Epoch 38/43\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8740 - loss: 0.2844\n",
            "Epoch 38: val_loss did not improve from 0.40035\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8740 - loss: 0.2844 - val_accuracy: 0.8371 - val_loss: 0.4082 - learning_rate: 1.2453e-06\n",
            "Epoch 38: early stopping\n",
            "Restoring model weights from the end of the best epoch: 28.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:42:30,969] Trial 9 finished with value: -0.40034618973731995 and parameters: {'epochs': 43, 'batch_size': 64, 'learning_rate': 0.0037574488561793865, 'stop_patience': 10, 'reduce_lr_factor': 0.1349269974059714, 'reduce_lr_patience': 5}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5490 - loss: 0.7047\n",
            "Epoch 1: val_loss improved from inf to 0.70130, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5490 - loss: 0.7046 - val_accuracy: 0.4830 - val_loss: 0.7013 - learning_rate: 0.0075\n",
            "Epoch 2/35\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5599 - loss: 0.6859\n",
            "Epoch 2: val_loss improved from 0.70130 to 0.68391, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5595 - loss: 0.6860 - val_accuracy: 0.5669 - val_loss: 0.6839 - learning_rate: 0.0075\n",
            "Epoch 3/35\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5679 - loss: 0.6838\n",
            "Epoch 3: val_loss improved from 0.68391 to 0.65992, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5680 - loss: 0.6837 - val_accuracy: 0.5977 - val_loss: 0.6599 - learning_rate: 0.0075\n",
            "Epoch 4/35\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6201 - loss: 0.6427\n",
            "Epoch 4: val_loss did not improve from 0.65992\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6206 - loss: 0.6420 - val_accuracy: 0.5428 - val_loss: 1.0017 - learning_rate: 0.0075\n",
            "Epoch 5/35\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6432 - loss: 0.5956\n",
            "Epoch 5: val_loss improved from 0.65992 to 0.64206, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6445 - loss: 0.5947 - val_accuracy: 0.6409 - val_loss: 0.6421 - learning_rate: 0.0075\n",
            "Epoch 6/35\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6967 - loss: 0.5332\n",
            "Epoch 6: val_loss improved from 0.64206 to 0.50672, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6968 - loss: 0.5331 - val_accuracy: 0.7581 - val_loss: 0.5067 - learning_rate: 0.0075\n",
            "Epoch 7/35\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7184 - loss: 0.5090\n",
            "Epoch 7: val_loss did not improve from 0.50672\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7187 - loss: 0.5087 - val_accuracy: 0.7905 - val_loss: 0.5147 - learning_rate: 0.0075\n",
            "Epoch 8/35\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7260 - loss: 0.5024\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0035323093637116376.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.50672\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7261 - loss: 0.5025 - val_accuracy: 0.7473 - val_loss: 0.5970 - learning_rate: 0.0075\n",
            "Epoch 9/35\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7829 - loss: 0.4511\n",
            "Epoch 9: val_loss improved from 0.50672 to 0.45724, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7829 - loss: 0.4511 - val_accuracy: 0.7938 - val_loss: 0.4572 - learning_rate: 0.0035\n",
            "Epoch 10/35\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7940 - loss: 0.4237\n",
            "Epoch 10: val_loss did not improve from 0.45724\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7948 - loss: 0.4229 - val_accuracy: 0.7091 - val_loss: 0.5209 - learning_rate: 0.0035\n",
            "Epoch 11/35\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 0.4511\n",
            "Epoch 11: val_loss improved from 0.45724 to 0.45250, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7910 - loss: 0.4506 - val_accuracy: 0.7922 - val_loss: 0.4525 - learning_rate: 0.0035\n",
            "Epoch 12/35\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8089 - loss: 0.4061\n",
            "Epoch 12: val_loss did not improve from 0.45250\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8093 - loss: 0.4054 - val_accuracy: 0.7731 - val_loss: 0.4758 - learning_rate: 0.0035\n",
            "Epoch 13/35\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8166 - loss: 0.4018\n",
            "Epoch 13: val_loss improved from 0.45250 to 0.44419, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8167 - loss: 0.4015 - val_accuracy: 0.8113 - val_loss: 0.4442 - learning_rate: 0.0035\n",
            "Epoch 14/35\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.3846\n",
            "Epoch 14: val_loss did not improve from 0.44419\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8169 - loss: 0.3845 - val_accuracy: 0.7573 - val_loss: 0.4774 - learning_rate: 0.0035\n",
            "Epoch 15/35\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8246 - loss: 0.3814\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.001672641398666109.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.44419\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8248 - loss: 0.3812 - val_accuracy: 0.7382 - val_loss: 0.4778 - learning_rate: 0.0035\n",
            "Epoch 16/35\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8327 - loss: 0.3629\n",
            "Epoch 16: val_loss improved from 0.44419 to 0.43340, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8330 - loss: 0.3626 - val_accuracy: 0.8121 - val_loss: 0.4334 - learning_rate: 0.0017\n",
            "Epoch 17/35\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8484 - loss: 0.3475\n",
            "Epoch 17: val_loss did not improve from 0.43340\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8483 - loss: 0.3474 - val_accuracy: 0.8196 - val_loss: 0.4502 - learning_rate: 0.0017\n",
            "Epoch 18/35\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8425 - loss: 0.3480\n",
            "Epoch 18: val_loss improved from 0.43340 to 0.42766, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8425 - loss: 0.3480 - val_accuracy: 0.8163 - val_loss: 0.4277 - learning_rate: 0.0017\n",
            "Epoch 19/35\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8455 - loss: 0.3438\n",
            "Epoch 19: val_loss did not improve from 0.42766\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8455 - loss: 0.3438 - val_accuracy: 0.8121 - val_loss: 0.4891 - learning_rate: 0.0017\n",
            "Epoch 20/35\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8425 - loss: 0.3473\n",
            "Epoch 20: val_loss improved from 0.42766 to 0.41926, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8426 - loss: 0.3472 - val_accuracy: 0.8238 - val_loss: 0.4193 - learning_rate: 0.0017\n",
            "Epoch 21/35\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8467 - loss: 0.3402\n",
            "Epoch 21: val_loss did not improve from 0.41926\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8468 - loss: 0.3405 - val_accuracy: 0.8196 - val_loss: 0.4201 - learning_rate: 0.0017\n",
            "Epoch 22/35\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8521 - loss: 0.3327\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0007920396985999288.\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.41926\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8520 - loss: 0.3327 - val_accuracy: 0.8146 - val_loss: 0.4431 - learning_rate: 0.0017\n",
            "Epoch 23/35\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8545 - loss: 0.3271\n",
            "Epoch 23: val_loss improved from 0.41926 to 0.41737, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8545 - loss: 0.3271 - val_accuracy: 0.8229 - val_loss: 0.4174 - learning_rate: 7.9204e-04\n",
            "Epoch 24/35\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8559 - loss: 0.3234\n",
            "Epoch 24: val_loss improved from 0.41737 to 0.41385, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8560 - loss: 0.3234 - val_accuracy: 0.8238 - val_loss: 0.4139 - learning_rate: 7.9204e-04\n",
            "Epoch 25/35\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8516 - loss: 0.3242\n",
            "Epoch 25: val_loss did not improve from 0.41385\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8518 - loss: 0.3242 - val_accuracy: 0.8221 - val_loss: 0.4189 - learning_rate: 7.9204e-04\n",
            "Epoch 26/35\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8527 - loss: 0.3205\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0003750516248857743.\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.41385\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8529 - loss: 0.3205 - val_accuracy: 0.8180 - val_loss: 0.4204 - learning_rate: 7.9204e-04\n",
            "Epoch 27/35\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8531 - loss: 0.3153\n",
            "Epoch 27: val_loss did not improve from 0.41385\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8532 - loss: 0.3153 - val_accuracy: 0.8163 - val_loss: 0.4199 - learning_rate: 3.7505e-04\n",
            "Epoch 27: early stopping\n",
            "Restoring model weights from the end of the best epoch: 24.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:43:07,568] Trial 10 finished with value: -0.4138510823249817 and parameters: {'epochs': 35, 'batch_size': 32, 'learning_rate': 0.0074595841845211015, 'stop_patience': 3, 'reduce_lr_factor': 0.47352631043972965, 'reduce_lr_patience': 2}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/22\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5500 - loss: 0.6899\n",
            "Epoch 1: val_loss improved from inf to 0.65973, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5505 - loss: 0.6897 - val_accuracy: 0.5603 - val_loss: 0.6597 - learning_rate: 0.0023\n",
            "Epoch 2/22\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5893 - loss: 0.6756\n",
            "Epoch 2: val_loss improved from 0.65973 to 0.56996, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5901 - loss: 0.6748 - val_accuracy: 0.7298 - val_loss: 0.5700 - learning_rate: 0.0023\n",
            "Epoch 3/22\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6576 - loss: 0.6028\n",
            "Epoch 3: val_loss improved from 0.56996 to 0.47992, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6580 - loss: 0.6022 - val_accuracy: 0.8088 - val_loss: 0.4799 - learning_rate: 0.0023\n",
            "Epoch 4/22\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7137 - loss: 0.5321\n",
            "Epoch 4: val_loss did not improve from 0.47992\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7140 - loss: 0.5318 - val_accuracy: 0.6949 - val_loss: 0.6575 - learning_rate: 0.0023\n",
            "Epoch 5/22\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7378 - loss: 0.5057\n",
            "Epoch 5: val_loss did not improve from 0.47992\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7379 - loss: 0.5056 - val_accuracy: 0.7706 - val_loss: 0.5349 - learning_rate: 0.0023\n",
            "Epoch 6/22\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.4747\n",
            "Epoch 6: val_loss did not improve from 0.47992\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7571 - loss: 0.4744 - val_accuracy: 0.7914 - val_loss: 0.4815 - learning_rate: 0.0023\n",
            "Epoch 7/22\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7839 - loss: 0.4350\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.001161270235037679.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.47992\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7840 - loss: 0.4349 - val_accuracy: 0.7897 - val_loss: 0.4926 - learning_rate: 0.0023\n",
            "Epoch 8/22\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.3985\n",
            "Epoch 8: val_loss improved from 0.47992 to 0.45709, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.3985 - val_accuracy: 0.7972 - val_loss: 0.4571 - learning_rate: 0.0012\n",
            "Epoch 9/22\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8240 - loss: 0.3821\n",
            "Epoch 9: val_loss improved from 0.45709 to 0.41100, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.3823 - val_accuracy: 0.8204 - val_loss: 0.4110 - learning_rate: 0.0012\n",
            "Epoch 10/22\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8340 - loss: 0.3630\n",
            "Epoch 10: val_loss improved from 0.41100 to 0.39752, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8339 - loss: 0.3632 - val_accuracy: 0.8304 - val_loss: 0.3975 - learning_rate: 0.0012\n",
            "Epoch 11/22\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8387 - loss: 0.3523\n",
            "Epoch 11: val_loss did not improve from 0.39752\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8387 - loss: 0.3524 - val_accuracy: 0.8221 - val_loss: 0.4073 - learning_rate: 0.0012\n",
            "Epoch 12/22\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8336 - loss: 0.3617\n",
            "Epoch 12: val_loss did not improve from 0.39752\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8335 - loss: 0.3619 - val_accuracy: 0.8188 - val_loss: 0.4069 - learning_rate: 0.0012\n",
            "Epoch 13/22\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8464 - loss: 0.3451\n",
            "Epoch 13: val_loss did not improve from 0.39752\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8461 - loss: 0.3455 - val_accuracy: 0.8346 - val_loss: 0.4006 - learning_rate: 0.0012\n",
            "Epoch 14/22\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8440 - loss: 0.3375\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005806173065203221.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.39752\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8438 - loss: 0.3378 - val_accuracy: 0.8121 - val_loss: 0.4092 - learning_rate: 0.0012\n",
            "Epoch 15/22\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8638 - loss: 0.3050\n",
            "Epoch 15: val_loss did not improve from 0.39752\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8637 - loss: 0.3052 - val_accuracy: 0.8204 - val_loss: 0.3985 - learning_rate: 5.8062e-04\n",
            "Epoch 16/22\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8698 - loss: 0.2980\n",
            "Epoch 16: val_loss did not improve from 0.39752\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8698 - loss: 0.2980 - val_accuracy: 0.8146 - val_loss: 0.4015 - learning_rate: 5.8062e-04\n",
            "Epoch 17/22\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8722 - loss: 0.2956\n",
            "Epoch 17: val_loss did not improve from 0.39752\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8721 - loss: 0.2957 - val_accuracy: 0.8238 - val_loss: 0.4058 - learning_rate: 5.8062e-04\n",
            "Epoch 18/22\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8709 - loss: 0.2932\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002902997477609024.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.39752\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8708 - loss: 0.2936 - val_accuracy: 0.8146 - val_loss: 0.4020 - learning_rate: 5.8062e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:43:46,173] Trial 11 finished with value: -0.39752307534217834 and parameters: {'epochs': 22, 'batch_size': 16, 'learning_rate': 0.002322611563943389, 'stop_patience': 8, 'reduce_lr_factor': 0.49998468066093504, 'reduce_lr_patience': 4}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/27\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5581 - loss: 0.6868\n",
            "Epoch 1: val_loss improved from inf to 0.65753, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5580 - loss: 0.6868 - val_accuracy: 0.6201 - val_loss: 0.6575 - learning_rate: 2.3013e-04\n",
            "Epoch 2/27\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5887 - loss: 0.6635\n",
            "Epoch 2: val_loss improved from 0.65753 to 0.56557, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5892 - loss: 0.6632 - val_accuracy: 0.7149 - val_loss: 0.5656 - learning_rate: 2.3013e-04\n",
            "Epoch 3/27\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6736 - loss: 0.5978\n",
            "Epoch 3: val_loss did not improve from 0.56557\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6741 - loss: 0.5972 - val_accuracy: 0.7357 - val_loss: 0.5701 - learning_rate: 2.3013e-04\n",
            "Epoch 4/27\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7254 - loss: 0.5383\n",
            "Epoch 4: val_loss did not improve from 0.56557\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7255 - loss: 0.5383 - val_accuracy: 0.7556 - val_loss: 0.5771 - learning_rate: 2.3013e-04\n",
            "Epoch 5/27\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 0.5097\n",
            "Epoch 5: val_loss improved from 0.56557 to 0.45675, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7397 - loss: 0.5097 - val_accuracy: 0.8055 - val_loss: 0.4568 - learning_rate: 2.3013e-04\n",
            "Epoch 6/27\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7642 - loss: 0.4841\n",
            "Epoch 6: val_loss improved from 0.45675 to 0.45494, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7642 - loss: 0.4841 - val_accuracy: 0.8138 - val_loss: 0.4549 - learning_rate: 2.3013e-04\n",
            "Epoch 7/27\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7617 - loss: 0.4671\n",
            "Epoch 7: val_loss did not improve from 0.45494\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7620 - loss: 0.4670 - val_accuracy: 0.7997 - val_loss: 0.4669 - learning_rate: 2.3013e-04\n",
            "Epoch 8/27\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7844 - loss: 0.4470\n",
            "Epoch 8: val_loss improved from 0.45494 to 0.43893, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7844 - loss: 0.4469 - val_accuracy: 0.8229 - val_loss: 0.4389 - learning_rate: 2.3013e-04\n",
            "Epoch 9/27\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.4321\n",
            "Epoch 9: val_loss improved from 0.43893 to 0.42702, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7911 - loss: 0.4321 - val_accuracy: 0.8213 - val_loss: 0.4270 - learning_rate: 2.3013e-04\n",
            "Epoch 10/27\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8020 - loss: 0.4141\n",
            "Epoch 10: val_loss improved from 0.42702 to 0.40890, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8020 - loss: 0.4142 - val_accuracy: 0.8288 - val_loss: 0.4089 - learning_rate: 2.3013e-04\n",
            "Epoch 11/27\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8044 - loss: 0.4054\n",
            "Epoch 11: val_loss did not improve from 0.40890\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8046 - loss: 0.4054 - val_accuracy: 0.8213 - val_loss: 0.4264 - learning_rate: 2.3013e-04\n",
            "Epoch 12/27\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8154 - loss: 0.4000\n",
            "Epoch 12: val_loss improved from 0.40890 to 0.40073, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8155 - loss: 0.3999 - val_accuracy: 0.8196 - val_loss: 0.4007 - learning_rate: 2.3013e-04\n",
            "Epoch 13/27\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.3942\n",
            "Epoch 13: val_loss did not improve from 0.40073\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.3942 - val_accuracy: 0.8279 - val_loss: 0.4142 - learning_rate: 2.3013e-04\n",
            "Epoch 14/27\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8254 - loss: 0.3821\n",
            "Epoch 14: val_loss improved from 0.40073 to 0.39918, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8255 - loss: 0.3821 - val_accuracy: 0.8288 - val_loss: 0.3992 - learning_rate: 2.3013e-04\n",
            "Epoch 15/27\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8277 - loss: 0.3787\n",
            "Epoch 15: val_loss improved from 0.39918 to 0.39442, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8276 - loss: 0.3787 - val_accuracy: 0.8271 - val_loss: 0.3944 - learning_rate: 2.3013e-04\n",
            "Epoch 16/27\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8248 - loss: 0.3784\n",
            "Epoch 16: val_loss did not improve from 0.39442\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8248 - loss: 0.3784 - val_accuracy: 0.8238 - val_loss: 0.4043 - learning_rate: 2.3013e-04\n",
            "Epoch 17/27\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8359 - loss: 0.3664\n",
            "Epoch 17: val_loss did not improve from 0.39442\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 0.3665 - val_accuracy: 0.8188 - val_loss: 0.4030 - learning_rate: 2.3013e-04\n",
            "Epoch 18/27\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8314 - loss: 0.3662\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.243801057930308e-05.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.39442\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8314 - loss: 0.3662 - val_accuracy: 0.8362 - val_loss: 0.4028 - learning_rate: 2.3013e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:44:25,830] Trial 12 finished with value: -0.3944177031517029 and parameters: {'epochs': 27, 'batch_size': 16, 'learning_rate': 0.00023013169125637143, 'stop_patience': 3, 'reduce_lr_factor': 0.4016744170835907, 'reduce_lr_patience': 3}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5630 - loss: 0.6886\n",
            "Epoch 1: val_loss improved from inf to 0.65303, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5631 - loss: 0.6884 - val_accuracy: 0.7116 - val_loss: 0.6530 - learning_rate: 0.0025\n",
            "Epoch 2/35\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6211 - loss: 0.6302\n",
            "Epoch 2: val_loss improved from 0.65303 to 0.60063, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6214 - loss: 0.6300 - val_accuracy: 0.6991 - val_loss: 0.6006 - learning_rate: 0.0025\n",
            "Epoch 3/35\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6976 - loss: 0.5548\n",
            "Epoch 3: val_loss did not improve from 0.60063\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6980 - loss: 0.5543 - val_accuracy: 0.6816 - val_loss: 0.6783 - learning_rate: 0.0025\n",
            "Epoch 4/35\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7049 - loss: 0.5411\n",
            "Epoch 4: val_loss improved from 0.60063 to 0.56382, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7050 - loss: 0.5411 - val_accuracy: 0.6833 - val_loss: 0.5638 - learning_rate: 0.0025\n",
            "Epoch 5/35\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.4979\n",
            "Epoch 5: val_loss improved from 0.56382 to 0.51621, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7348 - loss: 0.4973 - val_accuracy: 0.7224 - val_loss: 0.5162 - learning_rate: 0.0025\n",
            "Epoch 6/35\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7554 - loss: 0.4655\n",
            "Epoch 6: val_loss improved from 0.51621 to 0.50956, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7555 - loss: 0.4654 - val_accuracy: 0.7406 - val_loss: 0.5096 - learning_rate: 0.0025\n",
            "Epoch 7/35\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7778 - loss: 0.4377\n",
            "Epoch 7: val_loss did not improve from 0.50956\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7779 - loss: 0.4376 - val_accuracy: 0.7132 - val_loss: 0.7502 - learning_rate: 0.0025\n",
            "Epoch 8/35\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7807 - loss: 0.4288\n",
            "Epoch 8: val_loss did not improve from 0.50956\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7808 - loss: 0.4287 - val_accuracy: 0.7897 - val_loss: 0.5133 - learning_rate: 0.0025\n",
            "Epoch 9/35\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.4223\n",
            "Epoch 9: val_loss did not improve from 0.50956\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7884 - loss: 0.4223 - val_accuracy: 0.7456 - val_loss: 0.5711 - learning_rate: 0.0025\n",
            "Epoch 10/35\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7993 - loss: 0.4107\n",
            "Epoch 10: val_loss improved from 0.50956 to 0.49513, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7996 - loss: 0.4105 - val_accuracy: 0.8071 - val_loss: 0.4951 - learning_rate: 0.0025\n",
            "Epoch 11/35\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.3897\n",
            "Epoch 11: val_loss improved from 0.49513 to 0.48044, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.3897 - val_accuracy: 0.8022 - val_loss: 0.4804 - learning_rate: 0.0025\n",
            "Epoch 12/35\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8193 - loss: 0.3907\n",
            "Epoch 12: val_loss did not improve from 0.48044\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.3903 - val_accuracy: 0.7905 - val_loss: 0.4977 - learning_rate: 0.0025\n",
            "Epoch 13/35\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8249 - loss: 0.3726\n",
            "Epoch 13: val_loss improved from 0.48044 to 0.41101, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8249 - loss: 0.3726 - val_accuracy: 0.8130 - val_loss: 0.4110 - learning_rate: 0.0025\n",
            "Epoch 14/35\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8207 - loss: 0.3761\n",
            "Epoch 14: val_loss did not improve from 0.41101\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8207 - loss: 0.3761 - val_accuracy: 0.8055 - val_loss: 0.4520 - learning_rate: 0.0025\n",
            "Epoch 15/35\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.3852\n",
            "Epoch 15: val_loss did not improve from 0.41101\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8066 - loss: 0.3852 - val_accuracy: 0.6725 - val_loss: 1.4252 - learning_rate: 0.0025\n",
            "Epoch 16/35\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8265 - loss: 0.3702\n",
            "Epoch 16: val_loss improved from 0.41101 to 0.39990, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8266 - loss: 0.3702 - val_accuracy: 0.8204 - val_loss: 0.3999 - learning_rate: 0.0025\n",
            "Epoch 17/35\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8196 - loss: 0.3803\n",
            "Epoch 17: val_loss did not improve from 0.39990\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.3801 - val_accuracy: 0.7614 - val_loss: 0.5684 - learning_rate: 0.0025\n",
            "Epoch 18/35\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8217 - loss: 0.3807\n",
            "Epoch 18: val_loss did not improve from 0.39990\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8218 - loss: 0.3805 - val_accuracy: 0.7938 - val_loss: 0.4404 - learning_rate: 0.0025\n",
            "Epoch 19/35\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.3590\n",
            "Epoch 19: val_loss improved from 0.39990 to 0.39791, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8348 - loss: 0.3595 - val_accuracy: 0.8304 - val_loss: 0.3979 - learning_rate: 0.0025\n",
            "Epoch 20/35\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7995 - loss: 0.3880\n",
            "Epoch 20: val_loss did not improve from 0.39791\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8001 - loss: 0.3874 - val_accuracy: 0.8146 - val_loss: 0.4471 - learning_rate: 0.0025\n",
            "Epoch 21/35\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8463 - loss: 0.3369\n",
            "Epoch 21: val_loss did not improve from 0.39791\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8463 - loss: 0.3369 - val_accuracy: 0.8346 - val_loss: 0.4099 - learning_rate: 0.0025\n",
            "Epoch 22/35\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.3530\n",
            "Epoch 22: val_loss did not improve from 0.39791\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8417 - loss: 0.3530 - val_accuracy: 0.8171 - val_loss: 0.4367 - learning_rate: 0.0025\n",
            "Epoch 23/35\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.3492\n",
            "Epoch 23: val_loss improved from 0.39791 to 0.38301, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8413 - loss: 0.3495 - val_accuracy: 0.8362 - val_loss: 0.3830 - learning_rate: 0.0025\n",
            "Epoch 24/35\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3508\n",
            "Epoch 24: val_loss did not improve from 0.38301\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8428 - loss: 0.3513 - val_accuracy: 0.8229 - val_loss: 0.4372 - learning_rate: 0.0025\n",
            "Epoch 25/35\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8445 - loss: 0.3453\n",
            "Epoch 25: val_loss did not improve from 0.38301\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8444 - loss: 0.3453 - val_accuracy: 0.8204 - val_loss: 0.4082 - learning_rate: 0.0025\n",
            "Epoch 26/35\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8523 - loss: 0.3341\n",
            "Epoch 26: val_loss did not improve from 0.38301\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8521 - loss: 0.3344 - val_accuracy: 0.8254 - val_loss: 0.4192 - learning_rate: 0.0025\n",
            "Epoch 27/35\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8471 - loss: 0.3372\n",
            "Epoch 27: val_loss did not improve from 0.38301\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8470 - loss: 0.3373 - val_accuracy: 0.8071 - val_loss: 0.4396 - learning_rate: 0.0025\n",
            "Epoch 28/35\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8463 - loss: 0.3280\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0011181916352376187.\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.38301\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8459 - loss: 0.3288 - val_accuracy: 0.8387 - val_loss: 0.3949 - learning_rate: 0.0025\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 23.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:45:17,230] Trial 13 finished with value: -0.38300517201423645 and parameters: {'epochs': 35, 'batch_size': 16, 'learning_rate': 0.002506218423284437, 'stop_patience': 5, 'reduce_lr_factor': 0.4461668791322522, 'reduce_lr_patience': 5}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/18\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5595 - loss: 0.6851\n",
            "Epoch 1: val_loss improved from inf to 0.64615, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5596 - loss: 0.6850 - val_accuracy: 0.6733 - val_loss: 0.6461 - learning_rate: 1.7512e-04\n",
            "Epoch 2/18\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6041 - loss: 0.6624\n",
            "Epoch 2: val_loss improved from 0.64615 to 0.56441, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6046 - loss: 0.6621 - val_accuracy: 0.7398 - val_loss: 0.5644 - learning_rate: 1.7512e-04\n",
            "Epoch 3/18\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6594 - loss: 0.6198\n",
            "Epoch 3: val_loss did not improve from 0.56441\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6598 - loss: 0.6195 - val_accuracy: 0.7165 - val_loss: 0.6053 - learning_rate: 1.7512e-04\n",
            "Epoch 4/18\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7150 - loss: 0.5653\n",
            "Epoch 4: val_loss did not improve from 0.56441\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7150 - loss: 0.5652 - val_accuracy: 0.7357 - val_loss: 0.6429 - learning_rate: 1.7512e-04\n",
            "Epoch 5/18\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7433 - loss: 0.5256\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 6.898815346154414e-05.\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.56441\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7435 - loss: 0.5255 - val_accuracy: 0.7273 - val_loss: 0.6617 - learning_rate: 1.7512e-04\n",
            "Epoch 6/18\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7570 - loss: 0.4966\n",
            "Epoch 6: val_loss improved from 0.56441 to 0.53378, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7574 - loss: 0.4966 - val_accuracy: 0.7938 - val_loss: 0.5338 - learning_rate: 6.8988e-05\n",
            "Epoch 7/18\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7735 - loss: 0.4808\n",
            "Epoch 7: val_loss improved from 0.53378 to 0.51572, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7735 - loss: 0.4808 - val_accuracy: 0.7922 - val_loss: 0.5157 - learning_rate: 6.8988e-05\n",
            "Epoch 8/18\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7753 - loss: 0.4742\n",
            "Epoch 8: val_loss did not improve from 0.51572\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7754 - loss: 0.4743 - val_accuracy: 0.7938 - val_loss: 0.5463 - learning_rate: 6.8988e-05\n",
            "Epoch 9/18\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7843 - loss: 0.4661\n",
            "Epoch 9: val_loss improved from 0.51572 to 0.50879, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7844 - loss: 0.4662 - val_accuracy: 0.7938 - val_loss: 0.5088 - learning_rate: 6.8988e-05\n",
            "Epoch 10/18\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7809 - loss: 0.4617\n",
            "Epoch 10: val_loss improved from 0.50879 to 0.47960, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7810 - loss: 0.4618 - val_accuracy: 0.7947 - val_loss: 0.4796 - learning_rate: 6.8988e-05\n",
            "Epoch 11/18\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7892 - loss: 0.4534\n",
            "Epoch 11: val_loss did not improve from 0.47960\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4534 - val_accuracy: 0.7972 - val_loss: 0.5174 - learning_rate: 6.8988e-05\n",
            "Epoch 12/18\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7946 - loss: 0.4477\n",
            "Epoch 12: val_loss did not improve from 0.47960\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7948 - loss: 0.4478 - val_accuracy: 0.7963 - val_loss: 0.5031 - learning_rate: 6.8988e-05\n",
            "Epoch 13/18\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7969 - loss: 0.4415\n",
            "Epoch 13: val_loss improved from 0.47960 to 0.45619, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7969 - loss: 0.4415 - val_accuracy: 0.7997 - val_loss: 0.4562 - learning_rate: 6.8988e-05\n",
            "Epoch 14/18\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.4336\n",
            "Epoch 14: val_loss did not improve from 0.45619\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8067 - loss: 0.4336 - val_accuracy: 0.7980 - val_loss: 0.4795 - learning_rate: 6.8988e-05\n",
            "Epoch 15/18\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8003 - loss: 0.4299\n",
            "Epoch 15: val_loss did not improve from 0.45619\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8003 - loss: 0.4299 - val_accuracy: 0.8022 - val_loss: 0.4808 - learning_rate: 6.8988e-05\n",
            "Epoch 16/18\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8023 - loss: 0.4219\n",
            "Epoch 16: val_loss improved from 0.45619 to 0.44683, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8024 - loss: 0.4220 - val_accuracy: 0.8055 - val_loss: 0.4468 - learning_rate: 6.8988e-05\n",
            "Epoch 17/18\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8062 - loss: 0.4217\n",
            "Epoch 17: val_loss did not improve from 0.44683\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8063 - loss: 0.4218 - val_accuracy: 0.8055 - val_loss: 0.4589 - learning_rate: 6.8988e-05\n",
            "Epoch 18/18\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8159 - loss: 0.4133\n",
            "Epoch 18: val_loss did not improve from 0.44683\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8159 - loss: 0.4134 - val_accuracy: 0.8088 - val_loss: 0.4495 - learning_rate: 6.8988e-05\n",
            "Restoring model weights from the end of the best epoch: 16.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:45:55,289] Trial 14 finished with value: -0.44683319330215454 and parameters: {'epochs': 18, 'batch_size': 16, 'learning_rate': 0.00017512161901780238, 'stop_patience': 8, 'reduce_lr_factor': 0.39394424278640516, 'reduce_lr_patience': 3}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5505 - loss: 0.6955\n",
            "Epoch 1: val_loss improved from inf to 0.68675, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5505 - loss: 0.6954 - val_accuracy: 0.5328 - val_loss: 0.6868 - learning_rate: 0.0065\n",
            "Epoch 2/10\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5571 - loss: 0.6847\n",
            "Epoch 2: val_loss did not improve from 0.68675\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5576 - loss: 0.6842 - val_accuracy: 0.6085 - val_loss: 0.9413 - learning_rate: 0.0065\n",
            "Epoch 3/10\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6381 - loss: 0.6164\n",
            "Epoch 3: val_loss did not improve from 0.68675\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6389 - loss: 0.6157 - val_accuracy: 0.6434 - val_loss: 0.9330 - learning_rate: 0.0065\n",
            "Epoch 4/10\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6686 - loss: 0.5691\n",
            "Epoch 4: val_loss improved from 0.68675 to 0.59956, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6687 - loss: 0.5690 - val_accuracy: 0.6966 - val_loss: 0.5996 - learning_rate: 0.0065\n",
            "Epoch 5/10\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7015 - loss: 0.5348\n",
            "Epoch 5: val_loss improved from 0.59956 to 0.53821, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7015 - loss: 0.5348 - val_accuracy: 0.7290 - val_loss: 0.5382 - learning_rate: 0.0065\n",
            "Epoch 6/10\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7070 - loss: 0.5204\n",
            "Epoch 6: val_loss improved from 0.53821 to 0.47066, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7070 - loss: 0.5204 - val_accuracy: 0.7872 - val_loss: 0.4707 - learning_rate: 0.0065\n",
            "Epoch 7/10\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7164 - loss: 0.5116\n",
            "Epoch 7: val_loss did not improve from 0.47066\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7164 - loss: 0.5116 - val_accuracy: 0.6983 - val_loss: 0.7831 - learning_rate: 0.0065\n",
            "Epoch 8/10\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7141 - loss: 0.5089\n",
            "Epoch 8: val_loss improved from 0.47066 to 0.45287, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7141 - loss: 0.5089 - val_accuracy: 0.8013 - val_loss: 0.4529 - learning_rate: 0.0065\n",
            "Epoch 9/10\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7163 - loss: 0.5044\n",
            "Epoch 9: val_loss did not improve from 0.45287\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7163 - loss: 0.5045 - val_accuracy: 0.7872 - val_loss: 0.4952 - learning_rate: 0.0065\n",
            "Epoch 10/10\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7231 - loss: 0.4954\n",
            "Epoch 10: val_loss did not improve from 0.45287\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7234 - loss: 0.4955 - val_accuracy: 0.7922 - val_loss: 0.4617 - learning_rate: 0.0065\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:46:19,766] Trial 15 finished with value: -0.45286837220191956 and parameters: {'epochs': 10, 'batch_size': 16, 'learning_rate': 0.006471393148196349, 'stop_patience': 5, 'reduce_lr_factor': 0.10135219162704845, 'reduce_lr_patience': 4}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/39\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5446 - loss: 0.7023\n",
            "Epoch 1: val_loss improved from inf to 0.70429, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5447 - loss: 0.7015 - val_accuracy: 0.4830 - val_loss: 0.7043 - learning_rate: 0.0099\n",
            "Epoch 2/39\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5605 - loss: 0.6862\n",
            "Epoch 2: val_loss did not improve from 0.70429\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5598 - loss: 0.6864 - val_accuracy: 0.4830 - val_loss: 0.7072 - learning_rate: 0.0099\n",
            "Epoch 3/39\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5601 - loss: 0.6864\n",
            "Epoch 3: val_loss improved from 0.70429 to 0.70244, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5599 - loss: 0.6864 - val_accuracy: 0.4830 - val_loss: 0.7024 - learning_rate: 0.0099\n",
            "Epoch 4/39\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5639 - loss: 0.6834\n",
            "Epoch 4: val_loss did not improve from 0.70244\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5649 - loss: 0.6826 - val_accuracy: 0.5353 - val_loss: 1.4082 - learning_rate: 0.0099\n",
            "Epoch 5/39\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6301 - loss: 0.6296\n",
            "Epoch 5: val_loss improved from 0.70244 to 0.59350, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6305 - loss: 0.6292 - val_accuracy: 0.6883 - val_loss: 0.5935 - learning_rate: 0.0099\n",
            "Epoch 6/39\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6546 - loss: 0.5913\n",
            "Epoch 6: val_loss did not improve from 0.59350\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6559 - loss: 0.5901 - val_accuracy: 0.6151 - val_loss: 0.5974 - learning_rate: 0.0099\n",
            "Epoch 7/39\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6792 - loss: 0.5764\n",
            "Epoch 7: val_loss improved from 0.59350 to 0.48921, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6793 - loss: 0.5760 - val_accuracy: 0.7914 - val_loss: 0.4892 - learning_rate: 0.0099\n",
            "Epoch 8/39\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6757 - loss: 0.5757\n",
            "Epoch 8: val_loss did not improve from 0.48921\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6753 - loss: 0.5760 - val_accuracy: 0.6160 - val_loss: 0.6290 - learning_rate: 0.0099\n",
            "Epoch 9/39\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6813 - loss: 0.5540\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.004925723335308809.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.48921\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6815 - loss: 0.5539 - val_accuracy: 0.7556 - val_loss: 0.5627 - learning_rate: 0.0099\n",
            "Epoch 10/39\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7107 - loss: 0.5321\n",
            "Epoch 10: val_loss improved from 0.48921 to 0.44414, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7108 - loss: 0.5318 - val_accuracy: 0.8005 - val_loss: 0.4441 - learning_rate: 0.0049\n",
            "Epoch 11/39\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7158 - loss: 0.5043\n",
            "Epoch 11: val_loss did not improve from 0.44414\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7159 - loss: 0.5043 - val_accuracy: 0.8047 - val_loss: 0.4817 - learning_rate: 0.0049\n",
            "Epoch 12/39\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7229 - loss: 0.5099\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0024572435035620983.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.44414\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7228 - loss: 0.5100 - val_accuracy: 0.7997 - val_loss: 0.4704 - learning_rate: 0.0049\n",
            "Epoch 13/39\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7279 - loss: 0.4978\n",
            "Epoch 13: val_loss did not improve from 0.44414\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7279 - loss: 0.4977 - val_accuracy: 0.8038 - val_loss: 0.4553 - learning_rate: 0.0025\n",
            "Epoch 14/39\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7330 - loss: 0.4935\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0012258190579719245.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.44414\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7332 - loss: 0.4935 - val_accuracy: 0.7955 - val_loss: 0.4611 - learning_rate: 0.0025\n",
            "Epoch 15/39\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7504 - loss: 0.4798\n",
            "Epoch 15: val_loss did not improve from 0.44414\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7504 - loss: 0.4798 - val_accuracy: 0.8063 - val_loss: 0.4471 - learning_rate: 0.0012\n",
            "Epoch 16/39\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7521 - loss: 0.4743\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006115114342747964.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.44414\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7521 - loss: 0.4743 - val_accuracy: 0.8055 - val_loss: 0.4476 - learning_rate: 0.0012\n",
            "Epoch 17/39\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7540 - loss: 0.4666\n",
            "Epoch 17: val_loss did not improve from 0.44414\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7544 - loss: 0.4668 - val_accuracy: 0.8047 - val_loss: 0.4514 - learning_rate: 6.1151e-04\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:46:40,618] Trial 16 finished with value: -0.4441433846950531 and parameters: {'epochs': 39, 'batch_size': 32, 'learning_rate': 0.009873970247425201, 'stop_patience': 7, 'reduce_lr_factor': 0.49885943849530157, 'reduce_lr_patience': 2}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/31\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5543 - loss: 0.6930\n",
            "Epoch 1: val_loss improved from inf to 0.66485, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5543 - loss: 0.6930 - val_accuracy: 0.6592 - val_loss: 0.6648 - learning_rate: 0.0038\n",
            "Epoch 2/31\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5843 - loss: 0.6702\n",
            "Epoch 2: val_loss did not improve from 0.66485\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5851 - loss: 0.6695 - val_accuracy: 0.7132 - val_loss: 0.6804 - learning_rate: 0.0038\n",
            "Epoch 3/31\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6605 - loss: 0.5872\n",
            "Epoch 3: val_loss did not improve from 0.66485\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6605 - loss: 0.5872 - val_accuracy: 0.6218 - val_loss: 0.6833 - learning_rate: 0.0038\n",
            "Epoch 4/31\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7024 - loss: 0.5427\n",
            "Epoch 4: val_loss improved from 0.66485 to 0.65959, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7027 - loss: 0.5423 - val_accuracy: 0.6758 - val_loss: 0.6596 - learning_rate: 0.0038\n",
            "Epoch 5/31\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7220 - loss: 0.5108\n",
            "Epoch 5: val_loss improved from 0.65959 to 0.45452, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7225 - loss: 0.5102 - val_accuracy: 0.7872 - val_loss: 0.4545 - learning_rate: 0.0038\n",
            "Epoch 6/31\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7492 - loss: 0.4806\n",
            "Epoch 6: val_loss improved from 0.45452 to 0.45302, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7492 - loss: 0.4805 - val_accuracy: 0.7830 - val_loss: 0.4530 - learning_rate: 0.0038\n",
            "Epoch 7/31\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7645 - loss: 0.4610\n",
            "Epoch 7: val_loss did not improve from 0.45302\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7648 - loss: 0.4609 - val_accuracy: 0.7872 - val_loss: 0.4701 - learning_rate: 0.0038\n",
            "Epoch 8/31\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7852 - loss: 0.4270\n",
            "Epoch 8: val_loss improved from 0.45302 to 0.43106, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7851 - loss: 0.4274 - val_accuracy: 0.8196 - val_loss: 0.4311 - learning_rate: 0.0038\n",
            "Epoch 9/31\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7944 - loss: 0.4137\n",
            "Epoch 9: val_loss did not improve from 0.43106\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7940 - loss: 0.4142 - val_accuracy: 0.7830 - val_loss: 0.5641 - learning_rate: 0.0038\n",
            "Epoch 10/31\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7752 - loss: 0.4287\n",
            "Epoch 10: val_loss did not improve from 0.43106\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7755 - loss: 0.4287 - val_accuracy: 0.7323 - val_loss: 0.6531 - learning_rate: 0.0038\n",
            "Epoch 11/31\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7879 - loss: 0.4200\n",
            "Epoch 11: val_loss did not improve from 0.43106\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7879 - loss: 0.4198 - val_accuracy: 0.8022 - val_loss: 0.4358 - learning_rate: 0.0038\n",
            "Epoch 12/31\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7854 - loss: 0.4211\n",
            "Epoch 12: val_loss did not improve from 0.43106\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7858 - loss: 0.4207 - val_accuracy: 0.7864 - val_loss: 0.4706 - learning_rate: 0.0038\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:47:03,780] Trial 17 finished with value: -0.43106314539909363 and parameters: {'epochs': 31, 'batch_size': 16, 'learning_rate': 0.0037651261677302283, 'stop_patience': 4, 'reduce_lr_factor': 0.18699301110930622, 'reduce_lr_patience': 5}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/23\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5437 - loss: 0.6882\n",
            "Epoch 1: val_loss improved from inf to 0.71298, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5446 - loss: 0.6879 - val_accuracy: 0.5761 - val_loss: 0.7130 - learning_rate: 0.0016\n",
            "Epoch 2/23\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6521 - loss: 0.6167\n",
            "Epoch 2: val_loss improved from 0.71298 to 0.66656, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6535 - loss: 0.6153 - val_accuracy: 0.6268 - val_loss: 0.6666 - learning_rate: 0.0016\n",
            "Epoch 3/23\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7086 - loss: 0.5443\n",
            "Epoch 3: val_loss improved from 0.66656 to 0.53253, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7086 - loss: 0.5443 - val_accuracy: 0.7215 - val_loss: 0.5325 - learning_rate: 0.0016\n",
            "Epoch 4/23\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.4940\n",
            "Epoch 4: val_loss improved from 0.53253 to 0.43639, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7402 - loss: 0.4936 - val_accuracy: 0.8121 - val_loss: 0.4364 - learning_rate: 0.0016\n",
            "Epoch 5/23\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7577 - loss: 0.4795\n",
            "Epoch 5: val_loss did not improve from 0.43639\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7578 - loss: 0.4798 - val_accuracy: 0.7589 - val_loss: 0.5320 - learning_rate: 0.0016\n",
            "Epoch 6/23\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7735 - loss: 0.4424\n",
            "Epoch 6: val_loss did not improve from 0.43639\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7739 - loss: 0.4423 - val_accuracy: 0.7440 - val_loss: 0.5326 - learning_rate: 0.0016\n",
            "Epoch 7/23\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7876 - loss: 0.4272\n",
            "Epoch 7: val_loss did not improve from 0.43639\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7878 - loss: 0.4270 - val_accuracy: 0.7822 - val_loss: 0.4846 - learning_rate: 0.0016\n",
            "Epoch 8/23\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8049 - loss: 0.4076\n",
            "Epoch 8: val_loss improved from 0.43639 to 0.42824, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8050 - loss: 0.4075 - val_accuracy: 0.8005 - val_loss: 0.4282 - learning_rate: 0.0016\n",
            "Epoch 9/23\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8158 - loss: 0.3934\n",
            "Epoch 9: val_loss improved from 0.42824 to 0.40654, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8157 - loss: 0.3936 - val_accuracy: 0.8238 - val_loss: 0.4065 - learning_rate: 0.0016\n",
            "Epoch 10/23\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8165 - loss: 0.3803\n",
            "Epoch 10: val_loss did not improve from 0.40654\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8167 - loss: 0.3805 - val_accuracy: 0.7947 - val_loss: 0.4660 - learning_rate: 0.0016\n",
            "Epoch 11/23\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8117 - loss: 0.4034\n",
            "Epoch 11: val_loss improved from 0.40654 to 0.40374, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8114 - loss: 0.4035 - val_accuracy: 0.8329 - val_loss: 0.4037 - learning_rate: 0.0016\n",
            "Epoch 12/23\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8092 - loss: 0.3853\n",
            "Epoch 12: val_loss did not improve from 0.40374\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8092 - loss: 0.3853 - val_accuracy: 0.8288 - val_loss: 0.4059 - learning_rate: 0.0016\n",
            "Epoch 13/23\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.3746\n",
            "Epoch 13: val_loss did not improve from 0.40374\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8238 - loss: 0.3746 - val_accuracy: 0.8304 - val_loss: 0.4285 - learning_rate: 0.0016\n",
            "Epoch 14/23\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8140 - loss: 0.3806\n",
            "Epoch 14: val_loss did not improve from 0.40374\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8142 - loss: 0.3806 - val_accuracy: 0.8055 - val_loss: 0.4700 - learning_rate: 0.0016\n",
            "Epoch 15/23\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8194 - loss: 0.3700\n",
            "Epoch 15: val_loss improved from 0.40374 to 0.39365, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8194 - loss: 0.3700 - val_accuracy: 0.8337 - val_loss: 0.3936 - learning_rate: 0.0016\n",
            "Epoch 16/23\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8257 - loss: 0.3523\n",
            "Epoch 16: val_loss did not improve from 0.39365\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.3524 - val_accuracy: 0.8279 - val_loss: 0.4052 - learning_rate: 0.0016\n",
            "Epoch 17/23\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.3615\n",
            "Epoch 17: val_loss did not improve from 0.39365\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8285 - loss: 0.3615 - val_accuracy: 0.8354 - val_loss: 0.3992 - learning_rate: 0.0016\n",
            "Epoch 18/23\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8345 - loss: 0.3487\n",
            "Epoch 18: val_loss did not improve from 0.39365\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8345 - loss: 0.3488 - val_accuracy: 0.8279 - val_loss: 0.4354 - learning_rate: 0.0016\n",
            "Epoch 19/23\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8370 - loss: 0.3427\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005634798134897385.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.39365\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8369 - loss: 0.3430 - val_accuracy: 0.8188 - val_loss: 0.4140 - learning_rate: 0.0016\n",
            "Epoch 20/23\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8429 - loss: 0.3330\n",
            "Epoch 20: val_loss did not improve from 0.39365\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.3328 - val_accuracy: 0.8213 - val_loss: 0.4149 - learning_rate: 5.6348e-04\n",
            "Epoch 21/23\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8656 - loss: 0.3011\n",
            "Epoch 21: val_loss did not improve from 0.39365\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8654 - loss: 0.3013 - val_accuracy: 0.8254 - val_loss: 0.4013 - learning_rate: 5.6348e-04\n",
            "Epoch 22/23\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8657 - loss: 0.2971\n",
            "Epoch 22: val_loss did not improve from 0.39365\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8656 - loss: 0.2972 - val_accuracy: 0.8238 - val_loss: 0.4106 - learning_rate: 5.6348e-04\n",
            "Epoch 23/23\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8700 - loss: 0.2879\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.000203638491244176.\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.39365\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8700 - loss: 0.2880 - val_accuracy: 0.8188 - val_loss: 0.4332 - learning_rate: 5.6348e-04\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:47:47,935] Trial 18 finished with value: -0.3936469554901123 and parameters: {'epochs': 23, 'batch_size': 16, 'learning_rate': 0.0015591820556434106, 'stop_patience': 9, 'reduce_lr_factor': 0.36139449283111796, 'reduce_lr_patience': 4}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5568 - loss: 0.6887\n",
            "Epoch 1: val_loss improved from inf to 0.61775, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5576 - loss: 0.6882 - val_accuracy: 0.6251 - val_loss: 0.6178 - learning_rate: 0.0029\n",
            "Epoch 2/50\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6414 - loss: 0.6104\n",
            "Epoch 2: val_loss did not improve from 0.61775\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6425 - loss: 0.6096 - val_accuracy: 0.5977 - val_loss: 1.0991 - learning_rate: 0.0029\n",
            "Epoch 3/50\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7221 - loss: 0.5360\n",
            "Epoch 3: val_loss did not improve from 0.61775\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7228 - loss: 0.5349 - val_accuracy: 0.7357 - val_loss: 0.6727 - learning_rate: 0.0029\n",
            "Epoch 4/50\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7316 - loss: 0.5045\n",
            "Epoch 4: val_loss improved from 0.61775 to 0.48425, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7321 - loss: 0.5041 - val_accuracy: 0.7897 - val_loss: 0.4842 - learning_rate: 0.0029\n",
            "Epoch 5/50\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7402 - loss: 0.4964\n",
            "Epoch 5: val_loss improved from 0.48425 to 0.45072, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7404 - loss: 0.4963 - val_accuracy: 0.8105 - val_loss: 0.4507 - learning_rate: 0.0029\n",
            "Epoch 6/50\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7552 - loss: 0.4681\n",
            "Epoch 6: val_loss did not improve from 0.45072\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7553 - loss: 0.4681 - val_accuracy: 0.8180 - val_loss: 0.4849 - learning_rate: 0.0029\n",
            "Epoch 7/50\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7706 - loss: 0.4426\n",
            "Epoch 7: val_loss improved from 0.45072 to 0.42097, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7706 - loss: 0.4428 - val_accuracy: 0.8146 - val_loss: 0.4210 - learning_rate: 0.0029\n",
            "Epoch 8/50\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7933 - loss: 0.4183\n",
            "Epoch 8: val_loss improved from 0.42097 to 0.41292, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7932 - loss: 0.4185 - val_accuracy: 0.8238 - val_loss: 0.4129 - learning_rate: 0.0029\n",
            "Epoch 9/50\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7851 - loss: 0.4172\n",
            "Epoch 9: val_loss did not improve from 0.41292\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7855 - loss: 0.4170 - val_accuracy: 0.8071 - val_loss: 0.4148 - learning_rate: 0.0029\n",
            "Epoch 10/50\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7876 - loss: 0.4212\n",
            "Epoch 10: val_loss improved from 0.41292 to 0.38663, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7872 - loss: 0.4219 - val_accuracy: 0.8396 - val_loss: 0.3866 - learning_rate: 0.0029\n",
            "Epoch 11/50\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7894 - loss: 0.4507\n",
            "Epoch 11: val_loss improved from 0.38663 to 0.38513, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7894 - loss: 0.4508 - val_accuracy: 0.8229 - val_loss: 0.3851 - learning_rate: 0.0029\n",
            "Epoch 12/50\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8089 - loss: 0.4052\n",
            "Epoch 12: val_loss did not improve from 0.38513\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8076 - loss: 0.4067 - val_accuracy: 0.8063 - val_loss: 0.4430 - learning_rate: 0.0029\n",
            "Epoch 13/50\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8150 - loss: 0.3923\n",
            "Epoch 13: val_loss did not improve from 0.38513\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8147 - loss: 0.3928 - val_accuracy: 0.8047 - val_loss: 0.4479 - learning_rate: 0.0029\n",
            "Epoch 14/50\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8018 - loss: 0.4033\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0013177482934661588.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.38513\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8017 - loss: 0.4036 - val_accuracy: 0.8271 - val_loss: 0.4096 - learning_rate: 0.0029\n",
            "Epoch 15/50\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8388 - loss: 0.3526\n",
            "Epoch 15: val_loss did not improve from 0.38513\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8388 - loss: 0.3526 - val_accuracy: 0.8296 - val_loss: 0.3999 - learning_rate: 0.0013\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:48:10,701] Trial 19 finished with value: -0.3851254880428314 and parameters: {'epochs': 50, 'batch_size': 32, 'learning_rate': 0.0028968422258499327, 'stop_patience': 4, 'reduce_lr_factor': 0.45489127493386333, 'reduce_lr_patience': 3}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/41\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5393 - loss: 0.6871\n",
            "Epoch 1: val_loss improved from inf to 0.58082, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5395 - loss: 0.6871 - val_accuracy: 0.7523 - val_loss: 0.5808 - learning_rate: 0.0017\n",
            "Epoch 2/41\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6450 - loss: 0.6274\n",
            "Epoch 2: val_loss did not improve from 0.58082\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6462 - loss: 0.6262 - val_accuracy: 0.6542 - val_loss: 0.8448 - learning_rate: 0.0017\n",
            "Epoch 3/41\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6836 - loss: 0.5712\n",
            "Epoch 3: val_loss did not improve from 0.58082\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6841 - loss: 0.5703 - val_accuracy: 0.6850 - val_loss: 0.6279 - learning_rate: 0.0017\n",
            "Epoch 4/41\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7098 - loss: 0.5293\n",
            "Epoch 4: val_loss improved from 0.58082 to 0.58065, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7102 - loss: 0.5291 - val_accuracy: 0.6899 - val_loss: 0.5806 - learning_rate: 0.0017\n",
            "Epoch 5/41\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7466 - loss: 0.4761\n",
            "Epoch 5: val_loss improved from 0.58065 to 0.56397, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7467 - loss: 0.4759 - val_accuracy: 0.7348 - val_loss: 0.5640 - learning_rate: 0.0017\n",
            "Epoch 6/41\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.4566\n",
            "Epoch 6: val_loss improved from 0.56397 to 0.48595, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7601 - loss: 0.4566 - val_accuracy: 0.7922 - val_loss: 0.4860 - learning_rate: 0.0017\n",
            "Epoch 7/41\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7694 - loss: 0.4515\n",
            "Epoch 7: val_loss improved from 0.48595 to 0.41450, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7694 - loss: 0.4515 - val_accuracy: 0.8246 - val_loss: 0.4145 - learning_rate: 0.0017\n",
            "Epoch 8/41\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7807 - loss: 0.4336\n",
            "Epoch 8: val_loss did not improve from 0.41450\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7807 - loss: 0.4337 - val_accuracy: 0.7481 - val_loss: 0.6175 - learning_rate: 0.0017\n",
            "Epoch 9/41\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.4323\n",
            "Epoch 9: val_loss did not improve from 0.41450\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7764 - loss: 0.4321 - val_accuracy: 0.8254 - val_loss: 0.4175 - learning_rate: 0.0017\n",
            "Epoch 10/41\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8056 - loss: 0.4015\n",
            "Epoch 10: val_loss did not improve from 0.41450\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8056 - loss: 0.4017 - val_accuracy: 0.7864 - val_loss: 0.4751 - learning_rate: 0.0017\n",
            "Epoch 11/41\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.3899\n",
            "Epoch 11: val_loss did not improve from 0.41450\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8091 - loss: 0.3900 - val_accuracy: 0.7963 - val_loss: 0.4876 - learning_rate: 0.0017\n",
            "Epoch 12/41\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8213 - loss: 0.3959\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0004844109681948391.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.41450\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8211 - loss: 0.3961 - val_accuracy: 0.7390 - val_loss: 0.6151 - learning_rate: 0.0017\n",
            "Epoch 13/41\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8435 - loss: 0.3486\n",
            "Epoch 13: val_loss improved from 0.41450 to 0.40176, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8438 - loss: 0.3483 - val_accuracy: 0.8396 - val_loss: 0.4018 - learning_rate: 4.8441e-04\n",
            "Epoch 14/41\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8535 - loss: 0.3248\n",
            "Epoch 14: val_loss improved from 0.40176 to 0.39891, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8535 - loss: 0.3248 - val_accuracy: 0.8337 - val_loss: 0.3989 - learning_rate: 4.8441e-04\n",
            "Epoch 15/41\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8595 - loss: 0.3151\n",
            "Epoch 15: val_loss did not improve from 0.39891\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8594 - loss: 0.3152 - val_accuracy: 0.8404 - val_loss: 0.4000 - learning_rate: 4.8441e-04\n",
            "Epoch 16/41\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8667 - loss: 0.3100\n",
            "Epoch 16: val_loss did not improve from 0.39891\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.3101 - val_accuracy: 0.8396 - val_loss: 0.4097 - learning_rate: 4.8441e-04\n",
            "Epoch 17/41\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8676 - loss: 0.3029\n",
            "Epoch 17: val_loss did not improve from 0.39891\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8676 - loss: 0.3030 - val_accuracy: 0.8246 - val_loss: 0.4056 - learning_rate: 4.8441e-04\n",
            "Epoch 18/41\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8681 - loss: 0.2988\n",
            "Epoch 18: val_loss did not improve from 0.39891\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8681 - loss: 0.2990 - val_accuracy: 0.8321 - val_loss: 0.4127 - learning_rate: 4.8441e-04\n",
            "Epoch 19/41\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8729 - loss: 0.2949\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00014049866257863003.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.39891\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8728 - loss: 0.2951 - val_accuracy: 0.8221 - val_loss: 0.4293 - learning_rate: 4.8441e-04\n",
            "Epoch 20/41\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8824 - loss: 0.2784\n",
            "Epoch 20: val_loss did not improve from 0.39891\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8824 - loss: 0.2785 - val_accuracy: 0.8180 - val_loss: 0.4373 - learning_rate: 1.4050e-04\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:48:58,185] Trial 20 finished with value: -0.3989063501358032 and parameters: {'epochs': 41, 'batch_size': 16, 'learning_rate': 0.001670151074073905, 'stop_patience': 6, 'reduce_lr_factor': 0.2900402197695394, 'reduce_lr_patience': 5}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/34\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5528 - loss: 0.6939\n",
            "Epoch 1: val_loss improved from inf to 0.65299, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5529 - loss: 0.6939 - val_accuracy: 0.7157 - val_loss: 0.6530 - learning_rate: 0.0029\n",
            "Epoch 2/34\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6186 - loss: 0.6506\n",
            "Epoch 2: val_loss did not improve from 0.65299\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6187 - loss: 0.6505 - val_accuracy: 0.5486 - val_loss: 0.6840 - learning_rate: 0.0029\n",
            "Epoch 3/34\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6702 - loss: 0.5783\n",
            "Epoch 3: val_loss improved from 0.65299 to 0.54677, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6711 - loss: 0.5774 - val_accuracy: 0.7157 - val_loss: 0.5468 - learning_rate: 0.0029\n",
            "Epoch 4/34\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7227 - loss: 0.5321\n",
            "Epoch 4: val_loss improved from 0.54677 to 0.48976, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7226 - loss: 0.5319 - val_accuracy: 0.7523 - val_loss: 0.4898 - learning_rate: 0.0029\n",
            "Epoch 5/34\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7319 - loss: 0.5087\n",
            "Epoch 5: val_loss improved from 0.48976 to 0.48108, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7324 - loss: 0.5082 - val_accuracy: 0.7539 - val_loss: 0.4811 - learning_rate: 0.0029\n",
            "Epoch 6/34\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7605 - loss: 0.4634\n",
            "Epoch 6: val_loss improved from 0.48108 to 0.43878, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7605 - loss: 0.4634 - val_accuracy: 0.8013 - val_loss: 0.4388 - learning_rate: 0.0029\n",
            "Epoch 7/34\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7688 - loss: 0.4505\n",
            "Epoch 7: val_loss did not improve from 0.43878\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7688 - loss: 0.4505 - val_accuracy: 0.7490 - val_loss: 0.5033 - learning_rate: 0.0029\n",
            "Epoch 8/34\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7734 - loss: 0.4413\n",
            "Epoch 8: val_loss did not improve from 0.43878\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7736 - loss: 0.4412 - val_accuracy: 0.6808 - val_loss: 0.6660 - learning_rate: 0.0029\n",
            "Epoch 9/34\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7775 - loss: 0.4370\n",
            "Epoch 9: val_loss did not improve from 0.43878\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7777 - loss: 0.4370 - val_accuracy: 0.7257 - val_loss: 0.5957 - learning_rate: 0.0029\n",
            "Epoch 10/34\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7925 - loss: 0.4228\n",
            "Epoch 10: val_loss did not improve from 0.43878\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7925 - loss: 0.4228 - val_accuracy: 0.6874 - val_loss: 0.9809 - learning_rate: 0.0029\n",
            "Epoch 11/34\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.4096\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0013144850890309005.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.43878\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8086 - loss: 0.4095 - val_accuracy: 0.7980 - val_loss: 0.4393 - learning_rate: 0.0029\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:49:26,243] Trial 21 finished with value: -0.43878233432769775 and parameters: {'epochs': 34, 'batch_size': 16, 'learning_rate': 0.00293765773147366, 'stop_patience': 5, 'reduce_lr_factor': 0.4474602547507872, 'reduce_lr_patience': 5}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/31\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5607 - loss: 0.6817\n",
            "Epoch 1: val_loss improved from inf to 0.78560, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5609 - loss: 0.6816 - val_accuracy: 0.5603 - val_loss: 0.7856 - learning_rate: 8.9064e-04\n",
            "Epoch 2/31\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6741 - loss: 0.6093\n",
            "Epoch 2: val_loss improved from 0.78560 to 0.62202, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6744 - loss: 0.6089 - val_accuracy: 0.6633 - val_loss: 0.6220 - learning_rate: 8.9064e-04\n",
            "Epoch 3/31\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6981 - loss: 0.5595\n",
            "Epoch 3: val_loss did not improve from 0.62202\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6982 - loss: 0.5594 - val_accuracy: 0.6692 - val_loss: 0.6881 - learning_rate: 8.9064e-04\n",
            "Epoch 4/31\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7267 - loss: 0.5234\n",
            "Epoch 4: val_loss improved from 0.62202 to 0.47306, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7271 - loss: 0.5229 - val_accuracy: 0.7839 - val_loss: 0.4731 - learning_rate: 8.9064e-04\n",
            "Epoch 5/31\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7584 - loss: 0.4703\n",
            "Epoch 5: val_loss improved from 0.47306 to 0.43351, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7587 - loss: 0.4704 - val_accuracy: 0.8105 - val_loss: 0.4335 - learning_rate: 8.9064e-04\n",
            "Epoch 6/31\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7671 - loss: 0.4522\n",
            "Epoch 6: val_loss improved from 0.43351 to 0.40490, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7671 - loss: 0.4523 - val_accuracy: 0.8263 - val_loss: 0.4049 - learning_rate: 8.9064e-04\n",
            "Epoch 7/31\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7762 - loss: 0.4407\n",
            "Epoch 7: val_loss did not improve from 0.40490\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7763 - loss: 0.4408 - val_accuracy: 0.8321 - val_loss: 0.4126 - learning_rate: 8.9064e-04\n",
            "Epoch 8/31\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7796 - loss: 0.4314\n",
            "Epoch 8: val_loss did not improve from 0.40490\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7801 - loss: 0.4311 - val_accuracy: 0.8038 - val_loss: 0.4813 - learning_rate: 8.9064e-04\n",
            "Epoch 9/31\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7952 - loss: 0.4104\n",
            "Epoch 9: val_loss did not improve from 0.40490\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4104 - val_accuracy: 0.8005 - val_loss: 0.4722 - learning_rate: 8.9064e-04\n",
            "Epoch 10/31\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8119 - loss: 0.3989\n",
            "Epoch 10: val_loss did not improve from 0.40490\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.3989 - val_accuracy: 0.7531 - val_loss: 0.5391 - learning_rate: 8.9064e-04\n",
            "Epoch 11/31\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.4188\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00037730873981333014.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.40490\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.4187 - val_accuracy: 0.8379 - val_loss: 0.4093 - learning_rate: 8.9064e-04\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:49:52,367] Trial 22 finished with value: -0.40489864349365234 and parameters: {'epochs': 31, 'batch_size': 16, 'learning_rate': 0.0008906371598417499, 'stop_patience': 5, 'reduce_lr_factor': 0.42363911396637377, 'reduce_lr_patience': 5}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5512 - loss: 0.6882\n",
            "Epoch 1: val_loss improved from inf to 0.83701, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5514 - loss: 0.6881 - val_accuracy: 0.5686 - val_loss: 0.8370 - learning_rate: 0.0024\n",
            "Epoch 2/26\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6299 - loss: 0.6462\n",
            "Epoch 2: val_loss improved from 0.83701 to 0.52444, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6305 - loss: 0.6455 - val_accuracy: 0.7614 - val_loss: 0.5244 - learning_rate: 0.0024\n",
            "Epoch 3/26\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6887 - loss: 0.5806\n",
            "Epoch 3: val_loss did not improve from 0.52444\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6891 - loss: 0.5802 - val_accuracy: 0.6442 - val_loss: 0.6732 - learning_rate: 0.0024\n",
            "Epoch 4/26\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7111 - loss: 0.5431\n",
            "Epoch 4: val_loss improved from 0.52444 to 0.46164, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7113 - loss: 0.5426 - val_accuracy: 0.7830 - val_loss: 0.4616 - learning_rate: 0.0024\n",
            "Epoch 5/26\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7274 - loss: 0.5120\n",
            "Epoch 5: val_loss improved from 0.46164 to 0.45033, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7280 - loss: 0.5112 - val_accuracy: 0.7938 - val_loss: 0.4503 - learning_rate: 0.0024\n",
            "Epoch 6/26\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7529 - loss: 0.4739\n",
            "Epoch 6: val_loss did not improve from 0.45033\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7532 - loss: 0.4735 - val_accuracy: 0.7041 - val_loss: 0.5424 - learning_rate: 0.0024\n",
            "Epoch 7/26\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7491 - loss: 0.4576\n",
            "Epoch 7: val_loss did not improve from 0.45033\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7492 - loss: 0.4576 - val_accuracy: 0.7315 - val_loss: 0.5776 - learning_rate: 0.0024\n",
            "Epoch 8/26\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7774 - loss: 0.4480\n",
            "Epoch 8: val_loss did not improve from 0.45033\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7777 - loss: 0.4476 - val_accuracy: 0.7706 - val_loss: 0.5059 - learning_rate: 0.0024\n",
            "Epoch 9/26\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7894 - loss: 0.4189\n",
            "Epoch 9: val_loss improved from 0.45033 to 0.43760, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7893 - loss: 0.4192 - val_accuracy: 0.8105 - val_loss: 0.4376 - learning_rate: 0.0024\n",
            "Epoch 10/26\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7933 - loss: 0.4095\n",
            "Epoch 10: val_loss did not improve from 0.43760\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7933 - loss: 0.4095 - val_accuracy: 0.7747 - val_loss: 0.4456 - learning_rate: 0.0024\n",
            "Epoch 11/26\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.4063\n",
            "Epoch 11: val_loss improved from 0.43760 to 0.42334, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8053 - loss: 0.4065 - val_accuracy: 0.8113 - val_loss: 0.4233 - learning_rate: 0.0024\n",
            "Epoch 12/26\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8047 - loss: 0.3988\n",
            "Epoch 12: val_loss improved from 0.42334 to 0.40317, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8048 - loss: 0.3987 - val_accuracy: 0.8221 - val_loss: 0.4032 - learning_rate: 0.0024\n",
            "Epoch 13/26\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8120 - loss: 0.3892\n",
            "Epoch 13: val_loss did not improve from 0.40317\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.3893 - val_accuracy: 0.8138 - val_loss: 0.4368 - learning_rate: 0.0024\n",
            "Epoch 14/26\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8190 - loss: 0.3754\n",
            "Epoch 14: val_loss did not improve from 0.40317\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8189 - loss: 0.3754 - val_accuracy: 0.8221 - val_loss: 0.4170 - learning_rate: 0.0024\n",
            "Epoch 15/26\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8230 - loss: 0.3750\n",
            "Epoch 15: val_loss did not improve from 0.40317\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8227 - loss: 0.3753 - val_accuracy: 0.8288 - val_loss: 0.4107 - learning_rate: 0.0024\n",
            "Epoch 16/26\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8076 - loss: 0.3842\n",
            "Epoch 16: val_loss did not improve from 0.40317\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8073 - loss: 0.3845 - val_accuracy: 0.8238 - val_loss: 0.4084 - learning_rate: 0.0024\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:50:28,027] Trial 23 finished with value: -0.4031657576560974 and parameters: {'epochs': 26, 'batch_size': 16, 'learning_rate': 0.0023627491298120144, 'stop_patience': 4, 'reduce_lr_factor': 0.4649964271156424, 'reduce_lr_patience': 5}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/41\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5417 - loss: 0.6902\n",
            "Epoch 1: val_loss improved from inf to 0.66215, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5420 - loss: 0.6901 - val_accuracy: 0.5719 - val_loss: 0.6621 - learning_rate: 0.0031\n",
            "Epoch 2/41\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5886 - loss: 0.6613\n",
            "Epoch 2: val_loss improved from 0.66215 to 0.62047, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5900 - loss: 0.6604 - val_accuracy: 0.6110 - val_loss: 0.6205 - learning_rate: 0.0031\n",
            "Epoch 3/41\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6676 - loss: 0.5824\n",
            "Epoch 3: val_loss did not improve from 0.62047\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6682 - loss: 0.5818 - val_accuracy: 0.6201 - val_loss: 0.7833 - learning_rate: 0.0031\n",
            "Epoch 4/41\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7165 - loss: 0.5220\n",
            "Epoch 4: val_loss improved from 0.62047 to 0.51602, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7169 - loss: 0.5216 - val_accuracy: 0.7357 - val_loss: 0.5160 - learning_rate: 0.0031\n",
            "Epoch 5/41\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.5033\n",
            "Epoch 5: val_loss improved from 0.51602 to 0.50766, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7328 - loss: 0.5032 - val_accuracy: 0.7199 - val_loss: 0.5077 - learning_rate: 0.0031\n",
            "Epoch 6/41\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7501 - loss: 0.5026\n",
            "Epoch 6: val_loss improved from 0.50766 to 0.47076, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7502 - loss: 0.5023 - val_accuracy: 0.7722 - val_loss: 0.4708 - learning_rate: 0.0031\n",
            "Epoch 7/41\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7725 - loss: 0.4518\n",
            "Epoch 7: val_loss did not improve from 0.47076\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7727 - loss: 0.4516 - val_accuracy: 0.6866 - val_loss: 0.5848 - learning_rate: 0.0031\n",
            "Epoch 8/41\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7864 - loss: 0.4394\n",
            "Epoch 8: val_loss improved from 0.47076 to 0.41962, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7864 - loss: 0.4395 - val_accuracy: 0.8271 - val_loss: 0.4196 - learning_rate: 0.0031\n",
            "Epoch 9/41\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7736 - loss: 0.4286\n",
            "Epoch 9: val_loss did not improve from 0.41962\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7739 - loss: 0.4288 - val_accuracy: 0.7822 - val_loss: 0.5505 - learning_rate: 0.0031\n",
            "Epoch 10/41\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.4187\n",
            "Epoch 10: val_loss did not improve from 0.41962\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7925 - loss: 0.4188 - val_accuracy: 0.8180 - val_loss: 0.4340 - learning_rate: 0.0031\n",
            "Epoch 11/41\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.4169\n",
            "Epoch 11: val_loss did not improve from 0.41962\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7867 - loss: 0.4170 - val_accuracy: 0.8279 - val_loss: 0.4896 - learning_rate: 0.0031\n",
            "Epoch 12/41\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8077 - loss: 0.3969\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0011803546256054574.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.41962\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8074 - loss: 0.3972 - val_accuracy: 0.8254 - val_loss: 0.4406 - learning_rate: 0.0031\n",
            "Epoch 13/41\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.3623\n",
            "Epoch 13: val_loss improved from 0.41962 to 0.41107, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.3618 - val_accuracy: 0.8321 - val_loss: 0.4111 - learning_rate: 0.0012\n",
            "Epoch 14/41\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.3351\n",
            "Epoch 14: val_loss did not improve from 0.41107\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8395 - loss: 0.3352 - val_accuracy: 0.8204 - val_loss: 0.4203 - learning_rate: 0.0012\n",
            "Epoch 15/41\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8446 - loss: 0.3347\n",
            "Epoch 15: val_loss did not improve from 0.41107\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8446 - loss: 0.3347 - val_accuracy: 0.8346 - val_loss: 0.4115 - learning_rate: 0.0012\n",
            "Epoch 16/41\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8497 - loss: 0.3284\n",
            "Epoch 16: val_loss did not improve from 0.41107\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8497 - loss: 0.3284 - val_accuracy: 0.8213 - val_loss: 0.4327 - learning_rate: 0.0012\n",
            "Epoch 17/41\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.3223\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0004446947346759445.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.41107\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8571 - loss: 0.3223 - val_accuracy: 0.8238 - val_loss: 0.4163 - learning_rate: 0.0012\n",
            "Epoch 18/41\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8659 - loss: 0.3069\n",
            "Epoch 18: val_loss did not improve from 0.41107\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8659 - loss: 0.3069 - val_accuracy: 0.8254 - val_loss: 0.4136 - learning_rate: 4.4469e-04\n",
            "Epoch 19/41\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8668 - loss: 0.3032\n",
            "Epoch 19: val_loss improved from 0.41107 to 0.41077, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8667 - loss: 0.3032 - val_accuracy: 0.8279 - val_loss: 0.4108 - learning_rate: 4.4469e-04\n",
            "Epoch 20/41\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8652 - loss: 0.2994\n",
            "Epoch 20: val_loss did not improve from 0.41077\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8653 - loss: 0.2994 - val_accuracy: 0.8279 - val_loss: 0.4152 - learning_rate: 4.4469e-04\n",
            "Epoch 21/41\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.3008\n",
            "Epoch 21: val_loss improved from 0.41077 to 0.40529, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8700 - loss: 0.3009 - val_accuracy: 0.8354 - val_loss: 0.4053 - learning_rate: 4.4469e-04\n",
            "Epoch 22/41\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8716 - loss: 0.2978\n",
            "Epoch 22: val_loss did not improve from 0.40529\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8716 - loss: 0.2977 - val_accuracy: 0.8346 - val_loss: 0.4137 - learning_rate: 4.4469e-04\n",
            "Epoch 23/41\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8647 - loss: 0.2961\n",
            "Epoch 23: val_loss did not improve from 0.40529\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8647 - loss: 0.2961 - val_accuracy: 0.8346 - val_loss: 0.4097 - learning_rate: 4.4469e-04\n",
            "Epoch 24/41\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.2937\n",
            "Epoch 24: val_loss did not improve from 0.40529\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8661 - loss: 0.2937 - val_accuracy: 0.8379 - val_loss: 0.4083 - learning_rate: 4.4469e-04\n",
            "Epoch 25/41\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8735 - loss: 0.2918\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001675372864502231.\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.40529\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8735 - loss: 0.2918 - val_accuracy: 0.8304 - val_loss: 0.4140 - learning_rate: 4.4469e-04\n",
            "Epoch 26/41\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8740 - loss: 0.2839\n",
            "Epoch 26: val_loss did not improve from 0.40529\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8740 - loss: 0.2838 - val_accuracy: 0.8362 - val_loss: 0.4213 - learning_rate: 1.6754e-04\n",
            "Epoch 27/41\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8740 - loss: 0.2833\n",
            "Epoch 27: val_loss did not improve from 0.40529\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8740 - loss: 0.2833 - val_accuracy: 0.8329 - val_loss: 0.4354 - learning_rate: 1.6754e-04\n",
            "Epoch 28/41\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8725 - loss: 0.2801\n",
            "Epoch 28: val_loss did not improve from 0.40529\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8725 - loss: 0.2801 - val_accuracy: 0.8379 - val_loss: 0.4275 - learning_rate: 1.6754e-04\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 21.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:51:26,778] Trial 24 finished with value: -0.4052858352661133 and parameters: {'epochs': 41, 'batch_size': 16, 'learning_rate': 0.003133018988693733, 'stop_patience': 7, 'reduce_lr_factor': 0.37674672197229947, 'reduce_lr_patience': 4}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5570 - loss: 0.6953\n",
            "Epoch 1: val_loss improved from inf to 0.69299, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5568 - loss: 0.6952 - val_accuracy: 0.5121 - val_loss: 0.6930 - learning_rate: 0.0047\n",
            "Epoch 2/20\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5615 - loss: 0.6862\n",
            "Epoch 2: val_loss improved from 0.69299 to 0.62795, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5614 - loss: 0.6861 - val_accuracy: 0.6983 - val_loss: 0.6279 - learning_rate: 0.0047\n",
            "Epoch 3/20\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6273 - loss: 0.6355\n",
            "Epoch 3: val_loss did not improve from 0.62795\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6274 - loss: 0.6353 - val_accuracy: 0.6318 - val_loss: 0.6368 - learning_rate: 0.0047\n",
            "Epoch 4/20\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6620 - loss: 0.6006\n",
            "Epoch 4: val_loss improved from 0.62795 to 0.49378, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6621 - loss: 0.6005 - val_accuracy: 0.7772 - val_loss: 0.4938 - learning_rate: 0.0047\n",
            "Epoch 5/20\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6869 - loss: 0.5649\n",
            "Epoch 5: val_loss did not improve from 0.49378\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6870 - loss: 0.5650 - val_accuracy: 0.6351 - val_loss: 0.6536 - learning_rate: 0.0047\n",
            "Epoch 6/20\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7044 - loss: 0.5465\n",
            "Epoch 6: val_loss did not improve from 0.49378\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7043 - loss: 0.5465 - val_accuracy: 0.7556 - val_loss: 0.5157 - learning_rate: 0.0047\n",
            "Epoch 7/20\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7192 - loss: 0.5160\n",
            "Epoch 7: val_loss improved from 0.49378 to 0.47179, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7193 - loss: 0.5160 - val_accuracy: 0.7905 - val_loss: 0.4718 - learning_rate: 0.0047\n",
            "Epoch 8/20\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7265 - loss: 0.5089\n",
            "Epoch 8: val_loss did not improve from 0.47179\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7267 - loss: 0.5087 - val_accuracy: 0.7880 - val_loss: 0.4756 - learning_rate: 0.0047\n",
            "Epoch 9/20\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7217 - loss: 0.5174\n",
            "Epoch 9: val_loss did not improve from 0.47179\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7219 - loss: 0.5172 - val_accuracy: 0.7157 - val_loss: 0.6652 - learning_rate: 0.0047\n",
            "Epoch 10/20\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.4965\n",
            "Epoch 10: val_loss improved from 0.47179 to 0.45801, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7322 - loss: 0.4960 - val_accuracy: 0.7847 - val_loss: 0.4580 - learning_rate: 0.0047\n",
            "Epoch 11/20\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7627 - loss: 0.4837\n",
            "Epoch 11: val_loss did not improve from 0.45801\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7627 - loss: 0.4837 - val_accuracy: 0.7639 - val_loss: 0.4979 - learning_rate: 0.0047\n",
            "Epoch 12/20\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7780 - loss: 0.4766\n",
            "Epoch 12: val_loss did not improve from 0.45801\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7780 - loss: 0.4761 - val_accuracy: 0.7440 - val_loss: 0.4900 - learning_rate: 0.0047\n",
            "Epoch 13/20\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7760 - loss: 0.4600\n",
            "Epoch 13: val_loss did not improve from 0.45801\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7766 - loss: 0.4594 - val_accuracy: 0.7706 - val_loss: 0.4585 - learning_rate: 0.0047\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:51:57,840] Trial 25 finished with value: -0.45801475644111633 and parameters: {'epochs': 20, 'batch_size': 16, 'learning_rate': 0.004659461478284737, 'stop_patience': 3, 'reduce_lr_factor': 0.4780619352606677, 'reduce_lr_patience': 5}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/33\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5326 - loss: 0.6918\n",
            "Epoch 1: val_loss improved from inf to 0.71451, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5329 - loss: 0.6917 - val_accuracy: 0.4863 - val_loss: 0.7145 - learning_rate: 6.0532e-05\n",
            "Epoch 2/33\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5672 - loss: 0.6826\n",
            "Epoch 2: val_loss improved from 0.71451 to 0.68450, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5672 - loss: 0.6826 - val_accuracy: 0.4979 - val_loss: 0.6845 - learning_rate: 6.0532e-05\n",
            "Epoch 3/33\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5918 - loss: 0.6769\n",
            "Epoch 3: val_loss improved from 0.68450 to 0.64931, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5921 - loss: 0.6768 - val_accuracy: 0.6284 - val_loss: 0.6493 - learning_rate: 6.0532e-05\n",
            "Epoch 4/33\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6154 - loss: 0.6680\n",
            "Epoch 4: val_loss improved from 0.64931 to 0.60261, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6160 - loss: 0.6678 - val_accuracy: 0.7598 - val_loss: 0.6026 - learning_rate: 6.0532e-05\n",
            "Epoch 5/33\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6606 - loss: 0.6520\n",
            "Epoch 5: val_loss improved from 0.60261 to 0.55652, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6610 - loss: 0.6518 - val_accuracy: 0.7847 - val_loss: 0.5565 - learning_rate: 6.0532e-05\n",
            "Epoch 6/33\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6925 - loss: 0.6267\n",
            "Epoch 6: val_loss improved from 0.55652 to 0.51319, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6925 - loss: 0.6267 - val_accuracy: 0.7855 - val_loss: 0.5132 - learning_rate: 6.0532e-05\n",
            "Epoch 7/33\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7212 - loss: 0.5946\n",
            "Epoch 7: val_loss improved from 0.51319 to 0.48703, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7213 - loss: 0.5945 - val_accuracy: 0.7889 - val_loss: 0.4870 - learning_rate: 6.0532e-05\n",
            "Epoch 8/33\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.5676\n",
            "Epoch 8: val_loss improved from 0.48703 to 0.47126, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7357 - loss: 0.5675 - val_accuracy: 0.7955 - val_loss: 0.4713 - learning_rate: 6.0532e-05\n",
            "Epoch 9/33\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7486 - loss: 0.5346\n",
            "Epoch 9: val_loss did not improve from 0.47126\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7487 - loss: 0.5346 - val_accuracy: 0.7864 - val_loss: 0.4986 - learning_rate: 6.0532e-05\n",
            "Epoch 10/33\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7498 - loss: 0.5192\n",
            "Epoch 10: val_loss did not improve from 0.47126\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7500 - loss: 0.5191 - val_accuracy: 0.7922 - val_loss: 0.4851 - learning_rate: 6.0532e-05\n",
            "Epoch 11/33\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7776 - loss: 0.4927\n",
            "Epoch 11: val_loss did not improve from 0.47126\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 0.4928 - val_accuracy: 0.7955 - val_loss: 0.4924 - learning_rate: 6.0532e-05\n",
            "Epoch 12/33\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7786 - loss: 0.4788\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.5925883478027908e-05.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.47126\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7786 - loss: 0.4787 - val_accuracy: 0.7972 - val_loss: 0.5038 - learning_rate: 6.0532e-05\n",
            "Epoch 13/33\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7907 - loss: 0.4641\n",
            "Epoch 13: val_loss did not improve from 0.47126\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7907 - loss: 0.4641 - val_accuracy: 0.7988 - val_loss: 0.5010 - learning_rate: 2.5926e-05\n",
            "Epoch 14/33\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7965 - loss: 0.4580\n",
            "Epoch 14: val_loss did not improve from 0.47126\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7965 - loss: 0.4580 - val_accuracy: 0.8005 - val_loss: 0.5041 - learning_rate: 2.5926e-05\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:52:29,786] Trial 26 finished with value: -0.4712561368942261 and parameters: {'epochs': 33, 'batch_size': 16, 'learning_rate': 6.0532455877167365e-05, 'stop_patience': 6, 'reduce_lr_factor': 0.4282972291430568, 'reduce_lr_patience': 4}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/37\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5635 - loss: 0.6865\n",
            "Epoch 1: val_loss improved from inf to 0.60989, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5639 - loss: 0.6860 - val_accuracy: 0.7897 - val_loss: 0.6099 - learning_rate: 0.0015\n",
            "Epoch 2/37\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6381 - loss: 0.6210\n",
            "Epoch 2: val_loss improved from 0.60989 to 0.56842, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6390 - loss: 0.6201 - val_accuracy: 0.6467 - val_loss: 0.5684 - learning_rate: 0.0015\n",
            "Epoch 3/37\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6717 - loss: 0.5683\n",
            "Epoch 3: val_loss improved from 0.56842 to 0.54773, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6725 - loss: 0.5677 - val_accuracy: 0.6725 - val_loss: 0.5477 - learning_rate: 0.0015\n",
            "Epoch 4/37\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7235 - loss: 0.5141\n",
            "Epoch 4: val_loss did not improve from 0.54773\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7237 - loss: 0.5139 - val_accuracy: 0.6683 - val_loss: 0.5693 - learning_rate: 0.0015\n",
            "Epoch 5/37\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.4913\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0006240312154558742.\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.54773\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7377 - loss: 0.4912 - val_accuracy: 0.6800 - val_loss: 0.7242 - learning_rate: 0.0015\n",
            "Epoch 6/37\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8007 - loss: 0.4117\n",
            "Epoch 6: val_loss improved from 0.54773 to 0.52102, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8009 - loss: 0.4115 - val_accuracy: 0.7606 - val_loss: 0.5210 - learning_rate: 6.2403e-04\n",
            "Epoch 7/37\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8324 - loss: 0.3734\n",
            "Epoch 7: val_loss improved from 0.52102 to 0.39174, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8323 - loss: 0.3736 - val_accuracy: 0.8379 - val_loss: 0.3917 - learning_rate: 6.2403e-04\n",
            "Epoch 8/37\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8221 - loss: 0.3727\n",
            "Epoch 8: val_loss did not improve from 0.39174\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8218 - loss: 0.3732 - val_accuracy: 0.8229 - val_loss: 0.4192 - learning_rate: 6.2403e-04\n",
            "Epoch 9/37\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8387 - loss: 0.3532\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002583798521161636.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.39174\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 0.3535 - val_accuracy: 0.8263 - val_loss: 0.3929 - learning_rate: 6.2403e-04\n",
            "Epoch 10/37\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8560 - loss: 0.3275\n",
            "Epoch 10: val_loss improved from 0.39174 to 0.38011, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8561 - loss: 0.3274 - val_accuracy: 0.8421 - val_loss: 0.3801 - learning_rate: 2.5838e-04\n",
            "Epoch 11/37\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8576 - loss: 0.3182\n",
            "Epoch 11: val_loss did not improve from 0.38011\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8576 - loss: 0.3182 - val_accuracy: 0.8337 - val_loss: 0.3990 - learning_rate: 2.5838e-04\n",
            "Epoch 12/37\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8640 - loss: 0.3096\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00010698205994563885.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.38011\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8640 - loss: 0.3097 - val_accuracy: 0.8321 - val_loss: 0.3896 - learning_rate: 2.5838e-04\n",
            "Epoch 13/37\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8702 - loss: 0.2919\n",
            "Epoch 13: val_loss did not improve from 0.38011\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8702 - loss: 0.2919 - val_accuracy: 0.8254 - val_loss: 0.4137 - learning_rate: 1.0698e-04\n",
            "Epoch 14/37\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8712 - loss: 0.2947\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.429587264388204e-05.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.38011\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8712 - loss: 0.2946 - val_accuracy: 0.8288 - val_loss: 0.4136 - learning_rate: 1.0698e-04\n",
            "Epoch 15/37\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8781 - loss: 0.2810\n",
            "Epoch 15: val_loss did not improve from 0.38011\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8781 - loss: 0.2811 - val_accuracy: 0.8296 - val_loss: 0.4102 - learning_rate: 4.4296e-05\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:53:02,616] Trial 27 finished with value: -0.38010838627815247 and parameters: {'epochs': 37, 'batch_size': 16, 'learning_rate': 0.001507141417784854, 'stop_patience': 5, 'reduce_lr_factor': 0.41404954950896333, 'reduce_lr_patience': 2}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/44\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5625 - loss: 0.6858\n",
            "Epoch 1: val_loss improved from inf to 0.75939, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5627 - loss: 0.6846 - val_accuracy: 0.5902 - val_loss: 0.7594 - learning_rate: 0.0015\n",
            "Epoch 2/44\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6494 - loss: 0.6166\n",
            "Epoch 2: val_loss improved from 0.75939 to 0.50715, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6505 - loss: 0.6150 - val_accuracy: 0.7839 - val_loss: 0.5072 - learning_rate: 0.0015\n",
            "Epoch 3/44\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7125 - loss: 0.5475\n",
            "Epoch 3: val_loss improved from 0.50715 to 0.47203, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7116 - loss: 0.5479 - val_accuracy: 0.7947 - val_loss: 0.4720 - learning_rate: 0.0015\n",
            "Epoch 4/44\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7519 - loss: 0.5004\n",
            "Epoch 4: val_loss did not improve from 0.47203\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7517 - loss: 0.5006 - val_accuracy: 0.7099 - val_loss: 0.7101 - learning_rate: 0.0015\n",
            "Epoch 5/44\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7729 - loss: 0.4576\n",
            "Epoch 5: val_loss improved from 0.47203 to 0.40996, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7728 - loss: 0.4577 - val_accuracy: 0.8171 - val_loss: 0.4100 - learning_rate: 0.0015\n",
            "Epoch 6/44\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7756 - loss: 0.4497\n",
            "Epoch 6: val_loss did not improve from 0.40996\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7764 - loss: 0.4494 - val_accuracy: 0.8130 - val_loss: 0.4150 - learning_rate: 0.0015\n",
            "Epoch 7/44\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7961 - loss: 0.4269\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0004688671728493108.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.40996\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7962 - loss: 0.4269 - val_accuracy: 0.8113 - val_loss: 0.4115 - learning_rate: 0.0015\n",
            "Epoch 8/44\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7989 - loss: 0.4015\n",
            "Epoch 8: val_loss improved from 0.40996 to 0.38879, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8010 - loss: 0.4001 - val_accuracy: 0.8279 - val_loss: 0.3888 - learning_rate: 4.6887e-04\n",
            "Epoch 9/44\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8440 - loss: 0.3531\n",
            "Epoch 9: val_loss did not improve from 0.38879\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8434 - loss: 0.3540 - val_accuracy: 0.8254 - val_loss: 0.3927 - learning_rate: 4.6887e-04\n",
            "Epoch 10/44\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8382 - loss: 0.3600\n",
            "Epoch 10: val_loss improved from 0.38879 to 0.38534, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8373 - loss: 0.3610 - val_accuracy: 0.8313 - val_loss: 0.3853 - learning_rate: 4.6887e-04\n",
            "Epoch 11/44\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 0.3511\n",
            "Epoch 11: val_loss improved from 0.38534 to 0.38077, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8360 - loss: 0.3525 - val_accuracy: 0.8238 - val_loss: 0.3808 - learning_rate: 4.6887e-04\n",
            "Epoch 12/44\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8391 - loss: 0.3515\n",
            "Epoch 12: val_loss improved from 0.38077 to 0.37499, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8383 - loss: 0.3522 - val_accuracy: 0.8296 - val_loss: 0.3750 - learning_rate: 4.6887e-04\n",
            "Epoch 13/44\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8486 - loss: 0.3478\n",
            "Epoch 13: val_loss did not improve from 0.37499\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8484 - loss: 0.3481 - val_accuracy: 0.8296 - val_loss: 0.3907 - learning_rate: 4.6887e-04\n",
            "Epoch 14/44\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8521 - loss: 0.3357\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00015073649017580178.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.37499\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8512 - loss: 0.3367 - val_accuracy: 0.8321 - val_loss: 0.3762 - learning_rate: 4.6887e-04\n",
            "Epoch 15/44\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8637 - loss: 0.3239\n",
            "Epoch 15: val_loss improved from 0.37499 to 0.37341, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8639 - loss: 0.3238 - val_accuracy: 0.8421 - val_loss: 0.3734 - learning_rate: 1.5074e-04\n",
            "Epoch 16/44\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8663 - loss: 0.3106\n",
            "Epoch 16: val_loss did not improve from 0.37341\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8664 - loss: 0.3107 - val_accuracy: 0.8437 - val_loss: 0.3738 - learning_rate: 1.5074e-04\n",
            "Epoch 17/44\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8690 - loss: 0.3089\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 4.8460399717812066e-05.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.37341\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8689 - loss: 0.3090 - val_accuracy: 0.8421 - val_loss: 0.3764 - learning_rate: 1.5074e-04\n",
            "Epoch 18/44\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8743 - loss: 0.3039\n",
            "Epoch 18: val_loss did not improve from 0.37341\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8741 - loss: 0.3041 - val_accuracy: 0.8396 - val_loss: 0.3773 - learning_rate: 4.8460e-05\n",
            "Epoch 19/44\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8729 - loss: 0.3052\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.5579573557816084e-05.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.37341\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8726 - loss: 0.3055 - val_accuracy: 0.8404 - val_loss: 0.3824 - learning_rate: 4.8460e-05\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:53:19,521] Trial 28 finished with value: -0.3734094202518463 and parameters: {'epochs': 44, 'batch_size': 64, 'learning_rate': 0.0014584154114660936, 'stop_patience': 4, 'reduce_lr_factor': 0.32149082413749586, 'reduce_lr_patience': 2}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/47\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5470 - loss: 0.6864\n",
            "Epoch 1: val_loss improved from inf to 0.67325, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5473 - loss: 0.6863 - val_accuracy: 0.5653 - val_loss: 0.6733 - learning_rate: 8.0653e-04\n",
            "Epoch 2/47\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6178 - loss: 0.6503\n",
            "Epoch 2: val_loss improved from 0.67325 to 0.58131, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6184 - loss: 0.6498 - val_accuracy: 0.7323 - val_loss: 0.5813 - learning_rate: 8.0653e-04\n",
            "Epoch 3/47\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6902 - loss: 0.5769\n",
            "Epoch 3: val_loss improved from 0.58131 to 0.54228, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6902 - loss: 0.5770 - val_accuracy: 0.7664 - val_loss: 0.5423 - learning_rate: 8.0653e-04\n",
            "Epoch 4/47\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7186 - loss: 0.5383\n",
            "Epoch 4: val_loss did not improve from 0.54228\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7188 - loss: 0.5383 - val_accuracy: 0.6841 - val_loss: 0.7402 - learning_rate: 8.0653e-04\n",
            "Epoch 5/47\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7414 - loss: 0.5050\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0002469841690036817.\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.54228\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7414 - loss: 0.5050 - val_accuracy: 0.7024 - val_loss: 0.7282 - learning_rate: 8.0653e-04\n",
            "Epoch 6/47\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7697 - loss: 0.4733\n",
            "Epoch 6: val_loss did not improve from 0.54228\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7698 - loss: 0.4733 - val_accuracy: 0.7722 - val_loss: 0.5538 - learning_rate: 2.4698e-04\n",
            "Epoch 7/47\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4558\n",
            "Epoch 7: val_loss improved from 0.54228 to 0.49398, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7771 - loss: 0.4561 - val_accuracy: 0.7880 - val_loss: 0.4940 - learning_rate: 2.4698e-04\n",
            "Epoch 8/47\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.4424\n",
            "Epoch 8: val_loss improved from 0.49398 to 0.47763, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7933 - loss: 0.4426 - val_accuracy: 0.8071 - val_loss: 0.4776 - learning_rate: 2.4698e-04\n",
            "Epoch 9/47\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7921 - loss: 0.4346\n",
            "Epoch 9: val_loss improved from 0.47763 to 0.47028, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7927 - loss: 0.4347 - val_accuracy: 0.8005 - val_loss: 0.4703 - learning_rate: 2.4698e-04\n",
            "Epoch 10/47\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4222\n",
            "Epoch 10: val_loss did not improve from 0.47028\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8074 - loss: 0.4228 - val_accuracy: 0.7922 - val_loss: 0.4763 - learning_rate: 2.4698e-04\n",
            "Epoch 11/47\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7998 - loss: 0.4185\n",
            "Epoch 11: val_loss improved from 0.47028 to 0.46352, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8001 - loss: 0.4186 - val_accuracy: 0.7963 - val_loss: 0.4635 - learning_rate: 2.4698e-04\n",
            "Epoch 12/47\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8108 - loss: 0.4063\n",
            "Epoch 12: val_loss improved from 0.46352 to 0.44392, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8109 - loss: 0.4067 - val_accuracy: 0.7980 - val_loss: 0.4439 - learning_rate: 2.4698e-04\n",
            "Epoch 13/47\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8129 - loss: 0.4057\n",
            "Epoch 13: val_loss improved from 0.44392 to 0.43859, saving model to BEST_CNN_SEQ_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8129 - loss: 0.4059 - val_accuracy: 0.8047 - val_loss: 0.4386 - learning_rate: 2.4698e-04\n",
            "Epoch 14/47\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8263 - loss: 0.3939\n",
            "Epoch 14: val_loss did not improve from 0.43859\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8265 - loss: 0.3943 - val_accuracy: 0.8113 - val_loss: 0.4463 - learning_rate: 2.4698e-04\n",
            "Epoch 15/47\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8213 - loss: 0.3905\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 7.563437976973935e-05.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.43859\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8213 - loss: 0.3906 - val_accuracy: 0.8121 - val_loss: 0.4589 - learning_rate: 2.4698e-04\n",
            "Epoch 16/47\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8382 - loss: 0.3757\n",
            "Epoch 16: val_loss did not improve from 0.43859\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8382 - loss: 0.3758 - val_accuracy: 0.8138 - val_loss: 0.4652 - learning_rate: 7.5634e-05\n",
            "Epoch 17/47\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8349 - loss: 0.3730\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.31616451921281e-05.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.43859\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8351 - loss: 0.3732 - val_accuracy: 0.7930 - val_loss: 0.5024 - learning_rate: 7.5634e-05\n",
            "Epoch 18/47\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8437 - loss: 0.3674\n",
            "Epoch 18: val_loss did not improve from 0.43859\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8437 - loss: 0.3674 - val_accuracy: 0.8038 - val_loss: 0.4889 - learning_rate: 2.3162e-05\n",
            "Epoch 19/47\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8396 - loss: 0.3639\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 7.092830077820724e-06.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.43859\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8396 - loss: 0.3641 - val_accuracy: 0.8096 - val_loss: 0.4774 - learning_rate: 2.3162e-05\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:53:34,623] Trial 29 finished with value: -0.43858930468559265 and parameters: {'epochs': 47, 'batch_size': 64, 'learning_rate': 0.0008065271211336973, 'stop_patience': 6, 'reduce_lr_factor': 0.3062317066289694, 'reduce_lr_patience': 2}. Best is trial 2 with value: -0.3720824718475342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Melhor combinação encontrada:\n",
            "trial                   2.000000\n",
            "epochs                 45.000000\n",
            "batch_size             16.000000\n",
            "learning_rate           0.001121\n",
            "stop_patience           4.000000\n",
            "reduce_lr_factor        0.475345\n",
            "reduce_lr_patience      2.000000\n",
            "recall_Compra(1)        0.906752\n",
            "recall_Vende(0)         0.750430\n",
            "precision_Compra(1)     0.795487\n",
            "precision_Vende(0)      0.882591\n",
            "macro_recall            0.828591\n",
            "accuracy                0.831255\n",
            "f1_macro                0.829323\n",
            "f1_weighted             0.829942\n",
            "min_val_loss            0.372082\n",
            "Name: 0, dtype: float64\n",
            "🔍 Hiperparâmetros: {'epochs': 45, 'batch_size': 16, 'learning_rate': 0.001120992598403538, 'stop_patience': 4, 'reduce_lr_factor': 0.4753446437596067, 'reduce_lr_patience': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_ram_model, best_ram_history, df_results, best_ram_metrics, best_ram_y_pred = train_model(\n",
        "    model_fn=model_cnn_ramificado,\n",
        "    model_path = \"BEST_CNN_RAM_PETR4.keras\",\n",
        "    X_train=[X_train1, X_train2],\n",
        "    y_train=y_train,\n",
        "    X_test=[X_test1, X_test2],\n",
        "    y_test=y_test,\n",
        "    prob=0.5,\n",
        "    n_trials=30,\n",
        "    metric_to_optimize=metric_optimization\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFbMWLy46TCm",
        "outputId": "476b02eb-5ccf-469c-dd3b-0ae7a8fa1fc7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:53:34,637] A new study created in memory with name: no-name-37ae0a56-2b7c-4bc7-af75-56bddcd4848e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5910 - loss: 0.6779\n",
            "Epoch 1: val_loss improved from inf to 1.13252, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5915 - loss: 0.6774 - val_accuracy: 0.5835 - val_loss: 1.1325 - learning_rate: 0.0025\n",
            "Epoch 2/25\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7049 - loss: 0.5562\n",
            "Epoch 2: val_loss improved from 1.13252 to 0.58712, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7059 - loss: 0.5552 - val_accuracy: 0.7764 - val_loss: 0.5871 - learning_rate: 0.0025\n",
            "Epoch 3/25\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7570 - loss: 0.4916\n",
            "Epoch 3: val_loss improved from 0.58712 to 0.44781, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7570 - loss: 0.4914 - val_accuracy: 0.8071 - val_loss: 0.4478 - learning_rate: 0.0025\n",
            "Epoch 4/25\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7729 - loss: 0.4593\n",
            "Epoch 4: val_loss improved from 0.44781 to 0.36786, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7731 - loss: 0.4592 - val_accuracy: 0.8495 - val_loss: 0.3679 - learning_rate: 0.0025\n",
            "Epoch 5/25\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7846 - loss: 0.4348\n",
            "Epoch 5: val_loss did not improve from 0.36786\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7846 - loss: 0.4348 - val_accuracy: 0.8121 - val_loss: 0.4367 - learning_rate: 0.0025\n",
            "Epoch 6/25\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7952 - loss: 0.4173\n",
            "Epoch 6: val_loss improved from 0.36786 to 0.36393, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7953 - loss: 0.4174 - val_accuracy: 0.8537 - val_loss: 0.3639 - learning_rate: 0.0025\n",
            "Epoch 7/25\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7994 - loss: 0.4076\n",
            "Epoch 7: val_loss did not improve from 0.36393\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7993 - loss: 0.4079 - val_accuracy: 0.8063 - val_loss: 0.4377 - learning_rate: 0.0025\n",
            "Epoch 8/25\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8107 - loss: 0.3852\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005639829448199535.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.36393\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8112 - loss: 0.3852 - val_accuracy: 0.8570 - val_loss: 0.3775 - learning_rate: 0.0025\n",
            "Epoch 9/25\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8328 - loss: 0.3601\n",
            "Epoch 9: val_loss improved from 0.36393 to 0.35086, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8332 - loss: 0.3595 - val_accuracy: 0.8537 - val_loss: 0.3509 - learning_rate: 5.6398e-04\n",
            "Epoch 10/25\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8603 - loss: 0.3320\n",
            "Epoch 10: val_loss improved from 0.35086 to 0.34558, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8603 - loss: 0.3322 - val_accuracy: 0.8562 - val_loss: 0.3456 - learning_rate: 5.6398e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8646 - loss: 0.3278\n",
            "Epoch 11: val_loss did not improve from 0.34558\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8645 - loss: 0.3278 - val_accuracy: 0.8462 - val_loss: 0.3475 - learning_rate: 5.6398e-04\n",
            "Epoch 12/25\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8618 - loss: 0.3208\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00012636294519879855.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.34558\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8619 - loss: 0.3210 - val_accuracy: 0.8437 - val_loss: 0.3467 - learning_rate: 5.6398e-04\n",
            "Epoch 13/25\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8763 - loss: 0.3086\n",
            "Epoch 13: val_loss did not improve from 0.34558\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8764 - loss: 0.3087 - val_accuracy: 0.8587 - val_loss: 0.3493 - learning_rate: 1.2636e-04\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:53:49,183] Trial 0 finished with value: -0.34558263421058655 and parameters: {'epochs': 25, 'batch_size': 32, 'learning_rate': 0.0025171680039335884, 'stop_patience': 3, 'reduce_lr_factor': 0.2240545554622081, 'reduce_lr_patience': 2}. Best is trial 0 with value: -0.34558263421058655.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/24\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5999 - loss: 0.6729\n",
            "Epoch 1: val_loss improved from inf to 0.45128, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6017 - loss: 0.6714 - val_accuracy: 0.8146 - val_loss: 0.4513 - learning_rate: 0.0014\n",
            "Epoch 2/24\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7039 - loss: 0.5615\n",
            "Epoch 2: val_loss improved from 0.45128 to 0.42219, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7043 - loss: 0.5609 - val_accuracy: 0.8254 - val_loss: 0.4222 - learning_rate: 0.0014\n",
            "Epoch 3/24\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7561 - loss: 0.5009\n",
            "Epoch 3: val_loss did not improve from 0.42219\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7560 - loss: 0.5008 - val_accuracy: 0.8155 - val_loss: 0.4321 - learning_rate: 0.0014\n",
            "Epoch 4/24\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7744 - loss: 0.4696\n",
            "Epoch 4: val_loss did not improve from 0.42219\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7740 - loss: 0.4698 - val_accuracy: 0.7914 - val_loss: 0.4806 - learning_rate: 0.0014\n",
            "Epoch 5/24\n",
            "\u001b[1m135/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7828 - loss: 0.4462\n",
            "Epoch 5: val_loss did not improve from 0.42219\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7826 - loss: 0.4465 - val_accuracy: 0.8146 - val_loss: 0.4560 - learning_rate: 0.0014\n",
            "Epoch 5: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:53:56,698] Trial 1 finished with value: -0.4221917688846588 and parameters: {'epochs': 24, 'batch_size': 32, 'learning_rate': 0.0014121332800503975, 'stop_patience': 3, 'reduce_lr_factor': 0.1749623035392709, 'reduce_lr_patience': 5}. Best is trial 0 with value: -0.34558263421058655.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/17\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5774 - loss: 0.6849\n",
            "Epoch 1: val_loss improved from inf to 0.49048, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5790 - loss: 0.6835 - val_accuracy: 0.7764 - val_loss: 0.4905 - learning_rate: 0.0094\n",
            "Epoch 2/17\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6672 - loss: 0.5813\n",
            "Epoch 2: val_loss did not improve from 0.49048\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6683 - loss: 0.5799 - val_accuracy: 0.6908 - val_loss: 0.8803 - learning_rate: 0.0094\n",
            "Epoch 3/17\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.5044\n",
            "Epoch 3: val_loss improved from 0.49048 to 0.42517, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7344 - loss: 0.5042 - val_accuracy: 0.8038 - val_loss: 0.4252 - learning_rate: 0.0094\n",
            "Epoch 4/17\n",
            "\u001b[1m283/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7371 - loss: 0.4863\n",
            "Epoch 4: val_loss did not improve from 0.42517\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7379 - loss: 0.4858 - val_accuracy: 0.8421 - val_loss: 0.4761 - learning_rate: 0.0094\n",
            "Epoch 5/17\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7700 - loss: 0.4506\n",
            "Epoch 5: val_loss did not improve from 0.42517\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7700 - loss: 0.4505 - val_accuracy: 0.6692 - val_loss: 0.7202 - learning_rate: 0.0094\n",
            "Epoch 6/17\n",
            "\u001b[1m283/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7828 - loss: 0.4355\n",
            "Epoch 6: val_loss did not improve from 0.42517\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7823 - loss: 0.4357 - val_accuracy: 0.7406 - val_loss: 0.5653 - learning_rate: 0.0094\n",
            "Epoch 7/17\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7827 - loss: 0.4256\n",
            "Epoch 7: val_loss improved from 0.42517 to 0.34211, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7827 - loss: 0.4256 - val_accuracy: 0.8554 - val_loss: 0.3421 - learning_rate: 0.0094\n",
            "Epoch 8/17\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7977 - loss: 0.4172\n",
            "Epoch 8: val_loss did not improve from 0.34211\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7977 - loss: 0.4172 - val_accuracy: 0.8587 - val_loss: 0.3482 - learning_rate: 0.0094\n",
            "Epoch 9/17\n",
            "\u001b[1m281/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.4049\n",
            "Epoch 9: val_loss did not improve from 0.34211\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8002 - loss: 0.4049 - val_accuracy: 0.7706 - val_loss: 0.4332 - learning_rate: 0.0094\n",
            "Epoch 10/17\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.3980\n",
            "Epoch 10: val_loss did not improve from 0.34211\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8046 - loss: 0.3982 - val_accuracy: 0.7332 - val_loss: 0.9333 - learning_rate: 0.0094\n",
            "Epoch 11/17\n",
            "\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8141 - loss: 0.3995\n",
            "Epoch 11: val_loss did not improve from 0.34211\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8142 - loss: 0.3990 - val_accuracy: 0.8446 - val_loss: 0.3926 - learning_rate: 0.0094\n",
            "Epoch 12/17\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8284 - loss: 0.3808\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.003644262545096678.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.34211\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8283 - loss: 0.3808 - val_accuracy: 0.8529 - val_loss: 0.3443 - learning_rate: 0.0094\n",
            "Epoch 13/17\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8480 - loss: 0.3341\n",
            "Epoch 13: val_loss did not improve from 0.34211\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8481 - loss: 0.3340 - val_accuracy: 0.8545 - val_loss: 0.3545 - learning_rate: 0.0036\n",
            "Epoch 14/17\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8570 - loss: 0.3273\n",
            "Epoch 14: val_loss did not improve from 0.34211\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.3273 - val_accuracy: 0.8379 - val_loss: 0.4257 - learning_rate: 0.0036\n",
            "Epoch 15/17\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8587 - loss: 0.3146\n",
            "Epoch 15: val_loss did not improve from 0.34211\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8587 - loss: 0.3146 - val_accuracy: 0.8570 - val_loss: 0.3434 - learning_rate: 0.0036\n",
            "Epoch 16/17\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8644 - loss: 0.3149\n",
            "Epoch 16: val_loss did not improve from 0.34211\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8644 - loss: 0.3148 - val_accuracy: 0.8537 - val_loss: 0.4122 - learning_rate: 0.0036\n",
            "Epoch 17/17\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8663 - loss: 0.3067\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.001415506118413602.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.34211\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8663 - loss: 0.3068 - val_accuracy: 0.8404 - val_loss: 0.3601 - learning_rate: 0.0036\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:54:23,301] Trial 2 finished with value: -0.34211134910583496 and parameters: {'epochs': 17, 'batch_size': 16, 'learning_rate': 0.009382261568429863, 'stop_patience': 10, 'reduce_lr_factor': 0.38842046683618237, 'reduce_lr_patience': 5}. Best is trial 2 with value: -0.34211134910583496.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/28\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5815 - loss: 0.6767\n",
            "Epoch 1: val_loss improved from inf to 0.72395, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5821 - loss: 0.6762 - val_accuracy: 0.6916 - val_loss: 0.7239 - learning_rate: 0.0032\n",
            "Epoch 2/28\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6839 - loss: 0.5679\n",
            "Epoch 2: val_loss improved from 0.72395 to 0.55543, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6843 - loss: 0.5675 - val_accuracy: 0.7947 - val_loss: 0.5554 - learning_rate: 0.0032\n",
            "Epoch 3/28\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7408 - loss: 0.4998\n",
            "Epoch 3: val_loss did not improve from 0.55543\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7408 - loss: 0.4996 - val_accuracy: 0.6800 - val_loss: 0.7828 - learning_rate: 0.0032\n",
            "Epoch 4/28\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7643 - loss: 0.4639\n",
            "Epoch 4: val_loss improved from 0.55543 to 0.52915, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7644 - loss: 0.4637 - val_accuracy: 0.7423 - val_loss: 0.5292 - learning_rate: 0.0032\n",
            "Epoch 5/28\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7677 - loss: 0.4443\n",
            "Epoch 5: val_loss improved from 0.52915 to 0.44319, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7678 - loss: 0.4443 - val_accuracy: 0.8022 - val_loss: 0.4432 - learning_rate: 0.0032\n",
            "Epoch 6/28\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7891 - loss: 0.4249\n",
            "Epoch 6: val_loss did not improve from 0.44319\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7891 - loss: 0.4250 - val_accuracy: 0.7980 - val_loss: 0.4720 - learning_rate: 0.0032\n",
            "Epoch 7/28\n",
            "\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7958 - loss: 0.4149\n",
            "Epoch 7: val_loss did not improve from 0.44319\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7962 - loss: 0.4146 - val_accuracy: 0.7739 - val_loss: 0.5900 - learning_rate: 0.0032\n",
            "Epoch 8/28\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8020 - loss: 0.4120\n",
            "Epoch 8: val_loss did not improve from 0.44319\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8021 - loss: 0.4118 - val_accuracy: 0.7980 - val_loss: 0.5002 - learning_rate: 0.0032\n",
            "Epoch 9/28\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.3956\n",
            "Epoch 9: val_loss did not improve from 0.44319\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.3957 - val_accuracy: 0.7955 - val_loss: 0.4772 - learning_rate: 0.0032\n",
            "Epoch 10/28\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8120 - loss: 0.3902\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0011447289753846006.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.44319\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8122 - loss: 0.3899 - val_accuracy: 0.8047 - val_loss: 0.4432 - learning_rate: 0.0032\n",
            "Epoch 11/28\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8467 - loss: 0.3324\n",
            "Epoch 11: val_loss improved from 0.44319 to 0.33829, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8471 - loss: 0.3320 - val_accuracy: 0.8587 - val_loss: 0.3383 - learning_rate: 0.0011\n",
            "Epoch 12/28\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8561 - loss: 0.3225\n",
            "Epoch 12: val_loss did not improve from 0.33829\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3224 - val_accuracy: 0.8570 - val_loss: 0.3409 - learning_rate: 0.0011\n",
            "Epoch 13/28\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8634 - loss: 0.3093\n",
            "Epoch 13: val_loss did not improve from 0.33829\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8634 - loss: 0.3093 - val_accuracy: 0.8570 - val_loss: 0.3565 - learning_rate: 0.0011\n",
            "Epoch 14/28\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8644 - loss: 0.3095\n",
            "Epoch 14: val_loss did not improve from 0.33829\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8644 - loss: 0.3095 - val_accuracy: 0.8254 - val_loss: 0.3663 - learning_rate: 0.0011\n",
            "Epoch 15/28\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.3037\n",
            "Epoch 15: val_loss did not improve from 0.33829\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.3038 - val_accuracy: 0.8529 - val_loss: 0.3425 - learning_rate: 0.0011\n",
            "Epoch 16/28\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8630 - loss: 0.3001\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0004150351668444418.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.33829\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8631 - loss: 0.3001 - val_accuracy: 0.8437 - val_loss: 0.3538 - learning_rate: 0.0011\n",
            "Epoch 17/28\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8773 - loss: 0.2856\n",
            "Epoch 17: val_loss did not improve from 0.33829\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8773 - loss: 0.2856 - val_accuracy: 0.8462 - val_loss: 0.3656 - learning_rate: 4.1504e-04\n",
            "Epoch 18/28\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8817 - loss: 0.2780\n",
            "Epoch 18: val_loss did not improve from 0.33829\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8817 - loss: 0.2780 - val_accuracy: 0.8537 - val_loss: 0.3459 - learning_rate: 4.1504e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:54:49,362] Trial 3 finished with value: -0.3382944166660309 and parameters: {'epochs': 28, 'batch_size': 16, 'learning_rate': 0.003157333514055263, 'stop_patience': 7, 'reduce_lr_factor': 0.3625619485372854, 'reduce_lr_patience': 5}. Best is trial 3 with value: -0.3382944166660309.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5869 - loss: 0.6856\n",
            "Epoch 1: val_loss improved from inf to 1.16601, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5895 - loss: 0.6826 - val_accuracy: 0.5877 - val_loss: 1.1660 - learning_rate: 0.0038\n",
            "Epoch 2/50\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7198 - loss: 0.5397\n",
            "Epoch 2: val_loss improved from 1.16601 to 0.59734, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7201 - loss: 0.5393 - val_accuracy: 0.7930 - val_loss: 0.5973 - learning_rate: 0.0038\n",
            "Epoch 3/50\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7585 - loss: 0.4792\n",
            "Epoch 3: val_loss improved from 0.59734 to 0.49655, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7586 - loss: 0.4790 - val_accuracy: 0.7947 - val_loss: 0.4966 - learning_rate: 0.0038\n",
            "Epoch 4/50\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7715 - loss: 0.4495\n",
            "Epoch 4: val_loss improved from 0.49655 to 0.43677, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7714 - loss: 0.4497 - val_accuracy: 0.8329 - val_loss: 0.4368 - learning_rate: 0.0038\n",
            "Epoch 5/50\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.4339\n",
            "Epoch 5: val_loss improved from 0.43677 to 0.38842, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7873 - loss: 0.4338 - val_accuracy: 0.8529 - val_loss: 0.3884 - learning_rate: 0.0038\n",
            "Epoch 6/50\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7942 - loss: 0.4111\n",
            "Epoch 6: val_loss improved from 0.38842 to 0.34545, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7941 - loss: 0.4115 - val_accuracy: 0.8628 - val_loss: 0.3454 - learning_rate: 0.0038\n",
            "Epoch 7/50\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7934 - loss: 0.4031\n",
            "Epoch 7: val_loss did not improve from 0.34545\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.4029 - val_accuracy: 0.8562 - val_loss: 0.3529 - learning_rate: 0.0038\n",
            "Epoch 8/50\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8041 - loss: 0.4022\n",
            "Epoch 8: val_loss did not improve from 0.34545\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8041 - loss: 0.4023 - val_accuracy: 0.8404 - val_loss: 0.3822 - learning_rate: 0.0038\n",
            "Epoch 9/50\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8073 - loss: 0.4013\n",
            "Epoch 9: val_loss did not improve from 0.34545\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.4006 - val_accuracy: 0.6717 - val_loss: 0.9114 - learning_rate: 0.0038\n",
            "Epoch 10/50\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.3700\n",
            "Epoch 10: val_loss did not improve from 0.34545\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8254 - loss: 0.3700 - val_accuracy: 0.8545 - val_loss: 0.3657 - learning_rate: 0.0038\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:55:01,050] Trial 4 finished with value: -0.34544575214385986 and parameters: {'epochs': 50, 'batch_size': 32, 'learning_rate': 0.003788702108598841, 'stop_patience': 4, 'reduce_lr_factor': 0.35985530783743525, 'reduce_lr_patience': 5}. Best is trial 3 with value: -0.3382944166660309.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5744 - loss: 0.6894\n",
            "Epoch 1: val_loss improved from inf to 0.81263, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5767 - loss: 0.6876 - val_accuracy: 0.6326 - val_loss: 0.8126 - learning_rate: 0.0029\n",
            "Epoch 2/50\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7095 - loss: 0.5613\n",
            "Epoch 2: val_loss improved from 0.81263 to 0.48025, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7107 - loss: 0.5595 - val_accuracy: 0.8055 - val_loss: 0.4803 - learning_rate: 0.0029\n",
            "Epoch 3/50\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7486 - loss: 0.4863\n",
            "Epoch 3: val_loss did not improve from 0.48025\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7490 - loss: 0.4859 - val_accuracy: 0.7473 - val_loss: 0.5936 - learning_rate: 0.0029\n",
            "Epoch 4/50\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7587 - loss: 0.4671\n",
            "Epoch 4: val_loss did not improve from 0.48025\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7587 - loss: 0.4670 - val_accuracy: 0.8163 - val_loss: 0.5126 - learning_rate: 0.0029\n",
            "Epoch 5/50\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.4409\n",
            "Epoch 5: val_loss improved from 0.48025 to 0.36322, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7793 - loss: 0.4407 - val_accuracy: 0.8554 - val_loss: 0.3632 - learning_rate: 0.0029\n",
            "Epoch 6/50\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7849 - loss: 0.4225\n",
            "Epoch 6: val_loss did not improve from 0.36322\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7852 - loss: 0.4225 - val_accuracy: 0.8279 - val_loss: 0.4617 - learning_rate: 0.0029\n",
            "Epoch 7/50\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7900 - loss: 0.4170\n",
            "Epoch 7: val_loss did not improve from 0.36322\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7902 - loss: 0.4169 - val_accuracy: 0.7697 - val_loss: 0.4985 - learning_rate: 0.0029\n",
            "Epoch 8/50\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8092 - loss: 0.4059\n",
            "Epoch 8: val_loss did not improve from 0.36322\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8089 - loss: 0.4061 - val_accuracy: 0.8396 - val_loss: 0.3863 - learning_rate: 0.0029\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:55:10,764] Trial 5 finished with value: -0.3632160425186157 and parameters: {'epochs': 50, 'batch_size': 32, 'learning_rate': 0.00289062956210776, 'stop_patience': 3, 'reduce_lr_factor': 0.31271824702934614, 'reduce_lr_patience': 4}. Best is trial 3 with value: -0.3382944166660309.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/47\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5705 - loss: 0.6914\n",
            "Epoch 1: val_loss improved from inf to 1.14651, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5722 - loss: 0.6898 - val_accuracy: 0.5736 - val_loss: 1.1465 - learning_rate: 0.0058\n",
            "Epoch 2/47\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7030 - loss: 0.5580\n",
            "Epoch 2: val_loss improved from 1.14651 to 1.03385, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7040 - loss: 0.5562 - val_accuracy: 0.6284 - val_loss: 1.0338 - learning_rate: 0.0058\n",
            "Epoch 3/47\n",
            "\u001b[1m135/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7459 - loss: 0.4902\n",
            "Epoch 3: val_loss improved from 1.03385 to 0.42362, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7461 - loss: 0.4903 - val_accuracy: 0.8404 - val_loss: 0.4236 - learning_rate: 0.0058\n",
            "Epoch 4/47\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7584 - loss: 0.4714\n",
            "Epoch 4: val_loss did not improve from 0.42362\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7584 - loss: 0.4714 - val_accuracy: 0.7199 - val_loss: 0.7752 - learning_rate: 0.0058\n",
            "Epoch 5/47\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7627 - loss: 0.4481\n",
            "Epoch 5: val_loss improved from 0.42362 to 0.38941, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7629 - loss: 0.4485 - val_accuracy: 0.8204 - val_loss: 0.3894 - learning_rate: 0.0058\n",
            "Epoch 6/47\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7766 - loss: 0.4369\n",
            "Epoch 6: val_loss did not improve from 0.38941\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7766 - loss: 0.4370 - val_accuracy: 0.7606 - val_loss: 0.7012 - learning_rate: 0.0058\n",
            "Epoch 7/47\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7779 - loss: 0.4494\n",
            "Epoch 7: val_loss improved from 0.38941 to 0.35559, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7780 - loss: 0.4493 - val_accuracy: 0.8529 - val_loss: 0.3556 - learning_rate: 0.0058\n",
            "Epoch 8/47\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7834 - loss: 0.4185\n",
            "Epoch 8: val_loss did not improve from 0.35559\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7838 - loss: 0.4188 - val_accuracy: 0.6766 - val_loss: 0.6677 - learning_rate: 0.0058\n",
            "Epoch 9/47\n",
            "\u001b[1m137/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8010 - loss: 0.4098\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0023005019306657124.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.35559\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4097 - val_accuracy: 0.7722 - val_loss: 0.7706 - learning_rate: 0.0058\n",
            "Epoch 10/47\n",
            "\u001b[1m136/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8264 - loss: 0.3619\n",
            "Epoch 10: val_loss did not improve from 0.35559\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8269 - loss: 0.3613 - val_accuracy: 0.8429 - val_loss: 0.3732 - learning_rate: 0.0023\n",
            "Epoch 11/47\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8292 - loss: 0.3636\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009162114623455271.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.35559\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8300 - loss: 0.3626 - val_accuracy: 0.8570 - val_loss: 0.4109 - learning_rate: 0.0023\n",
            "Epoch 12/47\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8612 - loss: 0.3245\n",
            "Epoch 12: val_loss did not improve from 0.35559\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8614 - loss: 0.3243 - val_accuracy: 0.8554 - val_loss: 0.3617 - learning_rate: 9.1621e-04\n",
            "Epoch 13/47\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8700 - loss: 0.3073\n",
            "Epoch 13: val_loss improved from 0.35559 to 0.33789, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8701 - loss: 0.3074 - val_accuracy: 0.8404 - val_loss: 0.3379 - learning_rate: 9.1621e-04\n",
            "Epoch 14/47\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8679 - loss: 0.3111\n",
            "Epoch 14: val_loss did not improve from 0.33789\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8681 - loss: 0.3107 - val_accuracy: 0.8429 - val_loss: 0.3729 - learning_rate: 9.1621e-04\n",
            "Epoch 15/47\n",
            "\u001b[1m135/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8709 - loss: 0.3060\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00036489576089764606.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.33789\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8706 - loss: 0.3063 - val_accuracy: 0.8371 - val_loss: 0.3481 - learning_rate: 9.1621e-04\n",
            "Epoch 16/47\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8793 - loss: 0.2963\n",
            "Epoch 16: val_loss did not improve from 0.33789\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8794 - loss: 0.2963 - val_accuracy: 0.8520 - val_loss: 0.3557 - learning_rate: 3.6490e-04\n",
            "Epoch 17/47\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8787 - loss: 0.2909\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00014532553202480133.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.33789\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8792 - loss: 0.2907 - val_accuracy: 0.8537 - val_loss: 0.3693 - learning_rate: 3.6490e-04\n",
            "Epoch 18/47\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8795 - loss: 0.2864\n",
            "Epoch 18: val_loss did not improve from 0.33789\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8796 - loss: 0.2864 - val_accuracy: 0.8628 - val_loss: 0.3745 - learning_rate: 1.4533e-04\n",
            "Epoch 19/47\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8748 - loss: 0.2929\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 5.787820340441495e-05.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.33789\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8751 - loss: 0.2928 - val_accuracy: 0.8603 - val_loss: 0.3750 - learning_rate: 1.4533e-04\n",
            "Epoch 20/47\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8837 - loss: 0.2891\n",
            "Epoch 20: val_loss did not improve from 0.33789\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8837 - loss: 0.2890 - val_accuracy: 0.8628 - val_loss: 0.3642 - learning_rate: 5.7878e-05\n",
            "Epoch 21/47\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8769 - loss: 0.2855\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.3050912901919306e-05.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.33789\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8775 - loss: 0.2854 - val_accuracy: 0.8595 - val_loss: 0.3606 - learning_rate: 5.7878e-05\n",
            "Epoch 22/47\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8790 - loss: 0.2828\n",
            "Epoch 22: val_loss did not improve from 0.33789\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8793 - loss: 0.2827 - val_accuracy: 0.8628 - val_loss: 0.3664 - learning_rate: 2.3051e-05\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:55:36,254] Trial 6 finished with value: -0.3378903567790985 and parameters: {'epochs': 47, 'batch_size': 32, 'learning_rate': 0.005776296876826958, 'stop_patience': 9, 'reduce_lr_factor': 0.3982658779877797, 'reduce_lr_patience': 2}. Best is trial 6 with value: -0.3378903567790985.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5596 - loss: 0.6809\n",
            "Epoch 1: val_loss improved from inf to 0.54486, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5624 - loss: 0.6788 - val_accuracy: 0.7431 - val_loss: 0.5449 - learning_rate: 0.0086\n",
            "Epoch 2/40\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7115 - loss: 0.5321\n",
            "Epoch 2: val_loss improved from 0.54486 to 0.46795, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7112 - loss: 0.5328 - val_accuracy: 0.8130 - val_loss: 0.4680 - learning_rate: 0.0086\n",
            "Epoch 3/40\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7186 - loss: 0.5390\n",
            "Epoch 3: val_loss did not improve from 0.46795\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7187 - loss: 0.5387 - val_accuracy: 0.6883 - val_loss: 0.6905 - learning_rate: 0.0086\n",
            "Epoch 4/40\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7475 - loss: 0.4795\n",
            "Epoch 4: val_loss did not improve from 0.46795\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7485 - loss: 0.4786 - val_accuracy: 0.6584 - val_loss: 0.6499 - learning_rate: 0.0086\n",
            "Epoch 5/40\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7691 - loss: 0.4494\n",
            "Epoch 5: val_loss improved from 0.46795 to 0.46575, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7692 - loss: 0.4494 - val_accuracy: 0.8337 - val_loss: 0.4658 - learning_rate: 0.0086\n",
            "Epoch 6/40\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7840 - loss: 0.4268\n",
            "Epoch 6: val_loss did not improve from 0.46575\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7835 - loss: 0.4277 - val_accuracy: 0.7581 - val_loss: 0.4721 - learning_rate: 0.0086\n",
            "Epoch 7/40\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7863 - loss: 0.4288\n",
            "Epoch 7: val_loss did not improve from 0.46575\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7857 - loss: 0.4299 - val_accuracy: 0.7905 - val_loss: 0.4732 - learning_rate: 0.0086\n",
            "Epoch 8/40\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7870 - loss: 0.4211\n",
            "Epoch 8: val_loss improved from 0.46575 to 0.35504, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7870 - loss: 0.4213 - val_accuracy: 0.8520 - val_loss: 0.3550 - learning_rate: 0.0086\n",
            "Epoch 9/40\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8076 - loss: 0.4113\n",
            "Epoch 9: val_loss did not improve from 0.35504\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8070 - loss: 0.4119 - val_accuracy: 0.7240 - val_loss: 0.5560 - learning_rate: 0.0086\n",
            "Epoch 10/40\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7992 - loss: 0.4046\n",
            "Epoch 10: val_loss did not improve from 0.35504\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7991 - loss: 0.4046 - val_accuracy: 0.8105 - val_loss: 0.4855 - learning_rate: 0.0086\n",
            "Epoch 11/40\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7975 - loss: 0.4136\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.002792974285686665.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.35504\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7976 - loss: 0.4133 - val_accuracy: 0.8105 - val_loss: 0.4469 - learning_rate: 0.0086\n",
            "Epoch 12/40\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8283 - loss: 0.3628\n",
            "Epoch 12: val_loss did not improve from 0.35504\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8287 - loss: 0.3622 - val_accuracy: 0.8204 - val_loss: 0.4289 - learning_rate: 0.0028\n",
            "Epoch 13/40\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8451 - loss: 0.3354\n",
            "Epoch 13: val_loss did not improve from 0.35504\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8453 - loss: 0.3356 - val_accuracy: 0.8005 - val_loss: 0.4206 - learning_rate: 0.0028\n",
            "Epoch 14/40\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8492 - loss: 0.3333\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0009042190102902825.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.35504\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8493 - loss: 0.3336 - val_accuracy: 0.8229 - val_loss: 0.3706 - learning_rate: 0.0028\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:55:47,235] Trial 7 finished with value: -0.3550412654876709 and parameters: {'epochs': 40, 'batch_size': 64, 'learning_rate': 0.008627008872986279, 'stop_patience': 6, 'reduce_lr_factor': 0.32374770909107853, 'reduce_lr_patience': 3}. Best is trial 6 with value: -0.3378903567790985.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5741 - loss: 0.7022\n",
            "Epoch 1: val_loss improved from inf to 0.83644, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5771 - loss: 0.6993 - val_accuracy: 0.6717 - val_loss: 0.8364 - learning_rate: 0.0062\n",
            "Epoch 2/45\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6998 - loss: 0.5701\n",
            "Epoch 2: val_loss improved from 0.83644 to 0.48202, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7004 - loss: 0.5688 - val_accuracy: 0.8337 - val_loss: 0.4820 - learning_rate: 0.0062\n",
            "Epoch 3/45\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7388 - loss: 0.4968\n",
            "Epoch 3: val_loss did not improve from 0.48202\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7387 - loss: 0.4967 - val_accuracy: 0.7273 - val_loss: 0.5890 - learning_rate: 0.0062\n",
            "Epoch 4/45\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7478 - loss: 0.4862\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.002820973903242254.\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.48202\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7480 - loss: 0.4859 - val_accuracy: 0.7922 - val_loss: 0.4865 - learning_rate: 0.0062\n",
            "Epoch 5/45\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7817 - loss: 0.4376\n",
            "Epoch 5: val_loss improved from 0.48202 to 0.37881, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7817 - loss: 0.4375 - val_accuracy: 0.8479 - val_loss: 0.3788 - learning_rate: 0.0028\n",
            "Epoch 6/45\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7899 - loss: 0.4179\n",
            "Epoch 6: val_loss improved from 0.37881 to 0.36696, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.4175 - val_accuracy: 0.8479 - val_loss: 0.3670 - learning_rate: 0.0028\n",
            "Epoch 7/45\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8133 - loss: 0.3860\n",
            "Epoch 7: val_loss did not improve from 0.36696\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8133 - loss: 0.3860 - val_accuracy: 0.8180 - val_loss: 0.4151 - learning_rate: 0.0028\n",
            "Epoch 8/45\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8122 - loss: 0.3866\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0012901619074554074.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.36696\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8122 - loss: 0.3866 - val_accuracy: 0.8246 - val_loss: 0.3985 - learning_rate: 0.0028\n",
            "Epoch 9/45\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8474 - loss: 0.3430\n",
            "Epoch 9: val_loss improved from 0.36696 to 0.34915, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8476 - loss: 0.3427 - val_accuracy: 0.8545 - val_loss: 0.3491 - learning_rate: 0.0013\n",
            "Epoch 10/45\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8574 - loss: 0.3308\n",
            "Epoch 10: val_loss did not improve from 0.34915\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8575 - loss: 0.3306 - val_accuracy: 0.8446 - val_loss: 0.3576 - learning_rate: 0.0013\n",
            "Epoch 11/45\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8581 - loss: 0.3305\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005900507050622295.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.34915\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8581 - loss: 0.3305 - val_accuracy: 0.8379 - val_loss: 0.3720 - learning_rate: 0.0013\n",
            "Epoch 12/45\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8671 - loss: 0.3204\n",
            "Epoch 12: val_loss did not improve from 0.34915\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8673 - loss: 0.3201 - val_accuracy: 0.8562 - val_loss: 0.3504 - learning_rate: 5.9005e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:56:02,596] Trial 8 finished with value: -0.34914663434028625 and parameters: {'epochs': 45, 'batch_size': 32, 'learning_rate': 0.006168135741044025, 'stop_patience': 3, 'reduce_lr_factor': 0.457346262395371, 'reduce_lr_patience': 2}. Best is trial 6 with value: -0.3378903567790985.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5904 - loss: 0.6746\n",
            "Epoch 1: val_loss improved from inf to 0.52869, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5943 - loss: 0.6710 - val_accuracy: 0.7224 - val_loss: 0.5287 - learning_rate: 0.0035\n",
            "Epoch 2/32\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7077 - loss: 0.5582\n",
            "Epoch 2: val_loss did not improve from 0.52869\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7078 - loss: 0.5579 - val_accuracy: 0.7298 - val_loss: 0.6804 - learning_rate: 0.0035\n",
            "Epoch 3/32\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7566 - loss: 0.4920\n",
            "Epoch 3: val_loss did not improve from 0.52869\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7565 - loss: 0.4917 - val_accuracy: 0.7581 - val_loss: 0.6373 - learning_rate: 0.0035\n",
            "Epoch 4/32\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7782 - loss: 0.4588\n",
            "Epoch 4: val_loss did not improve from 0.52869\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7780 - loss: 0.4589 - val_accuracy: 0.7323 - val_loss: 0.6819 - learning_rate: 0.0035\n",
            "Epoch 5/32\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7891 - loss: 0.4315\n",
            "Epoch 5: val_loss improved from 0.52869 to 0.45683, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7890 - loss: 0.4315 - val_accuracy: 0.8171 - val_loss: 0.4568 - learning_rate: 0.0035\n",
            "Epoch 6/32\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7777 - loss: 0.4378\n",
            "Epoch 6: val_loss improved from 0.45683 to 0.44008, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7782 - loss: 0.4374 - val_accuracy: 0.8096 - val_loss: 0.4401 - learning_rate: 0.0035\n",
            "Epoch 7/32\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7886 - loss: 0.4148\n",
            "Epoch 7: val_loss did not improve from 0.44008\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4146 - val_accuracy: 0.7847 - val_loss: 0.4526 - learning_rate: 0.0035\n",
            "Epoch 8/32\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8077 - loss: 0.3954\n",
            "Epoch 8: val_loss did not improve from 0.44008\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8078 - loss: 0.3954 - val_accuracy: 0.7440 - val_loss: 0.5821 - learning_rate: 0.0035\n",
            "Epoch 9/32\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8125 - loss: 0.3876\n",
            "Epoch 9: val_loss improved from 0.44008 to 0.39282, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8121 - loss: 0.3882 - val_accuracy: 0.8238 - val_loss: 0.3928 - learning_rate: 0.0035\n",
            "Epoch 10/32\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8145 - loss: 0.3836\n",
            "Epoch 10: val_loss did not improve from 0.39282\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8145 - loss: 0.3835 - val_accuracy: 0.7997 - val_loss: 0.4980 - learning_rate: 0.0035\n",
            "Epoch 11/32\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8223 - loss: 0.3737\n",
            "Epoch 11: val_loss did not improve from 0.39282\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8216 - loss: 0.3747 - val_accuracy: 0.8171 - val_loss: 0.4553 - learning_rate: 0.0035\n",
            "Epoch 12/32\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8198 - loss: 0.3699\n",
            "Epoch 12: val_loss improved from 0.39282 to 0.38033, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8200 - loss: 0.3703 - val_accuracy: 0.8296 - val_loss: 0.3803 - learning_rate: 0.0035\n",
            "Epoch 13/32\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8354 - loss: 0.3519\n",
            "Epoch 13: val_loss did not improve from 0.38033\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8355 - loss: 0.3524 - val_accuracy: 0.8271 - val_loss: 0.4117 - learning_rate: 0.0035\n",
            "Epoch 14/32\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8036 - loss: 0.3864\n",
            "Epoch 14: val_loss improved from 0.38033 to 0.34914, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8049 - loss: 0.3859 - val_accuracy: 0.8570 - val_loss: 0.3491 - learning_rate: 0.0035\n",
            "Epoch 15/32\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8239 - loss: 0.3626\n",
            "Epoch 15: val_loss did not improve from 0.34914\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.3628 - val_accuracy: 0.8329 - val_loss: 0.4244 - learning_rate: 0.0035\n",
            "Epoch 16/32\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 0.3595\n",
            "Epoch 16: val_loss did not improve from 0.34914\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8245 - loss: 0.3600 - val_accuracy: 0.8520 - val_loss: 0.3585 - learning_rate: 0.0035\n",
            "Epoch 17/32\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.3522\n",
            "Epoch 17: val_loss did not improve from 0.34914\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8250 - loss: 0.3518 - val_accuracy: 0.8296 - val_loss: 0.4037 - learning_rate: 0.0035\n",
            "Epoch 18/32\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8191 - loss: 0.3575\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0007400609247936893.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.34914\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8197 - loss: 0.3576 - val_accuracy: 0.8487 - val_loss: 0.3543 - learning_rate: 0.0035\n",
            "Epoch 19/32\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8573 - loss: 0.3277\n",
            "Epoch 19: val_loss improved from 0.34914 to 0.33382, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8578 - loss: 0.3266 - val_accuracy: 0.8653 - val_loss: 0.3338 - learning_rate: 7.4006e-04\n",
            "Epoch 20/32\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8714 - loss: 0.3019\n",
            "Epoch 20: val_loss did not improve from 0.33382\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8715 - loss: 0.3018 - val_accuracy: 0.8579 - val_loss: 0.3454 - learning_rate: 7.4006e-04\n",
            "Epoch 21/32\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8669 - loss: 0.3030\n",
            "Epoch 21: val_loss did not improve from 0.33382\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8673 - loss: 0.3026 - val_accuracy: 0.8562 - val_loss: 0.3365 - learning_rate: 7.4006e-04\n",
            "Epoch 22/32\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8739 - loss: 0.2912\n",
            "Epoch 22: val_loss did not improve from 0.33382\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8740 - loss: 0.2912 - val_accuracy: 0.8520 - val_loss: 0.3465 - learning_rate: 7.4006e-04\n",
            "Epoch 23/32\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8720 - loss: 0.2908\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001567502434065942.\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.33382\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8724 - loss: 0.2909 - val_accuracy: 0.8454 - val_loss: 0.3380 - learning_rate: 7.4006e-04\n",
            "Epoch 24/32\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8811 - loss: 0.2840\n",
            "Epoch 24: val_loss did not improve from 0.33382\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8811 - loss: 0.2841 - val_accuracy: 0.8537 - val_loss: 0.3432 - learning_rate: 1.5675e-04\n",
            "Epoch 25/32\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8789 - loss: 0.2805\n",
            "Epoch 25: val_loss did not improve from 0.33382\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8792 - loss: 0.2805 - val_accuracy: 0.8612 - val_loss: 0.3386 - learning_rate: 1.5675e-04\n",
            "Epoch 26/32\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8839 - loss: 0.2794\n",
            "Epoch 26: val_loss did not improve from 0.33382\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8840 - loss: 0.2794 - val_accuracy: 0.8570 - val_loss: 0.3433 - learning_rate: 1.5675e-04\n",
            "Epoch 27/32\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8835 - loss: 0.2760\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.320083309100362e-05.\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.33382\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8837 - loss: 0.2759 - val_accuracy: 0.8520 - val_loss: 0.3482 - learning_rate: 1.5675e-04\n",
            "Epoch 27: early stopping\n",
            "Restoring model weights from the end of the best epoch: 19.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:56:23,266] Trial 9 finished with value: -0.3338213562965393 and parameters: {'epochs': 32, 'batch_size': 64, 'learning_rate': 0.0034940308227381874, 'stop_patience': 8, 'reduce_lr_factor': 0.21180721293090354, 'reduce_lr_patience': 4}. Best is trial 9 with value: -0.3338213562965393.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/36\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5541 - loss: 0.6975\n",
            "Epoch 1: val_loss improved from inf to 0.60497, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5579 - loss: 0.6936 - val_accuracy: 0.7057 - val_loss: 0.6050 - learning_rate: 0.0073\n",
            "Epoch 2/36\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6899 - loss: 0.5482\n",
            "Epoch 2: val_loss did not improve from 0.60497\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6902 - loss: 0.5478 - val_accuracy: 0.6392 - val_loss: 0.8174 - learning_rate: 0.0073\n",
            "Epoch 3/36\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7331 - loss: 0.5020\n",
            "Epoch 3: val_loss improved from 0.60497 to 0.55293, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7326 - loss: 0.5021 - val_accuracy: 0.7564 - val_loss: 0.5529 - learning_rate: 0.0073\n",
            "Epoch 4/36\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7320 - loss: 0.5026\n",
            "Epoch 4: val_loss improved from 0.55293 to 0.43428, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7323 - loss: 0.5027 - val_accuracy: 0.7947 - val_loss: 0.4343 - learning_rate: 0.0073\n",
            "Epoch 5/36\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7720 - loss: 0.4532\n",
            "Epoch 5: val_loss improved from 0.43428 to 0.42006, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7719 - loss: 0.4533 - val_accuracy: 0.8196 - val_loss: 0.4201 - learning_rate: 0.0073\n",
            "Epoch 6/36\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7637 - loss: 0.4493\n",
            "Epoch 6: val_loss improved from 0.42006 to 0.38624, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7637 - loss: 0.4495 - val_accuracy: 0.8495 - val_loss: 0.3862 - learning_rate: 0.0073\n",
            "Epoch 7/36\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7826 - loss: 0.4357\n",
            "Epoch 7: val_loss improved from 0.38624 to 0.35870, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7826 - loss: 0.4358 - val_accuracy: 0.8479 - val_loss: 0.3587 - learning_rate: 0.0073\n",
            "Epoch 8/36\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7813 - loss: 0.4270\n",
            "Epoch 8: val_loss did not improve from 0.35870\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7815 - loss: 0.4270 - val_accuracy: 0.8437 - val_loss: 0.3827 - learning_rate: 0.0073\n",
            "Epoch 9/36\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.4108\n",
            "Epoch 9: val_loss did not improve from 0.35870\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7985 - loss: 0.4108 - val_accuracy: 0.8005 - val_loss: 0.4848 - learning_rate: 0.0073\n",
            "Epoch 10/36\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8020 - loss: 0.4024\n",
            "Epoch 10: val_loss did not improve from 0.35870\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8020 - loss: 0.4026 - val_accuracy: 0.8188 - val_loss: 0.3998 - learning_rate: 0.0073\n",
            "Epoch 11/36\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8067 - loss: 0.3911\n",
            "Epoch 11: val_loss improved from 0.35870 to 0.35691, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8069 - loss: 0.3915 - val_accuracy: 0.8479 - val_loss: 0.3569 - learning_rate: 0.0073\n",
            "Epoch 12/36\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8144 - loss: 0.3846\n",
            "Epoch 12: val_loss did not improve from 0.35691\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8140 - loss: 0.3849 - val_accuracy: 0.8180 - val_loss: 0.4641 - learning_rate: 0.0073\n",
            "Epoch 13/36\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8166 - loss: 0.3829\n",
            "Epoch 13: val_loss did not improve from 0.35691\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8163 - loss: 0.3833 - val_accuracy: 0.7988 - val_loss: 0.4097 - learning_rate: 0.0073\n",
            "Epoch 14/36\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7971 - loss: 0.4004\n",
            "Epoch 14: val_loss did not improve from 0.35691\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7972 - loss: 0.4004 - val_accuracy: 0.7082 - val_loss: 0.5570 - learning_rate: 0.0073\n",
            "Epoch 15/36\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8262 - loss: 0.3661\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0009447248128420477.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.35691\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8262 - loss: 0.3662 - val_accuracy: 0.8105 - val_loss: 0.3919 - learning_rate: 0.0073\n",
            "Epoch 16/36\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8441 - loss: 0.3474\n",
            "Epoch 16: val_loss did not improve from 0.35691\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8456 - loss: 0.3462 - val_accuracy: 0.8520 - val_loss: 0.3842 - learning_rate: 9.4472e-04\n",
            "Epoch 17/36\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8596 - loss: 0.3258\n",
            "Epoch 17: val_loss improved from 0.35691 to 0.33681, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8596 - loss: 0.3258 - val_accuracy: 0.8587 - val_loss: 0.3368 - learning_rate: 9.4472e-04\n",
            "Epoch 18/36\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8639 - loss: 0.3116\n",
            "Epoch 18: val_loss did not improve from 0.33681\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8644 - loss: 0.3116 - val_accuracy: 0.8412 - val_loss: 0.4230 - learning_rate: 9.4472e-04\n",
            "Epoch 19/36\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8689 - loss: 0.3124\n",
            "Epoch 19: val_loss did not improve from 0.33681\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8690 - loss: 0.3124 - val_accuracy: 0.8628 - val_loss: 0.3531 - learning_rate: 9.4472e-04\n",
            "Epoch 20/36\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8781 - loss: 0.2991\n",
            "Epoch 20: val_loss did not improve from 0.33681\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8781 - loss: 0.2993 - val_accuracy: 0.8470 - val_loss: 0.4068 - learning_rate: 9.4472e-04\n",
            "Epoch 21/36\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8778 - loss: 0.2949\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00012280992625298177.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.33681\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8778 - loss: 0.2950 - val_accuracy: 0.8362 - val_loss: 0.3841 - learning_rate: 9.4472e-04\n",
            "Epoch 22/36\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8757 - loss: 0.2908\n",
            "Epoch 22: val_loss did not improve from 0.33681\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8760 - loss: 0.2907 - val_accuracy: 0.8446 - val_loss: 0.3570 - learning_rate: 1.2281e-04\n",
            "Epoch 23/36\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8742 - loss: 0.2928\n",
            "Epoch 23: val_loss did not improve from 0.33681\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8747 - loss: 0.2926 - val_accuracy: 0.8595 - val_loss: 0.3615 - learning_rate: 1.2281e-04\n",
            "Epoch 24/36\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8732 - loss: 0.2876\n",
            "Epoch 24: val_loss did not improve from 0.33681\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8737 - loss: 0.2875 - val_accuracy: 0.8587 - val_loss: 0.3531 - learning_rate: 1.2281e-04\n",
            "Epoch 25/36\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8763 - loss: 0.2847\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.596473145847773e-05.\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.33681\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8764 - loss: 0.2851 - val_accuracy: 0.8587 - val_loss: 0.3456 - learning_rate: 1.2281e-04\n",
            "Epoch 25: early stopping\n",
            "Restoring model weights from the end of the best epoch: 17.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:56:39,958] Trial 10 finished with value: -0.3368092477321625 and parameters: {'epochs': 36, 'batch_size': 64, 'learning_rate': 0.007267368707335046, 'stop_patience': 8, 'reduce_lr_factor': 0.1299954466208691, 'reduce_lr_patience': 4}. Best is trial 9 with value: -0.3338213562965393.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/36\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5730 - loss: 0.6816\n",
            "Epoch 1: val_loss improved from inf to 0.57782, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5742 - loss: 0.6805 - val_accuracy: 0.7132 - val_loss: 0.5778 - learning_rate: 0.0071\n",
            "Epoch 2/36\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7174 - loss: 0.5382\n",
            "Epoch 2: val_loss improved from 0.57782 to 0.43241, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7178 - loss: 0.5377 - val_accuracy: 0.8188 - val_loss: 0.4324 - learning_rate: 0.0071\n",
            "Epoch 3/36\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7450 - loss: 0.4923\n",
            "Epoch 3: val_loss did not improve from 0.43241\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7450 - loss: 0.4919 - val_accuracy: 0.7473 - val_loss: 0.5524 - learning_rate: 0.0071\n",
            "Epoch 4/36\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7506 - loss: 0.4738\n",
            "Epoch 4: val_loss improved from 0.43241 to 0.37423, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7502 - loss: 0.4745 - val_accuracy: 0.8437 - val_loss: 0.3742 - learning_rate: 0.0071\n",
            "Epoch 5/36\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7853 - loss: 0.4428\n",
            "Epoch 5: val_loss did not improve from 0.37423\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7848 - loss: 0.4435 - val_accuracy: 0.7997 - val_loss: 0.4124 - learning_rate: 0.0071\n",
            "Epoch 6/36\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7867 - loss: 0.4300\n",
            "Epoch 6: val_loss did not improve from 0.37423\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 0.4297 - val_accuracy: 0.8146 - val_loss: 0.4985 - learning_rate: 0.0071\n",
            "Epoch 7/36\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7652 - loss: 0.4365\n",
            "Epoch 7: val_loss did not improve from 0.37423\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7659 - loss: 0.4366 - val_accuracy: 0.8462 - val_loss: 0.3818 - learning_rate: 0.0071\n",
            "Epoch 8/36\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8023 - loss: 0.4120\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0008262070525268711.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.37423\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8018 - loss: 0.4124 - val_accuracy: 0.8346 - val_loss: 0.4318 - learning_rate: 0.0071\n",
            "Epoch 9/36\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8041 - loss: 0.3931\n",
            "Epoch 9: val_loss improved from 0.37423 to 0.34591, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8068 - loss: 0.3907 - val_accuracy: 0.8562 - val_loss: 0.3459 - learning_rate: 8.2621e-04\n",
            "Epoch 10/36\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 0.3528\n",
            "Epoch 10: val_loss improved from 0.34591 to 0.33797, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8581 - loss: 0.3524 - val_accuracy: 0.8554 - val_loss: 0.3380 - learning_rate: 8.2621e-04\n",
            "Epoch 11/36\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8615 - loss: 0.3370\n",
            "Epoch 11: val_loss improved from 0.33797 to 0.33623, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8614 - loss: 0.3374 - val_accuracy: 0.8587 - val_loss: 0.3362 - learning_rate: 8.2621e-04\n",
            "Epoch 12/36\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8646 - loss: 0.3326\n",
            "Epoch 12: val_loss improved from 0.33623 to 0.33568, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8647 - loss: 0.3329 - val_accuracy: 0.8520 - val_loss: 0.3357 - learning_rate: 8.2621e-04\n",
            "Epoch 13/36\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8666 - loss: 0.3311\n",
            "Epoch 13: val_loss did not improve from 0.33568\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8668 - loss: 0.3312 - val_accuracy: 0.8595 - val_loss: 0.3444 - learning_rate: 8.2621e-04\n",
            "Epoch 14/36\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8694 - loss: 0.3284\n",
            "Epoch 14: val_loss improved from 0.33568 to 0.33189, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8694 - loss: 0.3282 - val_accuracy: 0.8612 - val_loss: 0.3319 - learning_rate: 8.2621e-04\n",
            "Epoch 15/36\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8659 - loss: 0.3282\n",
            "Epoch 15: val_loss did not improve from 0.33189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8659 - loss: 0.3281 - val_accuracy: 0.8479 - val_loss: 0.3582 - learning_rate: 8.2621e-04\n",
            "Epoch 16/36\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8727 - loss: 0.3142\n",
            "Epoch 16: val_loss did not improve from 0.33189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8724 - loss: 0.3143 - val_accuracy: 0.8412 - val_loss: 0.3527 - learning_rate: 8.2621e-04\n",
            "Epoch 17/36\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8721 - loss: 0.3133\n",
            "Epoch 17: val_loss did not improve from 0.33189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8722 - loss: 0.3131 - val_accuracy: 0.8603 - val_loss: 0.3324 - learning_rate: 8.2621e-04\n",
            "Epoch 18/36\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8673 - loss: 0.3117\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.598853525811762e-05.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.33189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8674 - loss: 0.3117 - val_accuracy: 0.8603 - val_loss: 0.3385 - learning_rate: 8.2621e-04\n",
            "Epoch 19/36\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8745 - loss: 0.3065\n",
            "Epoch 19: val_loss did not improve from 0.33189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8749 - loss: 0.3064 - val_accuracy: 0.8620 - val_loss: 0.3386 - learning_rate: 9.5989e-05\n",
            "Epoch 20/36\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8754 - loss: 0.3008\n",
            "Epoch 20: val_loss did not improve from 0.33189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8756 - loss: 0.3009 - val_accuracy: 0.8620 - val_loss: 0.3379 - learning_rate: 9.5989e-05\n",
            "Epoch 21/36\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8862 - loss: 0.2953\n",
            "Epoch 21: val_loss did not improve from 0.33189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8860 - loss: 0.2956 - val_accuracy: 0.8653 - val_loss: 0.3391 - learning_rate: 9.5989e-05\n",
            "Epoch 22/36\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8857 - loss: 0.2998\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.1151924984785727e-05.\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.33189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8857 - loss: 0.2998 - val_accuracy: 0.8662 - val_loss: 0.3397 - learning_rate: 9.5989e-05\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:56:57,024] Trial 11 finished with value: -0.33189353346824646 and parameters: {'epochs': 36, 'batch_size': 64, 'learning_rate': 0.007111454169656551, 'stop_patience': 8, 'reduce_lr_factor': 0.11617975846902845, 'reduce_lr_patience': 4}. Best is trial 11 with value: -0.33189353346824646.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/34\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5617 - loss: 0.6919\n",
            "Epoch 1: val_loss improved from inf to 0.88831, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5652 - loss: 0.6893 - val_accuracy: 0.5844 - val_loss: 0.8883 - learning_rate: 0.0047\n",
            "Epoch 2/34\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6818 - loss: 0.5743\n",
            "Epoch 2: val_loss improved from 0.88831 to 0.61719, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6833 - loss: 0.5726 - val_accuracy: 0.7564 - val_loss: 0.6172 - learning_rate: 0.0047\n",
            "Epoch 3/34\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7340 - loss: 0.5178\n",
            "Epoch 3: val_loss did not improve from 0.61719\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7341 - loss: 0.5177 - val_accuracy: 0.7024 - val_loss: 0.7331 - learning_rate: 0.0047\n",
            "Epoch 4/34\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7653 - loss: 0.4736\n",
            "Epoch 4: val_loss did not improve from 0.61719\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7653 - loss: 0.4737 - val_accuracy: 0.7448 - val_loss: 0.6189 - learning_rate: 0.0047\n",
            "Epoch 5/34\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7834 - loss: 0.4356\n",
            "Epoch 5: val_loss improved from 0.61719 to 0.36184, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7836 - loss: 0.4358 - val_accuracy: 0.8470 - val_loss: 0.3618 - learning_rate: 0.0047\n",
            "Epoch 6/34\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7874 - loss: 0.4229\n",
            "Epoch 6: val_loss did not improve from 0.36184\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7879 - loss: 0.4242 - val_accuracy: 0.7548 - val_loss: 0.4981 - learning_rate: 0.0047\n",
            "Epoch 7/34\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7980 - loss: 0.4079\n",
            "Epoch 7: val_loss did not improve from 0.36184\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7982 - loss: 0.4079 - val_accuracy: 0.8288 - val_loss: 0.3825 - learning_rate: 0.0047\n",
            "Epoch 8/34\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8206 - loss: 0.3843\n",
            "Epoch 8: val_loss did not improve from 0.36184\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8198 - loss: 0.3851 - val_accuracy: 0.7382 - val_loss: 0.5393 - learning_rate: 0.0047\n",
            "Epoch 9/34\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8176 - loss: 0.3796\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0010690789752430476.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.36184\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8171 - loss: 0.3803 - val_accuracy: 0.8529 - val_loss: 0.3637 - learning_rate: 0.0047\n",
            "Epoch 10/34\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8315 - loss: 0.3640\n",
            "Epoch 10: val_loss improved from 0.36184 to 0.34809, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8325 - loss: 0.3628 - val_accuracy: 0.8504 - val_loss: 0.3481 - learning_rate: 0.0011\n",
            "Epoch 11/34\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8564 - loss: 0.3372\n",
            "Epoch 11: val_loss did not improve from 0.34809\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8564 - loss: 0.3371 - val_accuracy: 0.8321 - val_loss: 0.3668 - learning_rate: 0.0011\n",
            "Epoch 12/34\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8607 - loss: 0.3263\n",
            "Epoch 12: val_loss improved from 0.34809 to 0.34071, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8609 - loss: 0.3264 - val_accuracy: 0.8529 - val_loss: 0.3407 - learning_rate: 0.0011\n",
            "Epoch 13/34\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8595 - loss: 0.3231\n",
            "Epoch 13: val_loss did not improve from 0.34071\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8598 - loss: 0.3229 - val_accuracy: 0.8412 - val_loss: 0.3605 - learning_rate: 0.0011\n",
            "Epoch 14/34\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8638 - loss: 0.3194\n",
            "Epoch 14: val_loss did not improve from 0.34071\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8638 - loss: 0.3193 - val_accuracy: 0.8479 - val_loss: 0.3524 - learning_rate: 0.0011\n",
            "Epoch 15/34\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8647 - loss: 0.3193\n",
            "Epoch 15: val_loss did not improve from 0.34071\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8648 - loss: 0.3192 - val_accuracy: 0.8454 - val_loss: 0.3480 - learning_rate: 0.0011\n",
            "Epoch 16/34\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8680 - loss: 0.3113\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00024261952380758407.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.34071\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8679 - loss: 0.3114 - val_accuracy: 0.8379 - val_loss: 0.3554 - learning_rate: 0.0011\n",
            "Epoch 17/34\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8779 - loss: 0.3004\n",
            "Epoch 17: val_loss did not improve from 0.34071\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8780 - loss: 0.3004 - val_accuracy: 0.8429 - val_loss: 0.3915 - learning_rate: 2.4262e-04\n",
            "Epoch 18/34\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8718 - loss: 0.2980\n",
            "Epoch 18: val_loss did not improve from 0.34071\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8723 - loss: 0.2981 - val_accuracy: 0.8437 - val_loss: 0.3805 - learning_rate: 2.4262e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:57:11,230] Trial 12 finished with value: -0.34071123600006104 and parameters: {'epochs': 34, 'batch_size': 64, 'learning_rate': 0.004710790705519832, 'stop_patience': 6, 'reduce_lr_factor': 0.22694257568444587, 'reduce_lr_patience': 4}. Best is trial 11 with value: -0.33189353346824646.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5554 - loss: 0.6835\n",
            "Epoch 1: val_loss improved from inf to 0.59317, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5581 - loss: 0.6827 - val_accuracy: 0.8047 - val_loss: 0.5932 - learning_rate: 4.7779e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6777 - loss: 0.6395\n",
            "Epoch 2: val_loss improved from 0.59317 to 0.55768, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6781 - loss: 0.6387 - val_accuracy: 0.7481 - val_loss: 0.5577 - learning_rate: 4.7779e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7159 - loss: 0.5946\n",
            "Epoch 3: val_loss did not improve from 0.55768\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7170 - loss: 0.5937 - val_accuracy: 0.7215 - val_loss: 0.6262 - learning_rate: 4.7779e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7365 - loss: 0.5619\n",
            "Epoch 4: val_loss improved from 0.55768 to 0.55299, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7371 - loss: 0.5609 - val_accuracy: 0.7697 - val_loss: 0.5530 - learning_rate: 4.7779e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7554 - loss: 0.5214\n",
            "Epoch 5: val_loss did not improve from 0.55299\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7557 - loss: 0.5211 - val_accuracy: 0.7739 - val_loss: 0.5788 - learning_rate: 4.7779e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7738 - loss: 0.4956\n",
            "Epoch 6: val_loss did not improve from 0.55299\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7741 - loss: 0.4954 - val_accuracy: 0.7781 - val_loss: 0.6011 - learning_rate: 4.7779e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7882 - loss: 0.4710\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 4.844646585110922e-05.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.55299\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7883 - loss: 0.4711 - val_accuracy: 0.7789 - val_loss: 0.6277 - learning_rate: 4.7779e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7944 - loss: 0.4596\n",
            "Epoch 8: val_loss improved from 0.55299 to 0.44342, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7949 - loss: 0.4595 - val_accuracy: 0.8313 - val_loss: 0.4434 - learning_rate: 4.8446e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4487\n",
            "Epoch 9: val_loss improved from 0.44342 to 0.44151, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8047 - loss: 0.4491 - val_accuracy: 0.8254 - val_loss: 0.4415 - learning_rate: 4.8446e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.4450\n",
            "Epoch 10: val_loss did not improve from 0.44151\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4458 - val_accuracy: 0.8263 - val_loss: 0.4425 - learning_rate: 4.8446e-05\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:57:19,505] Trial 13 finished with value: -0.44150641560554504 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 0.00047778800391209096, 'stop_patience': 8, 'reduce_lr_factor': 0.10139740825033036, 'reduce_lr_patience': 3}. Best is trial 11 with value: -0.33189353346824646.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/34\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5617 - loss: 0.6980\n",
            "Epoch 1: val_loss improved from inf to 0.42972, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5671 - loss: 0.6932 - val_accuracy: 0.8204 - val_loss: 0.4297 - learning_rate: 0.0075\n",
            "Epoch 2/34\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7044 - loss: 0.5599\n",
            "Epoch 2: val_loss did not improve from 0.42972\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7039 - loss: 0.5603 - val_accuracy: 0.7930 - val_loss: 0.4563 - learning_rate: 0.0075\n",
            "Epoch 3/34\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7544 - loss: 0.4774\n",
            "Epoch 3: val_loss did not improve from 0.42972\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7543 - loss: 0.4777 - val_accuracy: 0.5960 - val_loss: 1.4584 - learning_rate: 0.0075\n",
            "Epoch 4/34\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7550 - loss: 0.4783\n",
            "Epoch 4: val_loss improved from 0.42972 to 0.39357, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7560 - loss: 0.4764 - val_accuracy: 0.8404 - val_loss: 0.3936 - learning_rate: 0.0075\n",
            "Epoch 5/34\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7741 - loss: 0.4398\n",
            "Epoch 5: val_loss improved from 0.39357 to 0.35854, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7742 - loss: 0.4400 - val_accuracy: 0.8470 - val_loss: 0.3585 - learning_rate: 0.0075\n",
            "Epoch 6/34\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7852 - loss: 0.4412\n",
            "Epoch 6: val_loss improved from 0.35854 to 0.35325, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7856 - loss: 0.4411 - val_accuracy: 0.8520 - val_loss: 0.3532 - learning_rate: 0.0075\n",
            "Epoch 7/34\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7957 - loss: 0.4101\n",
            "Epoch 7: val_loss did not improve from 0.35325\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7959 - loss: 0.4103 - val_accuracy: 0.8396 - val_loss: 0.3836 - learning_rate: 0.0075\n",
            "Epoch 8/34\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.4254\n",
            "Epoch 8: val_loss did not improve from 0.35325\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7905 - loss: 0.4249 - val_accuracy: 0.8570 - val_loss: 0.3805 - learning_rate: 0.0075\n",
            "Epoch 9/34\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8058 - loss: 0.3989\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.001716634105274908.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.35325\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8057 - loss: 0.3986 - val_accuracy: 0.8520 - val_loss: 0.3714 - learning_rate: 0.0075\n",
            "Epoch 10/34\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8281 - loss: 0.3564\n",
            "Epoch 10: val_loss did not improve from 0.35325\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8287 - loss: 0.3560 - val_accuracy: 0.7988 - val_loss: 0.4018 - learning_rate: 0.0017\n",
            "Epoch 11/34\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 0.3319\n",
            "Epoch 11: val_loss did not improve from 0.35325\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8568 - loss: 0.3319 - val_accuracy: 0.8387 - val_loss: 0.3673 - learning_rate: 0.0017\n",
            "Epoch 12/34\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8618 - loss: 0.3281\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00039424334225746874.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.35325\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8616 - loss: 0.3280 - val_accuracy: 0.8121 - val_loss: 0.3951 - learning_rate: 0.0017\n",
            "Epoch 13/34\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.3244\n",
            "Epoch 13: val_loss improved from 0.35325 to 0.33885, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8702 - loss: 0.3237 - val_accuracy: 0.8603 - val_loss: 0.3389 - learning_rate: 3.9424e-04\n",
            "Epoch 14/34\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8697 - loss: 0.3104\n",
            "Epoch 14: val_loss did not improve from 0.33885\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8699 - loss: 0.3104 - val_accuracy: 0.8653 - val_loss: 0.3493 - learning_rate: 3.9424e-04\n",
            "Epoch 15/34\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8684 - loss: 0.3059\n",
            "Epoch 15: val_loss did not improve from 0.33885\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8690 - loss: 0.3062 - val_accuracy: 0.8628 - val_loss: 0.3425 - learning_rate: 3.9424e-04\n",
            "Epoch 16/34\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8757 - loss: 0.3098\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.054218835678716e-05.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.33885\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8758 - loss: 0.3096 - val_accuracy: 0.8595 - val_loss: 0.3429 - learning_rate: 3.9424e-04\n",
            "Epoch 17/34\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8722 - loss: 0.2974\n",
            "Epoch 17: val_loss did not improve from 0.33885\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8726 - loss: 0.2977 - val_accuracy: 0.8637 - val_loss: 0.3403 - learning_rate: 9.0542e-05\n",
            "Epoch 18/34\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8735 - loss: 0.3019\n",
            "Epoch 18: val_loss improved from 0.33885 to 0.33684, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8735 - loss: 0.3019 - val_accuracy: 0.8653 - val_loss: 0.3368 - learning_rate: 9.0542e-05\n",
            "Epoch 19/34\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 0.3046\n",
            "Epoch 19: val_loss improved from 0.33684 to 0.33619, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8668 - loss: 0.3040 - val_accuracy: 0.8678 - val_loss: 0.3362 - learning_rate: 9.0542e-05\n",
            "Epoch 20/34\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8795 - loss: 0.3014\n",
            "Epoch 20: val_loss did not improve from 0.33619\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8797 - loss: 0.3014 - val_accuracy: 0.8653 - val_loss: 0.3377 - learning_rate: 9.0542e-05\n",
            "Epoch 21/34\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8765 - loss: 0.3009\n",
            "Epoch 21: val_loss did not improve from 0.33619\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8771 - loss: 0.3009 - val_accuracy: 0.8645 - val_loss: 0.3371 - learning_rate: 9.0542e-05\n",
            "Epoch 22/34\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8769 - loss: 0.3005\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.079398002517736e-05.\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.33619\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8775 - loss: 0.3004 - val_accuracy: 0.8620 - val_loss: 0.3414 - learning_rate: 9.0542e-05\n",
            "Epoch 23/34\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8764 - loss: 0.2957\n",
            "Epoch 23: val_loss did not improve from 0.33619\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8765 - loss: 0.2957 - val_accuracy: 0.8628 - val_loss: 0.3387 - learning_rate: 2.0794e-05\n",
            "Epoch 24/34\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8773 - loss: 0.2988\n",
            "Epoch 24: val_loss did not improve from 0.33619\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8772 - loss: 0.2988 - val_accuracy: 0.8653 - val_loss: 0.3380 - learning_rate: 2.0794e-05\n",
            "Epoch 25/34\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.2962\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.775559151718082e-06.\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.33619\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8756 - loss: 0.2962 - val_accuracy: 0.8637 - val_loss: 0.3374 - learning_rate: 2.0794e-05\n",
            "Epoch 26/34\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8791 - loss: 0.2987\n",
            "Epoch 26: val_loss did not improve from 0.33619\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8793 - loss: 0.2986 - val_accuracy: 0.8662 - val_loss: 0.3371 - learning_rate: 4.7756e-06\n",
            "Epoch 27/34\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8768 - loss: 0.3005\n",
            "Epoch 27: val_loss did not improve from 0.33619\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8769 - loss: 0.3001 - val_accuracy: 0.8662 - val_loss: 0.3372 - learning_rate: 4.7756e-06\n",
            "Epoch 28/34\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8798 - loss: 0.2986\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.096758138871928e-06.\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.33619\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8798 - loss: 0.2984 - val_accuracy: 0.8653 - val_loss: 0.3374 - learning_rate: 4.7756e-06\n",
            "Epoch 29/34\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8772 - loss: 0.2969\n",
            "Epoch 29: val_loss did not improve from 0.33619\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8770 - loss: 0.2971 - val_accuracy: 0.8653 - val_loss: 0.3374 - learning_rate: 1.0968e-06\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 19.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:57:38,192] Trial 14 finished with value: -0.3361865282058716 and parameters: {'epochs': 34, 'batch_size': 64, 'learning_rate': 0.007474654374001503, 'stop_patience': 10, 'reduce_lr_factor': 0.22966066709434574, 'reduce_lr_patience': 3}. Best is trial 11 with value: -0.33189353346824646.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/39\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5945 - loss: 0.6818\n",
            "Epoch 1: val_loss improved from inf to 0.50325, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5954 - loss: 0.6808 - val_accuracy: 0.7822 - val_loss: 0.5032 - learning_rate: 0.0048\n",
            "Epoch 2/39\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7100 - loss: 0.5603\n",
            "Epoch 2: val_loss did not improve from 0.50325\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7102 - loss: 0.5599 - val_accuracy: 0.6791 - val_loss: 0.8687 - learning_rate: 0.0048\n",
            "Epoch 3/39\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7452 - loss: 0.4997\n",
            "Epoch 3: val_loss did not improve from 0.50325\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7457 - loss: 0.4993 - val_accuracy: 0.7955 - val_loss: 0.5123 - learning_rate: 0.0048\n",
            "Epoch 4/39\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 0.4589\n",
            "Epoch 4: val_loss improved from 0.50325 to 0.40347, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7719 - loss: 0.4585 - val_accuracy: 0.8454 - val_loss: 0.4035 - learning_rate: 0.0048\n",
            "Epoch 5/39\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7790 - loss: 0.4371\n",
            "Epoch 5: val_loss did not improve from 0.40347\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7790 - loss: 0.4375 - val_accuracy: 0.8204 - val_loss: 0.4932 - learning_rate: 0.0048\n",
            "Epoch 6/39\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7979 - loss: 0.4190\n",
            "Epoch 6: val_loss did not improve from 0.40347\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7977 - loss: 0.4192 - val_accuracy: 0.7448 - val_loss: 0.6264 - learning_rate: 0.0048\n",
            "Epoch 7/39\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7938 - loss: 0.4081\n",
            "Epoch 7: val_loss improved from 0.40347 to 0.35932, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7943 - loss: 0.4078 - val_accuracy: 0.8495 - val_loss: 0.3593 - learning_rate: 0.0048\n",
            "Epoch 8/39\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8041 - loss: 0.3992\n",
            "Epoch 8: val_loss did not improve from 0.35932\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8041 - loss: 0.3992 - val_accuracy: 0.8196 - val_loss: 0.4514 - learning_rate: 0.0048\n",
            "Epoch 9/39\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8086 - loss: 0.3938\n",
            "Epoch 9: val_loss did not improve from 0.35932\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8086 - loss: 0.3936 - val_accuracy: 0.8595 - val_loss: 0.3706 - learning_rate: 0.0048\n",
            "Epoch 10/39\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8069 - loss: 0.3921\n",
            "Epoch 10: val_loss did not improve from 0.35932\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8069 - loss: 0.3922 - val_accuracy: 0.8005 - val_loss: 0.4608 - learning_rate: 0.0048\n",
            "Epoch 11/39\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8316 - loss: 0.3660\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.000795263875037269.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.35932\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8309 - loss: 0.3666 - val_accuracy: 0.8246 - val_loss: 0.4343 - learning_rate: 0.0048\n",
            "Epoch 12/39\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8476 - loss: 0.3383\n",
            "Epoch 12: val_loss improved from 0.35932 to 0.33812, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8489 - loss: 0.3374 - val_accuracy: 0.8603 - val_loss: 0.3381 - learning_rate: 7.9526e-04\n",
            "Epoch 13/39\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8638 - loss: 0.3212\n",
            "Epoch 13: val_loss did not improve from 0.33812\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8638 - loss: 0.3211 - val_accuracy: 0.8545 - val_loss: 0.3523 - learning_rate: 7.9526e-04\n",
            "Epoch 14/39\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8781 - loss: 0.3066\n",
            "Epoch 14: val_loss did not improve from 0.33812\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8774 - loss: 0.3072 - val_accuracy: 0.8570 - val_loss: 0.3406 - learning_rate: 7.9526e-04\n",
            "Epoch 15/39\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8686 - loss: 0.3063\n",
            "Epoch 15: val_loss did not improve from 0.33812\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8688 - loss: 0.3064 - val_accuracy: 0.8545 - val_loss: 0.3443 - learning_rate: 7.9526e-04\n",
            "Epoch 16/39\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8626 - loss: 0.3067\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00013070740805863076.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.33812\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8630 - loss: 0.3067 - val_accuracy: 0.8487 - val_loss: 0.3460 - learning_rate: 7.9526e-04\n",
            "Epoch 17/39\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8818 - loss: 0.2947\n",
            "Epoch 17: val_loss did not improve from 0.33812\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8824 - loss: 0.2946 - val_accuracy: 0.8628 - val_loss: 0.3433 - learning_rate: 1.3071e-04\n",
            "Epoch 18/39\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8722 - loss: 0.2956\n",
            "Epoch 18: val_loss did not improve from 0.33812\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8726 - loss: 0.2955 - val_accuracy: 0.8620 - val_loss: 0.3436 - learning_rate: 1.3071e-04\n",
            "Epoch 19/39\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8833 - loss: 0.2894\n",
            "Epoch 19: val_loss did not improve from 0.33812\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8834 - loss: 0.2895 - val_accuracy: 0.8579 - val_loss: 0.3478 - learning_rate: 1.3071e-04\n",
            "Epoch 20/39\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8813 - loss: 0.2943\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 2.1482715457672408e-05.\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.33812\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8815 - loss: 0.2942 - val_accuracy: 0.8495 - val_loss: 0.3541 - learning_rate: 1.3071e-04\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:57:52,831] Trial 15 finished with value: -0.33812251687049866 and parameters: {'epochs': 39, 'batch_size': 64, 'learning_rate': 0.004838628720655643, 'stop_patience': 8, 'reduce_lr_factor': 0.16435728493802165, 'reduce_lr_patience': 4}. Best is trial 11 with value: -0.33189353346824646.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5696 - loss: 0.6893\n",
            "Epoch 1: val_loss improved from inf to 0.52116, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5723 - loss: 0.6872 - val_accuracy: 0.7415 - val_loss: 0.5212 - learning_rate: 0.0070\n",
            "Epoch 2/30\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7131 - loss: 0.5628\n",
            "Epoch 2: val_loss did not improve from 0.52116\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7125 - loss: 0.5637 - val_accuracy: 0.7032 - val_loss: 0.6888 - learning_rate: 0.0070\n",
            "Epoch 3/30\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7365 - loss: 0.4961\n",
            "Epoch 3: val_loss did not improve from 0.52116\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7375 - loss: 0.4954 - val_accuracy: 0.7814 - val_loss: 0.5386 - learning_rate: 0.0070\n",
            "Epoch 4/30\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7667 - loss: 0.4663\n",
            "Epoch 4: val_loss did not improve from 0.52116\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7655 - loss: 0.4677 - val_accuracy: 0.6891 - val_loss: 0.7336 - learning_rate: 0.0070\n",
            "Epoch 5/30\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7613 - loss: 0.4717\n",
            "Epoch 5: val_loss improved from 0.52116 to 0.37472, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7615 - loss: 0.4718 - val_accuracy: 0.8570 - val_loss: 0.3747 - learning_rate: 0.0070\n",
            "Epoch 6/30\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7769 - loss: 0.4332\n",
            "Epoch 6: val_loss did not improve from 0.37472\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7774 - loss: 0.4328 - val_accuracy: 0.8279 - val_loss: 0.3889 - learning_rate: 0.0070\n",
            "Epoch 7/30\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7755 - loss: 0.4258\n",
            "Epoch 7: val_loss did not improve from 0.37472\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7761 - loss: 0.4255 - val_accuracy: 0.7465 - val_loss: 0.5369 - learning_rate: 0.0070\n",
            "Epoch 8/30\n",
            "\u001b[1m63/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.4258\n",
            "Epoch 8: val_loss did not improve from 0.37472\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7762 - loss: 0.4252 - val_accuracy: 0.8055 - val_loss: 0.4903 - learning_rate: 0.0070\n",
            "Epoch 9/30\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7802 - loss: 0.4183\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0019121284430347928.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.37472\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7798 - loss: 0.4191 - val_accuracy: 0.8221 - val_loss: 0.3784 - learning_rate: 0.0070\n",
            "Epoch 10/30\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7905 - loss: 0.3891\n",
            "Epoch 10: val_loss did not improve from 0.37472\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7915 - loss: 0.3887 - val_accuracy: 0.8105 - val_loss: 0.4053 - learning_rate: 0.0019\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:58:02,173] Trial 16 finished with value: -0.37471622228622437 and parameters: {'epochs': 30, 'batch_size': 64, 'learning_rate': 0.007010482259692615, 'stop_patience': 5, 'reduce_lr_factor': 0.272752768554025, 'reduce_lr_patience': 4}. Best is trial 11 with value: -0.33189353346824646.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5743 - loss: 0.6950\n",
            "Epoch 1: val_loss improved from inf to 0.87675, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5767 - loss: 0.6930 - val_accuracy: 0.5943 - val_loss: 0.8768 - learning_rate: 0.0082\n",
            "Epoch 2/20\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6848 - loss: 0.5679\n",
            "Epoch 2: val_loss improved from 0.87675 to 0.40691, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6855 - loss: 0.5672 - val_accuracy: 0.8204 - val_loss: 0.4069 - learning_rate: 0.0082\n",
            "Epoch 3/20\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7220 - loss: 0.5163\n",
            "Epoch 3: val_loss did not improve from 0.40691\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7226 - loss: 0.5159 - val_accuracy: 0.7490 - val_loss: 0.6218 - learning_rate: 0.0082\n",
            "Epoch 4/20\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7399 - loss: 0.4828\n",
            "Epoch 4: val_loss improved from 0.40691 to 0.39698, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7395 - loss: 0.4836 - val_accuracy: 0.8238 - val_loss: 0.3970 - learning_rate: 0.0082\n",
            "Epoch 5/20\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7560 - loss: 0.4756\n",
            "Epoch 5: val_loss did not improve from 0.39698\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7554 - loss: 0.4762 - val_accuracy: 0.8562 - val_loss: 0.4440 - learning_rate: 0.0082\n",
            "Epoch 6/20\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7568 - loss: 0.4516\n",
            "Epoch 6: val_loss did not improve from 0.39698\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7566 - loss: 0.4520 - val_accuracy: 0.8288 - val_loss: 0.4098 - learning_rate: 0.0082\n",
            "Epoch 7/20\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7682 - loss: 0.4532\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0014216373669425492.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.39698\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7680 - loss: 0.4533 - val_accuracy: 0.7681 - val_loss: 0.4541 - learning_rate: 0.0082\n",
            "Epoch 8/20\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7898 - loss: 0.4120\n",
            "Epoch 8: val_loss improved from 0.39698 to 0.34462, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7903 - loss: 0.4116 - val_accuracy: 0.8446 - val_loss: 0.3446 - learning_rate: 0.0014\n",
            "Epoch 9/20\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8154 - loss: 0.3845\n",
            "Epoch 9: val_loss improved from 0.34462 to 0.33816, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8160 - loss: 0.3845 - val_accuracy: 0.8554 - val_loss: 0.3382 - learning_rate: 0.0014\n",
            "Epoch 10/20\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8200 - loss: 0.3780\n",
            "Epoch 10: val_loss did not improve from 0.33816\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8201 - loss: 0.3780 - val_accuracy: 0.8213 - val_loss: 0.3610 - learning_rate: 0.0014\n",
            "Epoch 11/20\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8340 - loss: 0.3693\n",
            "Epoch 11: val_loss did not improve from 0.33816\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8342 - loss: 0.3694 - val_accuracy: 0.8379 - val_loss: 0.3935 - learning_rate: 0.0014\n",
            "Epoch 12/20\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8440 - loss: 0.3614\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002461408984310968.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.33816\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8440 - loss: 0.3613 - val_accuracy: 0.8446 - val_loss: 0.3506 - learning_rate: 0.0014\n",
            "Epoch 13/20\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8505 - loss: 0.3515\n",
            "Epoch 13: val_loss did not improve from 0.33816\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8517 - loss: 0.3512 - val_accuracy: 0.8554 - val_loss: 0.3698 - learning_rate: 2.4614e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8569 - loss: 0.3410\n",
            "Epoch 14: val_loss did not improve from 0.33816\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8571 - loss: 0.3417 - val_accuracy: 0.8446 - val_loss: 0.3881 - learning_rate: 2.4614e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 0.3491\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.261659420751053e-05.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.33816\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8573 - loss: 0.3492 - val_accuracy: 0.8570 - val_loss: 0.3649 - learning_rate: 2.4614e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8672 - loss: 0.3425\n",
            "Epoch 16: val_loss did not improve from 0.33816\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8671 - loss: 0.3426 - val_accuracy: 0.8579 - val_loss: 0.3541 - learning_rate: 4.2617e-05\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:58:14,116] Trial 17 finished with value: -0.338155061006546 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.008210959322829123, 'stop_patience': 7, 'reduce_lr_factor': 0.17313901847653534, 'reduce_lr_patience': 3}. Best is trial 11 with value: -0.33189353346824646.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/42\n",
            "\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5912 - loss: 0.6722\n",
            "Epoch 1: val_loss improved from inf to 0.80222, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5934 - loss: 0.6701 - val_accuracy: 0.6351 - val_loss: 0.8022 - learning_rate: 0.0042\n",
            "Epoch 2/42\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7153 - loss: 0.5485\n",
            "Epoch 2: val_loss did not improve from 0.80222\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7154 - loss: 0.5483 - val_accuracy: 0.5902 - val_loss: 1.0807 - learning_rate: 0.0042\n",
            "Epoch 3/42\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7356 - loss: 0.5037\n",
            "Epoch 3: val_loss improved from 0.80222 to 0.54881, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7357 - loss: 0.5036 - val_accuracy: 0.6791 - val_loss: 0.5488 - learning_rate: 0.0042\n",
            "Epoch 4/42\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7429 - loss: 0.4754\n",
            "Epoch 4: val_loss did not improve from 0.54881\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7434 - loss: 0.4750 - val_accuracy: 0.6559 - val_loss: 0.9567 - learning_rate: 0.0042\n",
            "Epoch 5/42\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7749 - loss: 0.4579\n",
            "Epoch 5: val_loss did not improve from 0.54881\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7749 - loss: 0.4577 - val_accuracy: 0.8138 - val_loss: 0.5810 - learning_rate: 0.0042\n",
            "Epoch 6/42\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7845 - loss: 0.4243\n",
            "Epoch 6: val_loss improved from 0.54881 to 0.43301, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7848 - loss: 0.4240 - val_accuracy: 0.8504 - val_loss: 0.4330 - learning_rate: 0.0042\n",
            "Epoch 7/42\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7936 - loss: 0.4228\n",
            "Epoch 7: val_loss improved from 0.43301 to 0.37011, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.4228 - val_accuracy: 0.8520 - val_loss: 0.3701 - learning_rate: 0.0042\n",
            "Epoch 8/42\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8012 - loss: 0.3952\n",
            "Epoch 8: val_loss did not improve from 0.37011\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8013 - loss: 0.3953 - val_accuracy: 0.8204 - val_loss: 0.4144 - learning_rate: 0.0042\n",
            "Epoch 9/42\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8126 - loss: 0.3941\n",
            "Epoch 9: val_loss did not improve from 0.37011\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8126 - loss: 0.3943 - val_accuracy: 0.7772 - val_loss: 0.5855 - learning_rate: 0.0042\n",
            "Epoch 10/42\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8191 - loss: 0.3961\n",
            "Epoch 10: val_loss did not improve from 0.37011\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8190 - loss: 0.3960 - val_accuracy: 0.8412 - val_loss: 0.4193 - learning_rate: 0.0042\n",
            "Epoch 11/42\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8204 - loss: 0.3776\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0004332898586349811.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.37011\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8204 - loss: 0.3777 - val_accuracy: 0.8321 - val_loss: 0.3978 - learning_rate: 0.0042\n",
            "Epoch 12/42\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8602 - loss: 0.3330\n",
            "Epoch 12: val_loss improved from 0.37011 to 0.35191, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8603 - loss: 0.3330 - val_accuracy: 0.8545 - val_loss: 0.3519 - learning_rate: 4.3329e-04\n",
            "Epoch 13/42\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8693 - loss: 0.3160\n",
            "Epoch 13: val_loss did not improve from 0.35191\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8693 - loss: 0.3159 - val_accuracy: 0.8454 - val_loss: 0.3563 - learning_rate: 4.3329e-04\n",
            "Epoch 14/42\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8770 - loss: 0.3002\n",
            "Epoch 14: val_loss improved from 0.35191 to 0.34031, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8770 - loss: 0.3002 - val_accuracy: 0.8512 - val_loss: 0.3403 - learning_rate: 4.3329e-04\n",
            "Epoch 15/42\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8775 - loss: 0.3010\n",
            "Epoch 15: val_loss did not improve from 0.34031\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8775 - loss: 0.3010 - val_accuracy: 0.8504 - val_loss: 0.3436 - learning_rate: 4.3329e-04\n",
            "Epoch 16/42\n",
            "\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8781 - loss: 0.2939\n",
            "Epoch 16: val_loss did not improve from 0.34031\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8780 - loss: 0.2941 - val_accuracy: 0.8470 - val_loss: 0.3560 - learning_rate: 4.3329e-04\n",
            "Epoch 17/42\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8725 - loss: 0.2967\n",
            "Epoch 17: val_loss did not improve from 0.34031\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8726 - loss: 0.2967 - val_accuracy: 0.8587 - val_loss: 0.3487 - learning_rate: 4.3329e-04\n",
            "Epoch 18/42\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8802 - loss: 0.2931\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.5040008875872194e-05.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.34031\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8802 - loss: 0.2931 - val_accuracy: 0.8404 - val_loss: 0.3566 - learning_rate: 4.3329e-04\n",
            "Epoch 19/42\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8854 - loss: 0.2857\n",
            "Epoch 19: val_loss did not improve from 0.34031\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8854 - loss: 0.2857 - val_accuracy: 0.8387 - val_loss: 0.3545 - learning_rate: 4.5040e-05\n",
            "Epoch 20/42\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8767 - loss: 0.2889\n",
            "Epoch 20: val_loss did not improve from 0.34031\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8770 - loss: 0.2887 - val_accuracy: 0.8487 - val_loss: 0.3474 - learning_rate: 4.5040e-05\n",
            "Epoch 21/42\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8827 - loss: 0.2805\n",
            "Epoch 21: val_loss did not improve from 0.34031\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8827 - loss: 0.2805 - val_accuracy: 0.8479 - val_loss: 0.3569 - learning_rate: 4.5040e-05\n",
            "Epoch 22/42\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8887 - loss: 0.2835\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.681859783419596e-06.\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.34031\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8886 - loss: 0.2834 - val_accuracy: 0.8462 - val_loss: 0.3554 - learning_rate: 4.5040e-05\n",
            "Epoch 23/42\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8870 - loss: 0.2824\n",
            "Epoch 23: val_loss did not improve from 0.34031\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8871 - loss: 0.2824 - val_accuracy: 0.8454 - val_loss: 0.3537 - learning_rate: 4.6819e-06\n",
            "Epoch 23: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:58:54,691] Trial 18 finished with value: -0.34030914306640625 and parameters: {'epochs': 42, 'batch_size': 16, 'learning_rate': 0.00416829627581161, 'stop_patience': 9, 'reduce_lr_factor': 0.1039489120814936, 'reduce_lr_patience': 4}. Best is trial 11 with value: -0.33189353346824646.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5647 - loss: 0.6930\n",
            "Epoch 1: val_loss improved from inf to 0.49129, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5686 - loss: 0.6895 - val_accuracy: 0.7706 - val_loss: 0.4913 - learning_rate: 0.0060\n",
            "Epoch 2/32\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6878 - loss: 0.5629\n",
            "Epoch 2: val_loss improved from 0.49129 to 0.45718, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6888 - loss: 0.5620 - val_accuracy: 0.8130 - val_loss: 0.4572 - learning_rate: 0.0060\n",
            "Epoch 3/32\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7408 - loss: 0.5056\n",
            "Epoch 3: val_loss improved from 0.45718 to 0.39966, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7413 - loss: 0.5052 - val_accuracy: 0.8271 - val_loss: 0.3997 - learning_rate: 0.0060\n",
            "Epoch 4/32\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7625 - loss: 0.4684\n",
            "Epoch 4: val_loss did not improve from 0.39966\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7627 - loss: 0.4684 - val_accuracy: 0.7539 - val_loss: 0.4958 - learning_rate: 0.0060\n",
            "Epoch 5/32\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7894 - loss: 0.4351\n",
            "Epoch 5: val_loss did not improve from 0.39966\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7888 - loss: 0.4353 - val_accuracy: 0.8105 - val_loss: 0.4148 - learning_rate: 0.0060\n",
            "Epoch 6/32\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7853 - loss: 0.4279\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00160290197961472.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.39966\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7854 - loss: 0.4278 - val_accuracy: 0.8238 - val_loss: 0.4048 - learning_rate: 0.0060\n",
            "Epoch 7/32\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8134 - loss: 0.3861\n",
            "Epoch 7: val_loss improved from 0.39966 to 0.37626, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8139 - loss: 0.3857 - val_accuracy: 0.8238 - val_loss: 0.3763 - learning_rate: 0.0016\n",
            "Epoch 8/32\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8459 - loss: 0.3604\n",
            "Epoch 8: val_loss did not improve from 0.37626\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8458 - loss: 0.3602 - val_accuracy: 0.8063 - val_loss: 0.4234 - learning_rate: 0.0016\n",
            "Epoch 9/32\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8436 - loss: 0.3521\n",
            "Epoch 9: val_loss did not improve from 0.37626\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8437 - loss: 0.3522 - val_accuracy: 0.8204 - val_loss: 0.3992 - learning_rate: 0.0016\n",
            "Epoch 10/32\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.3376\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0004304191391533742.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.37626\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8586 - loss: 0.3375 - val_accuracy: 0.8146 - val_loss: 0.3892 - learning_rate: 0.0016\n",
            "Epoch 11/32\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8646 - loss: 0.3295\n",
            "Epoch 11: val_loss improved from 0.37626 to 0.36762, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8646 - loss: 0.3294 - val_accuracy: 0.8396 - val_loss: 0.3676 - learning_rate: 4.3042e-04\n",
            "Epoch 12/32\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8693 - loss: 0.3218\n",
            "Epoch 12: val_loss did not improve from 0.36762\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8696 - loss: 0.3217 - val_accuracy: 0.8371 - val_loss: 0.3677 - learning_rate: 4.3042e-04\n",
            "Epoch 13/32\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8765 - loss: 0.3143\n",
            "Epoch 13: val_loss did not improve from 0.36762\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8762 - loss: 0.3145 - val_accuracy: 0.8304 - val_loss: 0.3893 - learning_rate: 4.3042e-04\n",
            "Epoch 14/32\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8726 - loss: 0.3203\n",
            "Epoch 14: val_loss improved from 0.36762 to 0.36255, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8730 - loss: 0.3196 - val_accuracy: 0.8437 - val_loss: 0.3625 - learning_rate: 4.3042e-04\n",
            "Epoch 15/32\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8718 - loss: 0.3113\n",
            "Epoch 15: val_loss improved from 0.36255 to 0.34921, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8718 - loss: 0.3114 - val_accuracy: 0.8595 - val_loss: 0.3492 - learning_rate: 4.3042e-04\n",
            "Epoch 16/32\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8726 - loss: 0.3148\n",
            "Epoch 16: val_loss did not improve from 0.34921\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8732 - loss: 0.3146 - val_accuracy: 0.8529 - val_loss: 0.3497 - learning_rate: 4.3042e-04\n",
            "Epoch 17/32\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8754 - loss: 0.3092\n",
            "Epoch 17: val_loss did not improve from 0.34921\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8750 - loss: 0.3092 - val_accuracy: 0.8387 - val_loss: 0.3933 - learning_rate: 4.3042e-04\n",
            "Epoch 18/32\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8794 - loss: 0.3071\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00011557826976646143.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.34921\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8793 - loss: 0.3071 - val_accuracy: 0.8454 - val_loss: 0.3575 - learning_rate: 4.3042e-04\n",
            "Epoch 19/32\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8855 - loss: 0.3046\n",
            "Epoch 19: val_loss did not improve from 0.34921\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8850 - loss: 0.3047 - val_accuracy: 0.8479 - val_loss: 0.3603 - learning_rate: 1.1558e-04\n",
            "Epoch 20/32\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8733 - loss: 0.3030\n",
            "Epoch 20: val_loss did not improve from 0.34921\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8742 - loss: 0.3031 - val_accuracy: 0.8545 - val_loss: 0.3540 - learning_rate: 1.1558e-04\n",
            "Epoch 21/32\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8759 - loss: 0.2997\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 3.1035646107011226e-05.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.34921\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8766 - loss: 0.2999 - val_accuracy: 0.8470 - val_loss: 0.3625 - learning_rate: 1.1558e-04\n",
            "Epoch 22/32\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8766 - loss: 0.2979\n",
            "Epoch 22: val_loss did not improve from 0.34921\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8773 - loss: 0.2980 - val_accuracy: 0.8554 - val_loss: 0.3505 - learning_rate: 3.1036e-05\n",
            "Epoch 23/32\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8802 - loss: 0.3028\n",
            "Epoch 23: val_loss improved from 0.34921 to 0.34625, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8803 - loss: 0.3029 - val_accuracy: 0.8554 - val_loss: 0.3462 - learning_rate: 3.1036e-05\n",
            "Epoch 24/32\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8749 - loss: 0.3078\n",
            "Epoch 24: val_loss did not improve from 0.34625\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8752 - loss: 0.3075 - val_accuracy: 0.8562 - val_loss: 0.3465 - learning_rate: 3.1036e-05\n",
            "Epoch 25/32\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8765 - loss: 0.3002\n",
            "Epoch 25: val_loss did not improve from 0.34625\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8768 - loss: 0.3003 - val_accuracy: 0.8562 - val_loss: 0.3472 - learning_rate: 3.1036e-05\n",
            "Epoch 26/32\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8779 - loss: 0.3007\n",
            "Epoch 26: val_loss improved from 0.34625 to 0.34368, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8780 - loss: 0.3009 - val_accuracy: 0.8579 - val_loss: 0.3437 - learning_rate: 3.1036e-05\n",
            "Epoch 27/32\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8817 - loss: 0.3015\n",
            "Epoch 27: val_loss did not improve from 0.34368\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8817 - loss: 0.3013 - val_accuracy: 0.8579 - val_loss: 0.3499 - learning_rate: 3.1036e-05\n",
            "Epoch 28/32\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8782 - loss: 0.2950\n",
            "Epoch 28: val_loss did not improve from 0.34368\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8782 - loss: 0.2950 - val_accuracy: 0.8579 - val_loss: 0.3476 - learning_rate: 3.1036e-05\n",
            "Epoch 29/32\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8758 - loss: 0.2977\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 8.33384431163398e-06.\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.34368\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8761 - loss: 0.2977 - val_accuracy: 0.8570 - val_loss: 0.3499 - learning_rate: 3.1036e-05\n",
            "Epoch 30/32\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8761 - loss: 0.3022\n",
            "Epoch 30: val_loss did not improve from 0.34368\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8762 - loss: 0.3022 - val_accuracy: 0.8579 - val_loss: 0.3485 - learning_rate: 8.3338e-06\n",
            "Epoch 31/32\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8758 - loss: 0.2984\n",
            "Epoch 31: val_loss did not improve from 0.34368\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8763 - loss: 0.2982 - val_accuracy: 0.8579 - val_loss: 0.3478 - learning_rate: 8.3338e-06\n",
            "Epoch 32/32\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8775 - loss: 0.3029\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 2.237845039878257e-06.\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.34368\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8777 - loss: 0.3026 - val_accuracy: 0.8579 - val_loss: 0.3474 - learning_rate: 8.3338e-06\n",
            "Restoring model weights from the end of the best epoch: 26.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:59:17,327] Trial 19 finished with value: -0.34368181228637695 and parameters: {'epochs': 32, 'batch_size': 64, 'learning_rate': 0.005969285553730797, 'stop_patience': 9, 'reduce_lr_factor': 0.2685249314681749, 'reduce_lr_patience': 3}. Best is trial 11 with value: -0.33189353346824646.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/37\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5632 - loss: 0.6925\n",
            "Epoch 1: val_loss improved from inf to 0.64067, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5681 - loss: 0.6886 - val_accuracy: 0.6833 - val_loss: 0.6407 - learning_rate: 0.0098\n",
            "Epoch 2/37\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7081 - loss: 0.5369\n",
            "Epoch 2: val_loss did not improve from 0.64067\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7102 - loss: 0.5345 - val_accuracy: 0.6367 - val_loss: 0.7636 - learning_rate: 0.0098\n",
            "Epoch 3/37\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7465 - loss: 0.4844\n",
            "Epoch 3: val_loss improved from 0.64067 to 0.35862, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7458 - loss: 0.4855 - val_accuracy: 0.8470 - val_loss: 0.3586 - learning_rate: 0.0098\n",
            "Epoch 4/37\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7482 - loss: 0.4880\n",
            "Epoch 4: val_loss did not improve from 0.35862\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7481 - loss: 0.4880 - val_accuracy: 0.8495 - val_loss: 0.3694 - learning_rate: 0.0098\n",
            "Epoch 5/37\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7708 - loss: 0.4458\n",
            "Epoch 5: val_loss did not improve from 0.35862\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7703 - loss: 0.4462 - val_accuracy: 0.8520 - val_loss: 0.3747 - learning_rate: 0.0098\n",
            "Epoch 6/37\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7756 - loss: 0.4347\n",
            "Epoch 6: val_loss did not improve from 0.35862\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7757 - loss: 0.4346 - val_accuracy: 0.8404 - val_loss: 0.3714 - learning_rate: 0.0098\n",
            "Epoch 7/37\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7917 - loss: 0.4245\n",
            "Epoch 7: val_loss did not improve from 0.35862\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7925 - loss: 0.4234 - val_accuracy: 0.8446 - val_loss: 0.3940 - learning_rate: 0.0098\n",
            "Epoch 8/37\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7930 - loss: 0.4218\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0014167233564566252.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.35862\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7930 - loss: 0.4219 - val_accuracy: 0.8304 - val_loss: 0.4874 - learning_rate: 0.0098\n",
            "Epoch 9/37\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8174 - loss: 0.3720\n",
            "Epoch 9: val_loss improved from 0.35862 to 0.34191, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8200 - loss: 0.3695 - val_accuracy: 0.8579 - val_loss: 0.3419 - learning_rate: 0.0014\n",
            "Epoch 10/37\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8534 - loss: 0.3371\n",
            "Epoch 10: val_loss did not improve from 0.34191\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8536 - loss: 0.3364 - val_accuracy: 0.8554 - val_loss: 0.3613 - learning_rate: 0.0014\n",
            "Epoch 11/37\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8604 - loss: 0.3295\n",
            "Epoch 11: val_loss did not improve from 0.34191\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8599 - loss: 0.3292 - val_accuracy: 0.8487 - val_loss: 0.3526 - learning_rate: 0.0014\n",
            "Epoch 12/37\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8591 - loss: 0.3150\n",
            "Epoch 12: val_loss did not improve from 0.34191\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8590 - loss: 0.3151 - val_accuracy: 0.8545 - val_loss: 0.3465 - learning_rate: 0.0014\n",
            "Epoch 13/37\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8704 - loss: 0.3092\n",
            "Epoch 13: val_loss improved from 0.34191 to 0.33789, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8703 - loss: 0.3090 - val_accuracy: 0.8554 - val_loss: 0.3379 - learning_rate: 0.0014\n",
            "Epoch 14/37\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8685 - loss: 0.3097\n",
            "Epoch 14: val_loss did not improve from 0.33789\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8684 - loss: 0.3097 - val_accuracy: 0.8554 - val_loss: 0.3617 - learning_rate: 0.0014\n",
            "Epoch 15/37\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8663 - loss: 0.3090\n",
            "Epoch 15: val_loss did not improve from 0.33789\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8665 - loss: 0.3092 - val_accuracy: 0.8562 - val_loss: 0.3510 - learning_rate: 0.0014\n",
            "Epoch 16/37\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8779 - loss: 0.2981\n",
            "Epoch 16: val_loss did not improve from 0.33789\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8773 - loss: 0.2984 - val_accuracy: 0.8354 - val_loss: 0.3722 - learning_rate: 0.0014\n",
            "Epoch 17/37\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8637 - loss: 0.3029\n",
            "Epoch 17: val_loss did not improve from 0.33789\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8639 - loss: 0.3029 - val_accuracy: 0.8504 - val_loss: 0.3498 - learning_rate: 0.0014\n",
            "Epoch 18/37\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8663 - loss: 0.2978\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00020418871615646684.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.33789\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.2974 - val_accuracy: 0.8263 - val_loss: 0.3845 - learning_rate: 0.0014\n",
            "Epoch 19/37\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8734 - loss: 0.2887\n",
            "Epoch 19: val_loss did not improve from 0.33789\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8739 - loss: 0.2888 - val_accuracy: 0.8204 - val_loss: 0.4139 - learning_rate: 2.0419e-04\n",
            "Epoch 20/37\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8765 - loss: 0.2846\n",
            "Epoch 20: val_loss did not improve from 0.33789\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8769 - loss: 0.2849 - val_accuracy: 0.8288 - val_loss: 0.3905 - learning_rate: 2.0419e-04\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:59:32,391] Trial 20 finished with value: -0.33789098262786865 and parameters: {'epochs': 37, 'batch_size': 64, 'learning_rate': 0.009829657578635615, 'stop_patience': 7, 'reduce_lr_factor': 0.14412744356254953, 'reduce_lr_patience': 5}. Best is trial 11 with value: -0.33189353346824646.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/33\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5472 - loss: 0.6977\n",
            "Epoch 1: val_loss improved from inf to 0.44909, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5523 - loss: 0.6931 - val_accuracy: 0.8105 - val_loss: 0.4491 - learning_rate: 0.0075\n",
            "Epoch 2/33\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6881 - loss: 0.5779\n",
            "Epoch 2: val_loss did not improve from 0.44909\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6881 - loss: 0.5779 - val_accuracy: 0.6625 - val_loss: 0.7156 - learning_rate: 0.0075\n",
            "Epoch 3/33\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7332 - loss: 0.5100\n",
            "Epoch 3: val_loss did not improve from 0.44909\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7331 - loss: 0.5099 - val_accuracy: 0.7548 - val_loss: 0.5102 - learning_rate: 0.0075\n",
            "Epoch 4/33\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7548 - loss: 0.4677\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0015596992659087094.\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.44909\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7543 - loss: 0.4682 - val_accuracy: 0.6683 - val_loss: 0.6671 - learning_rate: 0.0075\n",
            "Epoch 5/33\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7606 - loss: 0.4412\n",
            "Epoch 5: val_loss improved from 0.44909 to 0.36431, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7609 - loss: 0.4409 - val_accuracy: 0.8479 - val_loss: 0.3643 - learning_rate: 0.0016\n",
            "Epoch 6/33\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8125 - loss: 0.3873\n",
            "Epoch 6: val_loss did not improve from 0.36431\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8130 - loss: 0.3872 - val_accuracy: 0.8321 - val_loss: 0.3782 - learning_rate: 0.0016\n",
            "Epoch 7/33\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 0.3740\n",
            "Epoch 7: val_loss did not improve from 0.36431\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8253 - loss: 0.3738 - val_accuracy: 0.8462 - val_loss: 0.3987 - learning_rate: 0.0016\n",
            "Epoch 8/33\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8319 - loss: 0.3694\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00032249242553162693.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.36431\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8321 - loss: 0.3689 - val_accuracy: 0.8470 - val_loss: 0.3647 - learning_rate: 0.0016\n",
            "Epoch 9/33\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8518 - loss: 0.3430\n",
            "Epoch 9: val_loss did not improve from 0.36431\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8526 - loss: 0.3429 - val_accuracy: 0.8537 - val_loss: 0.3806 - learning_rate: 3.2249e-04\n",
            "Epoch 10/33\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8603 - loss: 0.3376\n",
            "Epoch 10: val_loss did not improve from 0.36431\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8608 - loss: 0.3370 - val_accuracy: 0.8495 - val_loss: 0.3747 - learning_rate: 3.2249e-04\n",
            "Epoch 11/33\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8642 - loss: 0.3328\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 6.668039207939008e-05.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.36431\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8641 - loss: 0.3328 - val_accuracy: 0.8512 - val_loss: 0.3859 - learning_rate: 3.2249e-04\n",
            "Epoch 12/33\n",
            "\u001b[1m63/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8616 - loss: 0.3317\n",
            "Epoch 12: val_loss did not improve from 0.36431\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8621 - loss: 0.3310 - val_accuracy: 0.8504 - val_loss: 0.3661 - learning_rate: 6.6680e-05\n",
            "Epoch 13/33\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.3228\n",
            "Epoch 13: val_loss did not improve from 0.36431\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8699 - loss: 0.3233 - val_accuracy: 0.8520 - val_loss: 0.3655 - learning_rate: 6.6680e-05\n",
            "Epoch 14/33\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8648 - loss: 0.3245\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.3787222072072369e-05.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.36431\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8648 - loss: 0.3247 - val_accuracy: 0.8520 - val_loss: 0.3646 - learning_rate: 6.6680e-05\n",
            "Epoch 15/33\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8650 - loss: 0.3214\n",
            "Epoch 15: val_loss did not improve from 0.36431\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8662 - loss: 0.3216 - val_accuracy: 0.8520 - val_loss: 0.3650 - learning_rate: 1.3787e-05\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:59:44,922] Trial 21 finished with value: -0.3643134832382202 and parameters: {'epochs': 33, 'batch_size': 64, 'learning_rate': 0.0075433145010619, 'stop_patience': 10, 'reduce_lr_factor': 0.20676576876968245, 'reduce_lr_patience': 3}. Best is trial 11 with value: -0.33189353346824646.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/28\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5595 - loss: 0.6911\n",
            "Epoch 1: val_loss improved from inf to 0.45614, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.5645 - loss: 0.6872 - val_accuracy: 0.8113 - val_loss: 0.4561 - learning_rate: 0.0068\n",
            "Epoch 2/28\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7050 - loss: 0.5659\n",
            "Epoch 2: val_loss improved from 0.45614 to 0.45246, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7046 - loss: 0.5661 - val_accuracy: 0.7880 - val_loss: 0.4525 - learning_rate: 0.0068\n",
            "Epoch 3/28\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7349 - loss: 0.5023\n",
            "Epoch 3: val_loss did not improve from 0.45246\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7349 - loss: 0.5016 - val_accuracy: 0.7506 - val_loss: 0.5759 - learning_rate: 0.0068\n",
            "Epoch 4/28\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7679 - loss: 0.4609\n",
            "Epoch 4: val_loss did not improve from 0.45246\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7675 - loss: 0.4612 - val_accuracy: 0.7074 - val_loss: 0.6682 - learning_rate: 0.0068\n",
            "Epoch 5/28\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7738 - loss: 0.4393\n",
            "Epoch 5: val_loss improved from 0.45246 to 0.36471, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7741 - loss: 0.4400 - val_accuracy: 0.8570 - val_loss: 0.3647 - learning_rate: 0.0068\n",
            "Epoch 6/28\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7735 - loss: 0.4409\n",
            "Epoch 6: val_loss improved from 0.36471 to 0.34152, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7738 - loss: 0.4401 - val_accuracy: 0.8512 - val_loss: 0.3415 - learning_rate: 0.0068\n",
            "Epoch 7/28\n",
            "\u001b[1m63/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7878 - loss: 0.4223\n",
            "Epoch 7: val_loss did not improve from 0.34152\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7885 - loss: 0.4224 - val_accuracy: 0.8495 - val_loss: 0.3749 - learning_rate: 0.0068\n",
            "Epoch 8/28\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7887 - loss: 0.4227\n",
            "Epoch 8: val_loss did not improve from 0.34152\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7891 - loss: 0.4216 - val_accuracy: 0.8346 - val_loss: 0.3843 - learning_rate: 0.0068\n",
            "Epoch 9/28\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8086 - loss: 0.3870\n",
            "Epoch 9: val_loss did not improve from 0.34152\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8091 - loss: 0.3872 - val_accuracy: 0.8088 - val_loss: 0.4307 - learning_rate: 0.0068\n",
            "Epoch 10/28\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8045 - loss: 0.3861\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.001784471536493775.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.34152\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8050 - loss: 0.3861 - val_accuracy: 0.7140 - val_loss: 0.4972 - learning_rate: 0.0068\n",
            "Epoch 11/28\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8454 - loss: 0.3433\n",
            "Epoch 11: val_loss did not improve from 0.34152\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8459 - loss: 0.3425 - val_accuracy: 0.8279 - val_loss: 0.3659 - learning_rate: 0.0018\n",
            "Epoch 12/28\n",
            "\u001b[1m63/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8571 - loss: 0.3254\n",
            "Epoch 12: val_loss did not improve from 0.34152\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 0.3259 - val_accuracy: 0.8346 - val_loss: 0.3528 - learning_rate: 0.0018\n",
            "Epoch 13/28\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8703 - loss: 0.3090\n",
            "Epoch 13: val_loss did not improve from 0.34152\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8698 - loss: 0.3095 - val_accuracy: 0.8404 - val_loss: 0.3562 - learning_rate: 0.0018\n",
            "Epoch 14/28\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8697 - loss: 0.3123\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0004715232408301062.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.34152\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8689 - loss: 0.3131 - val_accuracy: 0.8063 - val_loss: 0.4195 - learning_rate: 0.0018\n",
            "Epoch 15/28\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8789 - loss: 0.3034\n",
            "Epoch 15: val_loss did not improve from 0.34152\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8793 - loss: 0.3025 - val_accuracy: 0.8229 - val_loss: 0.4093 - learning_rate: 4.7152e-04\n",
            "Epoch 16/28\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8758 - loss: 0.2881\n",
            "Epoch 16: val_loss did not improve from 0.34152\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8769 - loss: 0.2881 - val_accuracy: 0.8404 - val_loss: 0.3942 - learning_rate: 4.7152e-04\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 14:59:57,542] Trial 22 finished with value: -0.341522753238678 and parameters: {'epochs': 28, 'batch_size': 64, 'learning_rate': 0.006753301817444361, 'stop_patience': 10, 'reduce_lr_factor': 0.2642369039866849, 'reduce_lr_patience': 4}. Best is trial 11 with value: -0.33189353346824646.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/42\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5602 - loss: 0.6898\n",
            "Epoch 1: val_loss improved from inf to 0.45504, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5624 - loss: 0.6883 - val_accuracy: 0.8022 - val_loss: 0.4550 - learning_rate: 0.0082\n",
            "Epoch 2/42\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7049 - loss: 0.5478\n",
            "Epoch 2: val_loss did not improve from 0.45504\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7053 - loss: 0.5473 - val_accuracy: 0.7672 - val_loss: 0.4627 - learning_rate: 0.0082\n",
            "Epoch 3/42\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7496 - loss: 0.4870\n",
            "Epoch 3: val_loss did not improve from 0.45504\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7496 - loss: 0.4870 - val_accuracy: 0.6958 - val_loss: 0.8007 - learning_rate: 0.0082\n",
            "Epoch 4/42\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7259 - loss: 0.4745\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.001602854796891563.\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.45504\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7267 - loss: 0.4748 - val_accuracy: 0.7589 - val_loss: 0.5062 - learning_rate: 0.0082\n",
            "Epoch 5/42\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.4241\n",
            "Epoch 5: val_loss improved from 0.45504 to 0.40006, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7867 - loss: 0.4227 - val_accuracy: 0.8279 - val_loss: 0.4001 - learning_rate: 0.0016\n",
            "Epoch 6/42\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8177 - loss: 0.3884\n",
            "Epoch 6: val_loss improved from 0.40006 to 0.38265, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8179 - loss: 0.3883 - val_accuracy: 0.8254 - val_loss: 0.3826 - learning_rate: 0.0016\n",
            "Epoch 7/42\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8193 - loss: 0.3780\n",
            "Epoch 7: val_loss did not improve from 0.38265\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8197 - loss: 0.3776 - val_accuracy: 0.8163 - val_loss: 0.4659 - learning_rate: 0.0016\n",
            "Epoch 8/42\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8380 - loss: 0.3737\n",
            "Epoch 8: val_loss improved from 0.38265 to 0.37262, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8376 - loss: 0.3732 - val_accuracy: 0.8288 - val_loss: 0.3726 - learning_rate: 0.0016\n",
            "Epoch 9/42\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8523 - loss: 0.3520\n",
            "Epoch 9: val_loss did not improve from 0.37262\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8522 - loss: 0.3520 - val_accuracy: 0.8080 - val_loss: 0.4200 - learning_rate: 0.0016\n",
            "Epoch 10/42\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8491 - loss: 0.3488\n",
            "Epoch 10: val_loss did not improve from 0.37262\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8490 - loss: 0.3486 - val_accuracy: 0.8063 - val_loss: 0.4118 - learning_rate: 0.0016\n",
            "Epoch 11/42\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.3400\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0003131593432539.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.37262\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8524 - loss: 0.3398 - val_accuracy: 0.8213 - val_loss: 0.3900 - learning_rate: 0.0016\n",
            "Epoch 12/42\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8706 - loss: 0.3265\n",
            "Epoch 12: val_loss improved from 0.37262 to 0.33756, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8705 - loss: 0.3260 - val_accuracy: 0.8587 - val_loss: 0.3376 - learning_rate: 3.1316e-04\n",
            "Epoch 13/42\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8660 - loss: 0.3205\n",
            "Epoch 13: val_loss did not improve from 0.33756\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8670 - loss: 0.3201 - val_accuracy: 0.8520 - val_loss: 0.3489 - learning_rate: 3.1316e-04\n",
            "Epoch 14/42\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8729 - loss: 0.3150\n",
            "Epoch 14: val_loss did not improve from 0.33756\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8731 - loss: 0.3150 - val_accuracy: 0.8545 - val_loss: 0.3720 - learning_rate: 3.1316e-04\n",
            "Epoch 15/42\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8597 - loss: 0.3165\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.118381563597251e-05.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.33756\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8598 - loss: 0.3165 - val_accuracy: 0.8520 - val_loss: 0.3469 - learning_rate: 3.1316e-04\n",
            "Epoch 16/42\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8746 - loss: 0.3134\n",
            "Epoch 16: val_loss improved from 0.33756 to 0.33287, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8747 - loss: 0.3133 - val_accuracy: 0.8603 - val_loss: 0.3329 - learning_rate: 6.1184e-05\n",
            "Epoch 17/42\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8664 - loss: 0.3121\n",
            "Epoch 17: val_loss improved from 0.33287 to 0.33236, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8668 - loss: 0.3120 - val_accuracy: 0.8637 - val_loss: 0.3324 - learning_rate: 6.1184e-05\n",
            "Epoch 18/42\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8762 - loss: 0.3126\n",
            "Epoch 18: val_loss improved from 0.33236 to 0.33130, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8763 - loss: 0.3125 - val_accuracy: 0.8620 - val_loss: 0.3313 - learning_rate: 6.1184e-05\n",
            "Epoch 19/42\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8753 - loss: 0.3096\n",
            "Epoch 19: val_loss did not improve from 0.33130\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8755 - loss: 0.3096 - val_accuracy: 0.8645 - val_loss: 0.3320 - learning_rate: 6.1184e-05\n",
            "Epoch 20/42\n",
            "\u001b[1m63/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8731 - loss: 0.3096\n",
            "Epoch 20: val_loss did not improve from 0.33130\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8737 - loss: 0.3089 - val_accuracy: 0.8612 - val_loss: 0.3318 - learning_rate: 6.1184e-05\n",
            "Epoch 21/42\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8717 - loss: 0.3059\n",
            "Epoch 21: val_loss improved from 0.33130 to 0.33027, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8718 - loss: 0.3060 - val_accuracy: 0.8595 - val_loss: 0.3303 - learning_rate: 6.1184e-05\n",
            "Epoch 22/42\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8697 - loss: 0.3076\n",
            "Epoch 22: val_loss improved from 0.33027 to 0.33004, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8702 - loss: 0.3076 - val_accuracy: 0.8612 - val_loss: 0.3300 - learning_rate: 6.1184e-05\n",
            "Epoch 23/42\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8712 - loss: 0.2997\n",
            "Epoch 23: val_loss did not improve from 0.33004\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8712 - loss: 0.3002 - val_accuracy: 0.8628 - val_loss: 0.3322 - learning_rate: 6.1184e-05\n",
            "Epoch 24/42\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8800 - loss: 0.3029\n",
            "Epoch 24: val_loss did not improve from 0.33004\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8800 - loss: 0.3030 - val_accuracy: 0.8612 - val_loss: 0.3337 - learning_rate: 6.1184e-05\n",
            "Epoch 25/42\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.3050\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.195384903605018e-05.\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.33004\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8770 - loss: 0.3050 - val_accuracy: 0.8628 - val_loss: 0.3353 - learning_rate: 6.1184e-05\n",
            "Epoch 26/42\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8734 - loss: 0.3019\n",
            "Epoch 26: val_loss did not improve from 0.33004\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8734 - loss: 0.3020 - val_accuracy: 0.8620 - val_loss: 0.3354 - learning_rate: 1.1954e-05\n",
            "Epoch 27/42\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8724 - loss: 0.3018\n",
            "Epoch 27: val_loss did not improve from 0.33004\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8730 - loss: 0.3020 - val_accuracy: 0.8645 - val_loss: 0.3345 - learning_rate: 1.1954e-05\n",
            "Epoch 28/42\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8723 - loss: 0.3072\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 2.3354950684772842e-06.\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.33004\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8729 - loss: 0.3071 - val_accuracy: 0.8645 - val_loss: 0.3347 - learning_rate: 1.1954e-05\n",
            "Epoch 29/42\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8794 - loss: 0.3049\n",
            "Epoch 29: val_loss did not improve from 0.33004\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8794 - loss: 0.3049 - val_accuracy: 0.8637 - val_loss: 0.3346 - learning_rate: 2.3355e-06\n",
            "Epoch 30/42\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8777 - loss: 0.3041\n",
            "Epoch 30: val_loss did not improve from 0.33004\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8779 - loss: 0.3041 - val_accuracy: 0.8637 - val_loss: 0.3347 - learning_rate: 2.3355e-06\n",
            "Epoch 31/42\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8782 - loss: 0.3038\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.33004\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8781 - loss: 0.3040 - val_accuracy: 0.8645 - val_loss: 0.3346 - learning_rate: 2.3355e-06\n",
            "Epoch 31: early stopping\n",
            "Restoring model weights from the end of the best epoch: 22.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:00:19,815] Trial 23 finished with value: -0.3300441801548004 and parameters: {'epochs': 42, 'batch_size': 64, 'learning_rate': 0.008203949936128756, 'stop_patience': 9, 'reduce_lr_factor': 0.19537598839784479, 'reduce_lr_patience': 3}. Best is trial 23 with value: -0.3300441801548004.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/44\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5643 - loss: 0.6926\n",
            "Epoch 1: val_loss improved from inf to 0.69089, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5717 - loss: 0.6862 - val_accuracy: 0.7290 - val_loss: 0.6909 - learning_rate: 0.0085\n",
            "Epoch 2/44\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7210 - loss: 0.5307\n",
            "Epoch 2: val_loss improved from 0.69089 to 0.40868, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7211 - loss: 0.5303 - val_accuracy: 0.8329 - val_loss: 0.4087 - learning_rate: 0.0085\n",
            "Epoch 3/44\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7273 - loss: 0.4992\n",
            "Epoch 3: val_loss did not improve from 0.40868\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7277 - loss: 0.4988 - val_accuracy: 0.7490 - val_loss: 0.4858 - learning_rate: 0.0085\n",
            "Epoch 4/44\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7576 - loss: 0.4733\n",
            "Epoch 4: val_loss improved from 0.40868 to 0.38222, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7576 - loss: 0.4733 - val_accuracy: 0.8313 - val_loss: 0.3822 - learning_rate: 0.0085\n",
            "Epoch 5/44\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7640 - loss: 0.4529\n",
            "Epoch 5: val_loss did not improve from 0.38222\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7639 - loss: 0.4529 - val_accuracy: 0.7531 - val_loss: 0.5000 - learning_rate: 0.0085\n",
            "Epoch 6/44\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7531 - loss: 0.4629\n",
            "Epoch 6: val_loss did not improve from 0.38222\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7527 - loss: 0.4640 - val_accuracy: 0.8545 - val_loss: 0.4138 - learning_rate: 0.0085\n",
            "Epoch 7/44\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7562 - loss: 0.4573\n",
            "Epoch 7: val_loss did not improve from 0.38222\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7560 - loss: 0.4568 - val_accuracy: 0.7124 - val_loss: 0.6298 - learning_rate: 0.0085\n",
            "Epoch 8/44\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7697 - loss: 0.4523\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0015855616997243192.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.38222\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7700 - loss: 0.4516 - val_accuracy: 0.8313 - val_loss: 0.4459 - learning_rate: 0.0085\n",
            "Epoch 9/44\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.3958\n",
            "Epoch 9: val_loss improved from 0.38222 to 0.36431, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8108 - loss: 0.3937 - val_accuracy: 0.8554 - val_loss: 0.3643 - learning_rate: 0.0016\n",
            "Epoch 10/44\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8345 - loss: 0.3702\n",
            "Epoch 10: val_loss did not improve from 0.36431\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8345 - loss: 0.3701 - val_accuracy: 0.8462 - val_loss: 0.3672 - learning_rate: 0.0016\n",
            "Epoch 11/44\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8451 - loss: 0.3594\n",
            "Epoch 11: val_loss did not improve from 0.36431\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8446 - loss: 0.3591 - val_accuracy: 0.8412 - val_loss: 0.3728 - learning_rate: 0.0016\n",
            "Epoch 12/44\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8495 - loss: 0.3521\n",
            "Epoch 12: val_loss did not improve from 0.36431\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8494 - loss: 0.3520 - val_accuracy: 0.8329 - val_loss: 0.3682 - learning_rate: 0.0016\n",
            "Epoch 13/44\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8529 - loss: 0.3502\n",
            "Epoch 13: val_loss improved from 0.36431 to 0.35598, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8533 - loss: 0.3490 - val_accuracy: 0.8429 - val_loss: 0.3560 - learning_rate: 0.0016\n",
            "Epoch 14/44\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8512 - loss: 0.3410\n",
            "Epoch 14: val_loss did not improve from 0.35598\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8512 - loss: 0.3409 - val_accuracy: 0.8221 - val_loss: 0.3993 - learning_rate: 0.0016\n",
            "Epoch 15/44\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8614 - loss: 0.3348\n",
            "Epoch 15: val_loss improved from 0.35598 to 0.34883, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8613 - loss: 0.3347 - val_accuracy: 0.8504 - val_loss: 0.3488 - learning_rate: 0.0016\n",
            "Epoch 16/44\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8577 - loss: 0.3340\n",
            "Epoch 16: val_loss did not improve from 0.34883\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8577 - loss: 0.3340 - val_accuracy: 0.8412 - val_loss: 0.3594 - learning_rate: 0.0016\n",
            "Epoch 17/44\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8638 - loss: 0.3253\n",
            "Epoch 17: val_loss improved from 0.34883 to 0.34809, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8637 - loss: 0.3254 - val_accuracy: 0.8537 - val_loss: 0.3481 - learning_rate: 0.0016\n",
            "Epoch 18/44\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8567 - loss: 0.3253\n",
            "Epoch 18: val_loss did not improve from 0.34809\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8570 - loss: 0.3254 - val_accuracy: 0.8470 - val_loss: 0.3616 - learning_rate: 0.0016\n",
            "Epoch 19/44\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8631 - loss: 0.3156\n",
            "Epoch 19: val_loss did not improve from 0.34809\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8632 - loss: 0.3157 - val_accuracy: 0.8362 - val_loss: 0.3581 - learning_rate: 0.0016\n",
            "Epoch 20/44\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8702 - loss: 0.3166\n",
            "Epoch 20: val_loss did not improve from 0.34809\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8701 - loss: 0.3166 - val_accuracy: 0.8088 - val_loss: 0.3847 - learning_rate: 0.0016\n",
            "Epoch 21/44\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8654 - loss: 0.3149\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002959430708427969.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.34809\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8652 - loss: 0.3151 - val_accuracy: 0.8404 - val_loss: 0.3969 - learning_rate: 0.0016\n",
            "Epoch 22/44\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8772 - loss: 0.3053\n",
            "Epoch 22: val_loss did not improve from 0.34809\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8772 - loss: 0.3053 - val_accuracy: 0.8545 - val_loss: 0.3611 - learning_rate: 2.9594e-04\n",
            "Epoch 23/44\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8742 - loss: 0.3035\n",
            "Epoch 23: val_loss did not improve from 0.34809\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8742 - loss: 0.3035 - val_accuracy: 0.8454 - val_loss: 0.3977 - learning_rate: 2.9594e-04\n",
            "Epoch 24/44\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8761 - loss: 0.2995\n",
            "Epoch 24: val_loss did not improve from 0.34809\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8761 - loss: 0.2995 - val_accuracy: 0.8504 - val_loss: 0.3785 - learning_rate: 2.9594e-04\n",
            "Epoch 25/44\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8735 - loss: 0.2972\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 5.523739561088395e-05.\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.34809\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8736 - loss: 0.2973 - val_accuracy: 0.8479 - val_loss: 0.3719 - learning_rate: 2.9594e-04\n",
            "Epoch 25: early stopping\n",
            "Restoring model weights from the end of the best epoch: 17.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:00:39,310] Trial 24 finished with value: -0.34809133410453796 and parameters: {'epochs': 44, 'batch_size': 64, 'learning_rate': 0.008494897137020143, 'stop_patience': 8, 'reduce_lr_factor': 0.1866487297490004, 'reduce_lr_patience': 4}. Best is trial 23 with value: -0.3300441801548004.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/39\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5897 - loss: 0.6805\n",
            "Epoch 1: val_loss improved from inf to 0.97972, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5917 - loss: 0.6789 - val_accuracy: 0.6126 - val_loss: 0.9797 - learning_rate: 0.0020\n",
            "Epoch 2/39\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7091 - loss: 0.5631\n",
            "Epoch 2: val_loss improved from 0.97972 to 0.66405, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7095 - loss: 0.5624 - val_accuracy: 0.7398 - val_loss: 0.6640 - learning_rate: 0.0020\n",
            "Epoch 3/39\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7391 - loss: 0.5014\n",
            "Epoch 3: val_loss improved from 0.66405 to 0.63206, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7397 - loss: 0.5007 - val_accuracy: 0.7573 - val_loss: 0.6321 - learning_rate: 0.0020\n",
            "Epoch 4/39\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7616 - loss: 0.4583\n",
            "Epoch 4: val_loss did not improve from 0.63206\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7618 - loss: 0.4582 - val_accuracy: 0.7506 - val_loss: 0.6733 - learning_rate: 0.0020\n",
            "Epoch 5/39\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7716 - loss: 0.4453\n",
            "Epoch 5: val_loss improved from 0.63206 to 0.37500, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7717 - loss: 0.4452 - val_accuracy: 0.8446 - val_loss: 0.3750 - learning_rate: 0.0020\n",
            "Epoch 6/39\n",
            "\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.4293\n",
            "Epoch 6: val_loss did not improve from 0.37500\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7865 - loss: 0.4293 - val_accuracy: 0.8412 - val_loss: 0.3920 - learning_rate: 0.0020\n",
            "Epoch 7/39\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.4139\n",
            "Epoch 7: val_loss did not improve from 0.37500\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7911 - loss: 0.4138 - val_accuracy: 0.8180 - val_loss: 0.4559 - learning_rate: 0.0020\n",
            "Epoch 8/39\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8090 - loss: 0.4101\n",
            "Epoch 8: val_loss improved from 0.37500 to 0.35117, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8090 - loss: 0.4101 - val_accuracy: 0.8529 - val_loss: 0.3512 - learning_rate: 0.0020\n",
            "Epoch 9/39\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8011 - loss: 0.3978\n",
            "Epoch 9: val_loss did not improve from 0.35117\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8014 - loss: 0.3977 - val_accuracy: 0.8495 - val_loss: 0.3636 - learning_rate: 0.0020\n",
            "Epoch 10/39\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8079 - loss: 0.3873\n",
            "Epoch 10: val_loss did not improve from 0.35117\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8080 - loss: 0.3874 - val_accuracy: 0.8321 - val_loss: 0.3872 - learning_rate: 0.0020\n",
            "Epoch 11/39\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8196 - loss: 0.3744\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00027458697765486505.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.35117\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8196 - loss: 0.3744 - val_accuracy: 0.8570 - val_loss: 0.3560 - learning_rate: 0.0020\n",
            "Epoch 12/39\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3377\n",
            "Epoch 12: val_loss improved from 0.35117 to 0.33512, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8449 - loss: 0.3374 - val_accuracy: 0.8595 - val_loss: 0.3351 - learning_rate: 2.7459e-04\n",
            "Epoch 13/39\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.3101\n",
            "Epoch 13: val_loss improved from 0.33512 to 0.33389, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8718 - loss: 0.3101 - val_accuracy: 0.8620 - val_loss: 0.3339 - learning_rate: 2.7459e-04\n",
            "Epoch 14/39\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8722 - loss: 0.3056\n",
            "Epoch 14: val_loss did not improve from 0.33389\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8722 - loss: 0.3056 - val_accuracy: 0.8545 - val_loss: 0.3482 - learning_rate: 2.7459e-04\n",
            "Epoch 15/39\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.3055\n",
            "Epoch 15: val_loss did not improve from 0.33389\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8718 - loss: 0.3054 - val_accuracy: 0.8570 - val_loss: 0.3407 - learning_rate: 2.7459e-04\n",
            "Epoch 16/39\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.2957\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.78424136873656e-05.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.33389\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8830 - loss: 0.2958 - val_accuracy: 0.8554 - val_loss: 0.3402 - learning_rate: 2.7459e-04\n",
            "Epoch 17/39\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8768 - loss: 0.2941\n",
            "Epoch 17: val_loss did not improve from 0.33389\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.2941 - val_accuracy: 0.8504 - val_loss: 0.3540 - learning_rate: 3.7842e-05\n",
            "Epoch 18/39\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8666 - loss: 0.2956\n",
            "Epoch 18: val_loss did not improve from 0.33389\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8669 - loss: 0.2955 - val_accuracy: 0.8537 - val_loss: 0.3513 - learning_rate: 3.7842e-05\n",
            "Epoch 19/39\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8746 - loss: 0.2954\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 5.215280701515124e-06.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.33389\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8749 - loss: 0.2953 - val_accuracy: 0.8512 - val_loss: 0.3536 - learning_rate: 3.7842e-05\n",
            "Epoch 20/39\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8859 - loss: 0.2834\n",
            "Epoch 20: val_loss did not improve from 0.33389\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8860 - loss: 0.2836 - val_accuracy: 0.8529 - val_loss: 0.3513 - learning_rate: 5.2153e-06\n",
            "Epoch 21/39\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8754 - loss: 0.2907\n",
            "Epoch 21: val_loss did not improve from 0.33389\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8755 - loss: 0.2907 - val_accuracy: 0.8537 - val_loss: 0.3496 - learning_rate: 5.2153e-06\n",
            "Epoch 22/39\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8764 - loss: 0.2895\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.33389\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8766 - loss: 0.2894 - val_accuracy: 0.8529 - val_loss: 0.3501 - learning_rate: 5.2153e-06\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:01:18,818] Trial 25 finished with value: -0.33388811349868774 and parameters: {'epochs': 39, 'batch_size': 16, 'learning_rate': 0.001992420818006966, 'stop_patience': 9, 'reduce_lr_factor': 0.13781575824652073, 'reduce_lr_patience': 3}. Best is trial 23 with value: -0.3300441801548004.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/42\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5807 - loss: 0.7057\n",
            "Epoch 1: val_loss improved from inf to 0.46968, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5848 - loss: 0.6993 - val_accuracy: 0.8005 - val_loss: 0.4697 - learning_rate: 0.0091\n",
            "Epoch 2/42\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7034 - loss: 0.5547\n",
            "Epoch 2: val_loss did not improve from 0.46968\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7030 - loss: 0.5535 - val_accuracy: 0.6949 - val_loss: 0.6398 - learning_rate: 0.0091\n",
            "Epoch 3/42\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7393 - loss: 0.4943\n",
            "Epoch 3: val_loss improved from 0.46968 to 0.38539, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7382 - loss: 0.4947 - val_accuracy: 0.8462 - val_loss: 0.3854 - learning_rate: 0.0091\n",
            "Epoch 4/42\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7554 - loss: 0.4810\n",
            "Epoch 4: val_loss did not improve from 0.38539\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 0.4803 - val_accuracy: 0.7348 - val_loss: 0.5239 - learning_rate: 0.0091\n",
            "Epoch 5/42\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7489 - loss: 0.4725\n",
            "Epoch 5: val_loss did not improve from 0.38539\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7490 - loss: 0.4723 - val_accuracy: 0.7988 - val_loss: 0.4913 - learning_rate: 0.0091\n",
            "Epoch 6/42\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7809 - loss: 0.4458\n",
            "Epoch 6: val_loss improved from 0.38539 to 0.35249, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7808 - loss: 0.4459 - val_accuracy: 0.8554 - val_loss: 0.3525 - learning_rate: 0.0091\n",
            "Epoch 7/42\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7785 - loss: 0.4440\n",
            "Epoch 7: val_loss did not improve from 0.35249\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7786 - loss: 0.4440 - val_accuracy: 0.8313 - val_loss: 0.3745 - learning_rate: 0.0091\n",
            "Epoch 8/42\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7953 - loss: 0.4242\n",
            "Epoch 8: val_loss did not improve from 0.35249\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7948 - loss: 0.4244 - val_accuracy: 0.8570 - val_loss: 0.3646 - learning_rate: 0.0091\n",
            "Epoch 9/42\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7926 - loss: 0.4128\n",
            "Epoch 9: val_loss did not improve from 0.35249\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7924 - loss: 0.4135 - val_accuracy: 0.8055 - val_loss: 0.4858 - learning_rate: 0.0091\n",
            "Epoch 10/42\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7914 - loss: 0.4070\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0018031849904981555.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.35249\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7920 - loss: 0.4071 - val_accuracy: 0.8479 - val_loss: 0.4313 - learning_rate: 0.0091\n",
            "Epoch 11/42\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8259 - loss: 0.3695\n",
            "Epoch 11: val_loss did not improve from 0.35249\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8287 - loss: 0.3668 - val_accuracy: 0.8487 - val_loss: 0.3629 - learning_rate: 0.0018\n",
            "Epoch 12/42\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8640 - loss: 0.3261\n",
            "Epoch 12: val_loss improved from 0.35249 to 0.35189, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8640 - loss: 0.3262 - val_accuracy: 0.8470 - val_loss: 0.3519 - learning_rate: 0.0018\n",
            "Epoch 13/42\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8668 - loss: 0.3239\n",
            "Epoch 13: val_loss did not improve from 0.35189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8667 - loss: 0.3239 - val_accuracy: 0.8354 - val_loss: 0.3720 - learning_rate: 0.0018\n",
            "Epoch 14/42\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8701 - loss: 0.3195\n",
            "Epoch 14: val_loss did not improve from 0.35189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8700 - loss: 0.3195 - val_accuracy: 0.8504 - val_loss: 0.3546 - learning_rate: 0.0018\n",
            "Epoch 15/42\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8658 - loss: 0.3168\n",
            "Epoch 15: val_loss did not improve from 0.35189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8656 - loss: 0.3171 - val_accuracy: 0.8371 - val_loss: 0.3562 - learning_rate: 0.0018\n",
            "Epoch 16/42\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8746 - loss: 0.3123\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0003566686632993849.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.35189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8745 - loss: 0.3124 - val_accuracy: 0.8229 - val_loss: 0.3821 - learning_rate: 0.0018\n",
            "Epoch 17/42\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8705 - loss: 0.3054\n",
            "Epoch 17: val_loss did not improve from 0.35189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8707 - loss: 0.3052 - val_accuracy: 0.8554 - val_loss: 0.3617 - learning_rate: 3.5667e-04\n",
            "Epoch 18/42\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8748 - loss: 0.2966\n",
            "Epoch 18: val_loss did not improve from 0.35189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8750 - loss: 0.2966 - val_accuracy: 0.8595 - val_loss: 0.3646 - learning_rate: 3.5667e-04\n",
            "Epoch 19/42\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8803 - loss: 0.2956\n",
            "Epoch 19: val_loss did not improve from 0.35189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8803 - loss: 0.2954 - val_accuracy: 0.8529 - val_loss: 0.3656 - learning_rate: 3.5667e-04\n",
            "Epoch 20/42\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8812 - loss: 0.2944\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 7.054879978976731e-05.\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.35189\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8812 - loss: 0.2944 - val_accuracy: 0.8454 - val_loss: 0.3986 - learning_rate: 3.5667e-04\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:01:34,263] Trial 26 finished with value: -0.3518868684768677 and parameters: {'epochs': 42, 'batch_size': 64, 'learning_rate': 0.009116237229679447, 'stop_patience': 8, 'reduce_lr_factor': 0.19779926522918634, 'reduce_lr_patience': 4}. Best is trial 23 with value: -0.3300441801548004.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/37\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5623 - loss: 0.6880\n",
            "Epoch 1: val_loss improved from inf to 0.43164, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5700 - loss: 0.6824 - val_accuracy: 0.8196 - val_loss: 0.4316 - learning_rate: 0.0054\n",
            "Epoch 2/37\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7096 - loss: 0.5438\n",
            "Epoch 2: val_loss improved from 0.43164 to 0.41825, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7094 - loss: 0.5434 - val_accuracy: 0.8196 - val_loss: 0.4182 - learning_rate: 0.0054\n",
            "Epoch 3/37\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7403 - loss: 0.5035\n",
            "Epoch 3: val_loss did not improve from 0.41825\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7403 - loss: 0.5034 - val_accuracy: 0.7997 - val_loss: 0.4464 - learning_rate: 0.0054\n",
            "Epoch 4/37\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7658 - loss: 0.4652\n",
            "Epoch 4: val_loss did not improve from 0.41825\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7657 - loss: 0.4654 - val_accuracy: 0.7448 - val_loss: 0.5098 - learning_rate: 0.0054\n",
            "Epoch 5/37\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7774 - loss: 0.4375\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0013507425536819096.\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.41825\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7776 - loss: 0.4375 - val_accuracy: 0.8379 - val_loss: 0.4488 - learning_rate: 0.0054\n",
            "Epoch 6/37\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8081 - loss: 0.4005\n",
            "Epoch 6: val_loss improved from 0.41825 to 0.40609, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8094 - loss: 0.3994 - val_accuracy: 0.8263 - val_loss: 0.4061 - learning_rate: 0.0014\n",
            "Epoch 7/37\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8318 - loss: 0.3788\n",
            "Epoch 7: val_loss did not improve from 0.40609\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8318 - loss: 0.3788 - val_accuracy: 0.8238 - val_loss: 0.4285 - learning_rate: 0.0014\n",
            "Epoch 8/37\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8363 - loss: 0.3614\n",
            "Epoch 8: val_loss improved from 0.40609 to 0.40435, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8362 - loss: 0.3614 - val_accuracy: 0.8171 - val_loss: 0.4043 - learning_rate: 0.0014\n",
            "Epoch 9/37\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8434 - loss: 0.3539\n",
            "Epoch 9: val_loss improved from 0.40435 to 0.39952, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8433 - loss: 0.3538 - val_accuracy: 0.8113 - val_loss: 0.3995 - learning_rate: 0.0014\n",
            "Epoch 10/37\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8551 - loss: 0.3442\n",
            "Epoch 10: val_loss improved from 0.39952 to 0.37629, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8551 - loss: 0.3441 - val_accuracy: 0.8271 - val_loss: 0.3763 - learning_rate: 0.0014\n",
            "Epoch 11/37\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8493 - loss: 0.3384\n",
            "Epoch 11: val_loss did not improve from 0.37629\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8492 - loss: 0.3387 - val_accuracy: 0.8354 - val_loss: 0.3949 - learning_rate: 0.0014\n",
            "Epoch 12/37\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8567 - loss: 0.3340\n",
            "Epoch 12: val_loss improved from 0.37629 to 0.36132, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8566 - loss: 0.3341 - val_accuracy: 0.8304 - val_loss: 0.3613 - learning_rate: 0.0014\n",
            "Epoch 13/37\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8651 - loss: 0.3224\n",
            "Epoch 13: val_loss did not improve from 0.36132\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8633 - loss: 0.3239 - val_accuracy: 0.8155 - val_loss: 0.3820 - learning_rate: 0.0014\n",
            "Epoch 14/37\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8675 - loss: 0.3180\n",
            "Epoch 14: val_loss did not improve from 0.36132\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8672 - loss: 0.3184 - val_accuracy: 0.8296 - val_loss: 0.3679 - learning_rate: 0.0014\n",
            "Epoch 15/37\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8621 - loss: 0.3162\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00033715419614725376.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.36132\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8620 - loss: 0.3167 - val_accuracy: 0.8362 - val_loss: 0.3631 - learning_rate: 0.0014\n",
            "Epoch 16/37\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8759 - loss: 0.3049\n",
            "Epoch 16: val_loss did not improve from 0.36132\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8760 - loss: 0.3048 - val_accuracy: 0.8470 - val_loss: 0.3689 - learning_rate: 3.3715e-04\n",
            "Epoch 17/37\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8699 - loss: 0.3016\n",
            "Epoch 17: val_loss did not improve from 0.36132\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8700 - loss: 0.3015 - val_accuracy: 0.8454 - val_loss: 0.3840 - learning_rate: 3.3715e-04\n",
            "Epoch 18/37\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8759 - loss: 0.2971\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 8.415589913921017e-05.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.36132\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8759 - loss: 0.2971 - val_accuracy: 0.8446 - val_loss: 0.3806 - learning_rate: 3.3715e-04\n",
            "Epoch 19/37\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8786 - loss: 0.2944\n",
            "Epoch 19: val_loss did not improve from 0.36132\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8786 - loss: 0.2944 - val_accuracy: 0.8512 - val_loss: 0.3764 - learning_rate: 8.4156e-05\n",
            "Epoch 20/37\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8765 - loss: 0.2936\n",
            "Epoch 20: val_loss did not improve from 0.36132\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8767 - loss: 0.2940 - val_accuracy: 0.8470 - val_loss: 0.3789 - learning_rate: 8.4156e-05\n",
            "Epoch 21/37\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8708 - loss: 0.2935\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.1005864978077387e-05.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.36132\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8710 - loss: 0.2936 - val_accuracy: 0.8479 - val_loss: 0.3794 - learning_rate: 8.4156e-05\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:01:50,001] Trial 27 finished with value: -0.3613249659538269 and parameters: {'epochs': 37, 'batch_size': 64, 'learning_rate': 0.0054114864947316646, 'stop_patience': 9, 'reduce_lr_factor': 0.2496065594846798, 'reduce_lr_patience': 3}. Best is trial 23 with value: -0.3300441801548004.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5620 - loss: 0.6949\n",
            "Epoch 1: val_loss improved from inf to 0.50684, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5656 - loss: 0.6919 - val_accuracy: 0.7697 - val_loss: 0.5068 - learning_rate: 0.0065\n",
            "Epoch 2/30\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6847 - loss: 0.5674\n",
            "Epoch 2: val_loss improved from 0.50684 to 0.49154, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6857 - loss: 0.5661 - val_accuracy: 0.7980 - val_loss: 0.4915 - learning_rate: 0.0065\n",
            "Epoch 3/30\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7461 - loss: 0.4979\n",
            "Epoch 3: val_loss did not improve from 0.49154\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7463 - loss: 0.4974 - val_accuracy: 0.7307 - val_loss: 0.5421 - learning_rate: 0.0065\n",
            "Epoch 4/30\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7875 - loss: 0.4488\n",
            "Epoch 4: val_loss improved from 0.49154 to 0.43808, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7865 - loss: 0.4492 - val_accuracy: 0.8113 - val_loss: 0.4381 - learning_rate: 0.0065\n",
            "Epoch 5/30\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7713 - loss: 0.4561\n",
            "Epoch 5: val_loss improved from 0.43808 to 0.41464, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7710 - loss: 0.4558 - val_accuracy: 0.8288 - val_loss: 0.4146 - learning_rate: 0.0065\n",
            "Epoch 6/30\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7971 - loss: 0.4207\n",
            "Epoch 6: val_loss did not improve from 0.41464\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7971 - loss: 0.4209 - val_accuracy: 0.7190 - val_loss: 0.6900 - learning_rate: 0.0065\n",
            "Epoch 7/30\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7979 - loss: 0.4171\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009962035231767033.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.41464\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7978 - loss: 0.4166 - val_accuracy: 0.8071 - val_loss: 0.4158 - learning_rate: 0.0065\n",
            "Epoch 8/30\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8131 - loss: 0.3871\n",
            "Epoch 8: val_loss improved from 0.41464 to 0.36253, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8157 - loss: 0.3846 - val_accuracy: 0.8296 - val_loss: 0.3625 - learning_rate: 9.9620e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8472 - loss: 0.3478\n",
            "Epoch 9: val_loss improved from 0.36253 to 0.34819, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8477 - loss: 0.3476 - val_accuracy: 0.8537 - val_loss: 0.3482 - learning_rate: 9.9620e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8515 - loss: 0.3382\n",
            "Epoch 10: val_loss did not improve from 0.34819\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8514 - loss: 0.3383 - val_accuracy: 0.8479 - val_loss: 0.3631 - learning_rate: 9.9620e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8501 - loss: 0.3323\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.000152233453833622.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.34819\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8506 - loss: 0.3322 - val_accuracy: 0.8454 - val_loss: 0.3530 - learning_rate: 9.9620e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8623 - loss: 0.3213\n",
            "Epoch 12: val_loss improved from 0.34819 to 0.34668, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8623 - loss: 0.3216 - val_accuracy: 0.8603 - val_loss: 0.3467 - learning_rate: 1.5223e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.3141\n",
            "Epoch 13: val_loss did not improve from 0.34668\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8699 - loss: 0.3142 - val_accuracy: 0.8587 - val_loss: 0.3500 - learning_rate: 1.5223e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8674 - loss: 0.3190\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.3263342850261328e-05.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.34668\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8674 - loss: 0.3190 - val_accuracy: 0.8537 - val_loss: 0.3529 - learning_rate: 1.5223e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8708 - loss: 0.3131\n",
            "Epoch 15: val_loss did not improve from 0.34668\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8708 - loss: 0.3133 - val_accuracy: 0.8570 - val_loss: 0.3470 - learning_rate: 2.3263e-05\n",
            "Epoch 16/30\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8711 - loss: 0.3139\n",
            "Epoch 16: val_loss improved from 0.34668 to 0.34585, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8711 - loss: 0.3140 - val_accuracy: 0.8562 - val_loss: 0.3459 - learning_rate: 2.3263e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.3166\n",
            "Epoch 17: val_loss did not improve from 0.34585\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8665 - loss: 0.3168 - val_accuracy: 0.8562 - val_loss: 0.3464 - learning_rate: 2.3263e-05\n",
            "Epoch 18/30\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8737 - loss: 0.3151\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 3.554955383615401e-06.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.34585\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8740 - loss: 0.3152 - val_accuracy: 0.8570 - val_loss: 0.3470 - learning_rate: 2.3263e-05\n",
            "Epoch 19/30\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8720 - loss: 0.3105\n",
            "Epoch 19: val_loss did not improve from 0.34585\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8716 - loss: 0.3109 - val_accuracy: 0.8562 - val_loss: 0.3462 - learning_rate: 3.5550e-06\n",
            "Epoch 20/30\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8740 - loss: 0.3093\n",
            "Epoch 20: val_loss improved from 0.34585 to 0.34569, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8740 - loss: 0.3095 - val_accuracy: 0.8562 - val_loss: 0.3457 - learning_rate: 3.5550e-06\n",
            "Epoch 21/30\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8765 - loss: 0.3112\n",
            "Epoch 21: val_loss improved from 0.34569 to 0.34511, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8757 - loss: 0.3113 - val_accuracy: 0.8570 - val_loss: 0.3451 - learning_rate: 3.5550e-06\n",
            "Epoch 22/30\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8599 - loss: 0.3140\n",
            "Epoch 22: val_loss improved from 0.34511 to 0.34476, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8601 - loss: 0.3141 - val_accuracy: 0.8570 - val_loss: 0.3448 - learning_rate: 3.5550e-06\n",
            "Epoch 23/30\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8620 - loss: 0.3146\n",
            "Epoch 23: val_loss did not improve from 0.34476\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8626 - loss: 0.3149 - val_accuracy: 0.8579 - val_loss: 0.3448 - learning_rate: 3.5550e-06\n",
            "Epoch 24/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8725 - loss: 0.3131\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.34476\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8725 - loss: 0.3132 - val_accuracy: 0.8562 - val_loss: 0.3448 - learning_rate: 3.5550e-06\n",
            "Epoch 25/30\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8759 - loss: 0.3136\n",
            "Epoch 25: val_loss did not improve from 0.34476\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8753 - loss: 0.3138 - val_accuracy: 0.8562 - val_loss: 0.3448 - learning_rate: 1.0000e-06\n",
            "Epoch 26/30\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8687 - loss: 0.3164\n",
            "Epoch 26: val_loss did not improve from 0.34476\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8688 - loss: 0.3165 - val_accuracy: 0.8562 - val_loss: 0.3448 - learning_rate: 1.0000e-06\n",
            "Epoch 27/30\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8670 - loss: 0.3173\n",
            "Epoch 27: val_loss did not improve from 0.34476\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8676 - loss: 0.3169 - val_accuracy: 0.8570 - val_loss: 0.3449 - learning_rate: 1.0000e-06\n",
            "Epoch 28/30\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8702 - loss: 0.3138\n",
            "Epoch 28: val_loss did not improve from 0.34476\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8702 - loss: 0.3139 - val_accuracy: 0.8570 - val_loss: 0.3448 - learning_rate: 1.0000e-06\n",
            "Epoch 29/30\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8673 - loss: 0.3135\n",
            "Epoch 29: val_loss did not improve from 0.34476\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8676 - loss: 0.3139 - val_accuracy: 0.8570 - val_loss: 0.3449 - learning_rate: 1.0000e-06\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 22.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:02:10,728] Trial 28 finished with value: -0.34476426243782043 and parameters: {'epochs': 30, 'batch_size': 64, 'learning_rate': 0.006519076028255286, 'stop_patience': 7, 'reduce_lr_factor': 0.1528136090159346, 'reduce_lr_patience': 2}. Best is trial 23 with value: -0.3300441801548004.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5729 - loss: 0.6837\n",
            "Epoch 1: val_loss improved from inf to 0.61504, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5732 - loss: 0.6834 - val_accuracy: 0.7323 - val_loss: 0.6150 - learning_rate: 0.0079\n",
            "Epoch 2/45\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6991 - loss: 0.5497\n",
            "Epoch 2: val_loss did not improve from 0.61504\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6991 - loss: 0.5497 - val_accuracy: 0.6342 - val_loss: 0.8501 - learning_rate: 0.0079\n",
            "Epoch 3/45\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7178 - loss: 0.5096\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.001669181005108773.\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.61504\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7183 - loss: 0.5091 - val_accuracy: 0.6933 - val_loss: 0.8039 - learning_rate: 0.0079\n",
            "Epoch 4/45\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7835 - loss: 0.4342\n",
            "Epoch 4: val_loss improved from 0.61504 to 0.34553, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7840 - loss: 0.4337 - val_accuracy: 0.8446 - val_loss: 0.3455 - learning_rate: 0.0017\n",
            "Epoch 5/45\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8036 - loss: 0.4046\n",
            "Epoch 5: val_loss did not improve from 0.34553\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.4045 - val_accuracy: 0.8537 - val_loss: 0.3483 - learning_rate: 0.0017\n",
            "Epoch 6/45\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8197 - loss: 0.3909\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00035394765426066216.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.34553\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.3908 - val_accuracy: 0.8354 - val_loss: 0.3492 - learning_rate: 0.0017\n",
            "Epoch 7/45\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8439 - loss: 0.3578\n",
            "Epoch 7: val_loss improved from 0.34553 to 0.33834, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8440 - loss: 0.3578 - val_accuracy: 0.8479 - val_loss: 0.3383 - learning_rate: 3.5395e-04\n",
            "Epoch 8/45\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8543 - loss: 0.3541\n",
            "Epoch 8: val_loss improved from 0.33834 to 0.32927, saving model to BEST_CNN_RAM_PETR4.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8543 - loss: 0.3541 - val_accuracy: 0.8487 - val_loss: 0.3293 - learning_rate: 3.5395e-04\n",
            "Epoch 9/45\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8516 - loss: 0.3521\n",
            "Epoch 9: val_loss did not improve from 0.32927\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8516 - loss: 0.3521 - val_accuracy: 0.8570 - val_loss: 0.3417 - learning_rate: 3.5395e-04\n",
            "Epoch 10/45\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8576 - loss: 0.3505\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 7.505413772744036e-05.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.32927\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8578 - loss: 0.3504 - val_accuracy: 0.8554 - val_loss: 0.3402 - learning_rate: 3.5395e-04\n",
            "Epoch 11/45\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8598 - loss: 0.3414\n",
            "Epoch 11: val_loss did not improve from 0.32927\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8601 - loss: 0.3413 - val_accuracy: 0.8512 - val_loss: 0.3430 - learning_rate: 7.5054e-05\n",
            "Epoch 12/45\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8614 - loss: 0.3425\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.5915131375460575e-05.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.32927\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8616 - loss: 0.3424 - val_accuracy: 0.8504 - val_loss: 0.3466 - learning_rate: 7.5054e-05\n",
            "Epoch 13/45\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8548 - loss: 0.3359\n",
            "Epoch 13: val_loss did not improve from 0.32927\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8549 - loss: 0.3360 - val_accuracy: 0.8529 - val_loss: 0.3389 - learning_rate: 1.5915e-05\n",
            "Epoch 14/45\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8628 - loss: 0.3343\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 3.374782760924538e-06.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.32927\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8631 - loss: 0.3343 - val_accuracy: 0.8520 - val_loss: 0.3376 - learning_rate: 1.5915e-05\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:02:35,889] Trial 29 finished with value: -0.3292672336101532 and parameters: {'epochs': 45, 'batch_size': 16, 'learning_rate': 0.007871687526525471, 'stop_patience': 6, 'reduce_lr_factor': 0.21204869015868694, 'reduce_lr_patience': 2}. Best is trial 29 with value: -0.3292672336101532.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Melhor combinação encontrada:\n",
            "trial                  29.000000\n",
            "epochs                 45.000000\n",
            "batch_size             16.000000\n",
            "learning_rate           0.007872\n",
            "stop_patience           6.000000\n",
            "reduce_lr_factor        0.212049\n",
            "reduce_lr_patience      2.000000\n",
            "recall_Compra(1)        0.882637\n",
            "recall_Vende(0)         0.812392\n",
            "precision_Compra(1)     0.834347\n",
            "precision_Vende(0)      0.866055\n",
            "macro_recall            0.847515\n",
            "accuracy                0.848712\n",
            "f1_macro                0.848089\n",
            "f1_weighted             0.848421\n",
            "min_val_loss            0.329267\n",
            "Name: 0, dtype: float64\n",
            "🔍 Hiperparâmetros: {'epochs': 45, 'batch_size': 16, 'learning_rate': 0.007871687526525471, 'stop_patience': 6, 'reduce_lr_factor': 0.21204869015868694, 'reduce_lr_patience': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_history([best_seq_history, best_ram_history], titles=titles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "GzlkMQEY6aRz",
        "outputId": "d21efb1d-b06a-437d-bdc4-96dc25455892"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix([best_seq_metrics, best_ram_metrics], titles=titles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "3y8ZnNyZ6bgH",
        "outputId": "311e8098-a472-42d3-88f3-b4619c755fb1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_classification_reports(\n",
        "    metrics_list=[best_seq_metrics, best_ram_metrics],\n",
        "    titles=titles\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krhbjhTD6c8M",
        "outputId": "dd3f2f4f-6d00-443b-9c8b-f14c53fbb41c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "📊 Relatório de Classificação - Modelo Sequencial\n",
            "==================================================\n",
            "\n",
            "Vende (0):\n",
            "Precision: 0.88\n",
            "Recall:    0.75\n",
            "F1-Score:  0.81\n",
            "\n",
            "Compra (1):\n",
            "Precision: 0.80\n",
            "Recall:    0.91\n",
            "F1-Score:  0.85\n",
            "\n",
            "Médias:\n",
            "Acurácia:  0.83\n",
            "Precision: 0.84\n",
            "Recall:    0.83\n",
            "F1-Score:  0.83\n",
            "\n",
            "\n",
            "==================================================\n",
            "📊 Relatório de Classificação - Modelo Ramificado\n",
            "==================================================\n",
            "\n",
            "Vende (0):\n",
            "Precision: 0.87\n",
            "Recall:    0.81\n",
            "F1-Score:  0.84\n",
            "\n",
            "Compra (1):\n",
            "Precision: 0.83\n",
            "Recall:    0.88\n",
            "F1-Score:  0.86\n",
            "\n",
            "Médias:\n",
            "Acurácia:  0.85\n",
            "Precision: 0.85\n",
            "Recall:    0.85\n",
            "F1-Score:  0.85\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultado_backtest = run_backtest(\n",
        "    predictions=best_seq_y_pred,\n",
        "    prices=prices,\n",
        "    capital=10000,\n",
        "    model_name=\"CNN Sequencial\",\n",
        "    stock_name=\"PETR4\",\n",
        "    metrics = best_seq_metrics,\n",
        "    cdi_df = cdi,\n",
        "    metric_optimization = metric_optimization\n",
        ")\n",
        "\n",
        "resultado_backtest = run_backtest(\n",
        "    predictions=best_ram_y_pred,\n",
        "    prices=prices,\n",
        "    capital=10000,\n",
        "    model_name=\"CNN Ramificado\",\n",
        "    stock_name=\"PETR4\",\n",
        "    metrics = best_ram_metrics,\n",
        "    cdi_df=cdi,\n",
        "    metric_optimization = metric_optimization\n",
        ")\n",
        "\n",
        "resultado_backtest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "qLNaj_Gt6eS1",
        "outputId": "e1a7ad0b-2fb1-4a93-a50c-011056d1730e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-cadec49cf654>:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  preco_atual = prices[i]\n",
            "<ipython-input-17-cadec49cf654>:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  preco_atual = prices[i]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Data          Modelo   Ação Métrica de Otimização  \\\n",
              "0  2025-04-13 14:10:15.041119  CNN Sequencial  CSAN3              val_loss   \n",
              "1  2025-04-13 14:10:15.069407  CNN Ramificado  CSAN3              val_loss   \n",
              "2  2025-04-13 14:37:38.702181  CNN Sequencial  BBAS3              val_loss   \n",
              "3  2025-04-13 14:37:38.727148  CNN Ramificado  BBAS3              val_loss   \n",
              "4  2025-04-13 15:02:36.679384  CNN Sequencial  PETR4              val_loss   \n",
              "5  2025-04-13 15:02:36.703969  CNN Ramificado  PETR4              val_loss   \n",
              "\n",
              "   Acurácia  Precision    Recall        F1       Matriz de Confusão  \\\n",
              "0  0.885329   0.882166  0.882586  0.882373   [[619, 69], [67, 431]]   \n",
              "1  0.881956   0.880287  0.876629  0.878284   [[626, 62], [78, 420]]   \n",
              "2  0.865823   0.861527  0.864002  0.862654   [[603, 86], [73, 423]]   \n",
              "3  0.898734   0.897139  0.894281  0.895610   [[635, 54], [66, 430]]   \n",
              "4  0.831255   0.839039  0.828591  0.829323  [[436, 145], [58, 564]]   \n",
              "5  0.848712   0.850201  0.847515  0.848089  [[472, 109], [73, 549]]   \n",
              "\n",
              "   Saldo Inicial  Saldo Final  Total de Ações   Lucro Total   Lucro (%)  \\\n",
              "0          10000     3.640817           990.0   9467.040666   94.670407   \n",
              "1          10000     8.435907          1065.0  10946.335745  109.463357   \n",
              "2          10000    39.235968           247.0   3720.565817   37.205658   \n",
              "3          10000    38.974524           310.0   7209.874334   72.098743   \n",
              "4          10000     1.062806           809.0  20128.224164  201.282242   \n",
              "5          10000    12.695825           817.0  20437.777196  204.377772   \n",
              "\n",
              "   Lucro (%) CDI  \n",
              "0      42.269210  \n",
              "1      42.269210  \n",
              "2      42.269210  \n",
              "3      42.269210  \n",
              "4      42.937875  \n",
              "5      42.937875  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35ee655f-a904-40be-bfc7-64d054a81d5a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Ação</th>\n",
              "      <th>Métrica de Otimização</th>\n",
              "      <th>Acurácia</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Matriz de Confusão</th>\n",
              "      <th>Saldo Inicial</th>\n",
              "      <th>Saldo Final</th>\n",
              "      <th>Total de Ações</th>\n",
              "      <th>Lucro Total</th>\n",
              "      <th>Lucro (%)</th>\n",
              "      <th>Lucro (%) CDI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-04-13 14:10:15.041119</td>\n",
              "      <td>CNN Sequencial</td>\n",
              "      <td>CSAN3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.885329</td>\n",
              "      <td>0.882166</td>\n",
              "      <td>0.882586</td>\n",
              "      <td>0.882373</td>\n",
              "      <td>[[619, 69], [67, 431]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>3.640817</td>\n",
              "      <td>990.0</td>\n",
              "      <td>9467.040666</td>\n",
              "      <td>94.670407</td>\n",
              "      <td>42.269210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-04-13 14:10:15.069407</td>\n",
              "      <td>CNN Ramificado</td>\n",
              "      <td>CSAN3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.881956</td>\n",
              "      <td>0.880287</td>\n",
              "      <td>0.876629</td>\n",
              "      <td>0.878284</td>\n",
              "      <td>[[626, 62], [78, 420]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>8.435907</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>10946.335745</td>\n",
              "      <td>109.463357</td>\n",
              "      <td>42.269210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-04-13 14:37:38.702181</td>\n",
              "      <td>CNN Sequencial</td>\n",
              "      <td>BBAS3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.865823</td>\n",
              "      <td>0.861527</td>\n",
              "      <td>0.864002</td>\n",
              "      <td>0.862654</td>\n",
              "      <td>[[603, 86], [73, 423]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>39.235968</td>\n",
              "      <td>247.0</td>\n",
              "      <td>3720.565817</td>\n",
              "      <td>37.205658</td>\n",
              "      <td>42.269210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-04-13 14:37:38.727148</td>\n",
              "      <td>CNN Ramificado</td>\n",
              "      <td>BBAS3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.898734</td>\n",
              "      <td>0.897139</td>\n",
              "      <td>0.894281</td>\n",
              "      <td>0.895610</td>\n",
              "      <td>[[635, 54], [66, 430]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>38.974524</td>\n",
              "      <td>310.0</td>\n",
              "      <td>7209.874334</td>\n",
              "      <td>72.098743</td>\n",
              "      <td>42.269210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-04-13 15:02:36.679384</td>\n",
              "      <td>CNN Sequencial</td>\n",
              "      <td>PETR4</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.831255</td>\n",
              "      <td>0.839039</td>\n",
              "      <td>0.828591</td>\n",
              "      <td>0.829323</td>\n",
              "      <td>[[436, 145], [58, 564]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.062806</td>\n",
              "      <td>809.0</td>\n",
              "      <td>20128.224164</td>\n",
              "      <td>201.282242</td>\n",
              "      <td>42.937875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-04-13 15:02:36.703969</td>\n",
              "      <td>CNN Ramificado</td>\n",
              "      <td>PETR4</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.848712</td>\n",
              "      <td>0.850201</td>\n",
              "      <td>0.847515</td>\n",
              "      <td>0.848089</td>\n",
              "      <td>[[472, 109], [73, 549]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>12.695825</td>\n",
              "      <td>817.0</td>\n",
              "      <td>20437.777196</td>\n",
              "      <td>204.377772</td>\n",
              "      <td>42.937875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35ee655f-a904-40be-bfc7-64d054a81d5a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-35ee655f-a904-40be-bfc7-64d054a81d5a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-35ee655f-a904-40be-bfc7-64d054a81d5a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-afb1f04a-346d-43dc-bd94-d26b551d2bc0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-afb1f04a-346d-43dc-bd94-d26b551d2bc0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-afb1f04a-346d-43dc-bd94-d26b551d2bc0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2323893f-9660-4909-9eb9-17f0fd299b18\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('resultado_backtest')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2323893f-9660-4909-9eb9-17f0fd299b18 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('resultado_backtest');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "resultado_backtest",
              "summary": "{\n  \"name\": \"resultado_backtest\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Data\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"2025-04-13 14:10:15.041119\",\n          \"2025-04-13 14:10:15.069407\",\n          \"2025-04-13 15:02:36.703969\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"CNN Ramificado\",\n          \"CNN Sequencial\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\\u00e7\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"CSAN3\",\n          \"BBAS3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"M\\u00e9trica de Otimiza\\u00e7\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"val_loss\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Acur\\u00e1cia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0251563107418573,\n        \"min\": 0.8312551953449709,\n        \"max\": 0.8987341772151899,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.8853288364249579\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021896508404045043,\n        \"min\": 0.8390388469818356,\n        \"max\": 0.8971392697563103,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.8821661807580174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.024215653012354885,\n        \"min\": 0.828591352087265,\n        \"max\": 0.8942805140690107,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.8825855748575698\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.024384078711310465,\n        \"min\": 0.829322943057327,\n        \"max\": 0.8956100425781823,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.8823731888814018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Matriz de Confus\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Saldo Inicial\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 10000,\n        \"max\": 10000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          10000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Saldo Final\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.326002879050517,\n        \"min\": 1.0628061294373763,\n        \"max\": 39.23596763610476,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.640817165378394\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total de A\\u00e7\\u00f5es\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 346.3995765971238,\n        \"min\": 247.0,\n        \"max\": 1065.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          990.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lucro Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6874.346256102763,\n        \"min\": 3720.565816879269,\n        \"max\": 20437.777196407304,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          9467.040666103368\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lucro (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 68.74346256102763,\n        \"min\": 37.20565816879269,\n        \"max\": 204.37777196407305,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          94.67040666103368\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lucro (%) CDI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.34529726851168036,\n        \"min\": 42.2692096209317,\n        \"max\": 42.93787490615002,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          42.93787490615002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7h2OLzc1xQQ"
      },
      "source": [
        "### VALE3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "vpo7vToC1zl8"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, features = preprocess_data(vl_train, vl_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "janela_curta = features[:7]\n",
        "janela_longa = features[7:]\n",
        "X_train1, X_test1, X_train2, X_test2, y_train, y_test, features = preprocess_data(vl_train, vl_test, split_features=[janela_curta,janela_longa])"
      ],
      "metadata": {
        "id": "3l5Aw40W7Z7G"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prices = vl_test.set_index(\"Date\")[\"Close\"]\n",
        "metric_optimization = 'val_loss'"
      ],
      "metadata": {
        "id": "GIK_Gx5Y7cmn"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_seq_model, best_seq_history, df_results, best_seq_metrics, best_seq_y_pred = train_model(\n",
        "    model_fn=model_cnn_sequencial,\n",
        "    model_path = \"BEST_CNN_SEQ_VALE3.keras\",\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    prob=0.5,\n",
        "    n_trials=30,\n",
        "    metric_to_optimize=metric_optimization\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R297zqAs7iHr",
        "outputId": "6be6ab76-191b-41f4-829a-4b6888f8f3bd"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:02:36,776] A new study created in memory with name: no-name-a78a57b9-79a3-4d8e-b4fc-b9587c11c758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/28\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5545 - loss: 0.6917\n",
            "Epoch 1: val_loss improved from inf to 0.69556, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5547 - loss: 0.6916 - val_accuracy: 0.4996 - val_loss: 0.6956 - learning_rate: 0.0058\n",
            "Epoch 2/28\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5666 - loss: 0.6847\n",
            "Epoch 2: val_loss did not improve from 0.69556\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5665 - loss: 0.6847 - val_accuracy: 0.5096 - val_loss: 0.7441 - learning_rate: 0.0058\n",
            "Epoch 3/28\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5660 - loss: 0.6756\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0021603113189390183.\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.69556\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5666 - loss: 0.6751 - val_accuracy: 0.5170 - val_loss: 2.2162 - learning_rate: 0.0058\n",
            "Epoch 4/28\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6363 - loss: 0.6082\n",
            "Epoch 4: val_loss improved from 0.69556 to 0.50237, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6368 - loss: 0.6078 - val_accuracy: 0.7988 - val_loss: 0.5024 - learning_rate: 0.0022\n",
            "Epoch 5/28\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6833 - loss: 0.5713\n",
            "Epoch 5: val_loss did not improve from 0.50237\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6840 - loss: 0.5705 - val_accuracy: 0.7797 - val_loss: 0.5152 - learning_rate: 0.0022\n",
            "Epoch 6/28\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7008 - loss: 0.5288\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0008092666778605931.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.50237\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7011 - loss: 0.5288 - val_accuracy: 0.8047 - val_loss: 0.5190 - learning_rate: 0.0022\n",
            "Epoch 7/28\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7269 - loss: 0.5049\n",
            "Epoch 7: val_loss improved from 0.50237 to 0.47132, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7270 - loss: 0.5048 - val_accuracy: 0.8005 - val_loss: 0.4713 - learning_rate: 8.0927e-04\n",
            "Epoch 8/28\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7507 - loss: 0.4956\n",
            "Epoch 8: val_loss improved from 0.47132 to 0.41694, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7507 - loss: 0.4951 - val_accuracy: 0.8071 - val_loss: 0.4169 - learning_rate: 8.0927e-04\n",
            "Epoch 9/28\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7544 - loss: 0.4884\n",
            "Epoch 9: val_loss did not improve from 0.41694\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7544 - loss: 0.4883 - val_accuracy: 0.7689 - val_loss: 0.5067 - learning_rate: 8.0927e-04\n",
            "Epoch 10/28\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7549 - loss: 0.4784\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00030315658622602325.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.41694\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7560 - loss: 0.4777 - val_accuracy: 0.7914 - val_loss: 0.4422 - learning_rate: 8.0927e-04\n",
            "Epoch 11/28\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7868 - loss: 0.4534\n",
            "Epoch 11: val_loss improved from 0.41694 to 0.38857, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7867 - loss: 0.4534 - val_accuracy: 0.8155 - val_loss: 0.3886 - learning_rate: 3.0316e-04\n",
            "Epoch 12/28\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7929 - loss: 0.4423\n",
            "Epoch 12: val_loss did not improve from 0.38857\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7929 - loss: 0.4423 - val_accuracy: 0.8188 - val_loss: 0.4010 - learning_rate: 3.0316e-04\n",
            "Epoch 13/28\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.4439\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00011356443574832578.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.38857\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7987 - loss: 0.4439 - val_accuracy: 0.8188 - val_loss: 0.3941 - learning_rate: 3.0316e-04\n",
            "Epoch 14/28\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 0.4350\n",
            "Epoch 14: val_loss did not improve from 0.38857\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7993 - loss: 0.4349 - val_accuracy: 0.8163 - val_loss: 0.3957 - learning_rate: 1.1356e-04\n",
            "Epoch 15/28\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.4272\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.2541978208770304e-05.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.38857\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7990 - loss: 0.4272 - val_accuracy: 0.8188 - val_loss: 0.3976 - learning_rate: 1.1356e-04\n",
            "Epoch 16/28\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7989 - loss: 0.4266\n",
            "Epoch 16: val_loss did not improve from 0.38857\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.4265 - val_accuracy: 0.8155 - val_loss: 0.4016 - learning_rate: 4.2542e-05\n",
            "Epoch 17/28\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8079 - loss: 0.4264\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.5936502766358576e-05.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.38857\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8078 - loss: 0.4264 - val_accuracy: 0.8155 - val_loss: 0.4000 - learning_rate: 4.2542e-05\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:02:59,982] Trial 0 finished with value: -0.38857200741767883 and parameters: {'epochs': 28, 'batch_size': 32, 'learning_rate': 0.005766881191508113, 'stop_patience': 6, 'reduce_lr_factor': 0.3746065260306838, 'reduce_lr_patience': 2}. Best is trial 0 with value: -0.38857200741767883.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/24\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5557 - loss: 0.6883\n",
            "Epoch 1: val_loss improved from inf to 0.69770, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5561 - loss: 0.6882 - val_accuracy: 0.4996 - val_loss: 0.6977 - learning_rate: 3.1301e-04\n",
            "Epoch 2/24\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5591 - loss: 0.6805\n",
            "Epoch 2: val_loss did not improve from 0.69770\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5593 - loss: 0.6805 - val_accuracy: 0.5254 - val_loss: 0.7552 - learning_rate: 3.1301e-04\n",
            "Epoch 3/24\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5957 - loss: 0.6632\n",
            "Epoch 3: val_loss improved from 0.69770 to 0.52520, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5957 - loss: 0.6632 - val_accuracy: 0.7332 - val_loss: 0.5252 - learning_rate: 3.1301e-04\n",
            "Epoch 4/24\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6289 - loss: 0.6310\n",
            "Epoch 4: val_loss improved from 0.52520 to 0.48256, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6290 - loss: 0.6310 - val_accuracy: 0.7756 - val_loss: 0.4826 - learning_rate: 3.1301e-04\n",
            "Epoch 5/24\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6830 - loss: 0.5896\n",
            "Epoch 5: val_loss improved from 0.48256 to 0.45812, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6832 - loss: 0.5894 - val_accuracy: 0.8071 - val_loss: 0.4581 - learning_rate: 3.1301e-04\n",
            "Epoch 6/24\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6905 - loss: 0.5577\n",
            "Epoch 6: val_loss did not improve from 0.45812\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6910 - loss: 0.5574 - val_accuracy: 0.8071 - val_loss: 0.4762 - learning_rate: 3.1301e-04\n",
            "Epoch 7/24\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7218 - loss: 0.5215\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 6.193132299462447e-05.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.45812\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7219 - loss: 0.5214 - val_accuracy: 0.8155 - val_loss: 0.4840 - learning_rate: 3.1301e-04\n",
            "Epoch 8/24\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7495 - loss: 0.4875\n",
            "Epoch 8: val_loss did not improve from 0.45812\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7495 - loss: 0.4875 - val_accuracy: 0.7997 - val_loss: 0.5439 - learning_rate: 6.1931e-05\n",
            "Epoch 9/24\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7544 - loss: 0.4842\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.2253659013550447e-05.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.45812\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7545 - loss: 0.4842 - val_accuracy: 0.7889 - val_loss: 0.5244 - learning_rate: 6.1931e-05\n",
            "Epoch 10/24\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7686 - loss: 0.4724\n",
            "Epoch 10: val_loss improved from 0.45812 to 0.42379, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7686 - loss: 0.4724 - val_accuracy: 0.8204 - val_loss: 0.4238 - learning_rate: 1.2254e-05\n",
            "Epoch 11/24\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7788 - loss: 0.4711\n",
            "Epoch 11: val_loss improved from 0.42379 to 0.42041, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7787 - loss: 0.4711 - val_accuracy: 0.8196 - val_loss: 0.4204 - learning_rate: 1.2254e-05\n",
            "Epoch 12/24\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7829 - loss: 0.4633\n",
            "Epoch 12: val_loss did not improve from 0.42041\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7829 - loss: 0.4633 - val_accuracy: 0.8204 - val_loss: 0.4231 - learning_rate: 1.2254e-05\n",
            "Epoch 13/24\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7848 - loss: 0.4633\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 2.4244947571691374e-06.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.42041\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7847 - loss: 0.4633 - val_accuracy: 0.8196 - val_loss: 0.4218 - learning_rate: 1.2254e-05\n",
            "Epoch 14/24\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7802 - loss: 0.4632\n",
            "Epoch 14: val_loss did not improve from 0.42041\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7803 - loss: 0.4632 - val_accuracy: 0.8213 - val_loss: 0.4229 - learning_rate: 2.4245e-06\n",
            "Epoch 15/24\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7794 - loss: 0.4665\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.42041\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7794 - loss: 0.4665 - val_accuracy: 0.8213 - val_loss: 0.4228 - learning_rate: 2.4245e-06\n",
            "Epoch 16/24\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7685 - loss: 0.4675\n",
            "Epoch 16: val_loss did not improve from 0.42041\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7687 - loss: 0.4675 - val_accuracy: 0.8221 - val_loss: 0.4227 - learning_rate: 1.0000e-06\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:03:31,047] Trial 1 finished with value: -0.4204093813896179 and parameters: {'epochs': 24, 'batch_size': 16, 'learning_rate': 0.00031300763046390506, 'stop_patience': 5, 'reduce_lr_factor': 0.1978588335765783, 'reduce_lr_patience': 2}. Best is trial 0 with value: -0.38857200741767883.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/44\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5660 - loss: 0.6842\n",
            "Epoch 1: val_loss improved from inf to 0.65765, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5665 - loss: 0.6840 - val_accuracy: 0.7132 - val_loss: 0.6577 - learning_rate: 0.0032\n",
            "Epoch 2/44\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5902 - loss: 0.6640\n",
            "Epoch 2: val_loss did not improve from 0.65765\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5925 - loss: 0.6616 - val_accuracy: 0.5902 - val_loss: 1.2596 - learning_rate: 0.0032\n",
            "Epoch 3/44\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6702 - loss: 0.5800\n",
            "Epoch 3: val_loss did not improve from 0.65765\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6708 - loss: 0.5791 - val_accuracy: 0.6958 - val_loss: 1.1064 - learning_rate: 0.0032\n",
            "Epoch 4/44\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6918 - loss: 0.5362\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0016021387918292004.\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.65765\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6921 - loss: 0.5360 - val_accuracy: 0.7157 - val_loss: 0.8937 - learning_rate: 0.0032\n",
            "Epoch 5/44\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7327 - loss: 0.4965\n",
            "Epoch 5: val_loss did not improve from 0.65765\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7325 - loss: 0.4965 - val_accuracy: 0.7656 - val_loss: 0.7778 - learning_rate: 0.0016\n",
            "Epoch 5: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:03:37,318] Trial 2 finished with value: -0.6576535105705261 and parameters: {'epochs': 44, 'batch_size': 64, 'learning_rate': 0.003216905383341724, 'stop_patience': 4, 'reduce_lr_factor': 0.49803729022889276, 'reduce_lr_patience': 3}. Best is trial 0 with value: -0.38857200741767883.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/24\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5590 - loss: 0.6918\n",
            "Epoch 1: val_loss improved from inf to 0.69921, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5590 - loss: 0.6918 - val_accuracy: 0.4996 - val_loss: 0.6992 - learning_rate: 0.0069\n",
            "Epoch 2/24\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5655 - loss: 0.6859\n",
            "Epoch 2: val_loss did not improve from 0.69921\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5655 - loss: 0.6859 - val_accuracy: 0.4996 - val_loss: 0.7000 - learning_rate: 0.0069\n",
            "Epoch 3/24\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5661 - loss: 0.6853\n",
            "Epoch 3: val_loss did not improve from 0.69921\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5661 - loss: 0.6853 - val_accuracy: 0.4996 - val_loss: 0.7004 - learning_rate: 0.0069\n",
            "Epoch 4/24\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5661 - loss: 0.6850\n",
            "Epoch 4: val_loss did not improve from 0.69921\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5660 - loss: 0.6850 - val_accuracy: 0.4996 - val_loss: 0.7026 - learning_rate: 0.0069\n",
            "Epoch 5/24\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5663 - loss: 0.6851\n",
            "Epoch 5: val_loss did not improve from 0.69921\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5663 - loss: 0.6851 - val_accuracy: 0.4996 - val_loss: 0.7024 - learning_rate: 0.0069\n",
            "Epoch 6/24\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5663 - loss: 0.6847\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0008209425755841771.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.69921\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5663 - loss: 0.6847 - val_accuracy: 0.4996 - val_loss: 0.7005 - learning_rate: 0.0069\n",
            "Epoch 7/24\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5659 - loss: 0.6843\n",
            "Epoch 7: val_loss did not improve from 0.69921\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5658 - loss: 0.6843 - val_accuracy: 0.4996 - val_loss: 0.7038 - learning_rate: 8.2094e-04\n",
            "Epoch 8/24\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5661 - loss: 0.6832\n",
            "Epoch 8: val_loss did not improve from 0.69921\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5660 - loss: 0.6832 - val_accuracy: 0.4996 - val_loss: 0.7035 - learning_rate: 8.2094e-04\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "[I 2025-04-13 15:03:56,764] Trial 3 finished with value: -0.6992131471633911 and parameters: {'epochs': 24, 'batch_size': 16, 'learning_rate': 0.006864984918006564, 'stop_patience': 7, 'reduce_lr_factor': 0.11958403074809408, 'reduce_lr_patience': 5}. Best is trial 0 with value: -0.38857200741767883.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/11\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5451 - loss: 0.6888\n",
            "Epoch 1: val_loss improved from inf to 0.71658, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5456 - loss: 0.6887 - val_accuracy: 0.5021 - val_loss: 0.7166 - learning_rate: 0.0027\n",
            "Epoch 2/11\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5726 - loss: 0.6816\n",
            "Epoch 2: val_loss improved from 0.71658 to 0.46205, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5735 - loss: 0.6807 - val_accuracy: 0.7797 - val_loss: 0.4621 - learning_rate: 0.0027\n",
            "Epoch 3/11\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6391 - loss: 0.6308\n",
            "Epoch 3: val_loss did not improve from 0.46205\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6392 - loss: 0.6306 - val_accuracy: 0.7639 - val_loss: 0.5024 - learning_rate: 0.0027\n",
            "Epoch 4/11\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6789 - loss: 0.5707\n",
            "Epoch 4: val_loss improved from 0.46205 to 0.45211, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6792 - loss: 0.5704 - val_accuracy: 0.8105 - val_loss: 0.4521 - learning_rate: 0.0027\n",
            "Epoch 5/11\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7028 - loss: 0.5296\n",
            "Epoch 5: val_loss improved from 0.45211 to 0.38746, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7029 - loss: 0.5296 - val_accuracy: 0.8346 - val_loss: 0.3875 - learning_rate: 0.0027\n",
            "Epoch 6/11\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7184 - loss: 0.5105\n",
            "Epoch 6: val_loss did not improve from 0.38746\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7185 - loss: 0.5105 - val_accuracy: 0.7706 - val_loss: 0.6463 - learning_rate: 0.0027\n",
            "Epoch 7/11\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7250 - loss: 0.4942\n",
            "Epoch 7: val_loss did not improve from 0.38746\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7253 - loss: 0.4943 - val_accuracy: 0.7099 - val_loss: 0.9620 - learning_rate: 0.0027\n",
            "Epoch 8/11\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7526 - loss: 0.4587\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0007216641870677924.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.38746\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7526 - loss: 0.4595 - val_accuracy: 0.7814 - val_loss: 0.6210 - learning_rate: 0.0027\n",
            "Epoch 9/11\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7878 - loss: 0.4197\n",
            "Epoch 9: val_loss did not improve from 0.38746\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7879 - loss: 0.4199 - val_accuracy: 0.8487 - val_loss: 0.4013 - learning_rate: 7.2166e-04\n",
            "Epoch 10/11\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.4155\n",
            "Epoch 10: val_loss improved from 0.38746 to 0.35198, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7900 - loss: 0.4158 - val_accuracy: 0.8520 - val_loss: 0.3520 - learning_rate: 7.2166e-04\n",
            "Epoch 11/11\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.4034\n",
            "Epoch 11: val_loss did not improve from 0.35198\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7984 - loss: 0.4036 - val_accuracy: 0.8196 - val_loss: 0.4083 - learning_rate: 7.2166e-04\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:04:11,307] Trial 4 finished with value: -0.3519790768623352 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 0.0027488908371958195, 'stop_patience': 9, 'reduce_lr_factor': 0.2625292326422555, 'reduce_lr_patience': 3}. Best is trial 4 with value: -0.3519790768623352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/36\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5593 - loss: 0.6934\n",
            "Epoch 1: val_loss improved from inf to 0.70299, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5594 - loss: 0.6933 - val_accuracy: 0.4996 - val_loss: 0.7030 - learning_rate: 0.0075\n",
            "Epoch 2/36\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5634 - loss: 0.6856\n",
            "Epoch 2: val_loss improved from 0.70299 to 0.70047, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5633 - loss: 0.6856 - val_accuracy: 0.4996 - val_loss: 0.7005 - learning_rate: 0.0075\n",
            "Epoch 3/36\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5666 - loss: 0.6850\n",
            "Epoch 3: val_loss improved from 0.70047 to 0.69919, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5665 - loss: 0.6850 - val_accuracy: 0.4996 - val_loss: 0.6992 - learning_rate: 0.0075\n",
            "Epoch 4/36\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5665 - loss: 0.6841\n",
            "Epoch 4: val_loss did not improve from 0.69919\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5665 - loss: 0.6841 - val_accuracy: 0.4996 - val_loss: 0.7970 - learning_rate: 0.0075\n",
            "Epoch 5/36\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5674 - loss: 0.6723\n",
            "Epoch 5: val_loss improved from 0.69919 to 0.65895, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5675 - loss: 0.6717 - val_accuracy: 0.6093 - val_loss: 0.6589 - learning_rate: 0.0075\n",
            "Epoch 6/36\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6238 - loss: 0.6105\n",
            "Epoch 6: val_loss did not improve from 0.65895\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6247 - loss: 0.6099 - val_accuracy: 0.4996 - val_loss: 2.5123 - learning_rate: 0.0075\n",
            "Epoch 7/36\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6654 - loss: 0.5836\n",
            "Epoch 7: val_loss improved from 0.65895 to 0.49951, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6662 - loss: 0.5828 - val_accuracy: 0.7839 - val_loss: 0.4995 - learning_rate: 0.0075\n",
            "Epoch 8/36\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6925 - loss: 0.5545\n",
            "Epoch 8: val_loss did not improve from 0.49951\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6933 - loss: 0.5540 - val_accuracy: 0.7648 - val_loss: 0.5518 - learning_rate: 0.0075\n",
            "Epoch 9/36\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7075 - loss: 0.5482\n",
            "Epoch 9: val_loss did not improve from 0.49951\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7075 - loss: 0.5485 - val_accuracy: 0.7681 - val_loss: 0.5335 - learning_rate: 0.0075\n",
            "Epoch 10/36\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7149 - loss: 0.5417\n",
            "Epoch 10: val_loss did not improve from 0.49951\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7151 - loss: 0.5421 - val_accuracy: 0.7656 - val_loss: 0.5318 - learning_rate: 0.0075\n",
            "Epoch 11/36\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7190 - loss: 0.5295\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0035242281254206755.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.49951\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.5296 - val_accuracy: 0.7373 - val_loss: 0.5737 - learning_rate: 0.0075\n",
            "Epoch 12/36\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7443 - loss: 0.5042\n",
            "Epoch 12: val_loss did not improve from 0.49951\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7443 - loss: 0.5041 - val_accuracy: 0.7714 - val_loss: 0.5443 - learning_rate: 0.0035\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:04:27,282] Trial 5 finished with value: -0.4995071589946747 and parameters: {'epochs': 36, 'batch_size': 32, 'learning_rate': 0.007454504574945669, 'stop_patience': 5, 'reduce_lr_factor': 0.472764892588297, 'reduce_lr_patience': 4}. Best is trial 4 with value: -0.3519790768623352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/19\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5498 - loss: 0.6896\n",
            "Epoch 1: val_loss improved from inf to 0.69675, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.5501 - loss: 0.6895 - val_accuracy: 0.4605 - val_loss: 0.6967 - learning_rate: 0.0067\n",
            "Epoch 2/19\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5641 - loss: 0.6862\n",
            "Epoch 2: val_loss improved from 0.69675 to 0.69526, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5641 - loss: 0.6861 - val_accuracy: 0.4996 - val_loss: 0.6953 - learning_rate: 0.0067\n",
            "Epoch 3/19\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5662 - loss: 0.6845\n",
            "Epoch 3: val_loss improved from 0.69526 to 0.69383, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5662 - loss: 0.6845 - val_accuracy: 0.5578 - val_loss: 0.6938 - learning_rate: 0.0067\n",
            "Epoch 4/19\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5739 - loss: 0.6749\n",
            "Epoch 4: val_loss did not improve from 0.69383\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5739 - loss: 0.6747 - val_accuracy: 0.4996 - val_loss: 1.0954 - learning_rate: 0.0067\n",
            "Epoch 5/19\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6257 - loss: 0.6240\n",
            "Epoch 5: val_loss improved from 0.69383 to 0.55409, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6259 - loss: 0.6237 - val_accuracy: 0.8138 - val_loss: 0.5541 - learning_rate: 0.0067\n",
            "Epoch 6/19\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6695 - loss: 0.5833\n",
            "Epoch 6: val_loss did not improve from 0.55409\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6695 - loss: 0.5836 - val_accuracy: 0.8105 - val_loss: 0.6748 - learning_rate: 0.0067\n",
            "Epoch 7/19\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7014 - loss: 0.5364\n",
            "Epoch 7: val_loss did not improve from 0.55409\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7010 - loss: 0.5365 - val_accuracy: 0.7697 - val_loss: 0.7879 - learning_rate: 0.0067\n",
            "Epoch 8/19\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7066 - loss: 0.5233\n",
            "Epoch 8: val_loss improved from 0.55409 to 0.40099, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7067 - loss: 0.5235 - val_accuracy: 0.8121 - val_loss: 0.4010 - learning_rate: 0.0067\n",
            "Epoch 9/19\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7224 - loss: 0.5158\n",
            "Epoch 9: val_loss did not improve from 0.40099\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7225 - loss: 0.5157 - val_accuracy: 0.8071 - val_loss: 0.4212 - learning_rate: 0.0067\n",
            "Epoch 10/19\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7328 - loss: 0.5018\n",
            "Epoch 10: val_loss did not improve from 0.40099\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7326 - loss: 0.5021 - val_accuracy: 0.7722 - val_loss: 0.5193 - learning_rate: 0.0067\n",
            "Epoch 11/19\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7403 - loss: 0.4888\n",
            "Epoch 11: val_loss improved from 0.40099 to 0.38983, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7403 - loss: 0.4892 - val_accuracy: 0.8246 - val_loss: 0.3898 - learning_rate: 0.0067\n",
            "Epoch 12/19\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7406 - loss: 0.4979\n",
            "Epoch 12: val_loss did not improve from 0.38983\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7402 - loss: 0.4983 - val_accuracy: 0.7390 - val_loss: 0.5553 - learning_rate: 0.0067\n",
            "Epoch 13/19\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7405 - loss: 0.4999\n",
            "Epoch 13: val_loss did not improve from 0.38983\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7400 - loss: 0.5002 - val_accuracy: 0.8146 - val_loss: 0.4088 - learning_rate: 0.0067\n",
            "Epoch 14/19\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7388 - loss: 0.4882\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0030712606247277727.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.38983\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7390 - loss: 0.4881 - val_accuracy: 0.8088 - val_loss: 0.4099 - learning_rate: 0.0067\n",
            "Epoch 15/19\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7562 - loss: 0.4659\n",
            "Epoch 15: val_loss did not improve from 0.38983\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7563 - loss: 0.4659 - val_accuracy: 0.8063 - val_loss: 0.4558 - learning_rate: 0.0031\n",
            "Epoch 16/19\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7695 - loss: 0.4558\n",
            "Epoch 16: val_loss did not improve from 0.38983\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7694 - loss: 0.4560 - val_accuracy: 0.8146 - val_loss: 0.4132 - learning_rate: 0.0031\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:04:49,256] Trial 6 finished with value: -0.38983431458473206 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.006687145121162215, 'stop_patience': 5, 'reduce_lr_factor': 0.45927829084008054, 'reduce_lr_patience': 3}. Best is trial 4 with value: -0.3519790768623352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/21\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5518 - loss: 0.6905\n",
            "Epoch 1: val_loss improved from inf to 0.69640, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5519 - loss: 0.6905 - val_accuracy: 0.4996 - val_loss: 0.6964 - learning_rate: 0.0039\n",
            "Epoch 2/21\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5663 - loss: 0.6854\n",
            "Epoch 2: val_loss did not improve from 0.69640\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5663 - loss: 0.6854 - val_accuracy: 0.4996 - val_loss: 0.6987 - learning_rate: 0.0039\n",
            "Epoch 3/21\n",
            "\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5666 - loss: 0.6846\n",
            "Epoch 3: val_loss did not improve from 0.69640\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5666 - loss: 0.6846 - val_accuracy: 0.4996 - val_loss: 0.7056 - learning_rate: 0.0039\n",
            "Epoch 4/21\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5663 - loss: 0.6845\n",
            "Epoch 4: val_loss did not improve from 0.69640\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5663 - loss: 0.6845 - val_accuracy: 0.4996 - val_loss: 0.7047 - learning_rate: 0.0039\n",
            "Epoch 4: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "[I 2025-04-13 15:04:58,773] Trial 7 finished with value: -0.6964004635810852 and parameters: {'epochs': 21, 'batch_size': 16, 'learning_rate': 0.003866208875984224, 'stop_patience': 3, 'reduce_lr_factor': 0.37675604722827105, 'reduce_lr_patience': 4}. Best is trial 4 with value: -0.3519790768623352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/11\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5532 - loss: 0.6852\n",
            "Epoch 1: val_loss improved from inf to 0.71345, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5547 - loss: 0.6850 - val_accuracy: 0.5104 - val_loss: 0.7134 - learning_rate: 0.0045\n",
            "Epoch 2/11\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5765 - loss: 0.6776\n",
            "Epoch 2: val_loss did not improve from 0.71345\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5782 - loss: 0.6761 - val_accuracy: 0.6243 - val_loss: 0.7556 - learning_rate: 0.0045\n",
            "Epoch 3/11\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6319 - loss: 0.6073\n",
            "Epoch 3: val_loss did not improve from 0.71345\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6315 - loss: 0.6077 - val_accuracy: 0.5852 - val_loss: 0.9138 - learning_rate: 0.0045\n",
            "Epoch 4/11\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6974 - loss: 0.5402\n",
            "Epoch 4: val_loss improved from 0.71345 to 0.67379, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6972 - loss: 0.5403 - val_accuracy: 0.6991 - val_loss: 0.6738 - learning_rate: 0.0045\n",
            "Epoch 5/11\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7141 - loss: 0.5035\n",
            "Epoch 5: val_loss improved from 0.67379 to 0.39798, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7143 - loss: 0.5035 - val_accuracy: 0.8246 - val_loss: 0.3980 - learning_rate: 0.0045\n",
            "Epoch 6/11\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7287 - loss: 0.4836\n",
            "Epoch 6: val_loss improved from 0.39798 to 0.35250, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7288 - loss: 0.4837 - val_accuracy: 0.8429 - val_loss: 0.3525 - learning_rate: 0.0045\n",
            "Epoch 7/11\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7676 - loss: 0.4459\n",
            "Epoch 7: val_loss did not improve from 0.35250\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7662 - loss: 0.4489 - val_accuracy: 0.8512 - val_loss: 0.3711 - learning_rate: 0.0045\n",
            "Epoch 8/11\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7559 - loss: 0.4611\n",
            "Epoch 8: val_loss did not improve from 0.35250\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7552 - loss: 0.4627 - val_accuracy: 0.7739 - val_loss: 0.5204 - learning_rate: 0.0045\n",
            "Epoch 9/11\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7647 - loss: 0.4468\n",
            "Epoch 9: val_loss did not improve from 0.35250\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7643 - loss: 0.4475 - val_accuracy: 0.8379 - val_loss: 0.3726 - learning_rate: 0.0045\n",
            "Epoch 10/11\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7565 - loss: 0.4426\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008873294053397367.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.35250\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7565 - loss: 0.4427 - val_accuracy: 0.8387 - val_loss: 0.3690 - learning_rate: 0.0045\n",
            "Epoch 11/11\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7737 - loss: 0.4292\n",
            "Epoch 11: val_loss did not improve from 0.35250\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7737 - loss: 0.4292 - val_accuracy: 0.8288 - val_loss: 0.3853 - learning_rate: 8.8733e-04\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:05:09,659] Trial 8 finished with value: -0.3525041937828064 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 0.004538606144512357, 'stop_patience': 6, 'reduce_lr_factor': 0.19550703911962658, 'reduce_lr_patience': 4}. Best is trial 4 with value: -0.3519790768623352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/28\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5493 - loss: 0.6876\n",
            "Epoch 1: val_loss improved from inf to 0.80712, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5497 - loss: 0.6874 - val_accuracy: 0.5071 - val_loss: 0.8071 - learning_rate: 0.0028\n",
            "Epoch 2/28\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5775 - loss: 0.6716\n",
            "Epoch 2: val_loss did not improve from 0.80712\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5793 - loss: 0.6701 - val_accuracy: 0.6010 - val_loss: 0.9506 - learning_rate: 0.0028\n",
            "Epoch 3/28\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6516 - loss: 0.5978\n",
            "Epoch 3: val_loss improved from 0.80712 to 0.39593, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6533 - loss: 0.5963 - val_accuracy: 0.8304 - val_loss: 0.3959 - learning_rate: 0.0028\n",
            "Epoch 4/28\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7129 - loss: 0.5238\n",
            "Epoch 4: val_loss improved from 0.39593 to 0.38053, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7124 - loss: 0.5249 - val_accuracy: 0.8337 - val_loss: 0.3805 - learning_rate: 0.0028\n",
            "Epoch 5/28\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7313 - loss: 0.4872\n",
            "Epoch 5: val_loss did not improve from 0.38053\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7313 - loss: 0.4873 - val_accuracy: 0.7623 - val_loss: 0.6791 - learning_rate: 0.0028\n",
            "Epoch 6/28\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7346 - loss: 0.4870\n",
            "Epoch 6: val_loss improved from 0.38053 to 0.37648, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7347 - loss: 0.4870 - val_accuracy: 0.8412 - val_loss: 0.3765 - learning_rate: 0.0028\n",
            "Epoch 7/28\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7616 - loss: 0.4631\n",
            "Epoch 7: val_loss improved from 0.37648 to 0.36336, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7616 - loss: 0.4634 - val_accuracy: 0.8412 - val_loss: 0.3634 - learning_rate: 0.0028\n",
            "Epoch 8/28\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4445\n",
            "Epoch 8: val_loss did not improve from 0.36336\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7731 - loss: 0.4448 - val_accuracy: 0.8263 - val_loss: 0.4460 - learning_rate: 0.0028\n",
            "Epoch 9/28\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7826 - loss: 0.4322\n",
            "Epoch 9: val_loss did not improve from 0.36336\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7824 - loss: 0.4325 - val_accuracy: 0.8163 - val_loss: 0.4809 - learning_rate: 0.0028\n",
            "Epoch 10/28\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7834 - loss: 0.4260\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00031821073766837845.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.36336\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7828 - loss: 0.4267 - val_accuracy: 0.8204 - val_loss: 0.4784 - learning_rate: 0.0028\n",
            "Epoch 11/28\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7843 - loss: 0.4232\n",
            "Epoch 11: val_loss did not improve from 0.36336\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7844 - loss: 0.4231 - val_accuracy: 0.8346 - val_loss: 0.3681 - learning_rate: 3.1821e-04\n",
            "Epoch 12/28\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8090 - loss: 0.3977\n",
            "Epoch 12: val_loss did not improve from 0.36336\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8090 - loss: 0.3978 - val_accuracy: 0.8329 - val_loss: 0.3885 - learning_rate: 3.1821e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:05:20,136] Trial 9 finished with value: -0.3633597493171692 and parameters: {'epochs': 28, 'batch_size': 64, 'learning_rate': 0.0028003582065748668, 'stop_patience': 5, 'reduce_lr_factor': 0.11363215414889966, 'reduce_lr_patience': 3}. Best is trial 4 with value: -0.3519790768623352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5453 - loss: 0.6930\n",
            "Epoch 1: val_loss improved from inf to 0.70118, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5465 - loss: 0.6927 - val_accuracy: 0.4996 - val_loss: 0.7012 - learning_rate: 0.0094\n",
            "Epoch 2/10\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5666 - loss: 0.6851\n",
            "Epoch 2: val_loss improved from 0.70118 to 0.69653, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5665 - loss: 0.6851 - val_accuracy: 0.4996 - val_loss: 0.6965 - learning_rate: 0.0094\n",
            "Epoch 3/10\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5666 - loss: 0.6864\n",
            "Epoch 3: val_loss did not improve from 0.69653\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5665 - loss: 0.6864 - val_accuracy: 0.4996 - val_loss: 0.7017 - learning_rate: 0.0094\n",
            "Epoch 4/10\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5666 - loss: 0.6849\n",
            "Epoch 4: val_loss did not improve from 0.69653\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5665 - loss: 0.6849 - val_accuracy: 0.4996 - val_loss: 0.7212 - learning_rate: 0.0094\n",
            "Epoch 5/10\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5665 - loss: 0.6852\n",
            "Epoch 5: val_loss did not improve from 0.69653\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5665 - loss: 0.6852 - val_accuracy: 0.4996 - val_loss: 0.7039 - learning_rate: 0.0094\n",
            "Epoch 6/10\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5665 - loss: 0.6845\n",
            "Epoch 6: val_loss did not improve from 0.69653\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5665 - loss: 0.6845 - val_accuracy: 0.4996 - val_loss: 0.7019 - learning_rate: 0.0094\n",
            "Epoch 7/10\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5665 - loss: 0.6840\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.002448011602938525.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.69653\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5665 - loss: 0.6840 - val_accuracy: 0.4996 - val_loss: 0.8920 - learning_rate: 0.0094\n",
            "Epoch 8/10\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5834 - loss: 0.6625\n",
            "Epoch 8: val_loss did not improve from 0.69653\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5841 - loss: 0.6619 - val_accuracy: 0.7282 - val_loss: 0.7174 - learning_rate: 0.0024\n",
            "Epoch 9/10\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6358 - loss: 0.6003\n",
            "Epoch 9: val_loss improved from 0.69653 to 0.66334, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6361 - loss: 0.6001 - val_accuracy: 0.7672 - val_loss: 0.6633 - learning_rate: 0.0024\n",
            "Epoch 10/10\n",
            "\u001b[1m137/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6673 - loss: 0.5803\n",
            "Epoch 10: val_loss improved from 0.66334 to 0.53590, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6672 - loss: 0.5808 - val_accuracy: 0.7922 - val_loss: 0.5359 - learning_rate: 0.0024\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:05:35,275] Trial 10 finished with value: -0.5358989238739014 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 0.009393035529964462, 'stop_patience': 10, 'reduce_lr_factor': 0.26061986245988755, 'reduce_lr_patience': 5}. Best is trial 4 with value: -0.3519790768623352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/11\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5583 - loss: 0.6867\n",
            "Epoch 1: val_loss improved from inf to 0.77270, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5595 - loss: 0.6861 - val_accuracy: 0.5079 - val_loss: 0.7727 - learning_rate: 0.0010\n",
            "Epoch 2/11\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5798 - loss: 0.6713\n",
            "Epoch 2: val_loss did not improve from 0.77270\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5798 - loss: 0.6710 - val_accuracy: 0.5079 - val_loss: 0.9331 - learning_rate: 0.0010\n",
            "Epoch 3/11\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5965 - loss: 0.6491\n",
            "Epoch 3: val_loss improved from 0.77270 to 0.47084, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5988 - loss: 0.6469 - val_accuracy: 0.7697 - val_loss: 0.4708 - learning_rate: 0.0010\n",
            "Epoch 4/11\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6889 - loss: 0.5616\n",
            "Epoch 4: val_loss did not improve from 0.47084\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6894 - loss: 0.5612 - val_accuracy: 0.7963 - val_loss: 0.5476 - learning_rate: 0.0010\n",
            "Epoch 5/11\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.5080\n",
            "Epoch 5: val_loss did not improve from 0.47084\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7324 - loss: 0.5082 - val_accuracy: 0.7722 - val_loss: 0.6240 - learning_rate: 0.0010\n",
            "Epoch 6/11\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7418 - loss: 0.4901\n",
            "Epoch 6: val_loss did not improve from 0.47084\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7418 - loss: 0.4901 - val_accuracy: 0.7789 - val_loss: 0.6497 - learning_rate: 0.0010\n",
            "Epoch 7/11\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7431 - loss: 0.4737\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00023308228297782012.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.47084\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7443 - loss: 0.4728 - val_accuracy: 0.8304 - val_loss: 0.4812 - learning_rate: 0.0010\n",
            "Epoch 8/11\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7705 - loss: 0.4518\n",
            "Epoch 8: val_loss did not improve from 0.47084\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7710 - loss: 0.4513 - val_accuracy: 0.7839 - val_loss: 0.5792 - learning_rate: 2.3308e-04\n",
            "Epoch 9/11\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7862 - loss: 0.4469\n",
            "Epoch 9: val_loss did not improve from 0.47084\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7857 - loss: 0.4468 - val_accuracy: 0.7930 - val_loss: 0.4782 - learning_rate: 2.3308e-04\n",
            "Epoch 10/11\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7785 - loss: 0.4375\n",
            "Epoch 10: val_loss improved from 0.47084 to 0.39066, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7786 - loss: 0.4375 - val_accuracy: 0.8329 - val_loss: 0.3907 - learning_rate: 2.3308e-04\n",
            "Epoch 11/11\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7859 - loss: 0.4331\n",
            "Epoch 11: val_loss improved from 0.39066 to 0.36834, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7852 - loss: 0.4334 - val_accuracy: 0.8379 - val_loss: 0.3683 - learning_rate: 2.3308e-04\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:05:45,725] Trial 11 finished with value: -0.3683392107486725 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 0.0010212313843109486, 'stop_patience': 9, 'reduce_lr_factor': 0.2282365006591205, 'reduce_lr_patience': 4}. Best is trial 4 with value: -0.3519790768623352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/17\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5537 - loss: 0.6880\n",
            "Epoch 1: val_loss improved from inf to 0.77057, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5552 - loss: 0.6875 - val_accuracy: 0.5112 - val_loss: 0.7706 - learning_rate: 0.0019\n",
            "Epoch 2/17\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5798 - loss: 0.6774\n",
            "Epoch 2: val_loss improved from 0.77057 to 0.47468, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5809 - loss: 0.6763 - val_accuracy: 0.7930 - val_loss: 0.4747 - learning_rate: 0.0019\n",
            "Epoch 3/17\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6574 - loss: 0.6039\n",
            "Epoch 3: val_loss did not improve from 0.47468\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6588 - loss: 0.6024 - val_accuracy: 0.8013 - val_loss: 0.4915 - learning_rate: 0.0019\n",
            "Epoch 4/17\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7153 - loss: 0.5354\n",
            "Epoch 4: val_loss did not improve from 0.47468\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7137 - loss: 0.5367 - val_accuracy: 0.8080 - val_loss: 0.4927 - learning_rate: 0.0019\n",
            "Epoch 5/17\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7392 - loss: 0.4928\n",
            "Epoch 5: val_loss did not improve from 0.47468\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7402 - loss: 0.4926 - val_accuracy: 0.8229 - val_loss: 0.5217 - learning_rate: 0.0019\n",
            "Epoch 6/17\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7508 - loss: 0.4632\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005924532736080035.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.47468\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7519 - loss: 0.4630 - val_accuracy: 0.8105 - val_loss: 0.6366 - learning_rate: 0.0019\n",
            "Epoch 7/17\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7682 - loss: 0.4575\n",
            "Epoch 7: val_loss improved from 0.47468 to 0.45391, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7684 - loss: 0.4567 - val_accuracy: 0.8379 - val_loss: 0.4539 - learning_rate: 5.9245e-04\n",
            "Epoch 8/17\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7856 - loss: 0.4284\n",
            "Epoch 8: val_loss improved from 0.45391 to 0.37533, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7856 - loss: 0.4285 - val_accuracy: 0.8404 - val_loss: 0.3753 - learning_rate: 5.9245e-04\n",
            "Epoch 9/17\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7886 - loss: 0.4183\n",
            "Epoch 9: val_loss did not improve from 0.37533\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7886 - loss: 0.4185 - val_accuracy: 0.7581 - val_loss: 0.6368 - learning_rate: 5.9245e-04\n",
            "Epoch 10/17\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7788 - loss: 0.4196\n",
            "Epoch 10: val_loss improved from 0.37533 to 0.34892, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7804 - loss: 0.4187 - val_accuracy: 0.8520 - val_loss: 0.3489 - learning_rate: 5.9245e-04\n",
            "Epoch 11/17\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7830 - loss: 0.4141\n",
            "Epoch 11: val_loss did not improve from 0.34892\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7832 - loss: 0.4140 - val_accuracy: 0.8470 - val_loss: 0.3880 - learning_rate: 5.9245e-04\n",
            "Epoch 12/17\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8073 - loss: 0.4008\n",
            "Epoch 12: val_loss did not improve from 0.34892\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8067 - loss: 0.4020 - val_accuracy: 0.8404 - val_loss: 0.4282 - learning_rate: 5.9245e-04\n",
            "Epoch 13/17\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8045 - loss: 0.4010\n",
            "Epoch 13: val_loss did not improve from 0.34892\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8043 - loss: 0.4011 - val_accuracy: 0.8362 - val_loss: 0.3498 - learning_rate: 5.9245e-04\n",
            "Epoch 14/17\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8125 - loss: 0.3859\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.000187336717607927.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.34892\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8121 - loss: 0.3871 - val_accuracy: 0.8354 - val_loss: 0.4086 - learning_rate: 5.9245e-04\n",
            "Epoch 15/17\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7994 - loss: 0.3983\n",
            "Epoch 15: val_loss improved from 0.34892 to 0.33782, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8002 - loss: 0.3980 - val_accuracy: 0.8504 - val_loss: 0.3378 - learning_rate: 1.8734e-04\n",
            "Epoch 16/17\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8141 - loss: 0.3746\n",
            "Epoch 16: val_loss did not improve from 0.33782\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8142 - loss: 0.3747 - val_accuracy: 0.8446 - val_loss: 0.3499 - learning_rate: 1.8734e-04\n",
            "Epoch 17/17\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8401 - loss: 0.3701\n",
            "Epoch 17: val_loss did not improve from 0.33782\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8389 - loss: 0.3707 - val_accuracy: 0.8412 - val_loss: 0.3499 - learning_rate: 1.8734e-04\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:05:59,455] Trial 12 finished with value: -0.33781784772872925 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 0.0018736363845014876, 'stop_patience': 8, 'reduce_lr_factor': 0.3162050428868693, 'reduce_lr_patience': 4}. Best is trial 12 with value: -0.33781784772872925.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/17\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5543 - loss: 0.6864\n",
            "Epoch 1: val_loss improved from inf to 0.66620, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5552 - loss: 0.6862 - val_accuracy: 0.5919 - val_loss: 0.6662 - learning_rate: 0.0021\n",
            "Epoch 2/17\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5741 - loss: 0.6654\n",
            "Epoch 2: val_loss did not improve from 0.66620\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5749 - loss: 0.6648 - val_accuracy: 0.5403 - val_loss: 1.8193 - learning_rate: 0.0021\n",
            "Epoch 3/17\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6468 - loss: 0.5962\n",
            "Epoch 3: val_loss improved from 0.66620 to 0.66273, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6476 - loss: 0.5959 - val_accuracy: 0.7573 - val_loss: 0.6627 - learning_rate: 0.0021\n",
            "Epoch 4/17\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6754 - loss: 0.5597\n",
            "Epoch 4: val_loss improved from 0.66273 to 0.43061, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6763 - loss: 0.5592 - val_accuracy: 0.8121 - val_loss: 0.4306 - learning_rate: 0.0021\n",
            "Epoch 5/17\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7246 - loss: 0.5108\n",
            "Epoch 5: val_loss did not improve from 0.43061\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7246 - loss: 0.5110 - val_accuracy: 0.7830 - val_loss: 0.5988 - learning_rate: 0.0021\n",
            "Epoch 6/17\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7255 - loss: 0.4857\n",
            "Epoch 6: val_loss did not improve from 0.43061\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7254 - loss: 0.4858 - val_accuracy: 0.6783 - val_loss: 0.6666 - learning_rate: 0.0021\n",
            "Epoch 7/17\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7428 - loss: 0.4784\n",
            "Epoch 7: val_loss improved from 0.43061 to 0.34629, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7426 - loss: 0.4787 - val_accuracy: 0.8470 - val_loss: 0.3463 - learning_rate: 0.0021\n",
            "Epoch 8/17\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7314 - loss: 0.4748\n",
            "Epoch 8: val_loss did not improve from 0.34629\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7319 - loss: 0.4750 - val_accuracy: 0.7440 - val_loss: 0.7662 - learning_rate: 0.0021\n",
            "Epoch 9/17\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7589 - loss: 0.4595\n",
            "Epoch 9: val_loss did not improve from 0.34629\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7586 - loss: 0.4603 - val_accuracy: 0.8296 - val_loss: 0.4722 - learning_rate: 0.0021\n",
            "Epoch 10/17\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7646 - loss: 0.4467\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0006892979532263818.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.34629\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7646 - loss: 0.4468 - val_accuracy: 0.8421 - val_loss: 0.4034 - learning_rate: 0.0021\n",
            "Epoch 11/17\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7707 - loss: 0.4290\n",
            "Epoch 11: val_loss did not improve from 0.34629\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7717 - loss: 0.4285 - val_accuracy: 0.8454 - val_loss: 0.3782 - learning_rate: 6.8930e-04\n",
            "Epoch 12/17\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8022 - loss: 0.3985\n",
            "Epoch 12: val_loss did not improve from 0.34629\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8020 - loss: 0.3989 - val_accuracy: 0.8279 - val_loss: 0.4265 - learning_rate: 6.8930e-04\n",
            "Epoch 13/17\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8100 - loss: 0.3853\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002242822659244753.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.34629\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8100 - loss: 0.3855 - val_accuracy: 0.8138 - val_loss: 0.4405 - learning_rate: 6.8930e-04\n",
            "Epoch 14/17\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8238 - loss: 0.3703\n",
            "Epoch 14: val_loss improved from 0.34629 to 0.34302, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8239 - loss: 0.3705 - val_accuracy: 0.8412 - val_loss: 0.3430 - learning_rate: 2.2428e-04\n",
            "Epoch 15/17\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8289 - loss: 0.3601\n",
            "Epoch 15: val_loss improved from 0.34302 to 0.33531, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8289 - loss: 0.3606 - val_accuracy: 0.8421 - val_loss: 0.3353 - learning_rate: 2.2428e-04\n",
            "Epoch 16/17\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8249 - loss: 0.3600\n",
            "Epoch 16: val_loss improved from 0.33531 to 0.33493, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8250 - loss: 0.3600 - val_accuracy: 0.8537 - val_loss: 0.3349 - learning_rate: 2.2428e-04\n",
            "Epoch 17/17\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8203 - loss: 0.3620\n",
            "Epoch 17: val_loss improved from 0.33493 to 0.33267, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8208 - loss: 0.3622 - val_accuracy: 0.8495 - val_loss: 0.3327 - learning_rate: 2.2428e-04\n",
            "Restoring model weights from the end of the best epoch: 17.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:06:21,137] Trial 13 finished with value: -0.3326718509197235 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.0021184541348516547, 'stop_patience': 8, 'reduce_lr_factor': 0.32537781163323903, 'reduce_lr_patience': 3}. Best is trial 13 with value: -0.3326718509197235.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5386 - loss: 0.6893\n",
            "Epoch 1: val_loss improved from inf to 0.70024, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5408 - loss: 0.6888 - val_accuracy: 0.5403 - val_loss: 0.7002 - learning_rate: 0.0017\n",
            "Epoch 2/16\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5653 - loss: 0.6779\n",
            "Epoch 2: val_loss did not improve from 0.70024\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5660 - loss: 0.6776 - val_accuracy: 0.5436 - val_loss: 0.7162 - learning_rate: 0.0017\n",
            "Epoch 3/16\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6010 - loss: 0.6429\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005869009222034118.\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.70024\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6013 - loss: 0.6427 - val_accuracy: 0.6359 - val_loss: 1.0686 - learning_rate: 0.0017\n",
            "Epoch 4/16\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7066 - loss: 0.5434\n",
            "Epoch 4: val_loss improved from 0.70024 to 0.50049, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7069 - loss: 0.5432 - val_accuracy: 0.7988 - val_loss: 0.5005 - learning_rate: 5.8690e-04\n",
            "Epoch 5/16\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7294 - loss: 0.5150\n",
            "Epoch 5: val_loss improved from 0.50049 to 0.46757, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7294 - loss: 0.5150 - val_accuracy: 0.8096 - val_loss: 0.4676 - learning_rate: 5.8690e-04\n",
            "Epoch 6/16\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7493 - loss: 0.4808\n",
            "Epoch 6: val_loss did not improve from 0.46757\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7495 - loss: 0.4807 - val_accuracy: 0.7930 - val_loss: 0.5605 - learning_rate: 5.8690e-04\n",
            "Epoch 7/16\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7529 - loss: 0.4727\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00020392585365172655.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.46757\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7531 - loss: 0.4723 - val_accuracy: 0.8130 - val_loss: 0.4697 - learning_rate: 5.8690e-04\n",
            "Epoch 8/16\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 0.4486\n",
            "Epoch 8: val_loss improved from 0.46757 to 0.39459, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7814 - loss: 0.4485 - val_accuracy: 0.8354 - val_loss: 0.3946 - learning_rate: 2.0393e-04\n",
            "Epoch 9/16\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.4307\n",
            "Epoch 9: val_loss improved from 0.39459 to 0.38719, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7917 - loss: 0.4314 - val_accuracy: 0.8362 - val_loss: 0.3872 - learning_rate: 2.0393e-04\n",
            "Epoch 10/16\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7915 - loss: 0.4283\n",
            "Epoch 10: val_loss improved from 0.38719 to 0.37997, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7914 - loss: 0.4282 - val_accuracy: 0.8387 - val_loss: 0.3800 - learning_rate: 2.0393e-04\n",
            "Epoch 11/16\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7933 - loss: 0.4237\n",
            "Epoch 11: val_loss improved from 0.37997 to 0.37768, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7928 - loss: 0.4237 - val_accuracy: 0.8354 - val_loss: 0.3777 - learning_rate: 2.0393e-04\n",
            "Epoch 12/16\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7931 - loss: 0.4166\n",
            "Epoch 12: val_loss did not improve from 0.37768\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7931 - loss: 0.4169 - val_accuracy: 0.8337 - val_loss: 0.3881 - learning_rate: 2.0393e-04\n",
            "Epoch 13/16\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8081 - loss: 0.4081\n",
            "Epoch 13: val_loss improved from 0.37768 to 0.36850, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8079 - loss: 0.4082 - val_accuracy: 0.8362 - val_loss: 0.3685 - learning_rate: 2.0393e-04\n",
            "Epoch 14/16\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.4128\n",
            "Epoch 14: val_loss improved from 0.36850 to 0.35956, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8032 - loss: 0.4128 - val_accuracy: 0.8387 - val_loss: 0.3596 - learning_rate: 2.0393e-04\n",
            "Epoch 15/16\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8122 - loss: 0.4052\n",
            "Epoch 15: val_loss improved from 0.35956 to 0.35198, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8119 - loss: 0.4052 - val_accuracy: 0.8362 - val_loss: 0.3520 - learning_rate: 2.0393e-04\n",
            "Epoch 16/16\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8124 - loss: 0.4051\n",
            "Epoch 16: val_loss improved from 0.35198 to 0.34590, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8122 - loss: 0.4049 - val_accuracy: 0.8387 - val_loss: 0.3459 - learning_rate: 2.0393e-04\n",
            "Restoring model weights from the end of the best epoch: 16.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:06:34,929] Trial 14 finished with value: -0.3458998203277588 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 0.0016891074747643858, 'stop_patience': 8, 'reduce_lr_factor': 0.34746214786946217, 'reduce_lr_patience': 2}. Best is trial 13 with value: -0.3326718509197235.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/34\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5475 - loss: 0.6891\n",
            "Epoch 1: val_loss improved from inf to 0.72045, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5489 - loss: 0.6888 - val_accuracy: 0.5204 - val_loss: 0.7205 - learning_rate: 0.0020\n",
            "Epoch 2/34\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5706 - loss: 0.6781\n",
            "Epoch 2: val_loss improved from 0.72045 to 0.69449, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5712 - loss: 0.6775 - val_accuracy: 0.6417 - val_loss: 0.6945 - learning_rate: 0.0020\n",
            "Epoch 3/34\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6573 - loss: 0.6047\n",
            "Epoch 3: val_loss did not improve from 0.69449\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6577 - loss: 0.6043 - val_accuracy: 0.5985 - val_loss: 1.8265 - learning_rate: 0.0020\n",
            "Epoch 4/34\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6691 - loss: 0.5842\n",
            "Epoch 4: val_loss did not improve from 0.69449\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6711 - loss: 0.5824 - val_accuracy: 0.7382 - val_loss: 0.7447 - learning_rate: 0.0020\n",
            "Epoch 5/34\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7129 - loss: 0.5179\n",
            "Epoch 5: val_loss improved from 0.69449 to 0.48029, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7131 - loss: 0.5179 - val_accuracy: 0.8063 - val_loss: 0.4803 - learning_rate: 0.0020\n",
            "Epoch 6/34\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7376 - loss: 0.4901\n",
            "Epoch 6: val_loss did not improve from 0.48029\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7372 - loss: 0.4905 - val_accuracy: 0.7864 - val_loss: 0.7351 - learning_rate: 0.0020\n",
            "Epoch 7/34\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7500 - loss: 0.4649\n",
            "Epoch 7: val_loss improved from 0.48029 to 0.41108, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7501 - loss: 0.4652 - val_accuracy: 0.8321 - val_loss: 0.4111 - learning_rate: 0.0020\n",
            "Epoch 8/34\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7530 - loss: 0.4620\n",
            "Epoch 8: val_loss did not improve from 0.41108\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7530 - loss: 0.4621 - val_accuracy: 0.7706 - val_loss: 0.6729 - learning_rate: 0.0020\n",
            "Epoch 9/34\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7381 - loss: 0.4601\n",
            "Epoch 9: val_loss did not improve from 0.41108\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7383 - loss: 0.4602 - val_accuracy: 0.7772 - val_loss: 0.7040 - learning_rate: 0.0020\n",
            "Epoch 10/34\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7676 - loss: 0.4413\n",
            "Epoch 10: val_loss did not improve from 0.41108\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7673 - loss: 0.4421 - val_accuracy: 0.7714 - val_loss: 0.6669 - learning_rate: 0.0020\n",
            "Epoch 11/34\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7782 - loss: 0.4351\n",
            "Epoch 11: val_loss did not improve from 0.41108\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7778 - loss: 0.4356 - val_accuracy: 0.8437 - val_loss: 0.4430 - learning_rate: 0.0020\n",
            "Epoch 12/34\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7787 - loss: 0.4280\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0006593272979499756.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.41108\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7779 - loss: 0.4290 - val_accuracy: 0.8263 - val_loss: 0.4824 - learning_rate: 0.0020\n",
            "Epoch 13/34\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7944 - loss: 0.4064\n",
            "Epoch 13: val_loss did not improve from 0.41108\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.4067 - val_accuracy: 0.8337 - val_loss: 0.4352 - learning_rate: 6.5933e-04\n",
            "Epoch 14/34\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 0.3888\n",
            "Epoch 14: val_loss improved from 0.41108 to 0.39773, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7991 - loss: 0.3893 - val_accuracy: 0.8379 - val_loss: 0.3977 - learning_rate: 6.5933e-04\n",
            "Epoch 15/34\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.3850\n",
            "Epoch 15: val_loss improved from 0.39773 to 0.38245, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8056 - loss: 0.3851 - val_accuracy: 0.8354 - val_loss: 0.3825 - learning_rate: 6.5933e-04\n",
            "Epoch 16/34\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8189 - loss: 0.3717\n",
            "Epoch 16: val_loss improved from 0.38245 to 0.36244, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8189 - loss: 0.3718 - val_accuracy: 0.8520 - val_loss: 0.3624 - learning_rate: 6.5933e-04\n",
            "Epoch 17/34\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8176 - loss: 0.3743\n",
            "Epoch 17: val_loss did not improve from 0.36244\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8176 - loss: 0.3744 - val_accuracy: 0.8146 - val_loss: 0.4124 - learning_rate: 6.5933e-04\n",
            "Epoch 18/34\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8286 - loss: 0.3656\n",
            "Epoch 18: val_loss did not improve from 0.36244\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8285 - loss: 0.3656 - val_accuracy: 0.7855 - val_loss: 0.5002 - learning_rate: 6.5933e-04\n",
            "Epoch 19/34\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8243 - loss: 0.3607\n",
            "Epoch 19: val_loss did not improve from 0.36244\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8241 - loss: 0.3614 - val_accuracy: 0.7822 - val_loss: 0.4625 - learning_rate: 6.5933e-04\n",
            "Epoch 20/34\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8243 - loss: 0.3551\n",
            "Epoch 20: val_loss improved from 0.36244 to 0.35840, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8243 - loss: 0.3553 - val_accuracy: 0.8437 - val_loss: 0.3584 - learning_rate: 6.5933e-04\n",
            "Epoch 21/34\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8209 - loss: 0.3584\n",
            "Epoch 21: val_loss did not improve from 0.35840\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8209 - loss: 0.3590 - val_accuracy: 0.8238 - val_loss: 0.4072 - learning_rate: 6.5933e-04\n",
            "Epoch 22/34\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8243 - loss: 0.3493\n",
            "Epoch 22: val_loss did not improve from 0.35840\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8241 - loss: 0.3501 - val_accuracy: 0.8404 - val_loss: 0.3621 - learning_rate: 6.5933e-04\n",
            "Epoch 23/34\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8352 - loss: 0.3462\n",
            "Epoch 23: val_loss improved from 0.35840 to 0.33367, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8351 - loss: 0.3465 - val_accuracy: 0.8537 - val_loss: 0.3337 - learning_rate: 6.5933e-04\n",
            "Epoch 24/34\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8209 - loss: 0.3577\n",
            "Epoch 24: val_loss did not improve from 0.33367\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8209 - loss: 0.3579 - val_accuracy: 0.8304 - val_loss: 0.3809 - learning_rate: 6.5933e-04\n",
            "Epoch 25/34\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8307 - loss: 0.3495\n",
            "Epoch 25: val_loss did not improve from 0.33367\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8306 - loss: 0.3498 - val_accuracy: 0.8288 - val_loss: 0.3856 - learning_rate: 6.5933e-04\n",
            "Epoch 26/34\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8224 - loss: 0.3502\n",
            "Epoch 26: val_loss improved from 0.33367 to 0.33203, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8225 - loss: 0.3504 - val_accuracy: 0.8520 - val_loss: 0.3320 - learning_rate: 6.5933e-04\n",
            "Epoch 27/34\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8331 - loss: 0.3415\n",
            "Epoch 27: val_loss did not improve from 0.33203\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8329 - loss: 0.3422 - val_accuracy: 0.8562 - val_loss: 0.3376 - learning_rate: 6.5933e-04\n",
            "Epoch 28/34\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8323 - loss: 0.3365\n",
            "Epoch 28: val_loss did not improve from 0.33203\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8321 - loss: 0.3372 - val_accuracy: 0.8362 - val_loss: 0.3389 - learning_rate: 6.5933e-04\n",
            "Epoch 29/34\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8285 - loss: 0.3401\n",
            "Epoch 29: val_loss did not improve from 0.33203\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8285 - loss: 0.3404 - val_accuracy: 0.8429 - val_loss: 0.3470 - learning_rate: 6.5933e-04\n",
            "Epoch 30/34\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8449 - loss: 0.3321\n",
            "Epoch 30: val_loss did not improve from 0.33203\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8448 - loss: 0.3324 - val_accuracy: 0.8595 - val_loss: 0.3421 - learning_rate: 6.5933e-04\n",
            "Epoch 31/34\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8302 - loss: 0.3369\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.000214471585631366.\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.33203\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8303 - loss: 0.3381 - val_accuracy: 0.8479 - val_loss: 0.3513 - learning_rate: 6.5933e-04\n",
            "Epoch 32/34\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8522 - loss: 0.3177\n",
            "Epoch 32: val_loss did not improve from 0.33203\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8521 - loss: 0.3180 - val_accuracy: 0.8487 - val_loss: 0.3588 - learning_rate: 2.1447e-04\n",
            "Epoch 33/34\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8528 - loss: 0.3123\n",
            "Epoch 33: val_loss did not improve from 0.33203\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8527 - loss: 0.3127 - val_accuracy: 0.8570 - val_loss: 0.3500 - learning_rate: 2.1447e-04\n",
            "Epoch 34/34\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8518 - loss: 0.3166\n",
            "Epoch 34: val_loss did not improve from 0.33203\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8515 - loss: 0.3172 - val_accuracy: 0.8545 - val_loss: 0.3712 - learning_rate: 2.1447e-04\n",
            "Epoch 34: early stopping\n",
            "Restoring model weights from the end of the best epoch: 26.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:07:15,996] Trial 15 finished with value: -0.3320251703262329 and parameters: {'epochs': 34, 'batch_size': 32, 'learning_rate': 0.0020269002924775594, 'stop_patience': 8, 'reduce_lr_factor': 0.325288488967878, 'reduce_lr_patience': 5}. Best is trial 15 with value: -0.3320251703262329.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/37\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5541 - loss: 0.6852\n",
            "Epoch 1: val_loss improved from inf to 0.70721, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5551 - loss: 0.6848 - val_accuracy: 0.5370 - val_loss: 0.7072 - learning_rate: 7.9001e-04\n",
            "Epoch 2/37\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5835 - loss: 0.6589\n",
            "Epoch 2: val_loss improved from 0.70721 to 0.44890, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5836 - loss: 0.6588 - val_accuracy: 0.8013 - val_loss: 0.4489 - learning_rate: 7.9001e-04\n",
            "Epoch 3/37\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6717 - loss: 0.5935\n",
            "Epoch 3: val_loss improved from 0.44890 to 0.42953, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6721 - loss: 0.5929 - val_accuracy: 0.8213 - val_loss: 0.4295 - learning_rate: 7.9001e-04\n",
            "Epoch 4/37\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7100 - loss: 0.5364\n",
            "Epoch 4: val_loss did not improve from 0.42953\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7103 - loss: 0.5362 - val_accuracy: 0.8121 - val_loss: 0.5057 - learning_rate: 7.9001e-04\n",
            "Epoch 5/37\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7390 - loss: 0.4995\n",
            "Epoch 5: val_loss improved from 0.42953 to 0.39693, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7391 - loss: 0.4994 - val_accuracy: 0.8387 - val_loss: 0.3969 - learning_rate: 7.9001e-04\n",
            "Epoch 6/37\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7513 - loss: 0.4730\n",
            "Epoch 6: val_loss did not improve from 0.39693\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7514 - loss: 0.4729 - val_accuracy: 0.7839 - val_loss: 0.6008 - learning_rate: 7.9001e-04\n",
            "Epoch 7/37\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7709 - loss: 0.4555\n",
            "Epoch 7: val_loss did not improve from 0.39693\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7706 - loss: 0.4557 - val_accuracy: 0.8429 - val_loss: 0.4247 - learning_rate: 7.9001e-04\n",
            "Epoch 8/37\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7595 - loss: 0.4459\n",
            "Epoch 8: val_loss did not improve from 0.39693\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7602 - loss: 0.4456 - val_accuracy: 0.8396 - val_loss: 0.4288 - learning_rate: 7.9001e-04\n",
            "Epoch 9/37\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7674 - loss: 0.4398\n",
            "Epoch 9: val_loss improved from 0.39693 to 0.36915, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7673 - loss: 0.4399 - val_accuracy: 0.8554 - val_loss: 0.3692 - learning_rate: 7.9001e-04\n",
            "Epoch 10/37\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7851 - loss: 0.4212\n",
            "Epoch 10: val_loss did not improve from 0.36915\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7848 - loss: 0.4215 - val_accuracy: 0.8504 - val_loss: 0.3920 - learning_rate: 7.9001e-04\n",
            "Epoch 11/37\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7821 - loss: 0.4262\n",
            "Epoch 11: val_loss did not improve from 0.36915\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7819 - loss: 0.4264 - val_accuracy: 0.8570 - val_loss: 0.3956 - learning_rate: 7.9001e-04\n",
            "Epoch 12/37\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7980 - loss: 0.4095\n",
            "Epoch 12: val_loss did not improve from 0.36915\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7978 - loss: 0.4097 - val_accuracy: 0.8396 - val_loss: 0.4502 - learning_rate: 7.9001e-04\n",
            "Epoch 13/37\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7996 - loss: 0.4104\n",
            "Epoch 13: val_loss improved from 0.36915 to 0.35092, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7991 - loss: 0.4107 - val_accuracy: 0.8579 - val_loss: 0.3509 - learning_rate: 7.9001e-04\n",
            "Epoch 14/37\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7979 - loss: 0.4039\n",
            "Epoch 14: val_loss did not improve from 0.35092\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7976 - loss: 0.4044 - val_accuracy: 0.8105 - val_loss: 0.5018 - learning_rate: 7.9001e-04\n",
            "Epoch 15/37\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7956 - loss: 0.3969\n",
            "Epoch 15: val_loss did not improve from 0.35092\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7956 - loss: 0.3970 - val_accuracy: 0.8529 - val_loss: 0.4054 - learning_rate: 7.9001e-04\n",
            "Epoch 16/37\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8050 - loss: 0.3907\n",
            "Epoch 16: val_loss did not improve from 0.35092\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8048 - loss: 0.3911 - val_accuracy: 0.8570 - val_loss: 0.3947 - learning_rate: 7.9001e-04\n",
            "Epoch 17/37\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.3928\n",
            "Epoch 17: val_loss did not improve from 0.35092\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.3933 - val_accuracy: 0.8446 - val_loss: 0.3704 - learning_rate: 7.9001e-04\n",
            "Epoch 18/37\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7998 - loss: 0.3931\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0003282226115347353.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.35092\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7998 - loss: 0.3938 - val_accuracy: 0.8346 - val_loss: 0.4474 - learning_rate: 7.9001e-04\n",
            "Epoch 19/37\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8158 - loss: 0.3683\n",
            "Epoch 19: val_loss did not improve from 0.35092\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8159 - loss: 0.3683 - val_accuracy: 0.8620 - val_loss: 0.3609 - learning_rate: 3.2822e-04\n",
            "Epoch 20/37\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8238 - loss: 0.3509\n",
            "Epoch 20: val_loss improved from 0.35092 to 0.34223, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8239 - loss: 0.3510 - val_accuracy: 0.8670 - val_loss: 0.3422 - learning_rate: 3.2822e-04\n",
            "Epoch 21/37\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8251 - loss: 0.3553\n",
            "Epoch 21: val_loss improved from 0.34223 to 0.31854, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8251 - loss: 0.3559 - val_accuracy: 0.8620 - val_loss: 0.3185 - learning_rate: 3.2822e-04\n",
            "Epoch 22/37\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8230 - loss: 0.3509\n",
            "Epoch 22: val_loss did not improve from 0.31854\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8231 - loss: 0.3518 - val_accuracy: 0.8396 - val_loss: 0.3602 - learning_rate: 3.2822e-04\n",
            "Epoch 23/37\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8307 - loss: 0.3480\n",
            "Epoch 23: val_loss did not improve from 0.31854\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8306 - loss: 0.3488 - val_accuracy: 0.8554 - val_loss: 0.3458 - learning_rate: 3.2822e-04\n",
            "Epoch 24/37\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8259 - loss: 0.3528\n",
            "Epoch 24: val_loss did not improve from 0.31854\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8259 - loss: 0.3528 - val_accuracy: 0.8313 - val_loss: 0.4109 - learning_rate: 3.2822e-04\n",
            "Epoch 25/37\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8302 - loss: 0.3416\n",
            "Epoch 25: val_loss did not improve from 0.31854\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8301 - loss: 0.3426 - val_accuracy: 0.8495 - val_loss: 0.3430 - learning_rate: 3.2822e-04\n",
            "Epoch 26/37\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 0.3349\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00013636476771417078.\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.31854\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8384 - loss: 0.3354 - val_accuracy: 0.8421 - val_loss: 0.3492 - learning_rate: 3.2822e-04\n",
            "Epoch 27/37\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8403 - loss: 0.3311\n",
            "Epoch 27: val_loss did not improve from 0.31854\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8404 - loss: 0.3313 - val_accuracy: 0.8529 - val_loss: 0.3825 - learning_rate: 1.3636e-04\n",
            "Epoch 28/37\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8422 - loss: 0.3254\n",
            "Epoch 28: val_loss did not improve from 0.31854\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8422 - loss: 0.3256 - val_accuracy: 0.8562 - val_loss: 0.3532 - learning_rate: 1.3636e-04\n",
            "Epoch 29/37\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8456 - loss: 0.3229\n",
            "Epoch 29: val_loss did not improve from 0.31854\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8456 - loss: 0.3231 - val_accuracy: 0.8512 - val_loss: 0.3650 - learning_rate: 1.3636e-04\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 21.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:07:53,015] Trial 16 finished with value: -0.31853818893432617 and parameters: {'epochs': 37, 'batch_size': 32, 'learning_rate': 0.0007900140402050623, 'stop_patience': 8, 'reduce_lr_factor': 0.4154642722129085, 'reduce_lr_patience': 5}. Best is trial 16 with value: -0.31853818893432617.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/38\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5506 - loss: 0.6893\n",
            "Epoch 1: val_loss improved from inf to 0.75466, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5508 - loss: 0.6893 - val_accuracy: 0.4996 - val_loss: 0.7547 - learning_rate: 3.6719e-04\n",
            "Epoch 2/38\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5653 - loss: 0.6808\n",
            "Epoch 2: val_loss improved from 0.75466 to 0.69656, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5653 - loss: 0.6808 - val_accuracy: 0.5345 - val_loss: 0.6966 - learning_rate: 3.6719e-04\n",
            "Epoch 3/38\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5812 - loss: 0.6707\n",
            "Epoch 3: val_loss improved from 0.69656 to 0.56138, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5813 - loss: 0.6706 - val_accuracy: 0.7398 - val_loss: 0.5614 - learning_rate: 3.6719e-04\n",
            "Epoch 4/38\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6185 - loss: 0.6355\n",
            "Epoch 4: val_loss improved from 0.56138 to 0.46587, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6187 - loss: 0.6354 - val_accuracy: 0.7697 - val_loss: 0.4659 - learning_rate: 3.6719e-04\n",
            "Epoch 5/38\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6815 - loss: 0.5826\n",
            "Epoch 5: val_loss improved from 0.46587 to 0.44854, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6817 - loss: 0.5823 - val_accuracy: 0.8063 - val_loss: 0.4485 - learning_rate: 3.6719e-04\n",
            "Epoch 6/38\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7169 - loss: 0.5383\n",
            "Epoch 6: val_loss did not improve from 0.44854\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7172 - loss: 0.5382 - val_accuracy: 0.8146 - val_loss: 0.4843 - learning_rate: 3.6719e-04\n",
            "Epoch 7/38\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7307 - loss: 0.5138\n",
            "Epoch 7: val_loss did not improve from 0.44854\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7308 - loss: 0.5137 - val_accuracy: 0.8180 - val_loss: 0.4901 - learning_rate: 3.6719e-04\n",
            "Epoch 8/38\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.4948\n",
            "Epoch 8: val_loss did not improve from 0.44854\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7382 - loss: 0.4946 - val_accuracy: 0.8155 - val_loss: 0.4832 - learning_rate: 3.6719e-04\n",
            "Epoch 9/38\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7517 - loss: 0.4844\n",
            "Epoch 9: val_loss did not improve from 0.44854\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7517 - loss: 0.4844 - val_accuracy: 0.8188 - val_loss: 0.4870 - learning_rate: 3.6719e-04\n",
            "Epoch 10/38\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7565 - loss: 0.4712\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00013360411016874793.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.44854\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7565 - loss: 0.4712 - val_accuracy: 0.8313 - val_loss: 0.4542 - learning_rate: 3.6719e-04\n",
            "Epoch 11/38\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7659 - loss: 0.4543\n",
            "Epoch 11: val_loss did not improve from 0.44854\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7660 - loss: 0.4543 - val_accuracy: 0.8188 - val_loss: 0.4643 - learning_rate: 1.3360e-04\n",
            "Epoch 12/38\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7804 - loss: 0.4468\n",
            "Epoch 12: val_loss improved from 0.44854 to 0.40896, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7803 - loss: 0.4468 - val_accuracy: 0.8238 - val_loss: 0.4090 - learning_rate: 1.3360e-04\n",
            "Epoch 13/38\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7815 - loss: 0.4431\n",
            "Epoch 13: val_loss did not improve from 0.40896\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7817 - loss: 0.4429 - val_accuracy: 0.8229 - val_loss: 0.4770 - learning_rate: 1.3360e-04\n",
            "Epoch 14/38\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7783 - loss: 0.4393\n",
            "Epoch 14: val_loss improved from 0.40896 to 0.40812, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7785 - loss: 0.4392 - val_accuracy: 0.8313 - val_loss: 0.4081 - learning_rate: 1.3360e-04\n",
            "Epoch 15/38\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7926 - loss: 0.4288\n",
            "Epoch 15: val_loss improved from 0.40812 to 0.40703, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7927 - loss: 0.4288 - val_accuracy: 0.8329 - val_loss: 0.4070 - learning_rate: 1.3360e-04\n",
            "Epoch 16/38\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7880 - loss: 0.4308\n",
            "Epoch 16: val_loss did not improve from 0.40703\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7882 - loss: 0.4306 - val_accuracy: 0.8329 - val_loss: 0.4211 - learning_rate: 1.3360e-04\n",
            "Epoch 17/38\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7893 - loss: 0.4254\n",
            "Epoch 17: val_loss improved from 0.40703 to 0.40326, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7894 - loss: 0.4253 - val_accuracy: 0.8329 - val_loss: 0.4033 - learning_rate: 1.3360e-04\n",
            "Epoch 18/38\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7937 - loss: 0.4230\n",
            "Epoch 18: val_loss improved from 0.40326 to 0.38673, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7937 - loss: 0.4230 - val_accuracy: 0.8446 - val_loss: 0.3867 - learning_rate: 1.3360e-04\n",
            "Epoch 19/38\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7918 - loss: 0.4183\n",
            "Epoch 19: val_loss did not improve from 0.38673\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7918 - loss: 0.4183 - val_accuracy: 0.8462 - val_loss: 0.3916 - learning_rate: 1.3360e-04\n",
            "Epoch 20/38\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7946 - loss: 0.4154\n",
            "Epoch 20: val_loss did not improve from 0.38673\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7947 - loss: 0.4154 - val_accuracy: 0.8271 - val_loss: 0.4446 - learning_rate: 1.3360e-04\n",
            "Epoch 21/38\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7979 - loss: 0.4140\n",
            "Epoch 21: val_loss did not improve from 0.38673\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7979 - loss: 0.4140 - val_accuracy: 0.8429 - val_loss: 0.4092 - learning_rate: 1.3360e-04\n",
            "Epoch 22/38\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.4132\n",
            "Epoch 22: val_loss did not improve from 0.38673\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8041 - loss: 0.4130 - val_accuracy: 0.8329 - val_loss: 0.4309 - learning_rate: 1.3360e-04\n",
            "Epoch 23/38\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.4056\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 4.8612435507628266e-05.\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.38673\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8015 - loss: 0.4056 - val_accuracy: 0.8446 - val_loss: 0.3978 - learning_rate: 1.3360e-04\n",
            "Epoch 24/38\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8131 - loss: 0.3994\n",
            "Epoch 24: val_loss did not improve from 0.38673\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8132 - loss: 0.3994 - val_accuracy: 0.8379 - val_loss: 0.3937 - learning_rate: 4.8612e-05\n",
            "Epoch 25/38\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8158 - loss: 0.3947\n",
            "Epoch 25: val_loss improved from 0.38673 to 0.36981, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8159 - loss: 0.3948 - val_accuracy: 0.8462 - val_loss: 0.3698 - learning_rate: 4.8612e-05\n",
            "Epoch 26/38\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8229 - loss: 0.3876\n",
            "Epoch 26: val_loss improved from 0.36981 to 0.36924, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8228 - loss: 0.3877 - val_accuracy: 0.8479 - val_loss: 0.3692 - learning_rate: 4.8612e-05\n",
            "Epoch 27/38\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8150 - loss: 0.3888\n",
            "Epoch 27: val_loss did not improve from 0.36924\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8149 - loss: 0.3889 - val_accuracy: 0.8454 - val_loss: 0.3774 - learning_rate: 4.8612e-05\n",
            "Epoch 28/38\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8189 - loss: 0.3918\n",
            "Epoch 28: val_loss did not improve from 0.36924\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8193 - loss: 0.3918 - val_accuracy: 0.8446 - val_loss: 0.3784 - learning_rate: 4.8612e-05\n",
            "Epoch 29/38\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8181 - loss: 0.3885\n",
            "Epoch 29: val_loss improved from 0.36924 to 0.36877, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8181 - loss: 0.3886 - val_accuracy: 0.8462 - val_loss: 0.3688 - learning_rate: 4.8612e-05\n",
            "Epoch 30/38\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8267 - loss: 0.3882\n",
            "Epoch 30: val_loss did not improve from 0.36877\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8266 - loss: 0.3882 - val_accuracy: 0.8437 - val_loss: 0.3752 - learning_rate: 4.8612e-05\n",
            "Epoch 31/38\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8216 - loss: 0.3848\n",
            "Epoch 31: val_loss did not improve from 0.36877\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8215 - loss: 0.3848 - val_accuracy: 0.8421 - val_loss: 0.3849 - learning_rate: 4.8612e-05\n",
            "Epoch 32/38\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8251 - loss: 0.3815\n",
            "Epoch 32: val_loss did not improve from 0.36877\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8251 - loss: 0.3816 - val_accuracy: 0.8454 - val_loss: 0.3811 - learning_rate: 4.8612e-05\n",
            "Epoch 33/38\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8266 - loss: 0.3833\n",
            "Epoch 33: val_loss did not improve from 0.36877\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8264 - loss: 0.3835 - val_accuracy: 0.8437 - val_loss: 0.3806 - learning_rate: 4.8612e-05\n",
            "Epoch 34/38\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8240 - loss: 0.3821\n",
            "Epoch 34: val_loss improved from 0.36877 to 0.36738, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8238 - loss: 0.3822 - val_accuracy: 0.8512 - val_loss: 0.3674 - learning_rate: 4.8612e-05\n",
            "Epoch 35/38\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8324 - loss: 0.3811\n",
            "Epoch 35: val_loss did not improve from 0.36738\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8322 - loss: 0.3812 - val_accuracy: 0.8429 - val_loss: 0.3760 - learning_rate: 4.8612e-05\n",
            "Epoch 36/38\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.3845\n",
            "Epoch 36: val_loss did not improve from 0.36738\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8263 - loss: 0.3845 - val_accuracy: 0.8470 - val_loss: 0.3734 - learning_rate: 4.8612e-05\n",
            "Epoch 37/38\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8290 - loss: 0.3750\n",
            "Epoch 37: val_loss did not improve from 0.36738\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8290 - loss: 0.3751 - val_accuracy: 0.8479 - val_loss: 0.3788 - learning_rate: 4.8612e-05\n",
            "Epoch 38/38\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8196 - loss: 0.3845\n",
            "Epoch 38: val_loss did not improve from 0.36738\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8197 - loss: 0.3845 - val_accuracy: 0.8504 - val_loss: 0.3749 - learning_rate: 4.8612e-05\n",
            "Restoring model weights from the end of the best epoch: 34.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:08:39,197] Trial 17 finished with value: -0.3673752248287201 and parameters: {'epochs': 38, 'batch_size': 32, 'learning_rate': 0.0003671912001139382, 'stop_patience': 10, 'reduce_lr_factor': 0.36385432314677224, 'reduce_lr_patience': 5}. Best is trial 16 with value: -0.31853818893432617.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5538 - loss: 0.6891\n",
            "Epoch 1: val_loss improved from inf to 0.73986, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5546 - loss: 0.6890 - val_accuracy: 0.4996 - val_loss: 0.7399 - learning_rate: 1.6576e-04\n",
            "Epoch 2/35\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5671 - loss: 0.6820\n",
            "Epoch 2: val_loss improved from 0.73986 to 0.66486, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5670 - loss: 0.6820 - val_accuracy: 0.5137 - val_loss: 0.6649 - learning_rate: 1.6576e-04\n",
            "Epoch 3/35\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5659 - loss: 0.6765\n",
            "Epoch 3: val_loss improved from 0.66486 to 0.65456, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5659 - loss: 0.6764 - val_accuracy: 0.6168 - val_loss: 0.6546 - learning_rate: 1.6576e-04\n",
            "Epoch 4/35\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5835 - loss: 0.6631\n",
            "Epoch 4: val_loss did not improve from 0.65456\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5841 - loss: 0.6629 - val_accuracy: 0.5869 - val_loss: 0.6962 - learning_rate: 1.6576e-04\n",
            "Epoch 5/35\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6057 - loss: 0.6412\n",
            "Epoch 5: val_loss improved from 0.65456 to 0.55437, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6059 - loss: 0.6411 - val_accuracy: 0.7224 - val_loss: 0.5544 - learning_rate: 1.6576e-04\n",
            "Epoch 6/35\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6516 - loss: 0.6079\n",
            "Epoch 6: val_loss improved from 0.55437 to 0.42475, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6518 - loss: 0.6077 - val_accuracy: 0.8080 - val_loss: 0.4247 - learning_rate: 1.6576e-04\n",
            "Epoch 7/35\n",
            "\u001b[1m137/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6889 - loss: 0.5729\n",
            "Epoch 7: val_loss did not improve from 0.42475\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6896 - loss: 0.5726 - val_accuracy: 0.8146 - val_loss: 0.4302 - learning_rate: 1.6576e-04\n",
            "Epoch 8/35\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7125 - loss: 0.5442\n",
            "Epoch 8: val_loss did not improve from 0.42475\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7127 - loss: 0.5441 - val_accuracy: 0.7606 - val_loss: 0.6622 - learning_rate: 1.6576e-04\n",
            "Epoch 9/35\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7227 - loss: 0.5217\n",
            "Epoch 9: val_loss did not improve from 0.42475\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7229 - loss: 0.5217 - val_accuracy: 0.7498 - val_loss: 0.7838 - learning_rate: 1.6576e-04\n",
            "Epoch 10/35\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7370 - loss: 0.5104\n",
            "Epoch 10: val_loss did not improve from 0.42475\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7371 - loss: 0.5103 - val_accuracy: 0.8013 - val_loss: 0.5695 - learning_rate: 1.6576e-04\n",
            "Epoch 11/35\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7493 - loss: 0.4942\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 7.124634296278865e-05.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.42475\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7493 - loss: 0.4942 - val_accuracy: 0.8246 - val_loss: 0.4911 - learning_rate: 1.6576e-04\n",
            "Epoch 12/35\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7542 - loss: 0.4790\n",
            "Epoch 12: val_loss did not improve from 0.42475\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7545 - loss: 0.4791 - val_accuracy: 0.8105 - val_loss: 0.5537 - learning_rate: 7.1246e-05\n",
            "Epoch 13/35\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7654 - loss: 0.4739\n",
            "Epoch 13: val_loss did not improve from 0.42475\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7654 - loss: 0.4738 - val_accuracy: 0.8063 - val_loss: 0.5851 - learning_rate: 7.1246e-05\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:08:55,602] Trial 18 finished with value: -0.4247469902038574 and parameters: {'epochs': 35, 'batch_size': 32, 'learning_rate': 0.00016575683023936215, 'stop_patience': 7, 'reduce_lr_factor': 0.4298244639744494, 'reduce_lr_patience': 5}. Best is trial 16 with value: -0.31853818893432617.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/48\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5550 - loss: 0.6900\n",
            "Epoch 1: val_loss improved from inf to 0.69969, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5555 - loss: 0.6898 - val_accuracy: 0.4996 - val_loss: 0.6997 - learning_rate: 0.0048\n",
            "Epoch 2/48\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5665 - loss: 0.6840\n",
            "Epoch 2: val_loss improved from 0.69969 to 0.67031, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5664 - loss: 0.6840 - val_accuracy: 0.5520 - val_loss: 0.6703 - learning_rate: 0.0048\n",
            "Epoch 3/48\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5692 - loss: 0.6747\n",
            "Epoch 3: val_loss improved from 0.67031 to 0.65626, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5694 - loss: 0.6746 - val_accuracy: 0.6143 - val_loss: 0.6563 - learning_rate: 0.0048\n",
            "Epoch 4/48\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6209 - loss: 0.6216\n",
            "Epoch 4: val_loss did not improve from 0.65626\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6210 - loss: 0.6216 - val_accuracy: 0.5594 - val_loss: 0.9769 - learning_rate: 0.0048\n",
            "Epoch 5/48\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6445 - loss: 0.5977\n",
            "Epoch 5: val_loss improved from 0.65626 to 0.39943, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6446 - loss: 0.5979 - val_accuracy: 0.8221 - val_loss: 0.3994 - learning_rate: 0.0048\n",
            "Epoch 6/48\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6597 - loss: 0.5628\n",
            "Epoch 6: val_loss did not improve from 0.39943\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6605 - loss: 0.5631 - val_accuracy: 0.7207 - val_loss: 0.7624 - learning_rate: 0.0048\n",
            "Epoch 7/48\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6689 - loss: 0.5628\n",
            "Epoch 7: val_loss did not improve from 0.39943\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6692 - loss: 0.5625 - val_accuracy: 0.5528 - val_loss: 0.9609 - learning_rate: 0.0048\n",
            "Epoch 8/48\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6978 - loss: 0.5379\n",
            "Epoch 8: val_loss did not improve from 0.39943\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6979 - loss: 0.5377 - val_accuracy: 0.8096 - val_loss: 0.4195 - learning_rate: 0.0048\n",
            "Epoch 9/48\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7114 - loss: 0.5128\n",
            "Epoch 9: val_loss did not improve from 0.39943\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7119 - loss: 0.5124 - val_accuracy: 0.7855 - val_loss: 0.8775 - learning_rate: 0.0048\n",
            "Epoch 10/48\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7230 - loss: 0.4997\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0020128161078559774.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.39943\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7231 - loss: 0.4995 - val_accuracy: 0.8096 - val_loss: 0.4769 - learning_rate: 0.0048\n",
            "Epoch 11/48\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7485 - loss: 0.4867\n",
            "Epoch 11: val_loss improved from 0.39943 to 0.37269, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7485 - loss: 0.4864 - val_accuracy: 0.8354 - val_loss: 0.3727 - learning_rate: 0.0020\n",
            "Epoch 12/48\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7525 - loss: 0.4518\n",
            "Epoch 12: val_loss did not improve from 0.37269\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7526 - loss: 0.4520 - val_accuracy: 0.8421 - val_loss: 0.3786 - learning_rate: 0.0020\n",
            "Epoch 13/48\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7674 - loss: 0.4446\n",
            "Epoch 13: val_loss improved from 0.37269 to 0.35890, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7673 - loss: 0.4448 - val_accuracy: 0.8387 - val_loss: 0.3589 - learning_rate: 0.0020\n",
            "Epoch 14/48\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.4276\n",
            "Epoch 14: val_loss did not improve from 0.35890\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7900 - loss: 0.4279 - val_accuracy: 0.8263 - val_loss: 0.3914 - learning_rate: 0.0020\n",
            "Epoch 15/48\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7833 - loss: 0.4276\n",
            "Epoch 15: val_loss did not improve from 0.35890\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7833 - loss: 0.4277 - val_accuracy: 0.8304 - val_loss: 0.4032 - learning_rate: 0.0020\n",
            "Epoch 16/48\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7928 - loss: 0.4219\n",
            "Epoch 16: val_loss did not improve from 0.35890\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7928 - loss: 0.4219 - val_accuracy: 0.8337 - val_loss: 0.4132 - learning_rate: 0.0020\n",
            "Epoch 17/48\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8017 - loss: 0.4040\n",
            "Epoch 17: val_loss did not improve from 0.35890\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8011 - loss: 0.4050 - val_accuracy: 0.8263 - val_loss: 0.4476 - learning_rate: 0.0020\n",
            "Epoch 18/48\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4037\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.000836918845532757.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.35890\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8042 - loss: 0.4048 - val_accuracy: 0.8337 - val_loss: 0.3678 - learning_rate: 0.0020\n",
            "Epoch 19/48\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8137 - loss: 0.3870\n",
            "Epoch 19: val_loss did not improve from 0.35890\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.3873 - val_accuracy: 0.8121 - val_loss: 0.4603 - learning_rate: 8.3692e-04\n",
            "Epoch 20/48\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8222 - loss: 0.3782\n",
            "Epoch 20: val_loss did not improve from 0.35890\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8221 - loss: 0.3784 - val_accuracy: 0.7947 - val_loss: 0.4727 - learning_rate: 8.3692e-04\n",
            "Epoch 21/48\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8173 - loss: 0.3818\n",
            "Epoch 21: val_loss did not improve from 0.35890\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8173 - loss: 0.3818 - val_accuracy: 0.7440 - val_loss: 0.5851 - learning_rate: 8.3692e-04\n",
            "Epoch 22/48\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8249 - loss: 0.3743\n",
            "Epoch 22: val_loss did not improve from 0.35890\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8248 - loss: 0.3744 - val_accuracy: 0.8030 - val_loss: 0.5256 - learning_rate: 8.3692e-04\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:09:22,911] Trial 19 finished with value: -0.3588964641094208 and parameters: {'epochs': 48, 'batch_size': 32, 'learning_rate': 0.004840885722212587, 'stop_patience': 9, 'reduce_lr_factor': 0.41579500320003865, 'reduce_lr_patience': 5}. Best is trial 16 with value: -0.31853818893432617.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/41\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5547 - loss: 0.6895\n",
            "Epoch 1: val_loss improved from inf to 0.75647, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5552 - loss: 0.6893 - val_accuracy: 0.5004 - val_loss: 0.7565 - learning_rate: 0.0014\n",
            "Epoch 2/41\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5665 - loss: 0.6738\n",
            "Epoch 2: val_loss improved from 0.75647 to 0.59167, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5668 - loss: 0.6735 - val_accuracy: 0.6459 - val_loss: 0.5917 - learning_rate: 0.0014\n",
            "Epoch 3/41\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6426 - loss: 0.6168\n",
            "Epoch 3: val_loss did not improve from 0.59167\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6428 - loss: 0.6162 - val_accuracy: 0.7165 - val_loss: 0.9106 - learning_rate: 0.0014\n",
            "Epoch 4/41\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6662 - loss: 0.5687\n",
            "Epoch 4: val_loss did not improve from 0.59167\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6670 - loss: 0.5682 - val_accuracy: 0.7041 - val_loss: 0.8572 - learning_rate: 0.0014\n",
            "Epoch 5/41\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7256 - loss: 0.5140\n",
            "Epoch 5: val_loss did not improve from 0.59167\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7259 - loss: 0.5140 - val_accuracy: 0.7581 - val_loss: 0.7226 - learning_rate: 0.0014\n",
            "Epoch 6/41\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7311 - loss: 0.4906\n",
            "Epoch 6: val_loss improved from 0.59167 to 0.50125, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7311 - loss: 0.4908 - val_accuracy: 0.7930 - val_loss: 0.5012 - learning_rate: 0.0014\n",
            "Epoch 7/41\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7657 - loss: 0.4628\n",
            "Epoch 7: val_loss improved from 0.50125 to 0.41979, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7654 - loss: 0.4631 - val_accuracy: 0.8196 - val_loss: 0.4198 - learning_rate: 0.0014\n",
            "Epoch 8/41\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7472 - loss: 0.4609\n",
            "Epoch 8: val_loss did not improve from 0.41979\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7479 - loss: 0.4607 - val_accuracy: 0.7772 - val_loss: 0.7042 - learning_rate: 0.0014\n",
            "Epoch 9/41\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7745 - loss: 0.4473\n",
            "Epoch 9: val_loss did not improve from 0.41979\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7740 - loss: 0.4476 - val_accuracy: 0.8487 - val_loss: 0.4215 - learning_rate: 0.0014\n",
            "Epoch 10/41\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7695 - loss: 0.4403\n",
            "Epoch 10: val_loss improved from 0.41979 to 0.38629, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7692 - loss: 0.4408 - val_accuracy: 0.8362 - val_loss: 0.3863 - learning_rate: 0.0014\n",
            "Epoch 11/41\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7691 - loss: 0.4358\n",
            "Epoch 11: val_loss did not improve from 0.38629\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7691 - loss: 0.4358 - val_accuracy: 0.8329 - val_loss: 0.3997 - learning_rate: 0.0014\n",
            "Epoch 12/41\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7884 - loss: 0.4211\n",
            "Epoch 12: val_loss did not improve from 0.38629\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7881 - loss: 0.4215 - val_accuracy: 0.7539 - val_loss: 0.7145 - learning_rate: 0.0014\n",
            "Epoch 13/41\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7933 - loss: 0.4134\n",
            "Epoch 13: val_loss did not improve from 0.38629\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7930 - loss: 0.4139 - val_accuracy: 0.8121 - val_loss: 0.4568 - learning_rate: 0.0014\n",
            "Epoch 14/41\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.4033\n",
            "Epoch 14: val_loss improved from 0.38629 to 0.32171, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8029 - loss: 0.4035 - val_accuracy: 0.8545 - val_loss: 0.3217 - learning_rate: 0.0014\n",
            "Epoch 15/41\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7933 - loss: 0.3982\n",
            "Epoch 15: val_loss improved from 0.32171 to 0.31753, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7928 - loss: 0.3993 - val_accuracy: 0.8562 - val_loss: 0.3175 - learning_rate: 0.0014\n",
            "Epoch 16/41\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8014 - loss: 0.3989\n",
            "Epoch 16: val_loss did not improve from 0.31753\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8009 - loss: 0.3996 - val_accuracy: 0.8379 - val_loss: 0.3666 - learning_rate: 0.0014\n",
            "Epoch 17/41\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7906 - loss: 0.4034\n",
            "Epoch 17: val_loss did not improve from 0.31753\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7903 - loss: 0.4039 - val_accuracy: 0.8096 - val_loss: 0.4914 - learning_rate: 0.0014\n",
            "Epoch 18/41\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.4003\n",
            "Epoch 18: val_loss did not improve from 0.31753\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7983 - loss: 0.4004 - val_accuracy: 0.8620 - val_loss: 0.3272 - learning_rate: 0.0014\n",
            "Epoch 19/41\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.3938\n",
            "Epoch 19: val_loss did not improve from 0.31753\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8008 - loss: 0.3942 - val_accuracy: 0.8562 - val_loss: 0.3256 - learning_rate: 0.0014\n",
            "Epoch 20/41\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.3926\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005914165272572021.\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.31753\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8013 - loss: 0.3931 - val_accuracy: 0.8487 - val_loss: 0.3386 - learning_rate: 0.0014\n",
            "Epoch 21/41\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8164 - loss: 0.3605\n",
            "Epoch 21: val_loss did not improve from 0.31753\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8163 - loss: 0.3611 - val_accuracy: 0.8346 - val_loss: 0.3745 - learning_rate: 5.9142e-04\n",
            "Epoch 22/41\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8278 - loss: 0.3480\n",
            "Epoch 22: val_loss did not improve from 0.31753\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8277 - loss: 0.3485 - val_accuracy: 0.8487 - val_loss: 0.3381 - learning_rate: 5.9142e-04\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:09:57,292] Trial 20 finished with value: -0.31752559542655945 and parameters: {'epochs': 41, 'batch_size': 32, 'learning_rate': 0.0014212445863227706, 'stop_patience': 7, 'reduce_lr_factor': 0.41612579191529886, 'reduce_lr_patience': 5}. Best is trial 20 with value: -0.31752559542655945.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/42\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5490 - loss: 0.6861\n",
            "Epoch 1: val_loss improved from inf to 0.56943, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5501 - loss: 0.6857 - val_accuracy: 0.6916 - val_loss: 0.5694 - learning_rate: 0.0014\n",
            "Epoch 2/42\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6122 - loss: 0.6428\n",
            "Epoch 2: val_loss did not improve from 0.56943\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6124 - loss: 0.6428 - val_accuracy: 0.7423 - val_loss: 0.5770 - learning_rate: 0.0014\n",
            "Epoch 3/42\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6925 - loss: 0.5549\n",
            "Epoch 3: val_loss improved from 0.56943 to 0.46874, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6930 - loss: 0.5542 - val_accuracy: 0.8171 - val_loss: 0.4687 - learning_rate: 0.0014\n",
            "Epoch 4/42\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7192 - loss: 0.5205\n",
            "Epoch 4: val_loss did not improve from 0.46874\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7192 - loss: 0.5210 - val_accuracy: 0.7016 - val_loss: 0.7939 - learning_rate: 0.0014\n",
            "Epoch 5/42\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7345 - loss: 0.4822\n",
            "Epoch 5: val_loss did not improve from 0.46874\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7345 - loss: 0.4829 - val_accuracy: 0.7905 - val_loss: 0.5792 - learning_rate: 0.0014\n",
            "Epoch 6/42\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7470 - loss: 0.4724\n",
            "Epoch 6: val_loss did not improve from 0.46874\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7470 - loss: 0.4724 - val_accuracy: 0.6650 - val_loss: 1.1197 - learning_rate: 0.0014\n",
            "Epoch 7/42\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7533 - loss: 0.4601\n",
            "Epoch 7: val_loss improved from 0.46874 to 0.40818, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7533 - loss: 0.4601 - val_accuracy: 0.8421 - val_loss: 0.4082 - learning_rate: 0.0014\n",
            "Epoch 8/42\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7623 - loss: 0.4460\n",
            "Epoch 8: val_loss did not improve from 0.40818\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7621 - loss: 0.4471 - val_accuracy: 0.8279 - val_loss: 0.4464 - learning_rate: 0.0014\n",
            "Epoch 9/42\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7652 - loss: 0.4432\n",
            "Epoch 9: val_loss improved from 0.40818 to 0.37867, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7654 - loss: 0.4434 - val_accuracy: 0.8479 - val_loss: 0.3787 - learning_rate: 0.0014\n",
            "Epoch 10/42\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7848 - loss: 0.4245\n",
            "Epoch 10: val_loss did not improve from 0.37867\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7844 - loss: 0.4250 - val_accuracy: 0.7124 - val_loss: 0.9308 - learning_rate: 0.0014\n",
            "Epoch 11/42\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7831 - loss: 0.4107\n",
            "Epoch 11: val_loss did not improve from 0.37867\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7830 - loss: 0.4113 - val_accuracy: 0.7290 - val_loss: 0.6882 - learning_rate: 0.0014\n",
            "Epoch 12/42\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7673 - loss: 0.4260\n",
            "Epoch 12: val_loss did not improve from 0.37867\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7675 - loss: 0.4261 - val_accuracy: 0.7606 - val_loss: 0.7207 - learning_rate: 0.0014\n",
            "Epoch 13/42\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7924 - loss: 0.4082\n",
            "Epoch 13: val_loss improved from 0.37867 to 0.33416, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7919 - loss: 0.4089 - val_accuracy: 0.8637 - val_loss: 0.3342 - learning_rate: 0.0014\n",
            "Epoch 14/42\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7961 - loss: 0.4062\n",
            "Epoch 14: val_loss did not improve from 0.33416\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7959 - loss: 0.4068 - val_accuracy: 0.8446 - val_loss: 0.4270 - learning_rate: 0.0014\n",
            "Epoch 15/42\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8004 - loss: 0.3957\n",
            "Epoch 15: val_loss did not improve from 0.33416\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8002 - loss: 0.3959 - val_accuracy: 0.7506 - val_loss: 0.7073 - learning_rate: 0.0014\n",
            "Epoch 16/42\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7961 - loss: 0.3928\n",
            "Epoch 16: val_loss did not improve from 0.33416\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7961 - loss: 0.3929 - val_accuracy: 0.8470 - val_loss: 0.3502 - learning_rate: 0.0014\n",
            "Epoch 17/42\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7977 - loss: 0.3995\n",
            "Epoch 17: val_loss did not improve from 0.33416\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7977 - loss: 0.3997 - val_accuracy: 0.7174 - val_loss: 0.9691 - learning_rate: 0.0014\n",
            "Epoch 18/42\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7977 - loss: 0.3861\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005784973785163422.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.33416\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7977 - loss: 0.3864 - val_accuracy: 0.7938 - val_loss: 0.5272 - learning_rate: 0.0014\n",
            "Epoch 19/42\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8274 - loss: 0.3518\n",
            "Epoch 19: val_loss did not improve from 0.33416\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8273 - loss: 0.3520 - val_accuracy: 0.8470 - val_loss: 0.3476 - learning_rate: 5.7850e-04\n",
            "Epoch 20/42\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8285 - loss: 0.3461\n",
            "Epoch 20: val_loss did not improve from 0.33416\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8284 - loss: 0.3469 - val_accuracy: 0.8362 - val_loss: 0.3701 - learning_rate: 5.7850e-04\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:10:23,325] Trial 21 finished with value: -0.3341624438762665 and parameters: {'epochs': 42, 'batch_size': 32, 'learning_rate': 0.0013970650579833697, 'stop_patience': 7, 'reduce_lr_factor': 0.41408050241572175, 'reduce_lr_patience': 5}. Best is trial 20 with value: -0.31752559542655945.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/31\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5666 - loss: 0.6890\n",
            "Epoch 1: val_loss improved from inf to 0.71091, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5665 - loss: 0.6888 - val_accuracy: 0.5037 - val_loss: 0.7109 - learning_rate: 0.0036\n",
            "Epoch 2/31\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5686 - loss: 0.6828\n",
            "Epoch 2: val_loss improved from 0.71091 to 0.55459, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5686 - loss: 0.6828 - val_accuracy: 0.7232 - val_loss: 0.5546 - learning_rate: 0.0036\n",
            "Epoch 3/31\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6087 - loss: 0.6507\n",
            "Epoch 3: val_loss did not improve from 0.55459\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6090 - loss: 0.6503 - val_accuracy: 0.5869 - val_loss: 2.1510 - learning_rate: 0.0036\n",
            "Epoch 4/31\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6345 - loss: 0.6100\n",
            "Epoch 4: val_loss improved from 0.55459 to 0.43726, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6352 - loss: 0.6093 - val_accuracy: 0.8005 - val_loss: 0.4373 - learning_rate: 0.0036\n",
            "Epoch 5/31\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6929 - loss: 0.5299\n",
            "Epoch 5: val_loss did not improve from 0.43726\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6936 - loss: 0.5301 - val_accuracy: 0.8180 - val_loss: 0.4996 - learning_rate: 0.0036\n",
            "Epoch 6/31\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7043 - loss: 0.5258\n",
            "Epoch 6: val_loss did not improve from 0.43726\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7051 - loss: 0.5250 - val_accuracy: 0.6833 - val_loss: 1.0815 - learning_rate: 0.0036\n",
            "Epoch 7/31\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7219 - loss: 0.4789\n",
            "Epoch 7: val_loss did not improve from 0.43726\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7222 - loss: 0.4795 - val_accuracy: 0.7082 - val_loss: 0.8332 - learning_rate: 0.0036\n",
            "Epoch 8/31\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7364 - loss: 0.4765\n",
            "Epoch 8: val_loss did not improve from 0.43726\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7362 - loss: 0.4773 - val_accuracy: 0.7689 - val_loss: 1.0981 - learning_rate: 0.0036\n",
            "Epoch 9/31\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7375 - loss: 0.4766\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.001453882455781583.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.43726\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7376 - loss: 0.4766 - val_accuracy: 0.7190 - val_loss: 1.1241 - learning_rate: 0.0036\n",
            "Epoch 10/31\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7722 - loss: 0.4409\n",
            "Epoch 10: val_loss did not improve from 0.43726\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7724 - loss: 0.4406 - val_accuracy: 0.8146 - val_loss: 0.5086 - learning_rate: 0.0015\n",
            "Epoch 11/31\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7815 - loss: 0.4203\n",
            "Epoch 11: val_loss improved from 0.43726 to 0.43644, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7817 - loss: 0.4206 - val_accuracy: 0.8038 - val_loss: 0.4364 - learning_rate: 0.0015\n",
            "Epoch 12/31\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 0.4109\n",
            "Epoch 12: val_loss improved from 0.43644 to 0.41863, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7907 - loss: 0.4111 - val_accuracy: 0.8213 - val_loss: 0.4186 - learning_rate: 0.0015\n",
            "Epoch 13/31\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8089 - loss: 0.3993\n",
            "Epoch 13: val_loss improved from 0.41863 to 0.33705, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8085 - loss: 0.3999 - val_accuracy: 0.8520 - val_loss: 0.3371 - learning_rate: 0.0015\n",
            "Epoch 14/31\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8096 - loss: 0.3964\n",
            "Epoch 14: val_loss did not improve from 0.33705\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8093 - loss: 0.3966 - val_accuracy: 0.7955 - val_loss: 0.4153 - learning_rate: 0.0015\n",
            "Epoch 15/31\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8142 - loss: 0.3838\n",
            "Epoch 15: val_loss did not improve from 0.33705\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8140 - loss: 0.3841 - val_accuracy: 0.8146 - val_loss: 0.4067 - learning_rate: 0.0015\n",
            "Epoch 16/31\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8208 - loss: 0.3928\n",
            "Epoch 16: val_loss did not improve from 0.33705\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8202 - loss: 0.3933 - val_accuracy: 0.8047 - val_loss: 0.4554 - learning_rate: 0.0015\n",
            "Epoch 17/31\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8223 - loss: 0.3809\n",
            "Epoch 17: val_loss did not improve from 0.33705\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8215 - loss: 0.3817 - val_accuracy: 0.7889 - val_loss: 0.5036 - learning_rate: 0.0015\n",
            "Epoch 18/31\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8285 - loss: 0.3823\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005822359866354344.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.33705\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8282 - loss: 0.3825 - val_accuracy: 0.8412 - val_loss: 0.3617 - learning_rate: 0.0015\n",
            "Epoch 19/31\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8338 - loss: 0.3662\n",
            "Epoch 19: val_loss improved from 0.33705 to 0.33640, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8338 - loss: 0.3663 - val_accuracy: 0.8446 - val_loss: 0.3364 - learning_rate: 5.8224e-04\n",
            "Epoch 20/31\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8209 - loss: 0.3660\n",
            "Epoch 20: val_loss improved from 0.33640 to 0.33062, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8213 - loss: 0.3663 - val_accuracy: 0.8545 - val_loss: 0.3306 - learning_rate: 5.8224e-04\n",
            "Epoch 21/31\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8321 - loss: 0.3640\n",
            "Epoch 21: val_loss did not improve from 0.33062\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8319 - loss: 0.3646 - val_accuracy: 0.8462 - val_loss: 0.3321 - learning_rate: 5.8224e-04\n",
            "Epoch 22/31\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8308 - loss: 0.3572\n",
            "Epoch 22: val_loss did not improve from 0.33062\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8308 - loss: 0.3572 - val_accuracy: 0.8246 - val_loss: 0.3759 - learning_rate: 5.8224e-04\n",
            "Epoch 23/31\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8326 - loss: 0.3534\n",
            "Epoch 23: val_loss did not improve from 0.33062\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8326 - loss: 0.3535 - val_accuracy: 0.8487 - val_loss: 0.3316 - learning_rate: 5.8224e-04\n",
            "Epoch 24/31\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8387 - loss: 0.3511\n",
            "Epoch 24: val_loss did not improve from 0.33062\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8383 - loss: 0.3521 - val_accuracy: 0.8346 - val_loss: 0.3486 - learning_rate: 5.8224e-04\n",
            "Epoch 25/31\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8271 - loss: 0.3545\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00023316791899936193.\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.33062\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8272 - loss: 0.3547 - val_accuracy: 0.8404 - val_loss: 0.3421 - learning_rate: 5.8224e-04\n",
            "Epoch 26/31\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8533 - loss: 0.3345\n",
            "Epoch 26: val_loss did not improve from 0.33062\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8531 - loss: 0.3348 - val_accuracy: 0.8113 - val_loss: 0.3987 - learning_rate: 2.3317e-04\n",
            "Epoch 27/31\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8543 - loss: 0.3295\n",
            "Epoch 27: val_loss did not improve from 0.33062\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8538 - loss: 0.3301 - val_accuracy: 0.8479 - val_loss: 0.3471 - learning_rate: 2.3317e-04\n",
            "Epoch 28/31\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8458 - loss: 0.3342\n",
            "Epoch 28: val_loss did not improve from 0.33062\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8457 - loss: 0.3348 - val_accuracy: 0.8387 - val_loss: 0.3401 - learning_rate: 2.3317e-04\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:10:59,455] Trial 22 finished with value: -0.3306175768375397 and parameters: {'epochs': 31, 'batch_size': 32, 'learning_rate': 0.0036304423454797136, 'stop_patience': 8, 'reduce_lr_factor': 0.4004697860040467, 'reduce_lr_patience': 5}. Best is trial 20 with value: -0.31752559542655945.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5538 - loss: 0.6879\n",
            "Epoch 1: val_loss improved from inf to 0.71424, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5543 - loss: 0.6877 - val_accuracy: 0.5121 - val_loss: 0.7142 - learning_rate: 9.3010e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5814 - loss: 0.6698\n",
            "Epoch 2: val_loss improved from 0.71424 to 0.49595, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5816 - loss: 0.6696 - val_accuracy: 0.7839 - val_loss: 0.4959 - learning_rate: 9.3010e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6438 - loss: 0.6121\n",
            "Epoch 3: val_loss did not improve from 0.49595\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6439 - loss: 0.6120 - val_accuracy: 0.7839 - val_loss: 0.5178 - learning_rate: 9.3010e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7044 - loss: 0.5478\n",
            "Epoch 4: val_loss improved from 0.49595 to 0.44721, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7042 - loss: 0.5478 - val_accuracy: 0.8238 - val_loss: 0.4472 - learning_rate: 9.3010e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7164 - loss: 0.5223\n",
            "Epoch 5: val_loss improved from 0.44721 to 0.39448, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7170 - loss: 0.5219 - val_accuracy: 0.8337 - val_loss: 0.3945 - learning_rate: 9.3010e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7308 - loss: 0.4919\n",
            "Epoch 6: val_loss did not improve from 0.39448\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7314 - loss: 0.4915 - val_accuracy: 0.8204 - val_loss: 0.4283 - learning_rate: 9.3010e-04\n",
            "Epoch 7/40\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7435 - loss: 0.4793\n",
            "Epoch 7: val_loss did not improve from 0.39448\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7437 - loss: 0.4791 - val_accuracy: 0.7697 - val_loss: 0.6401 - learning_rate: 9.3010e-04\n",
            "Epoch 8/40\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.4547\n",
            "Epoch 8: val_loss improved from 0.39448 to 0.36572, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7757 - loss: 0.4547 - val_accuracy: 0.8537 - val_loss: 0.3657 - learning_rate: 9.3010e-04\n",
            "Epoch 9/40\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7673 - loss: 0.4445\n",
            "Epoch 9: val_loss did not improve from 0.36572\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7674 - loss: 0.4444 - val_accuracy: 0.8130 - val_loss: 0.4629 - learning_rate: 9.3010e-04\n",
            "Epoch 10/40\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.4352\n",
            "Epoch 10: val_loss did not improve from 0.36572\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7792 - loss: 0.4351 - val_accuracy: 0.8279 - val_loss: 0.4428 - learning_rate: 9.3010e-04\n",
            "Epoch 11/40\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7784 - loss: 0.4325\n",
            "Epoch 11: val_loss did not improve from 0.36572\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7782 - loss: 0.4329 - val_accuracy: 0.7481 - val_loss: 0.4944 - learning_rate: 9.3010e-04\n",
            "Epoch 12/40\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7897 - loss: 0.4229\n",
            "Epoch 12: val_loss did not improve from 0.36572\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7891 - loss: 0.4236 - val_accuracy: 0.7573 - val_loss: 0.7485 - learning_rate: 9.3010e-04\n",
            "Epoch 13/40\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7923 - loss: 0.4155\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0003754676931704321.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.36572\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7923 - loss: 0.4156 - val_accuracy: 0.7481 - val_loss: 0.7864 - learning_rate: 9.3010e-04\n",
            "Epoch 14/40\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8080 - loss: 0.3922\n",
            "Epoch 14: val_loss did not improve from 0.36572\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8078 - loss: 0.3923 - val_accuracy: 0.8105 - val_loss: 0.4690 - learning_rate: 3.7547e-04\n",
            "Epoch 15/40\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8067 - loss: 0.3935\n",
            "Epoch 15: val_loss did not improve from 0.36572\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8067 - loss: 0.3935 - val_accuracy: 0.8470 - val_loss: 0.3775 - learning_rate: 3.7547e-04\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:11:21,533] Trial 23 finished with value: -0.3657205402851105 and parameters: {'epochs': 40, 'batch_size': 32, 'learning_rate': 0.0009300996501531804, 'stop_patience': 7, 'reduce_lr_factor': 0.40368545518122695, 'reduce_lr_patience': 5}. Best is trial 20 with value: -0.31752559542655945.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5580 - loss: 0.6885\n",
            "Epoch 1: val_loss improved from inf to 0.68880, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5581 - loss: 0.6885 - val_accuracy: 0.5004 - val_loss: 0.6888 - learning_rate: 0.0037\n",
            "Epoch 2/32\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5660 - loss: 0.6837\n",
            "Epoch 2: val_loss improved from 0.68880 to 0.62825, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5659 - loss: 0.6834 - val_accuracy: 0.5179 - val_loss: 0.6283 - learning_rate: 0.0037\n",
            "Epoch 3/32\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6089 - loss: 0.6459\n",
            "Epoch 3: val_loss improved from 0.62825 to 0.42699, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6096 - loss: 0.6455 - val_accuracy: 0.8088 - val_loss: 0.4270 - learning_rate: 0.0037\n",
            "Epoch 4/32\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6794 - loss: 0.5726\n",
            "Epoch 4: val_loss did not improve from 0.42699\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6793 - loss: 0.5727 - val_accuracy: 0.7980 - val_loss: 0.4934 - learning_rate: 0.0037\n",
            "Epoch 5/32\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6834 - loss: 0.5405\n",
            "Epoch 5: val_loss improved from 0.42699 to 0.39531, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6837 - loss: 0.5404 - val_accuracy: 0.8379 - val_loss: 0.3953 - learning_rate: 0.0037\n",
            "Epoch 6/32\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7081 - loss: 0.5236\n",
            "Epoch 6: val_loss did not improve from 0.39531\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7085 - loss: 0.5231 - val_accuracy: 0.8288 - val_loss: 0.4010 - learning_rate: 0.0037\n",
            "Epoch 7/32\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7196 - loss: 0.5033\n",
            "Epoch 7: val_loss did not improve from 0.39531\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7197 - loss: 0.5034 - val_accuracy: 0.6409 - val_loss: 1.9220 - learning_rate: 0.0037\n",
            "Epoch 8/32\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7316 - loss: 0.4868\n",
            "Epoch 8: val_loss did not improve from 0.39531\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7318 - loss: 0.4868 - val_accuracy: 0.7382 - val_loss: 0.7556 - learning_rate: 0.0037\n",
            "Epoch 9/32\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7437 - loss: 0.4730\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.001657916467267705.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.39531\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7438 - loss: 0.4732 - val_accuracy: 0.7623 - val_loss: 0.5892 - learning_rate: 0.0037\n",
            "Epoch 10/32\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7809 - loss: 0.4343\n",
            "Epoch 10: val_loss improved from 0.39531 to 0.36369, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7809 - loss: 0.4342 - val_accuracy: 0.8354 - val_loss: 0.3637 - learning_rate: 0.0017\n",
            "Epoch 11/32\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7891 - loss: 0.4180\n",
            "Epoch 11: val_loss did not improve from 0.36369\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7891 - loss: 0.4182 - val_accuracy: 0.8487 - val_loss: 0.3642 - learning_rate: 0.0017\n",
            "Epoch 12/32\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8085 - loss: 0.4152\n",
            "Epoch 12: val_loss did not improve from 0.36369\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8084 - loss: 0.4152 - val_accuracy: 0.8470 - val_loss: 0.3682 - learning_rate: 0.0017\n",
            "Epoch 13/32\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7950 - loss: 0.4056\n",
            "Epoch 13: val_loss improved from 0.36369 to 0.34625, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7949 - loss: 0.4060 - val_accuracy: 0.8495 - val_loss: 0.3463 - learning_rate: 0.0017\n",
            "Epoch 14/32\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7996 - loss: 0.4090\n",
            "Epoch 14: val_loss did not improve from 0.34625\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7990 - loss: 0.4096 - val_accuracy: 0.8387 - val_loss: 0.3780 - learning_rate: 0.0017\n",
            "Epoch 15/32\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.4081\n",
            "Epoch 15: val_loss did not improve from 0.34625\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8064 - loss: 0.4082 - val_accuracy: 0.8421 - val_loss: 0.3869 - learning_rate: 0.0017\n",
            "Epoch 16/32\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8103 - loss: 0.3951\n",
            "Epoch 16: val_loss did not improve from 0.34625\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8101 - loss: 0.3954 - val_accuracy: 0.8504 - val_loss: 0.3552 - learning_rate: 0.0017\n",
            "Epoch 17/32\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8144 - loss: 0.3879\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0007458659064113047.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.34625\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8140 - loss: 0.3888 - val_accuracy: 0.8354 - val_loss: 0.3698 - learning_rate: 0.0017\n",
            "Epoch 18/32\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8236 - loss: 0.3711\n",
            "Epoch 18: val_loss did not improve from 0.34625\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8235 - loss: 0.3716 - val_accuracy: 0.8155 - val_loss: 0.4426 - learning_rate: 7.4587e-04\n",
            "Epoch 19/32\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8208 - loss: 0.3799\n",
            "Epoch 19: val_loss improved from 0.34625 to 0.34380, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8209 - loss: 0.3799 - val_accuracy: 0.8529 - val_loss: 0.3438 - learning_rate: 7.4587e-04\n",
            "Epoch 20/32\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8306 - loss: 0.3673\n",
            "Epoch 20: val_loss improved from 0.34380 to 0.33630, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8303 - loss: 0.3677 - val_accuracy: 0.8570 - val_loss: 0.3363 - learning_rate: 7.4587e-04\n",
            "Epoch 21/32\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8206 - loss: 0.3788\n",
            "Epoch 21: val_loss improved from 0.33630 to 0.33006, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8205 - loss: 0.3796 - val_accuracy: 0.8504 - val_loss: 0.3301 - learning_rate: 7.4587e-04\n",
            "Epoch 22/32\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8306 - loss: 0.3621\n",
            "Epoch 22: val_loss did not improve from 0.33006\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8306 - loss: 0.3622 - val_accuracy: 0.8487 - val_loss: 0.3378 - learning_rate: 7.4587e-04\n",
            "Epoch 23/32\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8253 - loss: 0.3651\n",
            "Epoch 23: val_loss did not improve from 0.33006\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8254 - loss: 0.3654 - val_accuracy: 0.8296 - val_loss: 0.3549 - learning_rate: 7.4587e-04\n",
            "Epoch 24/32\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8195 - loss: 0.3697\n",
            "Epoch 24: val_loss did not improve from 0.33006\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8194 - loss: 0.3701 - val_accuracy: 0.8562 - val_loss: 0.3304 - learning_rate: 7.4587e-04\n",
            "Epoch 25/32\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8278 - loss: 0.3518\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00033555126257232197.\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.33006\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8277 - loss: 0.3523 - val_accuracy: 0.8495 - val_loss: 0.3349 - learning_rate: 7.4587e-04\n",
            "Epoch 26/32\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8419 - loss: 0.3439\n",
            "Epoch 26: val_loss did not improve from 0.33006\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8418 - loss: 0.3441 - val_accuracy: 0.8545 - val_loss: 0.3322 - learning_rate: 3.3555e-04\n",
            "Epoch 27/32\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8381 - loss: 0.3377\n",
            "Epoch 27: val_loss did not improve from 0.33006\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8382 - loss: 0.3379 - val_accuracy: 0.8529 - val_loss: 0.3410 - learning_rate: 3.3555e-04\n",
            "Epoch 28/32\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8437 - loss: 0.3324\n",
            "Epoch 28: val_loss did not improve from 0.33006\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8437 - loss: 0.3327 - val_accuracy: 0.8437 - val_loss: 0.3430 - learning_rate: 3.3555e-04\n",
            "Epoch 29/32\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8503 - loss: 0.3363\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00015095830257447836.\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.33006\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8503 - loss: 0.3363 - val_accuracy: 0.8470 - val_loss: 0.3523 - learning_rate: 3.3555e-04\n",
            "Epoch 30/32\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8581 - loss: 0.3238\n",
            "Epoch 30: val_loss did not improve from 0.33006\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8576 - loss: 0.3245 - val_accuracy: 0.8470 - val_loss: 0.3897 - learning_rate: 1.5096e-04\n",
            "Epoch 30: early stopping\n",
            "Restoring model weights from the end of the best epoch: 21.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:12:01,022] Trial 24 finished with value: -0.3300561308860779 and parameters: {'epochs': 32, 'batch_size': 32, 'learning_rate': 0.003685229512149847, 'stop_patience': 9, 'reduce_lr_factor': 0.44988147582153126, 'reduce_lr_patience': 4}. Best is trial 20 with value: -0.31752559542655945.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/46\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5547 - loss: 0.6905\n",
            "Epoch 1: val_loss improved from inf to 0.69761, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5549 - loss: 0.6904 - val_accuracy: 0.4996 - val_loss: 0.6976 - learning_rate: 0.0044\n",
            "Epoch 2/46\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5663 - loss: 0.6850\n",
            "Epoch 2: val_loss improved from 0.69761 to 0.66346, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5662 - loss: 0.6850 - val_accuracy: 0.5129 - val_loss: 0.6635 - learning_rate: 0.0044\n",
            "Epoch 3/46\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5694 - loss: 0.6662\n",
            "Epoch 3: val_loss improved from 0.66346 to 0.63624, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5697 - loss: 0.6661 - val_accuracy: 0.6983 - val_loss: 0.6362 - learning_rate: 0.0044\n",
            "Epoch 4/46\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6345 - loss: 0.5974\n",
            "Epoch 4: val_loss did not improve from 0.63624\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6350 - loss: 0.5971 - val_accuracy: 0.8013 - val_loss: 0.6635 - learning_rate: 0.0044\n",
            "Epoch 5/46\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7027 - loss: 0.5433\n",
            "Epoch 5: val_loss improved from 0.63624 to 0.48459, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7027 - loss: 0.5432 - val_accuracy: 0.8055 - val_loss: 0.4846 - learning_rate: 0.0044\n",
            "Epoch 6/46\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7237 - loss: 0.5003\n",
            "Epoch 6: val_loss did not improve from 0.48459\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7237 - loss: 0.5004 - val_accuracy: 0.8105 - val_loss: 0.6909 - learning_rate: 0.0044\n",
            "Epoch 7/46\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7459 - loss: 0.4836\n",
            "Epoch 7: val_loss did not improve from 0.48459\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7455 - loss: 0.4838 - val_accuracy: 0.7747 - val_loss: 0.7562 - learning_rate: 0.0044\n",
            "Epoch 8/46\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7243 - loss: 0.5016\n",
            "Epoch 8: val_loss did not improve from 0.48459\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7244 - loss: 0.5015 - val_accuracy: 0.8071 - val_loss: 0.4952 - learning_rate: 0.0044\n",
            "Epoch 9/46\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7390 - loss: 0.4692\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0020221399333059608.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.48459\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7390 - loss: 0.4693 - val_accuracy: 0.7415 - val_loss: 0.8846 - learning_rate: 0.0044\n",
            "Epoch 10/46\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7531 - loss: 0.4425\n",
            "Epoch 10: val_loss improved from 0.48459 to 0.39664, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7531 - loss: 0.4425 - val_accuracy: 0.8296 - val_loss: 0.3966 - learning_rate: 0.0020\n",
            "Epoch 11/46\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7758 - loss: 0.4324\n",
            "Epoch 11: val_loss did not improve from 0.39664\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7757 - loss: 0.4325 - val_accuracy: 0.8130 - val_loss: 0.5613 - learning_rate: 0.0020\n",
            "Epoch 12/46\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7810 - loss: 0.4243\n",
            "Epoch 12: val_loss did not improve from 0.39664\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7809 - loss: 0.4246 - val_accuracy: 0.8188 - val_loss: 0.4055 - learning_rate: 0.0020\n",
            "Epoch 13/46\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7779 - loss: 0.4147\n",
            "Epoch 13: val_loss improved from 0.39664 to 0.38010, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7781 - loss: 0.4152 - val_accuracy: 0.8479 - val_loss: 0.3801 - learning_rate: 0.0020\n",
            "Epoch 14/46\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7865 - loss: 0.4136\n",
            "Epoch 14: val_loss did not improve from 0.38010\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7863 - loss: 0.4138 - val_accuracy: 0.8412 - val_loss: 0.4081 - learning_rate: 0.0020\n",
            "Epoch 15/46\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7956 - loss: 0.3987\n",
            "Epoch 15: val_loss improved from 0.38010 to 0.37893, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7956 - loss: 0.3988 - val_accuracy: 0.8404 - val_loss: 0.3789 - learning_rate: 0.0020\n",
            "Epoch 16/46\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8028 - loss: 0.4050\n",
            "Epoch 16: val_loss improved from 0.37893 to 0.36566, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8025 - loss: 0.4054 - val_accuracy: 0.8554 - val_loss: 0.3657 - learning_rate: 0.0020\n",
            "Epoch 17/46\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8069 - loss: 0.3957\n",
            "Epoch 17: val_loss did not improve from 0.36566\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.3961 - val_accuracy: 0.8421 - val_loss: 0.3883 - learning_rate: 0.0020\n",
            "Epoch 18/46\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8003 - loss: 0.3964\n",
            "Epoch 18: val_loss did not improve from 0.36566\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8002 - loss: 0.3967 - val_accuracy: 0.8379 - val_loss: 0.5140 - learning_rate: 0.0020\n",
            "Epoch 19/46\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8099 - loss: 0.3900\n",
            "Epoch 19: val_loss did not improve from 0.36566\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8096 - loss: 0.3905 - val_accuracy: 0.8412 - val_loss: 0.4151 - learning_rate: 0.0020\n",
            "Epoch 20/46\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.3830\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0009192208574174816.\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.36566\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8088 - loss: 0.3835 - val_accuracy: 0.8254 - val_loss: 0.5374 - learning_rate: 0.0020\n",
            "Epoch 21/46\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8191 - loss: 0.3651\n",
            "Epoch 21: val_loss did not improve from 0.36566\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8191 - loss: 0.3653 - val_accuracy: 0.8487 - val_loss: 0.3881 - learning_rate: 9.1922e-04\n",
            "Epoch 22/46\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8390 - loss: 0.3540\n",
            "Epoch 22: val_loss did not improve from 0.36566\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8388 - loss: 0.3542 - val_accuracy: 0.8495 - val_loss: 0.3970 - learning_rate: 9.1922e-04\n",
            "Epoch 23/46\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8370 - loss: 0.3484\n",
            "Epoch 23: val_loss did not improve from 0.36566\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8368 - loss: 0.3487 - val_accuracy: 0.8529 - val_loss: 0.4081 - learning_rate: 9.1922e-04\n",
            "Epoch 24/46\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8397 - loss: 0.3482\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0004178578123579802.\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.36566\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8393 - loss: 0.3487 - val_accuracy: 0.8603 - val_loss: 0.4237 - learning_rate: 9.1922e-04\n",
            "Epoch 25/46\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8396 - loss: 0.3408\n",
            "Epoch 25: val_loss did not improve from 0.36566\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8395 - loss: 0.3408 - val_accuracy: 0.8579 - val_loss: 0.3865 - learning_rate: 4.1786e-04\n",
            "Epoch 25: early stopping\n",
            "Restoring model weights from the end of the best epoch: 16.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:12:58,050] Trial 25 finished with value: -0.36565759778022766 and parameters: {'epochs': 46, 'batch_size': 16, 'learning_rate': 0.004448386812230081, 'stop_patience': 9, 'reduce_lr_factor': 0.45457825629853255, 'reduce_lr_patience': 4}. Best is trial 20 with value: -0.31752559542655945.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5587 - loss: 0.6874\n",
            "Epoch 1: val_loss improved from inf to 0.73211, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5587 - loss: 0.6873 - val_accuracy: 0.5046 - val_loss: 0.7321 - learning_rate: 0.0028\n",
            "Epoch 2/50\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5766 - loss: 0.6776\n",
            "Epoch 2: val_loss did not improve from 0.73211\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5766 - loss: 0.6775 - val_accuracy: 0.5628 - val_loss: 1.0360 - learning_rate: 0.0028\n",
            "Epoch 3/50\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6553 - loss: 0.6108\n",
            "Epoch 3: val_loss improved from 0.73211 to 0.65000, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6554 - loss: 0.6106 - val_accuracy: 0.7623 - val_loss: 0.6500 - learning_rate: 0.0028\n",
            "Epoch 4/50\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6654 - loss: 0.5707\n",
            "Epoch 4: val_loss improved from 0.65000 to 0.50416, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6659 - loss: 0.5702 - val_accuracy: 0.8229 - val_loss: 0.5042 - learning_rate: 0.0028\n",
            "Epoch 5/50\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7115 - loss: 0.5208\n",
            "Epoch 5: val_loss improved from 0.50416 to 0.39449, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7116 - loss: 0.5207 - val_accuracy: 0.8229 - val_loss: 0.3945 - learning_rate: 0.0028\n",
            "Epoch 6/50\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7183 - loss: 0.4965\n",
            "Epoch 6: val_loss improved from 0.39449 to 0.39174, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7184 - loss: 0.4965 - val_accuracy: 0.8421 - val_loss: 0.3917 - learning_rate: 0.0028\n",
            "Epoch 7/50\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7302 - loss: 0.4733\n",
            "Epoch 7: val_loss did not improve from 0.39174\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7307 - loss: 0.4737 - val_accuracy: 0.8279 - val_loss: 0.4965 - learning_rate: 0.0028\n",
            "Epoch 8/50\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7404 - loss: 0.4761\n",
            "Epoch 8: val_loss did not improve from 0.39174\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7404 - loss: 0.4761 - val_accuracy: 0.8071 - val_loss: 0.6149 - learning_rate: 0.0028\n",
            "Epoch 9/50\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7523 - loss: 0.4688\n",
            "Epoch 9: val_loss did not improve from 0.39174\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7523 - loss: 0.4688 - val_accuracy: 0.8221 - val_loss: 0.5407 - learning_rate: 0.0028\n",
            "Epoch 10/50\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7614 - loss: 0.4597\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0013657607722227243.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.39174\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7613 - loss: 0.4599 - val_accuracy: 0.7972 - val_loss: 0.5807 - learning_rate: 0.0028\n",
            "Epoch 11/50\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7676 - loss: 0.4354\n",
            "Epoch 11: val_loss did not improve from 0.39174\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7682 - loss: 0.4351 - val_accuracy: 0.8321 - val_loss: 0.4561 - learning_rate: 0.0014\n",
            "Epoch 12/50\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7959 - loss: 0.4169\n",
            "Epoch 12: val_loss did not improve from 0.39174\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7956 - loss: 0.4170 - val_accuracy: 0.8238 - val_loss: 0.4787 - learning_rate: 0.0014\n",
            "Epoch 13/50\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7969 - loss: 0.4058\n",
            "Epoch 13: val_loss did not improve from 0.39174\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7966 - loss: 0.4063 - val_accuracy: 0.7905 - val_loss: 0.5793 - learning_rate: 0.0014\n",
            "Epoch 14/50\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8080 - loss: 0.4052\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0006747180081340747.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.39174\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8079 - loss: 0.4053 - val_accuracy: 0.8138 - val_loss: 0.4011 - learning_rate: 0.0014\n",
            "Epoch 15/50\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8092 - loss: 0.3895\n",
            "Epoch 15: val_loss improved from 0.39174 to 0.36920, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8092 - loss: 0.3895 - val_accuracy: 0.8221 - val_loss: 0.3692 - learning_rate: 6.7472e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8218 - loss: 0.3834\n",
            "Epoch 16: val_loss improved from 0.36920 to 0.34135, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8213 - loss: 0.3836 - val_accuracy: 0.8304 - val_loss: 0.3413 - learning_rate: 6.7472e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8151 - loss: 0.3823\n",
            "Epoch 17: val_loss did not improve from 0.34135\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8151 - loss: 0.3823 - val_accuracy: 0.8446 - val_loss: 0.3439 - learning_rate: 6.7472e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8174 - loss: 0.3726\n",
            "Epoch 18: val_loss did not improve from 0.34135\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8174 - loss: 0.3727 - val_accuracy: 0.8263 - val_loss: 0.3542 - learning_rate: 6.7472e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8169 - loss: 0.3795\n",
            "Epoch 19: val_loss improved from 0.34135 to 0.33868, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8169 - loss: 0.3796 - val_accuracy: 0.8462 - val_loss: 0.3387 - learning_rate: 6.7472e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8183 - loss: 0.3741\n",
            "Epoch 20: val_loss did not improve from 0.33868\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8183 - loss: 0.3743 - val_accuracy: 0.8379 - val_loss: 0.3925 - learning_rate: 6.7472e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8214 - loss: 0.3776\n",
            "Epoch 21: val_loss did not improve from 0.33868\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8213 - loss: 0.3776 - val_accuracy: 0.8529 - val_loss: 0.3757 - learning_rate: 6.7472e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8221 - loss: 0.3708\n",
            "Epoch 22: val_loss did not improve from 0.33868\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8221 - loss: 0.3708 - val_accuracy: 0.8462 - val_loss: 0.3511 - learning_rate: 6.7472e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8293 - loss: 0.3653\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00033332658517897315.\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.33868\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8293 - loss: 0.3653 - val_accuracy: 0.8462 - val_loss: 0.3529 - learning_rate: 6.7472e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8385 - loss: 0.3480\n",
            "Epoch 24: val_loss did not improve from 0.33868\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8383 - loss: 0.3483 - val_accuracy: 0.8279 - val_loss: 0.3609 - learning_rate: 3.3333e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8373 - loss: 0.3477\n",
            "Epoch 25: val_loss did not improve from 0.33868\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8371 - loss: 0.3480 - val_accuracy: 0.8470 - val_loss: 0.3812 - learning_rate: 3.3333e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8383 - loss: 0.3461\n",
            "Epoch 26: val_loss did not improve from 0.33868\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8383 - loss: 0.3462 - val_accuracy: 0.8387 - val_loss: 0.3618 - learning_rate: 3.3333e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8397 - loss: 0.3436\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00016467118063618886.\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.33868\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8397 - loss: 0.3437 - val_accuracy: 0.8454 - val_loss: 0.3433 - learning_rate: 3.3333e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 0.3266\n",
            "Epoch 28: val_loss did not improve from 0.33868\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8483 - loss: 0.3269 - val_accuracy: 0.8371 - val_loss: 0.3645 - learning_rate: 1.6467e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8584 - loss: 0.3203\n",
            "Epoch 29: val_loss did not improve from 0.33868\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8579 - loss: 0.3208 - val_accuracy: 0.8321 - val_loss: 0.3865 - learning_rate: 1.6467e-04\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 19.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:13:35,835] Trial 26 finished with value: -0.33867815136909485 and parameters: {'epochs': 50, 'batch_size': 32, 'learning_rate': 0.0027645660283425987, 'stop_patience': 10, 'reduce_lr_factor': 0.49402355427218697, 'reduce_lr_patience': 4}. Best is trial 20 with value: -0.31752559542655945.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/33\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5524 - loss: 0.6901\n",
            "Epoch 1: val_loss improved from inf to 0.69313, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5525 - loss: 0.6900 - val_accuracy: 0.4996 - val_loss: 0.6931 - learning_rate: 0.0057\n",
            "Epoch 2/33\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5619 - loss: 0.6853\n",
            "Epoch 2: val_loss did not improve from 0.69313\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5619 - loss: 0.6854 - val_accuracy: 0.4996 - val_loss: 0.6996 - learning_rate: 0.0057\n",
            "Epoch 3/33\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5667 - loss: 0.6849\n",
            "Epoch 3: val_loss did not improve from 0.69313\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5668 - loss: 0.6848 - val_accuracy: 0.4996 - val_loss: 0.6935 - learning_rate: 0.0057\n",
            "Epoch 4/33\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5631 - loss: 0.6801\n",
            "Epoch 4: val_loss did not improve from 0.69313\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5632 - loss: 0.6804 - val_accuracy: 0.4996 - val_loss: 0.6986 - learning_rate: 0.0057\n",
            "Epoch 5/33\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5668 - loss: 0.6848\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.002489732322918571.\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.69313\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5668 - loss: 0.6848 - val_accuracy: 0.4730 - val_loss: 0.6937 - learning_rate: 0.0057\n",
            "Epoch 6/33\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5664 - loss: 0.6842\n",
            "Epoch 6: val_loss improved from 0.69313 to 0.69184, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5663 - loss: 0.6842 - val_accuracy: 0.4863 - val_loss: 0.6918 - learning_rate: 0.0025\n",
            "Epoch 7/33\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5677 - loss: 0.6820\n",
            "Epoch 7: val_loss improved from 0.69184 to 0.66520, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5679 - loss: 0.6819 - val_accuracy: 0.5844 - val_loss: 0.6652 - learning_rate: 0.0025\n",
            "Epoch 8/33\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6023 - loss: 0.6661\n",
            "Epoch 8: val_loss improved from 0.66520 to 0.66367, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6030 - loss: 0.6659 - val_accuracy: 0.6775 - val_loss: 0.6637 - learning_rate: 0.0025\n",
            "Epoch 9/33\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6423 - loss: 0.6156\n",
            "Epoch 9: val_loss improved from 0.66367 to 0.54172, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6425 - loss: 0.6153 - val_accuracy: 0.7922 - val_loss: 0.5417 - learning_rate: 0.0025\n",
            "Epoch 10/33\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6499 - loss: 0.5768\n",
            "Epoch 10: val_loss did not improve from 0.54172\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6508 - loss: 0.5771 - val_accuracy: 0.8022 - val_loss: 0.6389 - learning_rate: 0.0025\n",
            "Epoch 11/33\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6869 - loss: 0.5500\n",
            "Epoch 11: val_loss did not improve from 0.54172\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6870 - loss: 0.5499 - val_accuracy: 0.7182 - val_loss: 0.9905 - learning_rate: 0.0025\n",
            "Epoch 12/33\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6927 - loss: 0.5328\n",
            "Epoch 12: val_loss did not improve from 0.54172\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6931 - loss: 0.5328 - val_accuracy: 0.7249 - val_loss: 0.8093 - learning_rate: 0.0025\n",
            "Epoch 13/33\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7165 - loss: 0.5023\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.001095985128243415.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.54172\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7165 - loss: 0.5023 - val_accuracy: 0.7731 - val_loss: 0.5838 - learning_rate: 0.0025\n",
            "Epoch 14/33\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7303 - loss: 0.4921\n",
            "Epoch 14: val_loss did not improve from 0.54172\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7305 - loss: 0.4921 - val_accuracy: 0.7465 - val_loss: 0.5438 - learning_rate: 0.0011\n",
            "Epoch 15/33\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7428 - loss: 0.4843\n",
            "Epoch 15: val_loss did not improve from 0.54172\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7425 - loss: 0.4844 - val_accuracy: 0.7032 - val_loss: 0.6164 - learning_rate: 0.0011\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:13:57,981] Trial 27 finished with value: -0.5417189002037048 and parameters: {'epochs': 33, 'batch_size': 32, 'learning_rate': 0.005655886307651942, 'stop_patience': 6, 'reduce_lr_factor': 0.440201988055143, 'reduce_lr_patience': 4}. Best is trial 20 with value: -0.31752559542655945.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5650 - loss: 0.6867\n",
            "Epoch 1: val_loss improved from inf to 0.74170, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.5652 - loss: 0.6865 - val_accuracy: 0.5387 - val_loss: 0.7417 - learning_rate: 9.5526e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5902 - loss: 0.6607\n",
            "Epoch 2: val_loss improved from 0.74170 to 0.49098, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5904 - loss: 0.6604 - val_accuracy: 0.7722 - val_loss: 0.4910 - learning_rate: 9.5526e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6482 - loss: 0.6080\n",
            "Epoch 3: val_loss did not improve from 0.49098\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6487 - loss: 0.6077 - val_accuracy: 0.7972 - val_loss: 0.4931 - learning_rate: 9.5526e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6888 - loss: 0.5573\n",
            "Epoch 4: val_loss improved from 0.49098 to 0.42514, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6898 - loss: 0.5568 - val_accuracy: 0.8271 - val_loss: 0.4251 - learning_rate: 9.5526e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7278 - loss: 0.5115\n",
            "Epoch 5: val_loss did not improve from 0.42514\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7278 - loss: 0.5114 - val_accuracy: 0.8138 - val_loss: 0.4926 - learning_rate: 9.5526e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7625 - loss: 0.4781\n",
            "Epoch 6: val_loss did not improve from 0.42514\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7619 - loss: 0.4781 - val_accuracy: 0.7548 - val_loss: 0.8672 - learning_rate: 9.5526e-04\n",
            "Epoch 7/40\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7573 - loss: 0.4683\n",
            "Epoch 7: val_loss did not improve from 0.42514\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7574 - loss: 0.4682 - val_accuracy: 0.8105 - val_loss: 0.5113 - learning_rate: 9.5526e-04\n",
            "Epoch 8/40\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7826 - loss: 0.4431\n",
            "Epoch 8: val_loss did not improve from 0.42514\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7820 - loss: 0.4433 - val_accuracy: 0.8013 - val_loss: 0.6320 - learning_rate: 9.5526e-04\n",
            "Epoch 9/40\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7797 - loss: 0.4390\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00044778312189278665.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.42514\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7794 - loss: 0.4392 - val_accuracy: 0.7872 - val_loss: 0.6613 - learning_rate: 9.5526e-04\n",
            "Epoch 10/40\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8053 - loss: 0.4112\n",
            "Epoch 10: val_loss improved from 0.42514 to 0.40334, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8052 - loss: 0.4112 - val_accuracy: 0.8429 - val_loss: 0.4033 - learning_rate: 4.4778e-04\n",
            "Epoch 11/40\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7975 - loss: 0.4006\n",
            "Epoch 11: val_loss improved from 0.40334 to 0.39576, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7975 - loss: 0.4007 - val_accuracy: 0.8387 - val_loss: 0.3958 - learning_rate: 4.4778e-04\n",
            "Epoch 12/40\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8063 - loss: 0.3944\n",
            "Epoch 12: val_loss improved from 0.39576 to 0.36604, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8061 - loss: 0.3946 - val_accuracy: 0.8437 - val_loss: 0.3660 - learning_rate: 4.4778e-04\n",
            "Epoch 13/40\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8008 - loss: 0.3923\n",
            "Epoch 13: val_loss did not improve from 0.36604\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8008 - loss: 0.3923 - val_accuracy: 0.8346 - val_loss: 0.4063 - learning_rate: 4.4778e-04\n",
            "Epoch 14/40\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8100 - loss: 0.3853\n",
            "Epoch 14: val_loss did not improve from 0.36604\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8097 - loss: 0.3857 - val_accuracy: 0.8246 - val_loss: 0.4622 - learning_rate: 4.4778e-04\n",
            "Epoch 15/40\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8126 - loss: 0.3846\n",
            "Epoch 15: val_loss did not improve from 0.36604\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8126 - loss: 0.3847 - val_accuracy: 0.8379 - val_loss: 0.3988 - learning_rate: 4.4778e-04\n",
            "Epoch 16/40\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8082 - loss: 0.3843\n",
            "Epoch 16: val_loss did not improve from 0.36604\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.3845 - val_accuracy: 0.8354 - val_loss: 0.4167 - learning_rate: 4.4778e-04\n",
            "Epoch 17/40\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8216 - loss: 0.3691\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00020990002750301845.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.36604\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8216 - loss: 0.3693 - val_accuracy: 0.8412 - val_loss: 0.3755 - learning_rate: 4.4778e-04\n",
            "Epoch 18/40\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8302 - loss: 0.3626\n",
            "Epoch 18: val_loss improved from 0.36604 to 0.33720, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8303 - loss: 0.3627 - val_accuracy: 0.8562 - val_loss: 0.3372 - learning_rate: 2.0990e-04\n",
            "Epoch 19/40\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8295 - loss: 0.3614\n",
            "Epoch 19: val_loss improved from 0.33720 to 0.32517, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8295 - loss: 0.3615 - val_accuracy: 0.8554 - val_loss: 0.3252 - learning_rate: 2.0990e-04\n",
            "Epoch 20/40\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8250 - loss: 0.3575\n",
            "Epoch 20: val_loss did not improve from 0.32517\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8250 - loss: 0.3575 - val_accuracy: 0.8529 - val_loss: 0.3253 - learning_rate: 2.0990e-04\n",
            "Epoch 21/40\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8280 - loss: 0.3540\n",
            "Epoch 21: val_loss did not improve from 0.32517\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8278 - loss: 0.3548 - val_accuracy: 0.8529 - val_loss: 0.3321 - learning_rate: 2.0990e-04\n",
            "Epoch 22/40\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8266 - loss: 0.3597\n",
            "Epoch 22: val_loss did not improve from 0.32517\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8269 - loss: 0.3601 - val_accuracy: 0.8462 - val_loss: 0.3466 - learning_rate: 2.0990e-04\n",
            "Epoch 23/40\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8298 - loss: 0.3542\n",
            "Epoch 23: val_loss did not improve from 0.32517\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8299 - loss: 0.3544 - val_accuracy: 0.8554 - val_loss: 0.3291 - learning_rate: 2.0990e-04\n",
            "Epoch 24/40\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8279 - loss: 0.3535\n",
            "Epoch 24: val_loss improved from 0.32517 to 0.32302, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8280 - loss: 0.3539 - val_accuracy: 0.8587 - val_loss: 0.3230 - learning_rate: 2.0990e-04\n",
            "Epoch 25/40\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8318 - loss: 0.3536\n",
            "Epoch 25: val_loss did not improve from 0.32302\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8318 - loss: 0.3536 - val_accuracy: 0.8437 - val_loss: 0.3437 - learning_rate: 2.0990e-04\n",
            "Epoch 26/40\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8266 - loss: 0.3555\n",
            "Epoch 26: val_loss did not improve from 0.32302\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8271 - loss: 0.3556 - val_accuracy: 0.8570 - val_loss: 0.3236 - learning_rate: 2.0990e-04\n",
            "Epoch 27/40\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8347 - loss: 0.3484\n",
            "Epoch 27: val_loss improved from 0.32302 to 0.32240, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8349 - loss: 0.3487 - val_accuracy: 0.8562 - val_loss: 0.3224 - learning_rate: 2.0990e-04\n",
            "Epoch 28/40\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8276 - loss: 0.3508\n",
            "Epoch 28: val_loss did not improve from 0.32240\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8279 - loss: 0.3508 - val_accuracy: 0.8579 - val_loss: 0.3304 - learning_rate: 2.0990e-04\n",
            "Epoch 29/40\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8314 - loss: 0.3504\n",
            "Epoch 29: val_loss did not improve from 0.32240\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8316 - loss: 0.3504 - val_accuracy: 0.8504 - val_loss: 0.3330 - learning_rate: 2.0990e-04\n",
            "Epoch 30/40\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8306 - loss: 0.3493\n",
            "Epoch 30: val_loss did not improve from 0.32240\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8307 - loss: 0.3494 - val_accuracy: 0.8487 - val_loss: 0.3340 - learning_rate: 2.0990e-04\n",
            "Epoch 31/40\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8344 - loss: 0.3422\n",
            "Epoch 31: val_loss did not improve from 0.32240\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8343 - loss: 0.3424 - val_accuracy: 0.8504 - val_loss: 0.3232 - learning_rate: 2.0990e-04\n",
            "Epoch 32/40\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8347 - loss: 0.3462\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 9.839142873246445e-05.\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.32240\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8348 - loss: 0.3462 - val_accuracy: 0.8520 - val_loss: 0.3364 - learning_rate: 2.0990e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8500 - loss: 0.3281\n",
            "Epoch 33: val_loss did not improve from 0.32240\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8499 - loss: 0.3285 - val_accuracy: 0.8562 - val_loss: 0.3336 - learning_rate: 9.8391e-05\n",
            "Epoch 34/40\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8478 - loss: 0.3256\n",
            "Epoch 34: val_loss did not improve from 0.32240\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8476 - loss: 0.3262 - val_accuracy: 0.8495 - val_loss: 0.3403 - learning_rate: 9.8391e-05\n",
            "Epoch 35/40\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8522 - loss: 0.3235\n",
            "Epoch 35: val_loss did not improve from 0.32240\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8521 - loss: 0.3240 - val_accuracy: 0.8595 - val_loss: 0.3304 - learning_rate: 9.8391e-05\n",
            "Epoch 36/40\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8520 - loss: 0.3230\n",
            "Epoch 36: val_loss did not improve from 0.32240\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8519 - loss: 0.3233 - val_accuracy: 0.8562 - val_loss: 0.3312 - learning_rate: 9.8391e-05\n",
            "Epoch 36: early stopping\n",
            "Restoring model weights from the end of the best epoch: 27.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:14:43,431] Trial 28 finished with value: -0.32239654660224915 and parameters: {'epochs': 40, 'batch_size': 32, 'learning_rate': 0.0009552629498519503, 'stop_patience': 9, 'reduce_lr_factor': 0.46875376954888326, 'reduce_lr_patience': 5}. Best is trial 20 with value: -0.31752559542655945.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5595 - loss: 0.6875\n",
            "Epoch 1: val_loss improved from inf to 0.71626, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5597 - loss: 0.6874 - val_accuracy: 0.5112 - val_loss: 0.7163 - learning_rate: 8.4030e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5746 - loss: 0.6722\n",
            "Epoch 2: val_loss improved from 0.71626 to 0.55552, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5755 - loss: 0.6715 - val_accuracy: 0.6542 - val_loss: 0.5555 - learning_rate: 8.4030e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6347 - loss: 0.6271\n",
            "Epoch 3: val_loss improved from 0.55552 to 0.41413, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6347 - loss: 0.6273 - val_accuracy: 0.8171 - val_loss: 0.4141 - learning_rate: 8.4030e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6913 - loss: 0.5722\n",
            "Epoch 4: val_loss did not improve from 0.41413\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6913 - loss: 0.5721 - val_accuracy: 0.8113 - val_loss: 0.4744 - learning_rate: 8.4030e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7193 - loss: 0.5197\n",
            "Epoch 5: val_loss did not improve from 0.41413\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7198 - loss: 0.5196 - val_accuracy: 0.6683 - val_loss: 1.2369 - learning_rate: 8.4030e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7521 - loss: 0.4779\n",
            "Epoch 6: val_loss did not improve from 0.41413\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7519 - loss: 0.4776 - val_accuracy: 0.7722 - val_loss: 0.7216 - learning_rate: 8.4030e-04\n",
            "Epoch 7/40\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7672 - loss: 0.4620\n",
            "Epoch 7: val_loss did not improve from 0.41413\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7668 - loss: 0.4621 - val_accuracy: 0.7714 - val_loss: 0.6671 - learning_rate: 8.4030e-04\n",
            "Epoch 8/40\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7704 - loss: 0.4442\n",
            "Epoch 8: val_loss improved from 0.41413 to 0.35803, saving model to BEST_CNN_SEQ_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7701 - loss: 0.4450 - val_accuracy: 0.8470 - val_loss: 0.3580 - learning_rate: 8.4030e-04\n",
            "Epoch 9/40\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7685 - loss: 0.4383\n",
            "Epoch 9: val_loss did not improve from 0.35803\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7685 - loss: 0.4386 - val_accuracy: 0.7797 - val_loss: 0.7076 - learning_rate: 8.4030e-04\n",
            "Epoch 10/40\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7842 - loss: 0.4289\n",
            "Epoch 10: val_loss did not improve from 0.35803\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7842 - loss: 0.4289 - val_accuracy: 0.8246 - val_loss: 0.4454 - learning_rate: 8.4030e-04\n",
            "Epoch 11/40\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7828 - loss: 0.4183\n",
            "Epoch 11: val_loss did not improve from 0.35803\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7829 - loss: 0.4184 - val_accuracy: 0.7731 - val_loss: 0.6221 - learning_rate: 8.4030e-04\n",
            "Epoch 12/40\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7959 - loss: 0.4129\n",
            "Epoch 12: val_loss did not improve from 0.35803\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7956 - loss: 0.4132 - val_accuracy: 0.7548 - val_loss: 0.6567 - learning_rate: 8.4030e-04\n",
            "Epoch 13/40\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7919 - loss: 0.4145\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0003254264565481202.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.35803\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7919 - loss: 0.4146 - val_accuracy: 0.8121 - val_loss: 0.4778 - learning_rate: 8.4030e-04\n",
            "Epoch 14/40\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8035 - loss: 0.3889\n",
            "Epoch 14: val_loss did not improve from 0.35803\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8035 - loss: 0.3889 - val_accuracy: 0.8454 - val_loss: 0.4051 - learning_rate: 3.2543e-04\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:15:02,973] Trial 29 finished with value: -0.3580297529697418 and parameters: {'epochs': 40, 'batch_size': 32, 'learning_rate': 0.0008402976922182054, 'stop_patience': 6, 'reduce_lr_factor': 0.38727521116419283, 'reduce_lr_patience': 5}. Best is trial 20 with value: -0.31752559542655945.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Melhor combinação encontrada:\n",
            "trial                  20.000000\n",
            "epochs                 41.000000\n",
            "batch_size             32.000000\n",
            "learning_rate           0.001421\n",
            "stop_patience           7.000000\n",
            "reduce_lr_factor        0.416126\n",
            "reduce_lr_patience      5.000000\n",
            "recall_Compra(1)        0.875415\n",
            "recall_Vende(0)         0.836938\n",
            "precision_Compra(1)     0.843200\n",
            "precision_Vende(0)      0.870242\n",
            "macro_recall            0.856177\n",
            "accuracy                0.856193\n",
            "f1_macro                0.856136\n",
            "f1_weighted             0.856138\n",
            "min_val_loss            0.317526\n",
            "Name: 0, dtype: float64\n",
            "🔍 Hiperparâmetros: {'epochs': 41, 'batch_size': 32, 'learning_rate': 0.0014212445863227706, 'stop_patience': 7, 'reduce_lr_factor': 0.41612579191529886, 'reduce_lr_patience': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_ram_model, best_ram_history, df_results, best_ram_metrics, best_ram_y_pred = train_model(\n",
        "    model_fn=model_cnn_ramificado,\n",
        "    model_path = \"BEST_CNN_RAM_VALE3.keras\",\n",
        "    X_train=[X_train1, X_train2],\n",
        "    y_train=y_train,\n",
        "    X_test=[X_test1, X_test2],\n",
        "    y_test=y_test,\n",
        "    prob=0.5,\n",
        "    n_trials=30,\n",
        "    metric_to_optimize=metric_optimization)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvQDq2Oh7nCG",
        "outputId": "e2f4480b-4b97-4977-f4f2-fc063366d782"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:15:02,987] A new study created in memory with name: no-name-327424b5-9cb4-4329-a8ef-cfc483774238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/31\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5968 - loss: 0.6775\n",
            "Epoch 1: val_loss improved from inf to 0.93138, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5977 - loss: 0.6764 - val_accuracy: 0.5378 - val_loss: 0.9314 - learning_rate: 0.0018\n",
            "Epoch 2/31\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6364 - loss: 0.6259\n",
            "Epoch 2: val_loss improved from 0.93138 to 0.54533, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6374 - loss: 0.6249 - val_accuracy: 0.7249 - val_loss: 0.5453 - learning_rate: 0.0018\n",
            "Epoch 3/31\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6902 - loss: 0.5641\n",
            "Epoch 3: val_loss improved from 0.54533 to 0.37121, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6902 - loss: 0.5631 - val_accuracy: 0.8371 - val_loss: 0.3712 - learning_rate: 0.0018\n",
            "Epoch 4/31\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7171 - loss: 0.5190\n",
            "Epoch 4: val_loss did not improve from 0.37121\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7176 - loss: 0.5186 - val_accuracy: 0.7839 - val_loss: 0.6017 - learning_rate: 0.0018\n",
            "Epoch 5/31\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7274 - loss: 0.4909\n",
            "Epoch 5: val_loss did not improve from 0.37121\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7277 - loss: 0.4908 - val_accuracy: 0.8437 - val_loss: 0.4037 - learning_rate: 0.0018\n",
            "Epoch 6/31\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7529 - loss: 0.4709\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00028731283939236493.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.37121\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7523 - loss: 0.4713 - val_accuracy: 0.8554 - val_loss: 0.3717 - learning_rate: 0.0018\n",
            "Epoch 7/31\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7725 - loss: 0.4435\n",
            "Epoch 7: val_loss did not improve from 0.37121\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7728 - loss: 0.4434 - val_accuracy: 0.8612 - val_loss: 0.3788 - learning_rate: 2.8731e-04\n",
            "Epoch 8/31\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7768 - loss: 0.4384\n",
            "Epoch 8: val_loss did not improve from 0.37121\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7769 - loss: 0.4384 - val_accuracy: 0.8595 - val_loss: 0.3713 - learning_rate: 2.8731e-04\n",
            "Epoch 9/31\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7917 - loss: 0.4272\n",
            "Epoch 9: val_loss improved from 0.37121 to 0.35808, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7920 - loss: 0.4275 - val_accuracy: 0.8620 - val_loss: 0.3581 - learning_rate: 2.8731e-04\n",
            "Epoch 10/31\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7916 - loss: 0.4251\n",
            "Epoch 10: val_loss did not improve from 0.35808\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7916 - loss: 0.4255 - val_accuracy: 0.8612 - val_loss: 0.3686 - learning_rate: 2.8731e-04\n",
            "Epoch 11/31\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7923 - loss: 0.4190\n",
            "Epoch 11: val_loss did not improve from 0.35808\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7928 - loss: 0.4196 - val_accuracy: 0.8603 - val_loss: 0.3666 - learning_rate: 2.8731e-04\n",
            "Epoch 12/31\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7943 - loss: 0.4229\n",
            "Epoch 12: val_loss improved from 0.35808 to 0.35725, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7948 - loss: 0.4226 - val_accuracy: 0.8612 - val_loss: 0.3573 - learning_rate: 2.8731e-04\n",
            "Epoch 13/31\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7951 - loss: 0.4130\n",
            "Epoch 13: val_loss improved from 0.35725 to 0.34904, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7956 - loss: 0.4133 - val_accuracy: 0.8628 - val_loss: 0.3490 - learning_rate: 2.8731e-04\n",
            "Epoch 14/31\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7994 - loss: 0.4126\n",
            "Epoch 14: val_loss did not improve from 0.34904\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7996 - loss: 0.4126 - val_accuracy: 0.8628 - val_loss: 0.3587 - learning_rate: 2.8731e-04\n",
            "Epoch 15/31\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8029 - loss: 0.4086\n",
            "Epoch 15: val_loss improved from 0.34904 to 0.34794, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8031 - loss: 0.4089 - val_accuracy: 0.8653 - val_loss: 0.3479 - learning_rate: 2.8731e-04\n",
            "Epoch 16/31\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8005 - loss: 0.4082\n",
            "Epoch 16: val_loss improved from 0.34794 to 0.34694, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8007 - loss: 0.4081 - val_accuracy: 0.8645 - val_loss: 0.3469 - learning_rate: 2.8731e-04\n",
            "Epoch 17/31\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8058 - loss: 0.4014\n",
            "Epoch 17: val_loss improved from 0.34694 to 0.34094, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8059 - loss: 0.4015 - val_accuracy: 0.8687 - val_loss: 0.3409 - learning_rate: 2.8731e-04\n",
            "Epoch 18/31\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8047 - loss: 0.4016\n",
            "Epoch 18: val_loss improved from 0.34094 to 0.32884, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8052 - loss: 0.4022 - val_accuracy: 0.8695 - val_loss: 0.3288 - learning_rate: 2.8731e-04\n",
            "Epoch 19/31\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8099 - loss: 0.3996\n",
            "Epoch 19: val_loss did not improve from 0.32884\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8100 - loss: 0.3996 - val_accuracy: 0.8720 - val_loss: 0.3428 - learning_rate: 2.8731e-04\n",
            "Epoch 20/31\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8061 - loss: 0.3936\n",
            "Epoch 20: val_loss did not improve from 0.32884\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8063 - loss: 0.3938 - val_accuracy: 0.8695 - val_loss: 0.3434 - learning_rate: 2.8731e-04\n",
            "Epoch 21/31\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8051 - loss: 0.4011\n",
            "Epoch 21: val_loss improved from 0.32884 to 0.32854, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8055 - loss: 0.4011 - val_accuracy: 0.8712 - val_loss: 0.3285 - learning_rate: 2.8731e-04\n",
            "Epoch 22/31\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.3934\n",
            "Epoch 22: val_loss did not improve from 0.32854\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8141 - loss: 0.3934 - val_accuracy: 0.8728 - val_loss: 0.3337 - learning_rate: 2.8731e-04\n",
            "Epoch 23/31\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8107 - loss: 0.3899\n",
            "Epoch 23: val_loss did not improve from 0.32854\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8107 - loss: 0.3903 - val_accuracy: 0.8695 - val_loss: 0.3352 - learning_rate: 2.8731e-04\n",
            "Epoch 24/31\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8152 - loss: 0.3909\n",
            "Epoch 24: val_loss improved from 0.32854 to 0.31924, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8155 - loss: 0.3912 - val_accuracy: 0.8703 - val_loss: 0.3192 - learning_rate: 2.8731e-04\n",
            "Epoch 25/31\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8114 - loss: 0.3890\n",
            "Epoch 25: val_loss did not improve from 0.31924\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8119 - loss: 0.3890 - val_accuracy: 0.8703 - val_loss: 0.3352 - learning_rate: 2.8731e-04\n",
            "Epoch 26/31\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8131 - loss: 0.3875\n",
            "Epoch 26: val_loss did not improve from 0.31924\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8131 - loss: 0.3878 - val_accuracy: 0.8720 - val_loss: 0.3248 - learning_rate: 2.8731e-04\n",
            "Epoch 27/31\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8170 - loss: 0.3827\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 4.514448949747455e-05.\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.31924\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8173 - loss: 0.3831 - val_accuracy: 0.8662 - val_loss: 0.3202 - learning_rate: 2.8731e-04\n",
            "Epoch 28/31\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8259 - loss: 0.3782\n",
            "Epoch 28: val_loss did not improve from 0.31924\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8260 - loss: 0.3784 - val_accuracy: 0.8396 - val_loss: 0.3969 - learning_rate: 4.5144e-05\n",
            "Epoch 29/31\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8270 - loss: 0.3756\n",
            "Epoch 29: val_loss did not improve from 0.31924\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8267 - loss: 0.3763 - val_accuracy: 0.8371 - val_loss: 0.4062 - learning_rate: 4.5144e-05\n",
            "Epoch 30/31\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8232 - loss: 0.3802\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 7.093400246638618e-06.\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.31924\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.3804 - val_accuracy: 0.8396 - val_loss: 0.4010 - learning_rate: 4.5144e-05\n",
            "Epoch 31/31\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8220 - loss: 0.3691\n",
            "Epoch 31: val_loss did not improve from 0.31924\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8229 - loss: 0.3702 - val_accuracy: 0.8362 - val_loss: 0.3868 - learning_rate: 7.0934e-06\n",
            "Restoring model weights from the end of the best epoch: 24.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:15:24,585] Trial 0 finished with value: -0.3192391097545624 and parameters: {'epochs': 31, 'batch_size': 64, 'learning_rate': 0.001828543622028191, 'stop_patience': 9, 'reduce_lr_factor': 0.15712659953907482, 'reduce_lr_patience': 3}. Best is trial 0 with value: -0.3192391097545624.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5702 - loss: 0.6794\n",
            "Epoch 1: val_loss improved from inf to 0.40457, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5710 - loss: 0.6787 - val_accuracy: 0.8421 - val_loss: 0.4046 - learning_rate: 0.0019\n",
            "Epoch 2/50\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6860 - loss: 0.5737\n",
            "Epoch 2: val_loss did not improve from 0.40457\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6861 - loss: 0.5735 - val_accuracy: 0.7091 - val_loss: 0.7141 - learning_rate: 0.0019\n",
            "Epoch 3/50\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7282 - loss: 0.5044\n",
            "Epoch 3: val_loss improved from 0.40457 to 0.31997, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7283 - loss: 0.5043 - val_accuracy: 0.8687 - val_loss: 0.3200 - learning_rate: 0.0019\n",
            "Epoch 4/50\n",
            "\u001b[1m282/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7434 - loss: 0.4735\n",
            "Epoch 4: val_loss improved from 0.31997 to 0.31419, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7436 - loss: 0.4738 - val_accuracy: 0.8628 - val_loss: 0.3142 - learning_rate: 0.0019\n",
            "Epoch 5/50\n",
            "\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7558 - loss: 0.4496\n",
            "Epoch 5: val_loss did not improve from 0.31419\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7558 - loss: 0.4499 - val_accuracy: 0.7656 - val_loss: 0.7594 - learning_rate: 0.0019\n",
            "Epoch 6/50\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7664 - loss: 0.4338\n",
            "Epoch 6: val_loss did not improve from 0.31419\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7665 - loss: 0.4341 - val_accuracy: 0.7315 - val_loss: 0.9338 - learning_rate: 0.0019\n",
            "Epoch 7/50\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7710 - loss: 0.4360\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.000413070641747827.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.31419\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7709 - loss: 0.4360 - val_accuracy: 0.7905 - val_loss: 0.5718 - learning_rate: 0.0019\n",
            "Epoch 8/50\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8038 - loss: 0.3940\n",
            "Epoch 8: val_loss improved from 0.31419 to 0.30106, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.3940 - val_accuracy: 0.8753 - val_loss: 0.3011 - learning_rate: 4.1307e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8113 - loss: 0.3830\n",
            "Epoch 9: val_loss did not improve from 0.30106\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8113 - loss: 0.3832 - val_accuracy: 0.8645 - val_loss: 0.3267 - learning_rate: 4.1307e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8109 - loss: 0.3767\n",
            "Epoch 10: val_loss did not improve from 0.30106\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8109 - loss: 0.3767 - val_accuracy: 0.8678 - val_loss: 0.3230 - learning_rate: 4.1307e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8202 - loss: 0.3757\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.114398731377784e-05.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.30106\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8198 - loss: 0.3760 - val_accuracy: 0.8703 - val_loss: 0.3028 - learning_rate: 4.1307e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8319 - loss: 0.3580\n",
            "Epoch 12: val_loss improved from 0.30106 to 0.27935, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8319 - loss: 0.3581 - val_accuracy: 0.8795 - val_loss: 0.2793 - learning_rate: 9.1144e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8468 - loss: 0.3560\n",
            "Epoch 13: val_loss improved from 0.27935 to 0.27849, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8466 - loss: 0.3561 - val_accuracy: 0.8778 - val_loss: 0.2785 - learning_rate: 9.1144e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8443 - loss: 0.3554\n",
            "Epoch 14: val_loss did not improve from 0.27849\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8442 - loss: 0.3555 - val_accuracy: 0.8795 - val_loss: 0.2799 - learning_rate: 9.1144e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8544 - loss: 0.3539\n",
            "Epoch 15: val_loss did not improve from 0.27849\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8543 - loss: 0.3540 - val_accuracy: 0.8770 - val_loss: 0.2800 - learning_rate: 9.1144e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8441 - loss: 0.3493\n",
            "Epoch 16: val_loss improved from 0.27849 to 0.27743, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8440 - loss: 0.3495 - val_accuracy: 0.8786 - val_loss: 0.2774 - learning_rate: 9.1144e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8489 - loss: 0.3496\n",
            "Epoch 17: val_loss did not improve from 0.27743\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8488 - loss: 0.3497 - val_accuracy: 0.8778 - val_loss: 0.2784 - learning_rate: 9.1144e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8480 - loss: 0.3500\n",
            "Epoch 18: val_loss did not improve from 0.27743\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8479 - loss: 0.3503 - val_accuracy: 0.8786 - val_loss: 0.2808 - learning_rate: 9.1144e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.3498\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.0110909695320024e-05.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.27743\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8490 - loss: 0.3499 - val_accuracy: 0.8820 - val_loss: 0.2776 - learning_rate: 9.1144e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8572 - loss: 0.3490\n",
            "Epoch 20: val_loss did not improve from 0.27743\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 0.3490 - val_accuracy: 0.8786 - val_loss: 0.2835 - learning_rate: 2.0111e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m283/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8508 - loss: 0.3483\n",
            "Epoch 21: val_loss did not improve from 0.27743\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8508 - loss: 0.3486 - val_accuracy: 0.8720 - val_loss: 0.2902 - learning_rate: 2.0111e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.3457\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.437470045530838e-06.\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.27743\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8509 - loss: 0.3461 - val_accuracy: 0.8695 - val_loss: 0.2923 - learning_rate: 2.0111e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8489 - loss: 0.3502\n",
            "Epoch 23: val_loss did not improve from 0.27743\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8489 - loss: 0.3503 - val_accuracy: 0.8695 - val_loss: 0.2914 - learning_rate: 4.4375e-06\n",
            "Epoch 24/50\n",
            "\u001b[1m283/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8496 - loss: 0.3441\n",
            "Epoch 24: val_loss did not improve from 0.27743\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8496 - loss: 0.3445 - val_accuracy: 0.8728 - val_loss: 0.2899 - learning_rate: 4.4375e-06\n",
            "Epoch 25/50\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8574 - loss: 0.3439\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.27743\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8570 - loss: 0.3442 - val_accuracy: 0.8728 - val_loss: 0.2900 - learning_rate: 4.4375e-06\n",
            "Epoch 26/50\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8567 - loss: 0.3456\n",
            "Epoch 26: val_loss did not improve from 0.27743\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8566 - loss: 0.3459 - val_accuracy: 0.8745 - val_loss: 0.2897 - learning_rate: 1.0000e-06\n",
            "Epoch 26: early stopping\n",
            "Restoring model weights from the end of the best epoch: 16.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:16:04,043] Trial 1 finished with value: -0.2774333953857422 and parameters: {'epochs': 50, 'batch_size': 16, 'learning_rate': 0.0018720637685351409, 'stop_patience': 10, 'reduce_lr_factor': 0.22064988223544002, 'reduce_lr_patience': 3}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/43\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5665 - loss: 0.6843\n",
            "Epoch 1: val_loss improved from inf to 0.56710, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5679 - loss: 0.6834 - val_accuracy: 0.6924 - val_loss: 0.5671 - learning_rate: 0.0057\n",
            "Epoch 2/43\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6374 - loss: 0.6039\n",
            "Epoch 2: val_loss did not improve from 0.56710\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6398 - loss: 0.6008 - val_accuracy: 0.7847 - val_loss: 0.5833 - learning_rate: 0.0057\n",
            "Epoch 3/43\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7031 - loss: 0.5197\n",
            "Epoch 3: val_loss improved from 0.56710 to 0.56246, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7036 - loss: 0.5198 - val_accuracy: 0.7947 - val_loss: 0.5625 - learning_rate: 0.0057\n",
            "Epoch 4/43\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7342 - loss: 0.4848\n",
            "Epoch 4: val_loss did not improve from 0.56246\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7343 - loss: 0.4846 - val_accuracy: 0.7149 - val_loss: 1.0692 - learning_rate: 0.0057\n",
            "Epoch 5/43\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7540 - loss: 0.4557\n",
            "Epoch 5: val_loss did not improve from 0.56246\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7542 - loss: 0.4553 - val_accuracy: 0.7224 - val_loss: 1.1751 - learning_rate: 0.0057\n",
            "Epoch 6/43\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7627 - loss: 0.4416\n",
            "Epoch 6: val_loss did not improve from 0.56246\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4416 - val_accuracy: 0.6567 - val_loss: 1.4114 - learning_rate: 0.0057\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:16:09,859] Trial 2 finished with value: -0.562460720539093 and parameters: {'epochs': 43, 'batch_size': 64, 'learning_rate': 0.005718774497704813, 'stop_patience': 3, 'reduce_lr_factor': 0.40219127158182777, 'reduce_lr_patience': 4}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/23\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5822 - loss: 0.6844\n",
            "Epoch 1: val_loss improved from inf to 1.42222, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5832 - loss: 0.6834 - val_accuracy: 0.5453 - val_loss: 1.4222 - learning_rate: 0.0084\n",
            "Epoch 2/23\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6715 - loss: 0.5793\n",
            "Epoch 2: val_loss improved from 1.42222 to 1.14617, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6722 - loss: 0.5785 - val_accuracy: 0.6958 - val_loss: 1.1462 - learning_rate: 0.0084\n",
            "Epoch 3/23\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7002 - loss: 0.5178\n",
            "Epoch 3: val_loss improved from 1.14617 to 1.07188, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7008 - loss: 0.5180 - val_accuracy: 0.7099 - val_loss: 1.0719 - learning_rate: 0.0084\n",
            "Epoch 4/23\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7212 - loss: 0.4798\n",
            "Epoch 4: val_loss improved from 1.07188 to 0.80279, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7220 - loss: 0.4797 - val_accuracy: 0.7249 - val_loss: 0.8028 - learning_rate: 0.0084\n",
            "Epoch 5/23\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7525 - loss: 0.4636\n",
            "Epoch 5: val_loss did not improve from 0.80279\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7525 - loss: 0.4635 - val_accuracy: 0.6525 - val_loss: 1.6344 - learning_rate: 0.0084\n",
            "Epoch 6/23\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7567 - loss: 0.4514\n",
            "Epoch 6: val_loss did not improve from 0.80279\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7573 - loss: 0.4508 - val_accuracy: 0.6284 - val_loss: 1.5355 - learning_rate: 0.0084\n",
            "Epoch 7/23\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4362\n",
            "Epoch 7: val_loss improved from 0.80279 to 0.36778, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7727 - loss: 0.4368 - val_accuracy: 0.8412 - val_loss: 0.3678 - learning_rate: 0.0084\n",
            "Epoch 8/23\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7712 - loss: 0.4286\n",
            "Epoch 8: val_loss improved from 0.36778 to 0.31390, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7712 - loss: 0.4287 - val_accuracy: 0.8770 - val_loss: 0.3139 - learning_rate: 0.0084\n",
            "Epoch 9/23\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7772 - loss: 0.4208\n",
            "Epoch 9: val_loss did not improve from 0.31390\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7772 - loss: 0.4206 - val_accuracy: 0.7107 - val_loss: 1.3207 - learning_rate: 0.0084\n",
            "Epoch 10/23\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7795 - loss: 0.4072\n",
            "Epoch 10: val_loss did not improve from 0.31390\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7799 - loss: 0.4075 - val_accuracy: 0.8479 - val_loss: 0.3827 - learning_rate: 0.0084\n",
            "Epoch 11/23\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7869 - loss: 0.3953\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0025683216121755014.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.31390\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7867 - loss: 0.3963 - val_accuracy: 0.8803 - val_loss: 0.3189 - learning_rate: 0.0084\n",
            "Epoch 12/23\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.3956\n",
            "Epoch 12: val_loss did not improve from 0.31390\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7911 - loss: 0.3956 - val_accuracy: 0.8579 - val_loss: 0.3266 - learning_rate: 0.0026\n",
            "Epoch 13/23\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.3776\n",
            "Epoch 13: val_loss did not improve from 0.31390\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8067 - loss: 0.3783 - val_accuracy: 0.8304 - val_loss: 0.4102 - learning_rate: 0.0026\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:16:21,243] Trial 3 finished with value: -0.31389713287353516 and parameters: {'epochs': 23, 'batch_size': 64, 'learning_rate': 0.008409663113879579, 'stop_patience': 5, 'reduce_lr_factor': 0.3054012486065254, 'reduce_lr_patience': 3}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5745 - loss: 0.6850\n",
            "Epoch 1: val_loss improved from inf to 0.66282, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5750 - loss: 0.6844 - val_accuracy: 0.6791 - val_loss: 0.6628 - learning_rate: 0.0095\n",
            "Epoch 2/12\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6631 - loss: 0.5771\n",
            "Epoch 2: val_loss improved from 0.66282 to 0.34782, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6639 - loss: 0.5761 - val_accuracy: 0.8470 - val_loss: 0.3478 - learning_rate: 0.0095\n",
            "Epoch 3/12\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7180 - loss: 0.5035\n",
            "Epoch 3: val_loss did not improve from 0.34782\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7179 - loss: 0.5032 - val_accuracy: 0.7249 - val_loss: 0.8718 - learning_rate: 0.0095\n",
            "Epoch 4/12\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7342 - loss: 0.4853\n",
            "Epoch 4: val_loss did not improve from 0.34782\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7340 - loss: 0.4854 - val_accuracy: 0.8213 - val_loss: 0.4259 - learning_rate: 0.0095\n",
            "Epoch 5/12\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7511 - loss: 0.4611\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0011628490025175867.\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.34782\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7508 - loss: 0.4621 - val_accuracy: 0.6991 - val_loss: 0.7060 - learning_rate: 0.0095\n",
            "Epoch 5: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:16:26,649] Trial 4 finished with value: -0.347820520401001 and parameters: {'epochs': 12, 'batch_size': 64, 'learning_rate': 0.009531932954001052, 'stop_patience': 3, 'reduce_lr_factor': 0.12199508922223115, 'reduce_lr_patience': 3}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5515 - loss: 0.6943\n",
            "Epoch 1: val_loss improved from inf to 0.59557, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5531 - loss: 0.6924 - val_accuracy: 0.6783 - val_loss: 0.5956 - learning_rate: 0.0091\n",
            "Epoch 2/10\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6551 - loss: 0.5900\n",
            "Epoch 2: val_loss improved from 0.59557 to 0.46689, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6560 - loss: 0.5889 - val_accuracy: 0.7664 - val_loss: 0.4669 - learning_rate: 0.0091\n",
            "Epoch 3/10\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7106 - loss: 0.5210\n",
            "Epoch 3: val_loss improved from 0.46689 to 0.32490, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7110 - loss: 0.5209 - val_accuracy: 0.8603 - val_loss: 0.3249 - learning_rate: 0.0091\n",
            "Epoch 4/10\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7246 - loss: 0.4847\n",
            "Epoch 4: val_loss did not improve from 0.32490\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7246 - loss: 0.4850 - val_accuracy: 0.8387 - val_loss: 0.3827 - learning_rate: 0.0091\n",
            "Epoch 5/10\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7275 - loss: 0.4796\n",
            "Epoch 5: val_loss did not improve from 0.32490\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7276 - loss: 0.4800 - val_accuracy: 0.8662 - val_loss: 0.3998 - learning_rate: 0.0091\n",
            "Epoch 6/10\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7401 - loss: 0.4815\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0013418506893905261.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.32490\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7403 - loss: 0.4812 - val_accuracy: 0.7714 - val_loss: 0.6238 - learning_rate: 0.0091\n",
            "Epoch 7/10\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7695 - loss: 0.4210\n",
            "Epoch 7: val_loss improved from 0.32490 to 0.28052, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7700 - loss: 0.4208 - val_accuracy: 0.8803 - val_loss: 0.2805 - learning_rate: 0.0013\n",
            "Epoch 8/10\n",
            "\u001b[1m136/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8024 - loss: 0.3969\n",
            "Epoch 8: val_loss did not improve from 0.28052\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8021 - loss: 0.3978 - val_accuracy: 0.8587 - val_loss: 0.3056 - learning_rate: 0.0013\n",
            "Epoch 9/10\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8025 - loss: 0.3952\n",
            "Epoch 9: val_loss did not improve from 0.28052\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8026 - loss: 0.3951 - val_accuracy: 0.8520 - val_loss: 0.3251 - learning_rate: 0.0013\n",
            "Epoch 10/10\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8152 - loss: 0.3863\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00019711354909448037.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.28052\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8147 - loss: 0.3870 - val_accuracy: 0.8736 - val_loss: 0.2859 - learning_rate: 0.0013\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:16:39,927] Trial 5 finished with value: -0.28052252531051636 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 0.009134649778343598, 'stop_patience': 8, 'reduce_lr_factor': 0.14689677826127712, 'reduce_lr_patience': 3}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/18\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5767 - loss: 0.6801\n",
            "Epoch 1: val_loss improved from inf to 0.46861, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5778 - loss: 0.6792 - val_accuracy: 0.8362 - val_loss: 0.4686 - learning_rate: 0.0017\n",
            "Epoch 2/18\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6513 - loss: 0.6104\n",
            "Epoch 2: val_loss did not improve from 0.46861\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6517 - loss: 0.6100 - val_accuracy: 0.6459 - val_loss: 0.9044 - learning_rate: 0.0017\n",
            "Epoch 3/18\n",
            "\u001b[1m135/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7018 - loss: 0.5468\n",
            "Epoch 3: val_loss did not improve from 0.46861\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7031 - loss: 0.5466 - val_accuracy: 0.7298 - val_loss: 0.7748 - learning_rate: 0.0017\n",
            "Epoch 4/18\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7329 - loss: 0.5005\n",
            "Epoch 4: val_loss improved from 0.46861 to 0.36802, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7330 - loss: 0.5003 - val_accuracy: 0.8495 - val_loss: 0.3680 - learning_rate: 0.0017\n",
            "Epoch 5/18\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.4712\n",
            "Epoch 5: val_loss did not improve from 0.36802\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7567 - loss: 0.4711 - val_accuracy: 0.8138 - val_loss: 0.4564 - learning_rate: 0.0017\n",
            "Epoch 6/18\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7516 - loss: 0.4520\n",
            "Epoch 6: val_loss did not improve from 0.36802\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7522 - loss: 0.4522 - val_accuracy: 0.7706 - val_loss: 0.7037 - learning_rate: 0.0017\n",
            "Epoch 7/18\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7768 - loss: 0.4354\n",
            "Epoch 7: val_loss did not improve from 0.36802\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7764 - loss: 0.4357 - val_accuracy: 0.7905 - val_loss: 0.5899 - learning_rate: 0.0017\n",
            "Epoch 8/18\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7694 - loss: 0.4250\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00043662165413300194.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.36802\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7698 - loss: 0.4250 - val_accuracy: 0.7756 - val_loss: 0.6637 - learning_rate: 0.0017\n",
            "Epoch 9/18\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7945 - loss: 0.3974\n",
            "Epoch 9: val_loss improved from 0.36802 to 0.33962, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7945 - loss: 0.3975 - val_accuracy: 0.8570 - val_loss: 0.3396 - learning_rate: 4.3662e-04\n",
            "Epoch 10/18\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.3868\n",
            "Epoch 10: val_loss improved from 0.33962 to 0.31323, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8062 - loss: 0.3869 - val_accuracy: 0.8645 - val_loss: 0.3132 - learning_rate: 4.3662e-04\n",
            "Epoch 11/18\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8050 - loss: 0.3819\n",
            "Epoch 11: val_loss improved from 0.31323 to 0.31154, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.3822 - val_accuracy: 0.8670 - val_loss: 0.3115 - learning_rate: 4.3662e-04\n",
            "Epoch 12/18\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8179 - loss: 0.3776\n",
            "Epoch 12: val_loss improved from 0.31154 to 0.30951, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8178 - loss: 0.3777 - val_accuracy: 0.8628 - val_loss: 0.3095 - learning_rate: 4.3662e-04\n",
            "Epoch 13/18\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8208 - loss: 0.3704\n",
            "Epoch 13: val_loss improved from 0.30951 to 0.29330, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8207 - loss: 0.3705 - val_accuracy: 0.8712 - val_loss: 0.2933 - learning_rate: 4.3662e-04\n",
            "Epoch 14/18\n",
            "\u001b[1m136/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8197 - loss: 0.3719\n",
            "Epoch 14: val_loss did not improve from 0.29330\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8193 - loss: 0.3725 - val_accuracy: 0.8720 - val_loss: 0.2992 - learning_rate: 4.3662e-04\n",
            "Epoch 15/18\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8120 - loss: 0.3741\n",
            "Epoch 15: val_loss did not improve from 0.29330\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8121 - loss: 0.3742 - val_accuracy: 0.8712 - val_loss: 0.2997 - learning_rate: 4.3662e-04\n",
            "Epoch 16/18\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8246 - loss: 0.3647\n",
            "Epoch 16: val_loss did not improve from 0.29330\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.3649 - val_accuracy: 0.8736 - val_loss: 0.2999 - learning_rate: 4.3662e-04\n",
            "Epoch 17/18\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8258 - loss: 0.3624\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00011001098246545785.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.29330\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8250 - loss: 0.3631 - val_accuracy: 0.8662 - val_loss: 0.3290 - learning_rate: 4.3662e-04\n",
            "Epoch 18/18\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3547\n",
            "Epoch 18: val_loss improved from 0.29330 to 0.28532, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8436 - loss: 0.3549 - val_accuracy: 0.8753 - val_loss: 0.2853 - learning_rate: 1.1001e-04\n",
            "Restoring model weights from the end of the best epoch: 18.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:16:58,885] Trial 6 finished with value: -0.2853209972381592 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.0017329039706937025, 'stop_patience': 7, 'reduce_lr_factor': 0.25195951682837625, 'reduce_lr_patience': 4}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/39\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5892 - loss: 0.6795\n",
            "Epoch 1: val_loss improved from inf to 1.35123, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5900 - loss: 0.6787 - val_accuracy: 0.5104 - val_loss: 1.3512 - learning_rate: 0.0015\n",
            "Epoch 2/39\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6304 - loss: 0.6341\n",
            "Epoch 2: val_loss improved from 1.35123 to 0.48183, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6317 - loss: 0.6330 - val_accuracy: 0.7714 - val_loss: 0.4818 - learning_rate: 0.0015\n",
            "Epoch 3/39\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6820 - loss: 0.5830\n",
            "Epoch 3: val_loss improved from 0.48183 to 0.36659, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6823 - loss: 0.5822 - val_accuracy: 0.8412 - val_loss: 0.3666 - learning_rate: 0.0015\n",
            "Epoch 4/39\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7142 - loss: 0.5336\n",
            "Epoch 4: val_loss did not improve from 0.36659\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7142 - loss: 0.5336 - val_accuracy: 0.8238 - val_loss: 0.4549 - learning_rate: 0.0015\n",
            "Epoch 5/39\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7387 - loss: 0.5056\n",
            "Epoch 5: val_loss did not improve from 0.36659\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7384 - loss: 0.5059 - val_accuracy: 0.7681 - val_loss: 0.6555 - learning_rate: 0.0015\n",
            "Epoch 6/39\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7442 - loss: 0.4923\n",
            "Epoch 6: val_loss did not improve from 0.36659\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7439 - loss: 0.4924 - val_accuracy: 0.8071 - val_loss: 0.5892 - learning_rate: 0.0015\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:17:04,951] Trial 7 finished with value: -0.36658555269241333 and parameters: {'epochs': 39, 'batch_size': 64, 'learning_rate': 0.0014676586178839865, 'stop_patience': 3, 'reduce_lr_factor': 0.3155493601008976, 'reduce_lr_patience': 5}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/23\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5724 - loss: 0.6787\n",
            "Epoch 1: val_loss improved from inf to 0.97290, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5748 - loss: 0.6769 - val_accuracy: 0.5420 - val_loss: 0.9729 - learning_rate: 0.0021\n",
            "Epoch 2/23\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6425 - loss: 0.6174\n",
            "Epoch 2: val_loss improved from 0.97290 to 0.37321, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6439 - loss: 0.6163 - val_accuracy: 0.8495 - val_loss: 0.3732 - learning_rate: 0.0021\n",
            "Epoch 3/23\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7002 - loss: 0.5478\n",
            "Epoch 3: val_loss did not improve from 0.37321\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7018 - loss: 0.5465 - val_accuracy: 0.8229 - val_loss: 0.4263 - learning_rate: 0.0021\n",
            "Epoch 4/23\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7371 - loss: 0.5033\n",
            "Epoch 4: val_loss did not improve from 0.37321\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7371 - loss: 0.5028 - val_accuracy: 0.8554 - val_loss: 0.3749 - learning_rate: 0.0021\n",
            "Epoch 5/23\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7499 - loss: 0.4750\n",
            "Epoch 5: val_loss did not improve from 0.37321\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7498 - loss: 0.4749 - val_accuracy: 0.8645 - val_loss: 0.3751 - learning_rate: 0.0021\n",
            "Epoch 6/23\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7507 - loss: 0.4625\n",
            "Epoch 6: val_loss improved from 0.37321 to 0.34172, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7511 - loss: 0.4629 - val_accuracy: 0.8678 - val_loss: 0.3417 - learning_rate: 0.0021\n",
            "Epoch 7/23\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7816 - loss: 0.4434\n",
            "Epoch 7: val_loss improved from 0.34172 to 0.33514, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7814 - loss: 0.4432 - val_accuracy: 0.8687 - val_loss: 0.3351 - learning_rate: 0.0021\n",
            "Epoch 8/23\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7772 - loss: 0.4287\n",
            "Epoch 8: val_loss did not improve from 0.33514\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7774 - loss: 0.4287 - val_accuracy: 0.8653 - val_loss: 0.3355 - learning_rate: 0.0021\n",
            "Epoch 9/23\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7806 - loss: 0.4162\n",
            "Epoch 9: val_loss improved from 0.33514 to 0.32515, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7809 - loss: 0.4172 - val_accuracy: 0.8653 - val_loss: 0.3251 - learning_rate: 0.0021\n",
            "Epoch 10/23\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7834 - loss: 0.4067\n",
            "Epoch 10: val_loss did not improve from 0.32515\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7841 - loss: 0.4069 - val_accuracy: 0.8761 - val_loss: 0.3325 - learning_rate: 0.0021\n",
            "Epoch 11/23\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7872 - loss: 0.4039\n",
            "Epoch 11: val_loss did not improve from 0.32515\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7882 - loss: 0.4043 - val_accuracy: 0.8404 - val_loss: 0.4020 - learning_rate: 0.0021\n",
            "Epoch 12/23\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8001 - loss: 0.3934\n",
            "Epoch 12: val_loss did not improve from 0.32515\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7998 - loss: 0.3938 - val_accuracy: 0.8579 - val_loss: 0.4023 - learning_rate: 0.0021\n",
            "Epoch 13/23\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7959 - loss: 0.3947\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0003845037097166273.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.32515\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7957 - loss: 0.3954 - val_accuracy: 0.8387 - val_loss: 0.4846 - learning_rate: 0.0021\n",
            "Epoch 14/23\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7942 - loss: 0.3911\n",
            "Epoch 14: val_loss improved from 0.32515 to 0.30099, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7950 - loss: 0.3909 - val_accuracy: 0.8761 - val_loss: 0.3010 - learning_rate: 3.8450e-04\n",
            "Epoch 15/23\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.3707\n",
            "Epoch 15: val_loss did not improve from 0.30099\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8041 - loss: 0.3709 - val_accuracy: 0.8736 - val_loss: 0.3088 - learning_rate: 3.8450e-04\n",
            "Epoch 16/23\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8314 - loss: 0.3629\n",
            "Epoch 16: val_loss improved from 0.30099 to 0.29762, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8304 - loss: 0.3635 - val_accuracy: 0.8786 - val_loss: 0.2976 - learning_rate: 3.8450e-04\n",
            "Epoch 17/23\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8360 - loss: 0.3603\n",
            "Epoch 17: val_loss did not improve from 0.29762\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8354 - loss: 0.3608 - val_accuracy: 0.8770 - val_loss: 0.3038 - learning_rate: 3.8450e-04\n",
            "Epoch 18/23\n",
            "\u001b[1m72/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8339 - loss: 0.3554\n",
            "Epoch 18: val_loss improved from 0.29762 to 0.29189, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8339 - loss: 0.3558 - val_accuracy: 0.8761 - val_loss: 0.2919 - learning_rate: 3.8450e-04\n",
            "Epoch 19/23\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8423 - loss: 0.3578\n",
            "Epoch 19: val_loss improved from 0.29189 to 0.28788, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8417 - loss: 0.3581 - val_accuracy: 0.8770 - val_loss: 0.2879 - learning_rate: 3.8450e-04\n",
            "Epoch 20/23\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8386 - loss: 0.3564\n",
            "Epoch 20: val_loss did not improve from 0.28788\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8379 - loss: 0.3569 - val_accuracy: 0.8770 - val_loss: 0.2889 - learning_rate: 3.8450e-04\n",
            "Epoch 21/23\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8340 - loss: 0.3557\n",
            "Epoch 21: val_loss improved from 0.28788 to 0.28336, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8341 - loss: 0.3561 - val_accuracy: 0.8761 - val_loss: 0.2834 - learning_rate: 3.8450e-04\n",
            "Epoch 22/23\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8339 - loss: 0.3482\n",
            "Epoch 22: val_loss did not improve from 0.28336\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8342 - loss: 0.3496 - val_accuracy: 0.8786 - val_loss: 0.2974 - learning_rate: 3.8450e-04\n",
            "Epoch 23/23\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8323 - loss: 0.3535\n",
            "Epoch 23: val_loss did not improve from 0.28336\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8322 - loss: 0.3543 - val_accuracy: 0.8786 - val_loss: 0.2933 - learning_rate: 3.8450e-04\n",
            "Restoring model weights from the end of the best epoch: 21.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:17:22,686] Trial 8 finished with value: -0.2833632528781891 and parameters: {'epochs': 23, 'batch_size': 64, 'learning_rate': 0.002079191816982261, 'stop_patience': 5, 'reduce_lr_factor': 0.18492940400111393, 'reduce_lr_patience': 4}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5536 - loss: 0.6915\n",
            "Epoch 1: val_loss improved from inf to 0.89602, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5541 - loss: 0.6907 - val_accuracy: 0.4996 - val_loss: 0.8960 - learning_rate: 0.0048\n",
            "Epoch 2/16\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6478 - loss: 0.6093\n",
            "Epoch 2: val_loss improved from 0.89602 to 0.70552, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6487 - loss: 0.6085 - val_accuracy: 0.6351 - val_loss: 0.7055 - learning_rate: 0.0048\n",
            "Epoch 3/16\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6921 - loss: 0.5359\n",
            "Epoch 3: val_loss improved from 0.70552 to 0.37470, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6930 - loss: 0.5354 - val_accuracy: 0.8470 - val_loss: 0.3747 - learning_rate: 0.0048\n",
            "Epoch 4/16\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7483 - loss: 0.4873\n",
            "Epoch 4: val_loss improved from 0.37470 to 0.36890, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7482 - loss: 0.4874 - val_accuracy: 0.8354 - val_loss: 0.3689 - learning_rate: 0.0048\n",
            "Epoch 5/16\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7654 - loss: 0.4512\n",
            "Epoch 5: val_loss improved from 0.36890 to 0.32361, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7653 - loss: 0.4513 - val_accuracy: 0.8470 - val_loss: 0.3236 - learning_rate: 0.0048\n",
            "Epoch 6/16\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7715 - loss: 0.4548\n",
            "Epoch 6: val_loss improved from 0.32361 to 0.30067, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7714 - loss: 0.4550 - val_accuracy: 0.8770 - val_loss: 0.3007 - learning_rate: 0.0048\n",
            "Epoch 7/16\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7734 - loss: 0.4340\n",
            "Epoch 7: val_loss did not improve from 0.30067\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7732 - loss: 0.4342 - val_accuracy: 0.7531 - val_loss: 0.5811 - learning_rate: 0.0048\n",
            "Epoch 8/16\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7659 - loss: 0.4360\n",
            "Epoch 8: val_loss did not improve from 0.30067\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7659 - loss: 0.4360 - val_accuracy: 0.8022 - val_loss: 0.7247 - learning_rate: 0.0048\n",
            "Epoch 9/16\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7667 - loss: 0.4256\n",
            "Epoch 9: val_loss did not improve from 0.30067\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7672 - loss: 0.4258 - val_accuracy: 0.8736 - val_loss: 0.3037 - learning_rate: 0.0048\n",
            "Epoch 10/16\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7950 - loss: 0.4152\n",
            "Epoch 10: val_loss did not improve from 0.30067\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7947 - loss: 0.4155 - val_accuracy: 0.7914 - val_loss: 0.5859 - learning_rate: 0.0048\n",
            "Epoch 11/16\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7861 - loss: 0.4213\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0014735037973903978.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.30067\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7861 - loss: 0.4214 - val_accuracy: 0.7938 - val_loss: 0.5030 - learning_rate: 0.0048\n",
            "Epoch 12/16\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.3800\n",
            "Epoch 12: val_loss improved from 0.30067 to 0.29662, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.3800 - val_accuracy: 0.8612 - val_loss: 0.2966 - learning_rate: 0.0015\n",
            "Epoch 13/16\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8206 - loss: 0.3660\n",
            "Epoch 13: val_loss did not improve from 0.29662\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8206 - loss: 0.3661 - val_accuracy: 0.8761 - val_loss: 0.3044 - learning_rate: 0.0015\n",
            "Epoch 14/16\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.3648\n",
            "Epoch 14: val_loss improved from 0.29662 to 0.29187, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8139 - loss: 0.3648 - val_accuracy: 0.8720 - val_loss: 0.2919 - learning_rate: 0.0015\n",
            "Epoch 15/16\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8239 - loss: 0.3629\n",
            "Epoch 15: val_loss improved from 0.29187 to 0.29135, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8240 - loss: 0.3631 - val_accuracy: 0.8695 - val_loss: 0.2913 - learning_rate: 0.0015\n",
            "Epoch 16/16\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8290 - loss: 0.3566\n",
            "Epoch 16: val_loss did not improve from 0.29135\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8291 - loss: 0.3569 - val_accuracy: 0.8670 - val_loss: 0.3084 - learning_rate: 0.0015\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:17:47,541] Trial 9 finished with value: -0.29134783148765564 and parameters: {'epochs': 16, 'batch_size': 16, 'learning_rate': 0.0047683824538190915, 'stop_patience': 10, 'reduce_lr_factor': 0.309015449492817, 'reduce_lr_patience': 5}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5521 - loss: 0.6888\n",
            "Epoch 1: val_loss improved from inf to 0.37870, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5535 - loss: 0.6877 - val_accuracy: 0.8628 - val_loss: 0.3787 - learning_rate: 0.0043\n",
            "Epoch 2/50\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6764 - loss: 0.5621\n",
            "Epoch 2: val_loss did not improve from 0.37870\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6766 - loss: 0.5619 - val_accuracy: 0.7614 - val_loss: 0.5644 - learning_rate: 0.0043\n",
            "Epoch 3/50\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7214 - loss: 0.5077\n",
            "Epoch 3: val_loss improved from 0.37870 to 0.31157, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7215 - loss: 0.5075 - val_accuracy: 0.8720 - val_loss: 0.3116 - learning_rate: 0.0043\n",
            "Epoch 4/50\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7541 - loss: 0.4658\n",
            "Epoch 4: val_loss did not improve from 0.31157\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7540 - loss: 0.4658 - val_accuracy: 0.8412 - val_loss: 0.3469 - learning_rate: 0.0043\n",
            "Epoch 5/50\n",
            "\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7526 - loss: 0.4457\n",
            "Epoch 5: val_loss improved from 0.31157 to 0.30974, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7528 - loss: 0.4462 - val_accuracy: 0.8612 - val_loss: 0.3097 - learning_rate: 0.0043\n",
            "Epoch 6/50\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7631 - loss: 0.4340\n",
            "Epoch 6: val_loss improved from 0.30974 to 0.29790, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7631 - loss: 0.4344 - val_accuracy: 0.8703 - val_loss: 0.2979 - learning_rate: 0.0043\n",
            "Epoch 7/50\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7659 - loss: 0.4281\n",
            "Epoch 7: val_loss did not improve from 0.29790\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7659 - loss: 0.4282 - val_accuracy: 0.8462 - val_loss: 0.3605 - learning_rate: 0.0043\n",
            "Epoch 8/50\n",
            "\u001b[1m283/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7643 - loss: 0.4237\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.002148874599740714.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.29790\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7647 - loss: 0.4243 - val_accuracy: 0.8512 - val_loss: 0.3832 - learning_rate: 0.0043\n",
            "Epoch 9/50\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7922 - loss: 0.3997\n",
            "Epoch 9: val_loss did not improve from 0.29790\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7922 - loss: 0.3997 - val_accuracy: 0.8446 - val_loss: 0.4082 - learning_rate: 0.0021\n",
            "Epoch 10/50\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8042 - loss: 0.3893\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0010656632561653373.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.29790\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8042 - loss: 0.3893 - val_accuracy: 0.8687 - val_loss: 0.3063 - learning_rate: 0.0021\n",
            "Epoch 11/50\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8140 - loss: 0.3734\n",
            "Epoch 11: val_loss improved from 0.29790 to 0.29597, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8140 - loss: 0.3735 - val_accuracy: 0.8662 - val_loss: 0.2960 - learning_rate: 0.0011\n",
            "Epoch 12/50\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8226 - loss: 0.3696\n",
            "Epoch 12: val_loss did not improve from 0.29597\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8225 - loss: 0.3697 - val_accuracy: 0.8470 - val_loss: 0.3786 - learning_rate: 0.0011\n",
            "Epoch 13/50\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8218 - loss: 0.3602\n",
            "Epoch 13: val_loss improved from 0.29597 to 0.29033, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8218 - loss: 0.3604 - val_accuracy: 0.8712 - val_loss: 0.2903 - learning_rate: 0.0011\n",
            "Epoch 14/50\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8220 - loss: 0.3602\n",
            "Epoch 14: val_loss did not improve from 0.29033\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8223 - loss: 0.3604 - val_accuracy: 0.8753 - val_loss: 0.3001 - learning_rate: 0.0011\n",
            "Epoch 15/50\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8218 - loss: 0.3505\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005284804580056844.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.29033\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.3506 - val_accuracy: 0.8662 - val_loss: 0.3043 - learning_rate: 0.0011\n",
            "Epoch 16/50\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8334 - loss: 0.3505\n",
            "Epoch 16: val_loss did not improve from 0.29033\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.3505 - val_accuracy: 0.8736 - val_loss: 0.3056 - learning_rate: 5.2848e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8328 - loss: 0.3453\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002620823966551296.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.29033\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8329 - loss: 0.3454 - val_accuracy: 0.8753 - val_loss: 0.2957 - learning_rate: 5.2848e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m283/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8526 - loss: 0.3359\n",
            "Epoch 18: val_loss did not improve from 0.29033\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8525 - loss: 0.3361 - val_accuracy: 0.8520 - val_loss: 0.3378 - learning_rate: 2.6208e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8525 - loss: 0.3358\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00012997110076677054.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.29033\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8524 - loss: 0.3358 - val_accuracy: 0.8637 - val_loss: 0.3267 - learning_rate: 2.6208e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8627 - loss: 0.3252\n",
            "Epoch 20: val_loss did not improve from 0.29033\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8626 - loss: 0.3254 - val_accuracy: 0.8446 - val_loss: 0.3723 - learning_rate: 1.2997e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.3264\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.445486761027336e-05.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.29033\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8588 - loss: 0.3265 - val_accuracy: 0.8462 - val_loss: 0.3596 - learning_rate: 1.2997e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8599 - loss: 0.3291\n",
            "Epoch 22: val_loss did not improve from 0.29033\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8599 - loss: 0.3293 - val_accuracy: 0.8595 - val_loss: 0.3582 - learning_rate: 6.4455e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8532 - loss: 0.3301\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 3.1964260989141385e-05.\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.29033\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8533 - loss: 0.3303 - val_accuracy: 0.8637 - val_loss: 0.3627 - learning_rate: 6.4455e-05\n",
            "Epoch 23: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:18:24,096] Trial 10 finished with value: -0.2903296649456024 and parameters: {'epochs': 50, 'batch_size': 16, 'learning_rate': 0.004333134143496001, 'stop_patience': 10, 'reduce_lr_factor': 0.49591691911637015, 'reduce_lr_patience': 2}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/36\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5528 - loss: 0.6964\n",
            "Epoch 1: val_loss improved from inf to 0.54066, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5545 - loss: 0.6952 - val_accuracy: 0.6758 - val_loss: 0.5407 - learning_rate: 0.0069\n",
            "Epoch 2/36\n",
            "\u001b[1m137/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6306 - loss: 0.6226\n",
            "Epoch 2: val_loss improved from 0.54066 to 0.33803, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6312 - loss: 0.6220 - val_accuracy: 0.8504 - val_loss: 0.3380 - learning_rate: 0.0069\n",
            "Epoch 3/36\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6801 - loss: 0.5628\n",
            "Epoch 3: val_loss did not improve from 0.33803\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6810 - loss: 0.5621 - val_accuracy: 0.8329 - val_loss: 0.4136 - learning_rate: 0.0069\n",
            "Epoch 4/36\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7194 - loss: 0.5197\n",
            "Epoch 4: val_loss improved from 0.33803 to 0.33144, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7201 - loss: 0.5191 - val_accuracy: 0.8603 - val_loss: 0.3314 - learning_rate: 0.0069\n",
            "Epoch 5/36\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7436 - loss: 0.4770\n",
            "Epoch 5: val_loss did not improve from 0.33144\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7439 - loss: 0.4775 - val_accuracy: 0.7282 - val_loss: 0.7464 - learning_rate: 0.0069\n",
            "Epoch 6/36\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7561 - loss: 0.4568\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0014780009608012694.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.33144\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7561 - loss: 0.4569 - val_accuracy: 0.7731 - val_loss: 0.7305 - learning_rate: 0.0069\n",
            "Epoch 7/36\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7852 - loss: 0.4129\n",
            "Epoch 7: val_loss improved from 0.33144 to 0.29471, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7852 - loss: 0.4129 - val_accuracy: 0.8753 - val_loss: 0.2947 - learning_rate: 0.0015\n",
            "Epoch 8/36\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8074 - loss: 0.3963\n",
            "Epoch 8: val_loss did not improve from 0.29471\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8073 - loss: 0.3965 - val_accuracy: 0.8520 - val_loss: 0.3128 - learning_rate: 0.0015\n",
            "Epoch 9/36\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8126 - loss: 0.3850\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003154881381372144.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.29471\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8125 - loss: 0.3853 - val_accuracy: 0.8271 - val_loss: 0.3873 - learning_rate: 0.0015\n",
            "Epoch 10/36\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.3668\n",
            "Epoch 10: val_loss did not improve from 0.29471\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8403 - loss: 0.3673 - val_accuracy: 0.8753 - val_loss: 0.3107 - learning_rate: 3.1549e-04\n",
            "Epoch 11/36\n",
            "\u001b[1m135/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8343 - loss: 0.3690\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 6.734282704373017e-05.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.29471\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8342 - loss: 0.3694 - val_accuracy: 0.8728 - val_loss: 0.3123 - learning_rate: 3.1549e-04\n",
            "Epoch 12/36\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.3705\n",
            "Epoch 12: val_loss did not improve from 0.29471\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8354 - loss: 0.3706 - val_accuracy: 0.8728 - val_loss: 0.3191 - learning_rate: 6.7343e-05\n",
            "Epoch 13/36\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8345 - loss: 0.3659\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.4374728929888998e-05.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.29471\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8346 - loss: 0.3663 - val_accuracy: 0.8712 - val_loss: 0.3203 - learning_rate: 6.7343e-05\n",
            "Epoch 14/36\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.3668\n",
            "Epoch 14: val_loss did not improve from 0.29471\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8405 - loss: 0.3675 - val_accuracy: 0.8728 - val_loss: 0.3188 - learning_rate: 1.4375e-05\n",
            "Epoch 15/36\n",
            "\u001b[1m136/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8367 - loss: 0.3638\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 3.068371773841007e-06.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.29471\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8368 - loss: 0.3644 - val_accuracy: 0.8720 - val_loss: 0.3199 - learning_rate: 1.4375e-05\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:18:40,010] Trial 11 finished with value: -0.2947079837322235 and parameters: {'epochs': 36, 'batch_size': 32, 'learning_rate': 0.006924149091559201, 'stop_patience': 8, 'reduce_lr_factor': 0.21345596929398586, 'reduce_lr_patience': 2}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5676 - loss: 0.6931\n",
            "Epoch 1: val_loss improved from inf to 0.96594, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5675 - loss: 0.6931 - val_accuracy: 0.4996 - val_loss: 0.9659 - learning_rate: 2.1335e-05\n",
            "Epoch 2/50\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5667 - loss: 0.6863\n",
            "Epoch 2: val_loss improved from 0.96594 to 0.87974, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5667 - loss: 0.6863 - val_accuracy: 0.4996 - val_loss: 0.8797 - learning_rate: 2.1335e-05\n",
            "Epoch 3/50\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5816 - loss: 0.6830\n",
            "Epoch 3: val_loss improved from 0.87974 to 0.84212, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5815 - loss: 0.6830 - val_accuracy: 0.4996 - val_loss: 0.8421 - learning_rate: 2.1335e-05\n",
            "Epoch 4/50\n",
            "\u001b[1m137/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5856 - loss: 0.6801\n",
            "Epoch 4: val_loss improved from 0.84212 to 0.82728, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5851 - loss: 0.6803 - val_accuracy: 0.4996 - val_loss: 0.8273 - learning_rate: 2.1335e-05\n",
            "Epoch 5/50\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5908 - loss: 0.6804\n",
            "Epoch 5: val_loss improved from 0.82728 to 0.82073, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5904 - loss: 0.6804 - val_accuracy: 0.4996 - val_loss: 0.8207 - learning_rate: 2.1335e-05\n",
            "Epoch 6/50\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5948 - loss: 0.6796\n",
            "Epoch 6: val_loss improved from 0.82073 to 0.79346, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5947 - loss: 0.6795 - val_accuracy: 0.4996 - val_loss: 0.7935 - learning_rate: 2.1335e-05\n",
            "Epoch 7/50\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5912 - loss: 0.6750\n",
            "Epoch 7: val_loss improved from 0.79346 to 0.78157, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5910 - loss: 0.6750 - val_accuracy: 0.4996 - val_loss: 0.7816 - learning_rate: 2.1335e-05\n",
            "Epoch 8/50\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5989 - loss: 0.6745\n",
            "Epoch 8: val_loss improved from 0.78157 to 0.77072, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5987 - loss: 0.6745 - val_accuracy: 0.4996 - val_loss: 0.7707 - learning_rate: 2.1335e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m136/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5956 - loss: 0.6707\n",
            "Epoch 9: val_loss improved from 0.77072 to 0.74648, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5954 - loss: 0.6708 - val_accuracy: 0.4996 - val_loss: 0.7465 - learning_rate: 2.1335e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6011 - loss: 0.6674\n",
            "Epoch 10: val_loss improved from 0.74648 to 0.74027, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6008 - loss: 0.6675 - val_accuracy: 0.4996 - val_loss: 0.7403 - learning_rate: 2.1335e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6006 - loss: 0.6652\n",
            "Epoch 11: val_loss improved from 0.74027 to 0.71447, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5999 - loss: 0.6654 - val_accuracy: 0.4996 - val_loss: 0.7145 - learning_rate: 2.1335e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6129 - loss: 0.6614\n",
            "Epoch 12: val_loss improved from 0.71447 to 0.69999, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6125 - loss: 0.6615 - val_accuracy: 0.5037 - val_loss: 0.7000 - learning_rate: 2.1335e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6059 - loss: 0.6625\n",
            "Epoch 13: val_loss improved from 0.69999 to 0.67523, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6063 - loss: 0.6625 - val_accuracy: 0.5079 - val_loss: 0.6752 - learning_rate: 2.1335e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6081 - loss: 0.6583\n",
            "Epoch 14: val_loss improved from 0.67523 to 0.66569, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6077 - loss: 0.6584 - val_accuracy: 0.5179 - val_loss: 0.6657 - learning_rate: 2.1335e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6078 - loss: 0.6573\n",
            "Epoch 15: val_loss improved from 0.66569 to 0.64634, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6078 - loss: 0.6573 - val_accuracy: 0.5270 - val_loss: 0.6463 - learning_rate: 2.1335e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6154 - loss: 0.6541\n",
            "Epoch 16: val_loss improved from 0.64634 to 0.62427, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6154 - loss: 0.6542 - val_accuracy: 0.5370 - val_loss: 0.6243 - learning_rate: 2.1335e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6181 - loss: 0.6511\n",
            "Epoch 17: val_loss improved from 0.62427 to 0.61268, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6180 - loss: 0.6511 - val_accuracy: 0.5536 - val_loss: 0.6127 - learning_rate: 2.1335e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6191 - loss: 0.6476\n",
            "Epoch 18: val_loss improved from 0.61268 to 0.58962, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6188 - loss: 0.6476 - val_accuracy: 0.6035 - val_loss: 0.5896 - learning_rate: 2.1335e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6265 - loss: 0.6474\n",
            "Epoch 19: val_loss improved from 0.58962 to 0.57848, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6264 - loss: 0.6474 - val_accuracy: 0.6284 - val_loss: 0.5785 - learning_rate: 2.1335e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6244 - loss: 0.6446\n",
            "Epoch 20: val_loss improved from 0.57848 to 0.57014, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6244 - loss: 0.6446 - val_accuracy: 0.6451 - val_loss: 0.5701 - learning_rate: 2.1335e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6312 - loss: 0.6423\n",
            "Epoch 21: val_loss improved from 0.57014 to 0.55852, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6307 - loss: 0.6425 - val_accuracy: 0.6708 - val_loss: 0.5585 - learning_rate: 2.1335e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6357 - loss: 0.6396\n",
            "Epoch 22: val_loss improved from 0.55852 to 0.54553, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6357 - loss: 0.6396 - val_accuracy: 0.6949 - val_loss: 0.5455 - learning_rate: 2.1335e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6470 - loss: 0.6354\n",
            "Epoch 23: val_loss improved from 0.54553 to 0.53215, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6467 - loss: 0.6355 - val_accuracy: 0.7423 - val_loss: 0.5322 - learning_rate: 2.1335e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6475 - loss: 0.6331\n",
            "Epoch 24: val_loss improved from 0.53215 to 0.52603, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6473 - loss: 0.6331 - val_accuracy: 0.7465 - val_loss: 0.5260 - learning_rate: 2.1335e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6479 - loss: 0.6300\n",
            "Epoch 25: val_loss improved from 0.52603 to 0.51254, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6479 - loss: 0.6301 - val_accuracy: 0.7739 - val_loss: 0.5125 - learning_rate: 2.1335e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6413 - loss: 0.6293\n",
            "Epoch 26: val_loss improved from 0.51254 to 0.50377, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6415 - loss: 0.6293 - val_accuracy: 0.7864 - val_loss: 0.5038 - learning_rate: 2.1335e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6580 - loss: 0.6245\n",
            "Epoch 27: val_loss improved from 0.50377 to 0.49532, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6577 - loss: 0.6246 - val_accuracy: 0.8013 - val_loss: 0.4953 - learning_rate: 2.1335e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6668 - loss: 0.6207\n",
            "Epoch 28: val_loss improved from 0.49532 to 0.48985, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6665 - loss: 0.6208 - val_accuracy: 0.7988 - val_loss: 0.4898 - learning_rate: 2.1335e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m137/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6617 - loss: 0.6216\n",
            "Epoch 29: val_loss improved from 0.48985 to 0.48418, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6613 - loss: 0.6217 - val_accuracy: 0.8013 - val_loss: 0.4842 - learning_rate: 2.1335e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6582 - loss: 0.6186\n",
            "Epoch 30: val_loss improved from 0.48418 to 0.47671, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6583 - loss: 0.6187 - val_accuracy: 0.8055 - val_loss: 0.4767 - learning_rate: 2.1335e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m137/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6655 - loss: 0.6151\n",
            "Epoch 31: val_loss improved from 0.47671 to 0.47090, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6656 - loss: 0.6152 - val_accuracy: 0.8138 - val_loss: 0.4709 - learning_rate: 2.1335e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m137/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6707 - loss: 0.6134\n",
            "Epoch 32: val_loss improved from 0.47090 to 0.46495, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6707 - loss: 0.6135 - val_accuracy: 0.8271 - val_loss: 0.4649 - learning_rate: 2.1335e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6679 - loss: 0.6104\n",
            "Epoch 33: val_loss improved from 0.46495 to 0.45979, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6680 - loss: 0.6105 - val_accuracy: 0.8279 - val_loss: 0.4598 - learning_rate: 2.1335e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6798 - loss: 0.6081\n",
            "Epoch 34: val_loss improved from 0.45979 to 0.45491, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6798 - loss: 0.6081 - val_accuracy: 0.8346 - val_loss: 0.4549 - learning_rate: 2.1335e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6799 - loss: 0.6058\n",
            "Epoch 35: val_loss improved from 0.45491 to 0.45055, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6798 - loss: 0.6058 - val_accuracy: 0.8462 - val_loss: 0.4506 - learning_rate: 2.1335e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6760 - loss: 0.6034\n",
            "Epoch 36: val_loss improved from 0.45055 to 0.44541, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6760 - loss: 0.6035 - val_accuracy: 0.8479 - val_loss: 0.4454 - learning_rate: 2.1335e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6912 - loss: 0.5984\n",
            "Epoch 37: val_loss improved from 0.44541 to 0.44149, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6911 - loss: 0.5984 - val_accuracy: 0.8512 - val_loss: 0.4415 - learning_rate: 2.1335e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6885 - loss: 0.5993\n",
            "Epoch 38: val_loss improved from 0.44149 to 0.43573, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6885 - loss: 0.5993 - val_accuracy: 0.8404 - val_loss: 0.4357 - learning_rate: 2.1335e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6867 - loss: 0.5945\n",
            "Epoch 39: val_loss improved from 0.43573 to 0.43331, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6867 - loss: 0.5946 - val_accuracy: 0.8504 - val_loss: 0.4333 - learning_rate: 2.1335e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6887 - loss: 0.5924\n",
            "Epoch 40: val_loss improved from 0.43331 to 0.42766, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6887 - loss: 0.5924 - val_accuracy: 0.8404 - val_loss: 0.4277 - learning_rate: 2.1335e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m135/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6949 - loss: 0.5905\n",
            "Epoch 41: val_loss improved from 0.42766 to 0.42438, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6949 - loss: 0.5908 - val_accuracy: 0.8487 - val_loss: 0.4244 - learning_rate: 2.1335e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6892 - loss: 0.5887\n",
            "Epoch 42: val_loss improved from 0.42438 to 0.42010, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6892 - loss: 0.5887 - val_accuracy: 0.8437 - val_loss: 0.4201 - learning_rate: 2.1335e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m135/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6949 - loss: 0.5878\n",
            "Epoch 43: val_loss improved from 0.42010 to 0.41660, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6956 - loss: 0.5878 - val_accuracy: 0.8437 - val_loss: 0.4166 - learning_rate: 2.1335e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m135/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6988 - loss: 0.5844\n",
            "Epoch 44: val_loss improved from 0.41660 to 0.41327, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6998 - loss: 0.5844 - val_accuracy: 0.8462 - val_loss: 0.4133 - learning_rate: 2.1335e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6976 - loss: 0.5820\n",
            "Epoch 45: val_loss improved from 0.41327 to 0.41065, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6982 - loss: 0.5821 - val_accuracy: 0.8487 - val_loss: 0.4107 - learning_rate: 2.1335e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7002 - loss: 0.5776\n",
            "Epoch 46: val_loss improved from 0.41065 to 0.40712, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7005 - loss: 0.5777 - val_accuracy: 0.8487 - val_loss: 0.4071 - learning_rate: 2.1335e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7088 - loss: 0.5769\n",
            "Epoch 47: val_loss improved from 0.40712 to 0.40382, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7089 - loss: 0.5769 - val_accuracy: 0.8487 - val_loss: 0.4038 - learning_rate: 2.1335e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7077 - loss: 0.5738\n",
            "Epoch 48: val_loss improved from 0.40382 to 0.40051, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7075 - loss: 0.5739 - val_accuracy: 0.8470 - val_loss: 0.4005 - learning_rate: 2.1335e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7115 - loss: 0.5710\n",
            "Epoch 49: val_loss improved from 0.40051 to 0.39802, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7115 - loss: 0.5711 - val_accuracy: 0.8512 - val_loss: 0.3980 - learning_rate: 2.1335e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7172 - loss: 0.5691\n",
            "Epoch 50: val_loss improved from 0.39802 to 0.39339, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7171 - loss: 0.5691 - val_accuracy: 0.8479 - val_loss: 0.3934 - learning_rate: 2.1335e-05\n",
            "Restoring model weights from the end of the best epoch: 50.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:19:33,589] Trial 12 finished with value: -0.39339303970336914 and parameters: {'epochs': 50, 'batch_size': 32, 'learning_rate': 2.133463352089267e-05, 'stop_patience': 8, 'reduce_lr_factor': 0.1035126247368423, 'reduce_lr_patience': 3}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/29\n",
            "\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5665 - loss: 0.6825\n",
            "Epoch 1: val_loss improved from inf to 0.66498, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5681 - loss: 0.6812 - val_accuracy: 0.6708 - val_loss: 0.6650 - learning_rate: 0.0037\n",
            "Epoch 2/29\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6781 - loss: 0.5712\n",
            "Epoch 2: val_loss improved from 0.66498 to 0.56823, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6783 - loss: 0.5707 - val_accuracy: 0.7406 - val_loss: 0.5682 - learning_rate: 0.0037\n",
            "Epoch 3/29\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7158 - loss: 0.5082\n",
            "Epoch 3: val_loss improved from 0.56823 to 0.34985, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7163 - loss: 0.5078 - val_accuracy: 0.8587 - val_loss: 0.3499 - learning_rate: 0.0037\n",
            "Epoch 4/29\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7466 - loss: 0.4582\n",
            "Epoch 4: val_loss did not improve from 0.34985\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7467 - loss: 0.4583 - val_accuracy: 0.8121 - val_loss: 0.4372 - learning_rate: 0.0037\n",
            "Epoch 5/29\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7572 - loss: 0.4461\n",
            "Epoch 5: val_loss improved from 0.34985 to 0.32929, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7573 - loss: 0.4464 - val_accuracy: 0.8520 - val_loss: 0.3293 - learning_rate: 0.0037\n",
            "Epoch 6/29\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7785 - loss: 0.4253\n",
            "Epoch 6: val_loss did not improve from 0.32929\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7785 - loss: 0.4254 - val_accuracy: 0.7880 - val_loss: 0.5281 - learning_rate: 0.0037\n",
            "Epoch 7/29\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7871 - loss: 0.4252\n",
            "Epoch 7: val_loss improved from 0.32929 to 0.31539, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7868 - loss: 0.4255 - val_accuracy: 0.8612 - val_loss: 0.3154 - learning_rate: 0.0037\n",
            "Epoch 8/29\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 0.4253\n",
            "Epoch 8: val_loss did not improve from 0.31539\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7717 - loss: 0.4255 - val_accuracy: 0.8130 - val_loss: 0.4206 - learning_rate: 0.0037\n",
            "Epoch 9/29\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7974 - loss: 0.4120\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0008800431664994337.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.31539\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7973 - loss: 0.4121 - val_accuracy: 0.8437 - val_loss: 0.3993 - learning_rate: 0.0037\n",
            "Epoch 10/29\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8052 - loss: 0.3821\n",
            "Epoch 10: val_loss did not improve from 0.31539\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.3819 - val_accuracy: 0.8504 - val_loss: 0.3319 - learning_rate: 8.8004e-04\n",
            "Epoch 11/29\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8294 - loss: 0.3583\n",
            "Epoch 11: val_loss improved from 0.31539 to 0.30218, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 0.3584 - val_accuracy: 0.8761 - val_loss: 0.3022 - learning_rate: 8.8004e-04\n",
            "Epoch 12/29\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8216 - loss: 0.3559\n",
            "Epoch 12: val_loss did not improve from 0.30218\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8217 - loss: 0.3563 - val_accuracy: 0.8637 - val_loss: 0.3060 - learning_rate: 8.8004e-04\n",
            "Epoch 13/29\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8266 - loss: 0.3510\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002086938327626005.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.30218\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8267 - loss: 0.3513 - val_accuracy: 0.8678 - val_loss: 0.3118 - learning_rate: 8.8004e-04\n",
            "Epoch 14/29\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8472 - loss: 0.3434\n",
            "Epoch 14: val_loss did not improve from 0.30218\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8472 - loss: 0.3435 - val_accuracy: 0.8271 - val_loss: 0.4002 - learning_rate: 2.0869e-04\n",
            "Epoch 15/29\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8519 - loss: 0.3381\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.948975108097404e-05.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.30218\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8518 - loss: 0.3383 - val_accuracy: 0.8163 - val_loss: 0.3727 - learning_rate: 2.0869e-04\n",
            "Epoch 16/29\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8594 - loss: 0.3317\n",
            "Epoch 16: val_loss did not improve from 0.30218\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8593 - loss: 0.3319 - val_accuracy: 0.8030 - val_loss: 0.4390 - learning_rate: 4.9490e-05\n",
            "Epoch 17/29\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8547 - loss: 0.3327\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.1736022059344258e-05.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.30218\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8548 - loss: 0.3328 - val_accuracy: 0.8105 - val_loss: 0.4126 - learning_rate: 4.9490e-05\n",
            "Epoch 18/29\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8551 - loss: 0.3305\n",
            "Epoch 18: val_loss did not improve from 0.30218\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8550 - loss: 0.3308 - val_accuracy: 0.8138 - val_loss: 0.4004 - learning_rate: 1.1736e-05\n",
            "Epoch 19/29\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8530 - loss: 0.3287\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.7830857041159714e-06.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.30218\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8530 - loss: 0.3288 - val_accuracy: 0.8138 - val_loss: 0.3986 - learning_rate: 1.1736e-05\n",
            "Epoch 20/29\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8634 - loss: 0.3312\n",
            "Epoch 20: val_loss did not improve from 0.30218\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8632 - loss: 0.3314 - val_accuracy: 0.8138 - val_loss: 0.3980 - learning_rate: 2.7831e-06\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:20:05,368] Trial 13 finished with value: -0.30218201875686646 and parameters: {'epochs': 29, 'batch_size': 16, 'learning_rate': 0.003711062908142598, 'stop_patience': 9, 'reduce_lr_factor': 0.23714045774966258, 'reduce_lr_patience': 2}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5554 - loss: 0.6934\n",
            "Epoch 1: val_loss improved from inf to 0.41662, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5560 - loss: 0.6928 - val_accuracy: 0.8204 - val_loss: 0.4166 - learning_rate: 0.0072\n",
            "Epoch 2/10\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6757 - loss: 0.5691\n",
            "Epoch 2: val_loss improved from 0.41662 to 0.34649, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6758 - loss: 0.5688 - val_accuracy: 0.8437 - val_loss: 0.3465 - learning_rate: 0.0072\n",
            "Epoch 3/10\n",
            "\u001b[1m136/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.5036\n",
            "Epoch 3: val_loss improved from 0.34649 to 0.31926, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7260 - loss: 0.5039 - val_accuracy: 0.8628 - val_loss: 0.3193 - learning_rate: 0.0072\n",
            "Epoch 4/10\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7435 - loss: 0.4902\n",
            "Epoch 4: val_loss did not improve from 0.31926\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7433 - loss: 0.4902 - val_accuracy: 0.6758 - val_loss: 0.9357 - learning_rate: 0.0072\n",
            "Epoch 5/10\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7459 - loss: 0.4749\n",
            "Epoch 5: val_loss did not improve from 0.31926\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7459 - loss: 0.4750 - val_accuracy: 0.7830 - val_loss: 0.7195 - learning_rate: 0.0072\n",
            "Epoch 6/10\n",
            "\u001b[1m137/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7597 - loss: 0.4462\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0011661678820683694.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.31926\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7596 - loss: 0.4470 - val_accuracy: 0.6492 - val_loss: 1.1366 - learning_rate: 0.0072\n",
            "Epoch 7/10\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7838 - loss: 0.4131\n",
            "Epoch 7: val_loss improved from 0.31926 to 0.29331, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7840 - loss: 0.4130 - val_accuracy: 0.8687 - val_loss: 0.2933 - learning_rate: 0.0012\n",
            "Epoch 8/10\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8063 - loss: 0.3883\n",
            "Epoch 8: val_loss improved from 0.29331 to 0.28954, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.3885 - val_accuracy: 0.8745 - val_loss: 0.2895 - learning_rate: 0.0012\n",
            "Epoch 9/10\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8119 - loss: 0.3768\n",
            "Epoch 9: val_loss did not improve from 0.28954\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.3776 - val_accuracy: 0.8512 - val_loss: 0.3155 - learning_rate: 0.0012\n",
            "Epoch 10/10\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.3652\n",
            "Epoch 10: val_loss did not improve from 0.28954\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8253 - loss: 0.3653 - val_accuracy: 0.8670 - val_loss: 0.3004 - learning_rate: 0.0012\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:20:17,689] Trial 14 finished with value: -0.28953590989112854 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 0.007221065906236191, 'stop_patience': 7, 'reduce_lr_factor': 0.16149525482935329, 'reduce_lr_patience': 3}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/44\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5570 - loss: 0.6989\n",
            "Epoch 1: val_loss improved from inf to 0.84259, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5571 - loss: 0.6987 - val_accuracy: 0.4996 - val_loss: 0.8426 - learning_rate: 0.0098\n",
            "Epoch 2/44\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5706 - loss: 0.6405\n",
            "Epoch 2: val_loss improved from 0.84259 to 0.72736, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5708 - loss: 0.6404 - val_accuracy: 0.5752 - val_loss: 0.7274 - learning_rate: 0.0098\n",
            "Epoch 3/44\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6570 - loss: 0.5829\n",
            "Epoch 3: val_loss improved from 0.72736 to 0.42456, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6585 - loss: 0.5822 - val_accuracy: 0.8279 - val_loss: 0.4246 - learning_rate: 0.0098\n",
            "Epoch 4/44\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.5104\n",
            "Epoch 4: val_loss improved from 0.42456 to 0.38213, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.5103 - val_accuracy: 0.8429 - val_loss: 0.3821 - learning_rate: 0.0098\n",
            "Epoch 5/44\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7451 - loss: 0.4873\n",
            "Epoch 5: val_loss improved from 0.38213 to 0.35667, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7450 - loss: 0.4874 - val_accuracy: 0.8587 - val_loss: 0.3567 - learning_rate: 0.0098\n",
            "Epoch 6/44\n",
            "\u001b[1m281/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7817 - loss: 0.4454\n",
            "Epoch 6: val_loss improved from 0.35667 to 0.33416, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7809 - loss: 0.4464 - val_accuracy: 0.8595 - val_loss: 0.3342 - learning_rate: 0.0098\n",
            "Epoch 7/44\n",
            "\u001b[1m283/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7672 - loss: 0.4425\n",
            "Epoch 7: val_loss did not improve from 0.33416\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7668 - loss: 0.4432 - val_accuracy: 0.8329 - val_loss: 0.6912 - learning_rate: 0.0098\n",
            "Epoch 8/44\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7790 - loss: 0.4303\n",
            "Epoch 8: val_loss did not improve from 0.33416\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.4304 - val_accuracy: 0.6949 - val_loss: 0.5668 - learning_rate: 0.0098\n",
            "Epoch 9/44\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7727 - loss: 0.4446\n",
            "Epoch 9: val_loss did not improve from 0.33416\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7728 - loss: 0.4449 - val_accuracy: 0.8603 - val_loss: 0.3564 - learning_rate: 0.0098\n",
            "Epoch 10/44\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7857 - loss: 0.4308\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.003646848640340154.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.33416\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7854 - loss: 0.4311 - val_accuracy: 0.8271 - val_loss: 0.4592 - learning_rate: 0.0098\n",
            "Epoch 11/44\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7944 - loss: 0.4001\n",
            "Epoch 11: val_loss did not improve from 0.33416\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.4000 - val_accuracy: 0.8429 - val_loss: 0.4564 - learning_rate: 0.0036\n",
            "Epoch 12/44\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8145 - loss: 0.3801\n",
            "Epoch 12: val_loss did not improve from 0.33416\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8145 - loss: 0.3802 - val_accuracy: 0.8479 - val_loss: 0.7210 - learning_rate: 0.0036\n",
            "Epoch 13/44\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.3744\n",
            "Epoch 13: val_loss did not improve from 0.33416\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8129 - loss: 0.3748 - val_accuracy: 0.8437 - val_loss: 0.6742 - learning_rate: 0.0036\n",
            "Epoch 14/44\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8029 - loss: 0.3890\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0013590374107698446.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.33416\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8029 - loss: 0.3891 - val_accuracy: 0.8362 - val_loss: 0.4146 - learning_rate: 0.0036\n",
            "Epoch 15/44\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8290 - loss: 0.3649\n",
            "Epoch 15: val_loss did not improve from 0.33416\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8291 - loss: 0.3649 - val_accuracy: 0.8288 - val_loss: 0.5142 - learning_rate: 0.0014\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:20:41,603] Trial 15 finished with value: -0.3341563045978546 and parameters: {'epochs': 44, 'batch_size': 16, 'learning_rate': 0.009785974505945101, 'stop_patience': 9, 'reduce_lr_factor': 0.3726607583390283, 'reduce_lr_patience': 4}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/28\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5535 - loss: 0.6933\n",
            "Epoch 1: val_loss improved from inf to 1.23686, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5543 - loss: 0.6927 - val_accuracy: 0.5411 - val_loss: 1.2369 - learning_rate: 0.0061\n",
            "Epoch 2/28\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6456 - loss: 0.5990\n",
            "Epoch 2: val_loss improved from 1.23686 to 0.80693, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6456 - loss: 0.5990 - val_accuracy: 0.7107 - val_loss: 0.8069 - learning_rate: 0.0061\n",
            "Epoch 3/28\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7063 - loss: 0.5208\n",
            "Epoch 3: val_loss improved from 0.80693 to 0.42883, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7064 - loss: 0.5205 - val_accuracy: 0.8163 - val_loss: 0.4288 - learning_rate: 0.0061\n",
            "Epoch 4/28\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7210 - loss: 0.5010\n",
            "Epoch 4: val_loss did not improve from 0.42883\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7211 - loss: 0.5010 - val_accuracy: 0.8105 - val_loss: 0.4519 - learning_rate: 0.0061\n",
            "Epoch 5/28\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7627 - loss: 0.4543\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0016013055896518004.\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.42883\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7625 - loss: 0.4544 - val_accuracy: 0.7739 - val_loss: 0.7542 - learning_rate: 0.0061\n",
            "Epoch 6/28\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8049 - loss: 0.4214\n",
            "Epoch 6: val_loss improved from 0.42883 to 0.30055, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4214 - val_accuracy: 0.8662 - val_loss: 0.3005 - learning_rate: 0.0016\n",
            "Epoch 7/28\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.4022\n",
            "Epoch 7: val_loss did not improve from 0.30055\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.4023 - val_accuracy: 0.8487 - val_loss: 0.3619 - learning_rate: 0.0016\n",
            "Epoch 8/28\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8152 - loss: 0.3959\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0004179347865053423.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.30055\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8149 - loss: 0.3961 - val_accuracy: 0.8570 - val_loss: 0.3051 - learning_rate: 0.0016\n",
            "Epoch 9/28\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8205 - loss: 0.3781\n",
            "Epoch 9: val_loss did not improve from 0.30055\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8207 - loss: 0.3782 - val_accuracy: 0.8479 - val_loss: 0.3267 - learning_rate: 4.1793e-04\n",
            "Epoch 10/28\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8352 - loss: 0.3747\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010907942331502549.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.30055\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8351 - loss: 0.3748 - val_accuracy: 0.8637 - val_loss: 0.3224 - learning_rate: 4.1793e-04\n",
            "Epoch 11/28\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.3674\n",
            "Epoch 11: val_loss did not improve from 0.30055\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8323 - loss: 0.3674 - val_accuracy: 0.8371 - val_loss: 0.3745 - learning_rate: 1.0908e-04\n",
            "Epoch 12/28\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8380 - loss: 0.3652\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.8469323631403636e-05.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.30055\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8380 - loss: 0.3653 - val_accuracy: 0.8512 - val_loss: 0.3761 - learning_rate: 1.0908e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:21:00,703] Trial 16 finished with value: -0.3005468249320984 and parameters: {'epochs': 28, 'batch_size': 16, 'learning_rate': 0.006135357776723571, 'stop_patience': 6, 'reduce_lr_factor': 0.2609962755515859, 'reduce_lr_patience': 2}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/22\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5880 - loss: 0.6770\n",
            "Epoch 1: val_loss improved from inf to 0.62737, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5885 - loss: 0.6763 - val_accuracy: 0.6717 - val_loss: 0.6274 - learning_rate: 0.0032\n",
            "Epoch 2/22\n",
            "\u001b[1m136/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6616 - loss: 0.5824\n",
            "Epoch 2: val_loss improved from 0.62737 to 0.56496, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6620 - loss: 0.5817 - val_accuracy: 0.7739 - val_loss: 0.5650 - learning_rate: 0.0032\n",
            "Epoch 3/22\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7044 - loss: 0.5406\n",
            "Epoch 3: val_loss did not improve from 0.56496\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7045 - loss: 0.5404 - val_accuracy: 0.6725 - val_loss: 0.8149 - learning_rate: 0.0032\n",
            "Epoch 4/22\n",
            "\u001b[1m135/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7245 - loss: 0.5014\n",
            "Epoch 4: val_loss improved from 0.56496 to 0.43150, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7247 - loss: 0.5020 - val_accuracy: 0.8421 - val_loss: 0.4315 - learning_rate: 0.0032\n",
            "Epoch 5/22\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7490 - loss: 0.4671\n",
            "Epoch 5: val_loss did not improve from 0.43150\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7491 - loss: 0.4671 - val_accuracy: 0.7415 - val_loss: 0.6029 - learning_rate: 0.0032\n",
            "Epoch 6/22\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7598 - loss: 0.4470\n",
            "Epoch 6: val_loss did not improve from 0.43150\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7597 - loss: 0.4473 - val_accuracy: 0.7880 - val_loss: 0.6366 - learning_rate: 0.0032\n",
            "Epoch 7/22\n",
            "\u001b[1m137/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7709 - loss: 0.4341\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.000634599599480331.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.43150\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7715 - loss: 0.4348 - val_accuracy: 0.7265 - val_loss: 0.7794 - learning_rate: 0.0032\n",
            "Epoch 8/22\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7980 - loss: 0.3987\n",
            "Epoch 8: val_loss improved from 0.43150 to 0.31856, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7981 - loss: 0.3988 - val_accuracy: 0.8612 - val_loss: 0.3186 - learning_rate: 6.3460e-04\n",
            "Epoch 9/22\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8191 - loss: 0.3778\n",
            "Epoch 9: val_loss improved from 0.31856 to 0.28635, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8191 - loss: 0.3778 - val_accuracy: 0.8745 - val_loss: 0.2864 - learning_rate: 6.3460e-04\n",
            "Epoch 10/22\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8136 - loss: 0.3788\n",
            "Epoch 10: val_loss did not improve from 0.28635\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.3789 - val_accuracy: 0.8662 - val_loss: 0.2949 - learning_rate: 6.3460e-04\n",
            "Epoch 11/22\n",
            "\u001b[1m137/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8193 - loss: 0.3701\n",
            "Epoch 11: val_loss improved from 0.28635 to 0.28467, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8194 - loss: 0.3706 - val_accuracy: 0.8761 - val_loss: 0.2847 - learning_rate: 6.3460e-04\n",
            "Epoch 12/22\n",
            "\u001b[1m137/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8278 - loss: 0.3644\n",
            "Epoch 12: val_loss did not improve from 0.28467\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8275 - loss: 0.3649 - val_accuracy: 0.8720 - val_loss: 0.2891 - learning_rate: 6.3460e-04\n",
            "Epoch 13/22\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8319 - loss: 0.3613\n",
            "Epoch 13: val_loss did not improve from 0.28467\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8318 - loss: 0.3614 - val_accuracy: 0.8703 - val_loss: 0.2906 - learning_rate: 6.3460e-04\n",
            "Epoch 14/22\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.3582\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00012640330790023385.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.28467\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8243 - loss: 0.3591 - val_accuracy: 0.8745 - val_loss: 0.2866 - learning_rate: 6.3460e-04\n",
            "Epoch 15/22\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.3525\n",
            "Epoch 15: val_loss did not improve from 0.28467\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8351 - loss: 0.3526 - val_accuracy: 0.8612 - val_loss: 0.3064 - learning_rate: 1.2640e-04\n",
            "Epoch 16/22\n",
            "\u001b[1m136/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8424 - loss: 0.3465\n",
            "Epoch 16: val_loss did not improve from 0.28467\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8426 - loss: 0.3471 - val_accuracy: 0.8603 - val_loss: 0.3106 - learning_rate: 1.2640e-04\n",
            "Epoch 17/22\n",
            "\u001b[1m134/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8418 - loss: 0.3451\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.5177759468704017e-05.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.28467\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8417 - loss: 0.3458 - val_accuracy: 0.8628 - val_loss: 0.2996 - learning_rate: 1.2640e-04\n",
            "Epoch 18/22\n",
            "\u001b[1m137/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8489 - loss: 0.3432\n",
            "Epoch 18: val_loss did not improve from 0.28467\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8490 - loss: 0.3438 - val_accuracy: 0.8520 - val_loss: 0.3158 - learning_rate: 2.5178e-05\n",
            "Epoch 19/22\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8559 - loss: 0.3417\n",
            "Epoch 19: val_loss did not improve from 0.28467\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8556 - loss: 0.3421 - val_accuracy: 0.8537 - val_loss: 0.3131 - learning_rate: 2.5178e-05\n",
            "Epoch 20/22\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8477 - loss: 0.3476\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 5.01505547106626e-06.\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.28467\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8477 - loss: 0.3476 - val_accuracy: 0.8504 - val_loss: 0.3173 - learning_rate: 2.5178e-05\n",
            "Epoch 21/22\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8485 - loss: 0.3427\n",
            "Epoch 21: val_loss did not improve from 0.28467\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8487 - loss: 0.3429 - val_accuracy: 0.8504 - val_loss: 0.3162 - learning_rate: 5.0151e-06\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:21:25,849] Trial 17 finished with value: -0.2846693992614746 and parameters: {'epochs': 22, 'batch_size': 32, 'learning_rate': 0.0031859661419865733, 'stop_patience': 10, 'reduce_lr_factor': 0.19918592637202143, 'reduce_lr_patience': 3}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5677 - loss: 0.6890\n",
            "Epoch 1: val_loss improved from inf to 0.70200, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5686 - loss: 0.6879 - val_accuracy: 0.5810 - val_loss: 0.7020 - learning_rate: 0.0080\n",
            "Epoch 2/32\n",
            "\u001b[1m135/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6382 - loss: 0.5792\n",
            "Epoch 2: val_loss improved from 0.70200 to 0.48903, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6404 - loss: 0.5780 - val_accuracy: 0.7448 - val_loss: 0.4890 - learning_rate: 0.0080\n",
            "Epoch 3/32\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6862 - loss: 0.5516\n",
            "Epoch 3: val_loss improved from 0.48903 to 0.43808, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6862 - loss: 0.5519 - val_accuracy: 0.8163 - val_loss: 0.4381 - learning_rate: 0.0080\n",
            "Epoch 4/32\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7278 - loss: 0.5201\n",
            "Epoch 4: val_loss did not improve from 0.43808\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7278 - loss: 0.5197 - val_accuracy: 0.5993 - val_loss: 1.0229 - learning_rate: 0.0080\n",
            "Epoch 5/32\n",
            "\u001b[1m136/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.4876\n",
            "Epoch 5: val_loss did not improve from 0.43808\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 0.4886 - val_accuracy: 0.7249 - val_loss: 0.5722 - learning_rate: 0.0080\n",
            "Epoch 6/32\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7545 - loss: 0.4563\n",
            "Epoch 6: val_loss did not improve from 0.43808\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7543 - loss: 0.4572 - val_accuracy: 0.8121 - val_loss: 0.4846 - learning_rate: 0.0080\n",
            "Epoch 7/32\n",
            "\u001b[1m135/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7655 - loss: 0.4608\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0011684699992627313.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.43808\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7651 - loss: 0.4611 - val_accuracy: 0.6110 - val_loss: 0.8653 - learning_rate: 0.0080\n",
            "Epoch 8/32\n",
            "\u001b[1m134/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.4264\n",
            "Epoch 8: val_loss improved from 0.43808 to 0.37197, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7758 - loss: 0.4257 - val_accuracy: 0.8803 - val_loss: 0.3720 - learning_rate: 0.0012\n",
            "Epoch 9/32\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8077 - loss: 0.4005\n",
            "Epoch 9: val_loss improved from 0.37197 to 0.32428, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8076 - loss: 0.4006 - val_accuracy: 0.8820 - val_loss: 0.3243 - learning_rate: 0.0012\n",
            "Epoch 10/32\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8090 - loss: 0.3882\n",
            "Epoch 10: val_loss improved from 0.32428 to 0.31645, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8091 - loss: 0.3882 - val_accuracy: 0.8803 - val_loss: 0.3164 - learning_rate: 0.0012\n",
            "Epoch 11/32\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8178 - loss: 0.3782\n",
            "Epoch 11: val_loss did not improve from 0.31645\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8178 - loss: 0.3789 - val_accuracy: 0.8811 - val_loss: 0.3388 - learning_rate: 0.0012\n",
            "Epoch 12/32\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8223 - loss: 0.3786\n",
            "Epoch 12: val_loss did not improve from 0.31645\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8223 - loss: 0.3787 - val_accuracy: 0.8703 - val_loss: 0.3387 - learning_rate: 0.0012\n",
            "Epoch 13/32\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8166 - loss: 0.3729\n",
            "Epoch 13: val_loss improved from 0.31645 to 0.29400, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8166 - loss: 0.3733 - val_accuracy: 0.8753 - val_loss: 0.2940 - learning_rate: 0.0012\n",
            "Epoch 14/32\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8242 - loss: 0.3740\n",
            "Epoch 14: val_loss did not improve from 0.29400\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8243 - loss: 0.3742 - val_accuracy: 0.8678 - val_loss: 0.3257 - learning_rate: 0.0012\n",
            "Epoch 15/32\n",
            "\u001b[1m135/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8365 - loss: 0.3686\n",
            "Epoch 15: val_loss did not improve from 0.29400\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8355 - loss: 0.3696 - val_accuracy: 0.8579 - val_loss: 0.3936 - learning_rate: 0.0012\n",
            "Epoch 16/32\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8321 - loss: 0.3671\n",
            "Epoch 16: val_loss did not improve from 0.29400\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8317 - loss: 0.3677 - val_accuracy: 0.8770 - val_loss: 0.3411 - learning_rate: 0.0012\n",
            "Epoch 17/32\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8316 - loss: 0.3627\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00017074168842671656.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.29400\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8317 - loss: 0.3632 - val_accuracy: 0.8703 - val_loss: 0.3742 - learning_rate: 0.0012\n",
            "Epoch 18/32\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8478 - loss: 0.3544\n",
            "Epoch 18: val_loss did not improve from 0.29400\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8472 - loss: 0.3548 - val_accuracy: 0.8554 - val_loss: 0.3878 - learning_rate: 1.7074e-04\n",
            "Epoch 19/32\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3526\n",
            "Epoch 19: val_loss did not improve from 0.29400\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3528 - val_accuracy: 0.8545 - val_loss: 0.4210 - learning_rate: 1.7074e-04\n",
            "Epoch 20/32\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8458 - loss: 0.3514\n",
            "Epoch 20: val_loss did not improve from 0.29400\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8457 - loss: 0.3517 - val_accuracy: 0.8662 - val_loss: 0.4094 - learning_rate: 1.7074e-04\n",
            "Epoch 21/32\n",
            "\u001b[1m147/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8402 - loss: 0.3509\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.494948316200866e-05.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.29400\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8402 - loss: 0.3510 - val_accuracy: 0.8695 - val_loss: 0.4355 - learning_rate: 1.7074e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:21:50,542] Trial 18 finished with value: -0.2939980626106262 and parameters: {'epochs': 32, 'batch_size': 32, 'learning_rate': 0.007996419017194384, 'stop_patience': 8, 'reduce_lr_factor': 0.1461241506084427, 'reduce_lr_patience': 4}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/44\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5650 - loss: 0.6805\n",
            "Epoch 1: val_loss improved from inf to 0.52576, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5653 - loss: 0.6802 - val_accuracy: 0.7190 - val_loss: 0.5258 - learning_rate: 0.0029\n",
            "Epoch 2/44\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6691 - loss: 0.5790\n",
            "Epoch 2: val_loss improved from 0.52576 to 0.37586, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6698 - loss: 0.5782 - val_accuracy: 0.8529 - val_loss: 0.3759 - learning_rate: 0.0029\n",
            "Epoch 3/44\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7106 - loss: 0.5186\n",
            "Epoch 3: val_loss improved from 0.37586 to 0.32007, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7114 - loss: 0.5181 - val_accuracy: 0.8628 - val_loss: 0.3201 - learning_rate: 0.0029\n",
            "Epoch 4/44\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7321 - loss: 0.4753\n",
            "Epoch 4: val_loss did not improve from 0.32007\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7326 - loss: 0.4753 - val_accuracy: 0.8288 - val_loss: 0.4519 - learning_rate: 0.0029\n",
            "Epoch 5/44\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7683 - loss: 0.4468\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0010703496703037155.\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.32007\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7680 - loss: 0.4471 - val_accuracy: 0.8595 - val_loss: 0.3247 - learning_rate: 0.0029\n",
            "Epoch 6/44\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7875 - loss: 0.4144\n",
            "Epoch 6: val_loss improved from 0.32007 to 0.31131, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7877 - loss: 0.4144 - val_accuracy: 0.8579 - val_loss: 0.3113 - learning_rate: 0.0011\n",
            "Epoch 7/44\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8039 - loss: 0.3978\n",
            "Epoch 7: val_loss did not improve from 0.31131\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.3979 - val_accuracy: 0.8745 - val_loss: 0.3500 - learning_rate: 0.0011\n",
            "Epoch 8/44\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8066 - loss: 0.3924\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00039008492525495177.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.31131\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.3927 - val_accuracy: 0.8504 - val_loss: 0.3516 - learning_rate: 0.0011\n",
            "Epoch 9/44\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8197 - loss: 0.3700\n",
            "Epoch 9: val_loss improved from 0.31131 to 0.30318, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.3701 - val_accuracy: 0.8670 - val_loss: 0.3032 - learning_rate: 3.9008e-04\n",
            "Epoch 10/44\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8272 - loss: 0.3670\n",
            "Epoch 10: val_loss improved from 0.30318 to 0.28603, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8274 - loss: 0.3672 - val_accuracy: 0.8728 - val_loss: 0.2860 - learning_rate: 3.9008e-04\n",
            "Epoch 11/44\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.3612\n",
            "Epoch 11: val_loss did not improve from 0.28603\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8362 - loss: 0.3615 - val_accuracy: 0.8579 - val_loss: 0.3117 - learning_rate: 3.9008e-04\n",
            "Epoch 12/44\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8305 - loss: 0.3602\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00014216498382399158.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.28603\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8304 - loss: 0.3604 - val_accuracy: 0.8770 - val_loss: 0.2969 - learning_rate: 3.9008e-04\n",
            "Epoch 13/44\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8406 - loss: 0.3561\n",
            "Epoch 13: val_loss did not improve from 0.28603\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8406 - loss: 0.3562 - val_accuracy: 0.8745 - val_loss: 0.3009 - learning_rate: 1.4216e-04\n",
            "Epoch 14/44\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.3496\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 5.181149195698395e-05.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.28603\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8525 - loss: 0.3496 - val_accuracy: 0.8479 - val_loss: 0.3088 - learning_rate: 1.4216e-04\n",
            "Epoch 15/44\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 0.3518\n",
            "Epoch 15: val_loss did not improve from 0.28603\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8485 - loss: 0.3518 - val_accuracy: 0.8412 - val_loss: 0.3350 - learning_rate: 5.1811e-05\n",
            "Epoch 16/44\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8524 - loss: 0.3452\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.888250271645601e-05.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.28603\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8523 - loss: 0.3454 - val_accuracy: 0.8653 - val_loss: 0.3131 - learning_rate: 5.1811e-05\n",
            "Epoch 17/44\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8507 - loss: 0.3462\n",
            "Epoch 17: val_loss did not improve from 0.28603\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8505 - loss: 0.3463 - val_accuracy: 0.8670 - val_loss: 0.3138 - learning_rate: 1.8883e-05\n",
            "Epoch 18/44\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3437\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 6.881657313022122e-06.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.28603\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8455 - loss: 0.3438 - val_accuracy: 0.8645 - val_loss: 0.3149 - learning_rate: 1.8883e-05\n",
            "Epoch 19/44\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8552 - loss: 0.3437\n",
            "Epoch 19: val_loss did not improve from 0.28603\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8552 - loss: 0.3438 - val_accuracy: 0.8653 - val_loss: 0.3142 - learning_rate: 6.8817e-06\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:22:20,901] Trial 19 finished with value: -0.2860284745693207 and parameters: {'epochs': 44, 'batch_size': 16, 'learning_rate': 0.0029369205829994876, 'stop_patience': 9, 'reduce_lr_factor': 0.36444623807325816, 'reduce_lr_patience': 2}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/36\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5500 - loss: 0.6867\n",
            "Epoch 1: val_loss improved from inf to 0.57152, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5506 - loss: 0.6865 - val_accuracy: 0.7273 - val_loss: 0.5715 - learning_rate: 3.7008e-04\n",
            "Epoch 2/36\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6340 - loss: 0.6366\n",
            "Epoch 2: val_loss improved from 0.57152 to 0.42915, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6343 - loss: 0.6364 - val_accuracy: 0.8421 - val_loss: 0.4291 - learning_rate: 3.7008e-04\n",
            "Epoch 3/36\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6858 - loss: 0.5868\n",
            "Epoch 3: val_loss did not improve from 0.42915\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6858 - loss: 0.5867 - val_accuracy: 0.7648 - val_loss: 0.4686 - learning_rate: 3.7008e-04\n",
            "Epoch 4/36\n",
            "\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7106 - loss: 0.5458\n",
            "Epoch 4: val_loss improved from 0.42915 to 0.36957, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7111 - loss: 0.5454 - val_accuracy: 0.8371 - val_loss: 0.3696 - learning_rate: 3.7008e-04\n",
            "Epoch 5/36\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7256 - loss: 0.5143\n",
            "Epoch 5: val_loss did not improve from 0.36957\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7258 - loss: 0.5142 - val_accuracy: 0.8296 - val_loss: 0.4172 - learning_rate: 3.7008e-04\n",
            "Epoch 6/36\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7465 - loss: 0.4923\n",
            "Epoch 6: val_loss did not improve from 0.36957\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7465 - loss: 0.4923 - val_accuracy: 0.8346 - val_loss: 0.4204 - learning_rate: 3.7008e-04\n",
            "Epoch 7/36\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7521 - loss: 0.4756\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00010012616740465665.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.36957\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7524 - loss: 0.4756 - val_accuracy: 0.8180 - val_loss: 0.5001 - learning_rate: 3.7008e-04\n",
            "Epoch 8/36\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7751 - loss: 0.4541\n",
            "Epoch 8: val_loss did not improve from 0.36957\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7752 - loss: 0.4541 - val_accuracy: 0.8512 - val_loss: 0.4064 - learning_rate: 1.0013e-04\n",
            "Epoch 9/36\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7773 - loss: 0.4494\n",
            "Epoch 9: val_loss did not improve from 0.36957\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7774 - loss: 0.4494 - val_accuracy: 0.8462 - val_loss: 0.4289 - learning_rate: 1.0013e-04\n",
            "Epoch 10/36\n",
            "\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7879 - loss: 0.4454\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.7089096795985128e-05.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.36957\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7879 - loss: 0.4454 - val_accuracy: 0.8479 - val_loss: 0.4314 - learning_rate: 1.0013e-04\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:22:41,109] Trial 20 finished with value: -0.36957260966300964 and parameters: {'epochs': 36, 'batch_size': 16, 'learning_rate': 0.0003700842962474824, 'stop_patience': 6, 'reduce_lr_factor': 0.27054961590237275, 'reduce_lr_patience': 3}. Best is trial 1 with value: -0.2774333953857422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5900 - loss: 0.6769\n",
            "Epoch 1: val_loss improved from inf to 0.76901, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5914 - loss: 0.6759 - val_accuracy: 0.6035 - val_loss: 0.7690 - learning_rate: 0.0024\n",
            "Epoch 2/25\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6448 - loss: 0.6209\n",
            "Epoch 2: val_loss improved from 0.76901 to 0.48325, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6450 - loss: 0.6207 - val_accuracy: 0.7481 - val_loss: 0.4832 - learning_rate: 0.0024\n",
            "Epoch 3/25\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6940 - loss: 0.5633\n",
            "Epoch 3: val_loss did not improve from 0.48325\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6945 - loss: 0.5624 - val_accuracy: 0.7872 - val_loss: 0.4833 - learning_rate: 0.0024\n",
            "Epoch 4/25\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7239 - loss: 0.5118\n",
            "Epoch 4: val_loss improved from 0.48325 to 0.35757, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7247 - loss: 0.5112 - val_accuracy: 0.8587 - val_loss: 0.3576 - learning_rate: 0.0024\n",
            "Epoch 5/25\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7383 - loss: 0.4868\n",
            "Epoch 5: val_loss did not improve from 0.35757\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7385 - loss: 0.4864 - val_accuracy: 0.8545 - val_loss: 0.3640 - learning_rate: 0.0024\n",
            "Epoch 6/25\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7595 - loss: 0.4633\n",
            "Epoch 6: val_loss improved from 0.35757 to 0.34210, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7594 - loss: 0.4633 - val_accuracy: 0.8570 - val_loss: 0.3421 - learning_rate: 0.0024\n",
            "Epoch 7/25\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7631 - loss: 0.4447\n",
            "Epoch 7: val_loss did not improve from 0.34210\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7629 - loss: 0.4454 - val_accuracy: 0.8529 - val_loss: 0.3857 - learning_rate: 0.0024\n",
            "Epoch 8/25\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7747 - loss: 0.4318\n",
            "Epoch 8: val_loss did not improve from 0.34210\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7746 - loss: 0.4321 - val_accuracy: 0.8171 - val_loss: 0.5484 - learning_rate: 0.0024\n",
            "Epoch 9/25\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7769 - loss: 0.4276\n",
            "Epoch 9: val_loss did not improve from 0.34210\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7765 - loss: 0.4279 - val_accuracy: 0.8662 - val_loss: 0.3545 - learning_rate: 0.0024\n",
            "Epoch 10/25\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7834 - loss: 0.4166\n",
            "Epoch 10: val_loss improved from 0.34210 to 0.33364, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7832 - loss: 0.4172 - val_accuracy: 0.8736 - val_loss: 0.3336 - learning_rate: 0.0024\n",
            "Epoch 11/25\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7923 - loss: 0.4071\n",
            "Epoch 11: val_loss did not improve from 0.33364\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7921 - loss: 0.4076 - val_accuracy: 0.8421 - val_loss: 0.4787 - learning_rate: 0.0024\n",
            "Epoch 12/25\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7987 - loss: 0.3991\n",
            "Epoch 12: val_loss did not improve from 0.33364\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7986 - loss: 0.3992 - val_accuracy: 0.8778 - val_loss: 0.3414 - learning_rate: 0.0024\n",
            "Epoch 13/25\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7976 - loss: 0.3948\n",
            "Epoch 13: val_loss did not improve from 0.33364\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7974 - loss: 0.3952 - val_accuracy: 0.7323 - val_loss: 0.6707 - learning_rate: 0.0024\n",
            "Epoch 14/25\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7996 - loss: 0.3946\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00045602809844389424.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.33364\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7998 - loss: 0.3949 - val_accuracy: 0.8288 - val_loss: 0.4103 - learning_rate: 0.0024\n",
            "Epoch 15/25\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.3755\n",
            "Epoch 15: val_loss improved from 0.33364 to 0.28374, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8090 - loss: 0.3754 - val_accuracy: 0.8778 - val_loss: 0.2837 - learning_rate: 4.5603e-04\n",
            "Epoch 16/25\n",
            "\u001b[1m65/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8368 - loss: 0.3571\n",
            "Epoch 16: val_loss improved from 0.28374 to 0.28072, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8356 - loss: 0.3586 - val_accuracy: 0.8770 - val_loss: 0.2807 - learning_rate: 4.5603e-04\n",
            "Epoch 17/25\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8202 - loss: 0.3615\n",
            "Epoch 17: val_loss did not improve from 0.28072\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8207 - loss: 0.3618 - val_accuracy: 0.8628 - val_loss: 0.3214 - learning_rate: 4.5603e-04\n",
            "Epoch 18/25\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.3611\n",
            "Epoch 18: val_loss did not improve from 0.28072\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8271 - loss: 0.3612 - val_accuracy: 0.8712 - val_loss: 0.2895 - learning_rate: 4.5603e-04\n",
            "Epoch 19/25\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8329 - loss: 0.3562\n",
            "Epoch 19: val_loss improved from 0.28072 to 0.27991, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8326 - loss: 0.3567 - val_accuracy: 0.8795 - val_loss: 0.2799 - learning_rate: 4.5603e-04\n",
            "Epoch 20/25\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: 0.3519\n",
            "Epoch 20: val_loss did not improve from 0.27991\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8399 - loss: 0.3527 - val_accuracy: 0.8662 - val_loss: 0.3105 - learning_rate: 4.5603e-04\n",
            "Epoch 21/25\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.3555\n",
            "Epoch 21: val_loss did not improve from 0.27991\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8250 - loss: 0.3560 - val_accuracy: 0.8786 - val_loss: 0.2817 - learning_rate: 4.5603e-04\n",
            "Epoch 22/25\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8351 - loss: 0.3505\n",
            "Epoch 22: val_loss improved from 0.27991 to 0.27440, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8349 - loss: 0.3517 - val_accuracy: 0.8803 - val_loss: 0.2744 - learning_rate: 4.5603e-04\n",
            "Epoch 23/25\n",
            "\u001b[1m74/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8356 - loss: 0.3515\n",
            "Epoch 23: val_loss did not improve from 0.27440\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8355 - loss: 0.3517 - val_accuracy: 0.8811 - val_loss: 0.2787 - learning_rate: 4.5603e-04\n",
            "Epoch 24/25\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8411 - loss: 0.3470\n",
            "Epoch 24: val_loss did not improve from 0.27440\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8405 - loss: 0.3477 - val_accuracy: 0.8803 - val_loss: 0.3016 - learning_rate: 4.5603e-04\n",
            "Epoch 25/25\n",
            "\u001b[1m64/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8307 - loss: 0.3493\n",
            "Epoch 25: val_loss did not improve from 0.27440\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8305 - loss: 0.3504 - val_accuracy: 0.8645 - val_loss: 0.3028 - learning_rate: 4.5603e-04\n",
            "Restoring model weights from the end of the best epoch: 22.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:22:59,808] Trial 21 finished with value: -0.27439600229263306 and parameters: {'epochs': 25, 'batch_size': 64, 'learning_rate': 0.002405747033049963, 'stop_patience': 5, 'reduce_lr_factor': 0.1895577900126439, 'reduce_lr_patience': 4}. Best is trial 21 with value: -0.27439600229263306.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5819 - loss: 0.6900\n",
            "Epoch 1: val_loss improved from inf to 0.79638, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5829 - loss: 0.6884 - val_accuracy: 0.5337 - val_loss: 0.7964 - learning_rate: 0.0029\n",
            "Epoch 2/15\n",
            "\u001b[1m143/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6686 - loss: 0.5898\n",
            "Epoch 2: val_loss improved from 0.79638 to 0.34186, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6693 - loss: 0.5889 - val_accuracy: 0.8470 - val_loss: 0.3419 - learning_rate: 0.0029\n",
            "Epoch 3/15\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7194 - loss: 0.5194\n",
            "Epoch 3: val_loss improved from 0.34186 to 0.34082, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7194 - loss: 0.5193 - val_accuracy: 0.8662 - val_loss: 0.3408 - learning_rate: 0.0029\n",
            "Epoch 4/15\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7339 - loss: 0.4913\n",
            "Epoch 4: val_loss did not improve from 0.34082\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7339 - loss: 0.4912 - val_accuracy: 0.8113 - val_loss: 0.4918 - learning_rate: 0.0029\n",
            "Epoch 5/15\n",
            "\u001b[1m141/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7503 - loss: 0.4586\n",
            "Epoch 5: val_loss did not improve from 0.34082\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7508 - loss: 0.4581 - val_accuracy: 0.8271 - val_loss: 0.4471 - learning_rate: 0.0029\n",
            "Epoch 6/15\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7638 - loss: 0.4301\n",
            "Epoch 6: val_loss did not improve from 0.34082\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7639 - loss: 0.4305 - val_accuracy: 0.7564 - val_loss: 0.8292 - learning_rate: 0.0029\n",
            "Epoch 7/15\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7566 - loss: 0.4326\n",
            "Epoch 7: val_loss did not improve from 0.34082\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7567 - loss: 0.4326 - val_accuracy: 0.7373 - val_loss: 0.9111 - learning_rate: 0.0029\n",
            "Epoch 8/15\n",
            "\u001b[1m138/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7764 - loss: 0.4168\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005936394284456457.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.34082\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7764 - loss: 0.4179 - val_accuracy: 0.6791 - val_loss: 1.3810 - learning_rate: 0.0029\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:23:11,259] Trial 22 finished with value: -0.3408168852329254 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 0.002901624434483872, 'stop_patience': 5, 'reduce_lr_factor': 0.20458865173529267, 'reduce_lr_patience': 5}. Best is trial 21 with value: -0.27439600229263306.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5588 - loss: 0.6856\n",
            "Epoch 1: val_loss improved from inf to 0.59596, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5607 - loss: 0.6847 - val_accuracy: 0.6633 - val_loss: 0.5960 - learning_rate: 7.8898e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6282 - loss: 0.6411\n",
            "Epoch 2: val_loss did not improve from 0.59596\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6289 - loss: 0.6404 - val_accuracy: 0.5628 - val_loss: 0.9444 - learning_rate: 7.8898e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m63/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6623 - loss: 0.6120\n",
            "Epoch 3: val_loss did not improve from 0.59596\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6642 - loss: 0.6105 - val_accuracy: 0.5985 - val_loss: 0.9989 - learning_rate: 7.8898e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6956 - loss: 0.5765\n",
            "Epoch 4: val_loss did not improve from 0.59596\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6956 - loss: 0.5763 - val_accuracy: 0.6484 - val_loss: 0.9339 - learning_rate: 7.8898e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7163 - loss: 0.5430\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.940458407094745e-05.\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.59596\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7164 - loss: 0.5428 - val_accuracy: 0.7382 - val_loss: 0.6851 - learning_rate: 7.8898e-04\n",
            "Epoch 5: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:23:17,815] Trial 23 finished with value: -0.5959584712982178 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.0007889784144509103, 'stop_patience': 4, 'reduce_lr_factor': 0.125991512414271, 'reduce_lr_patience': 4}. Best is trial 21 with value: -0.27439600229263306.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/27\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5662 - loss: 0.6844\n",
            "Epoch 1: val_loss improved from inf to 0.63522, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5673 - loss: 0.6836 - val_accuracy: 0.6825 - val_loss: 0.6352 - learning_rate: 0.0039\n",
            "Epoch 2/27\n",
            "\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6881 - loss: 0.5652\n",
            "Epoch 2: val_loss improved from 0.63522 to 0.43735, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6881 - loss: 0.5651 - val_accuracy: 0.8304 - val_loss: 0.4373 - learning_rate: 0.0039\n",
            "Epoch 3/27\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7301 - loss: 0.4962\n",
            "Epoch 3: val_loss improved from 0.43735 to 0.38835, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7302 - loss: 0.4961 - val_accuracy: 0.8487 - val_loss: 0.3884 - learning_rate: 0.0039\n",
            "Epoch 4/27\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7424 - loss: 0.4639\n",
            "Epoch 4: val_loss did not improve from 0.38835\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7426 - loss: 0.4640 - val_accuracy: 0.7490 - val_loss: 0.7818 - learning_rate: 0.0039\n",
            "Epoch 5/27\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7642 - loss: 0.4392\n",
            "Epoch 5: val_loss did not improve from 0.38835\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7642 - loss: 0.4394 - val_accuracy: 0.8446 - val_loss: 0.4509 - learning_rate: 0.0039\n",
            "Epoch 6/27\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7518 - loss: 0.4441\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0006900681237337176.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.38835\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7518 - loss: 0.4443 - val_accuracy: 0.7232 - val_loss: 0.5345 - learning_rate: 0.0039\n",
            "Epoch 7/27\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7799 - loss: 0.4026\n",
            "Epoch 7: val_loss improved from 0.38835 to 0.32464, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7804 - loss: 0.4024 - val_accuracy: 0.8462 - val_loss: 0.3246 - learning_rate: 6.9007e-04\n",
            "Epoch 8/27\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.3823\n",
            "Epoch 8: val_loss improved from 0.32464 to 0.28495, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.3824 - val_accuracy: 0.8736 - val_loss: 0.2849 - learning_rate: 6.9007e-04\n",
            "Epoch 9/27\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8221 - loss: 0.3721\n",
            "Epoch 9: val_loss did not improve from 0.28495\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8220 - loss: 0.3723 - val_accuracy: 0.8703 - val_loss: 0.3027 - learning_rate: 6.9007e-04\n",
            "Epoch 10/27\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8202 - loss: 0.3672\n",
            "Epoch 10: val_loss improved from 0.28495 to 0.28415, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8202 - loss: 0.3674 - val_accuracy: 0.8745 - val_loss: 0.2842 - learning_rate: 6.9007e-04\n",
            "Epoch 11/27\n",
            "\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.3574\n",
            "Epoch 11: val_loss improved from 0.28415 to 0.28086, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8251 - loss: 0.3577 - val_accuracy: 0.8845 - val_loss: 0.2809 - learning_rate: 6.9007e-04\n",
            "Epoch 12/27\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.3601\n",
            "Epoch 12: val_loss did not improve from 0.28086\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8230 - loss: 0.3603 - val_accuracy: 0.8662 - val_loss: 0.2974 - learning_rate: 6.9007e-04\n",
            "Epoch 13/27\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8253 - loss: 0.3603\n",
            "Epoch 13: val_loss did not improve from 0.28086\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8253 - loss: 0.3603 - val_accuracy: 0.8745 - val_loss: 0.2855 - learning_rate: 6.9007e-04\n",
            "Epoch 14/27\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8320 - loss: 0.3563\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00012175947330321354.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.28086\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8320 - loss: 0.3564 - val_accuracy: 0.8728 - val_loss: 0.2843 - learning_rate: 6.9007e-04\n",
            "Epoch 15/27\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8417 - loss: 0.3437\n",
            "Epoch 15: val_loss did not improve from 0.28086\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8416 - loss: 0.3438 - val_accuracy: 0.8645 - val_loss: 0.3064 - learning_rate: 1.2176e-04\n",
            "Epoch 16/27\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.3341\n",
            "Epoch 16: val_loss did not improve from 0.28086\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8518 - loss: 0.3344 - val_accuracy: 0.8504 - val_loss: 0.3327 - learning_rate: 1.2176e-04\n",
            "Epoch 17/27\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8559 - loss: 0.3325\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.148392211313504e-05.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.28086\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8557 - loss: 0.3329 - val_accuracy: 0.8703 - val_loss: 0.3152 - learning_rate: 1.2176e-04\n",
            "Epoch 18/27\n",
            "\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8619 - loss: 0.3361\n",
            "Epoch 18: val_loss did not improve from 0.28086\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8616 - loss: 0.3363 - val_accuracy: 0.8628 - val_loss: 0.3303 - learning_rate: 2.1484e-05\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:23:45,990] Trial 24 finished with value: -0.28086426854133606 and parameters: {'epochs': 27, 'batch_size': 16, 'learning_rate': 0.0039109402400138655, 'stop_patience': 7, 'reduce_lr_factor': 0.17644558570206262, 'reduce_lr_patience': 3}. Best is trial 21 with value: -0.27439600229263306.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5750 - loss: 0.6863\n",
            "Epoch 1: val_loss improved from inf to 0.53865, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5770 - loss: 0.6849 - val_accuracy: 0.6633 - val_loss: 0.5386 - learning_rate: 0.0054\n",
            "Epoch 2/26\n",
            "\u001b[1m63/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6429 - loss: 0.6031\n",
            "Epoch 2: val_loss did not improve from 0.53865\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6476 - loss: 0.5992 - val_accuracy: 0.6941 - val_loss: 0.9388 - learning_rate: 0.0054\n",
            "Epoch 3/26\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7066 - loss: 0.5206\n",
            "Epoch 3: val_loss improved from 0.53865 to 0.40524, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7078 - loss: 0.5190 - val_accuracy: 0.8321 - val_loss: 0.4052 - learning_rate: 0.0054\n",
            "Epoch 4/26\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7594 - loss: 0.4748\n",
            "Epoch 4: val_loss did not improve from 0.40524\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7582 - loss: 0.4747 - val_accuracy: 0.7140 - val_loss: 1.0043 - learning_rate: 0.0054\n",
            "Epoch 5/26\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7554 - loss: 0.4549\n",
            "Epoch 5: val_loss did not improve from 0.40524\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7552 - loss: 0.4553 - val_accuracy: 0.7307 - val_loss: 0.7254 - learning_rate: 0.0054\n",
            "Epoch 6/26\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7723 - loss: 0.4250\n",
            "Epoch 6: val_loss did not improve from 0.40524\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7725 - loss: 0.4253 - val_accuracy: 0.7249 - val_loss: 1.0659 - learning_rate: 0.0054\n",
            "Epoch 7/26\n",
            "\u001b[1m73/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7811 - loss: 0.4235\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.001251657287652672.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.40524\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7807 - loss: 0.4240 - val_accuracy: 0.6650 - val_loss: 1.3472 - learning_rate: 0.0054\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:23:53,635] Trial 25 finished with value: -0.4052412807941437 and parameters: {'epochs': 26, 'batch_size': 64, 'learning_rate': 0.005428072408465135, 'stop_patience': 4, 'reduce_lr_factor': 0.23058963942651556, 'reduce_lr_patience': 4}. Best is trial 21 with value: -0.27439600229263306.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5707 - loss: 0.6810\n",
            "Epoch 1: val_loss improved from inf to 0.62523, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5718 - loss: 0.6801 - val_accuracy: 0.6035 - val_loss: 0.6252 - learning_rate: 0.0024\n",
            "Epoch 2/13\n",
            "\u001b[1m134/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6589 - loss: 0.5970\n",
            "Epoch 2: val_loss improved from 0.62523 to 0.48925, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6600 - loss: 0.5952 - val_accuracy: 0.7947 - val_loss: 0.4892 - learning_rate: 0.0024\n",
            "Epoch 3/13\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7075 - loss: 0.5308\n",
            "Epoch 3: val_loss did not improve from 0.48925\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7076 - loss: 0.5305 - val_accuracy: 0.7805 - val_loss: 0.6366 - learning_rate: 0.0024\n",
            "Epoch 4/13\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7287 - loss: 0.4922\n",
            "Epoch 4: val_loss did not improve from 0.48925\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7288 - loss: 0.4922 - val_accuracy: 0.7581 - val_loss: 0.7352 - learning_rate: 0.0024\n",
            "Epoch 5/13\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7519 - loss: 0.4588\n",
            "Epoch 5: val_loss improved from 0.48925 to 0.39939, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7519 - loss: 0.4589 - val_accuracy: 0.8487 - val_loss: 0.3994 - learning_rate: 0.0024\n",
            "Epoch 6/13\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7640 - loss: 0.4538\n",
            "Epoch 6: val_loss did not improve from 0.39939\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7640 - loss: 0.4539 - val_accuracy: 0.7963 - val_loss: 0.6053 - learning_rate: 0.0024\n",
            "Epoch 7/13\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7719 - loss: 0.4345\n",
            "Epoch 7: val_loss did not improve from 0.39939\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7719 - loss: 0.4346 - val_accuracy: 0.7249 - val_loss: 0.9817 - learning_rate: 0.0024\n",
            "Epoch 8/13\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7720 - loss: 0.4221\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003445481142351497.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.39939\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7720 - loss: 0.4221 - val_accuracy: 0.7722 - val_loss: 0.6949 - learning_rate: 0.0024\n",
            "Epoch 9/13\n",
            "\u001b[1m135/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7967 - loss: 0.3947\n",
            "Epoch 9: val_loss improved from 0.39939 to 0.30274, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7978 - loss: 0.3949 - val_accuracy: 0.8736 - val_loss: 0.3027 - learning_rate: 3.4455e-04\n",
            "Epoch 10/13\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8121 - loss: 0.3815\n",
            "Epoch 10: val_loss improved from 0.30274 to 0.29690, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.3815 - val_accuracy: 0.8745 - val_loss: 0.2969 - learning_rate: 3.4455e-04\n",
            "Epoch 11/13\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.3778\n",
            "Epoch 11: val_loss improved from 0.29690 to 0.29546, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.3780 - val_accuracy: 0.8687 - val_loss: 0.2955 - learning_rate: 3.4455e-04\n",
            "Epoch 12/13\n",
            "\u001b[1m136/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8242 - loss: 0.3672\n",
            "Epoch 12: val_loss did not improve from 0.29546\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8241 - loss: 0.3676 - val_accuracy: 0.8703 - val_loss: 0.3115 - learning_rate: 3.4455e-04\n",
            "Epoch 13/13\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8261 - loss: 0.3661\n",
            "Epoch 13: val_loss did not improve from 0.29546\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8261 - loss: 0.3664 - val_accuracy: 0.8761 - val_loss: 0.3061 - learning_rate: 3.4455e-04\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:24:11,045] Trial 26 finished with value: -0.2954593896865845 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 0.0023767033701152756, 'stop_patience': 6, 'reduce_lr_factor': 0.1449689207759195, 'reduce_lr_patience': 3}. Best is trial 21 with value: -0.27439600229263306.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m69/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5682 - loss: 0.6904\n",
            "Epoch 1: val_loss improved from inf to 0.50362, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5696 - loss: 0.6888 - val_accuracy: 0.8429 - val_loss: 0.5036 - learning_rate: 0.0089\n",
            "Epoch 2/35\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6389 - loss: 0.6085\n",
            "Epoch 2: val_loss did not improve from 0.50362\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6411 - loss: 0.6056 - val_accuracy: 0.5478 - val_loss: 1.8050 - learning_rate: 0.0089\n",
            "Epoch 3/35\n",
            "\u001b[1m68/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7190 - loss: 0.5058\n",
            "Epoch 3: val_loss did not improve from 0.50362\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.5055 - val_accuracy: 0.5611 - val_loss: 1.6714 - learning_rate: 0.0089\n",
            "Epoch 4/35\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7389 - loss: 0.4808\n",
            "Epoch 4: val_loss improved from 0.50362 to 0.33811, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7393 - loss: 0.4805 - val_accuracy: 0.8662 - val_loss: 0.3381 - learning_rate: 0.0089\n",
            "Epoch 5/35\n",
            "\u001b[1m71/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7456 - loss: 0.4691\n",
            "Epoch 5: val_loss did not improve from 0.33811\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7464 - loss: 0.4683 - val_accuracy: 0.6052 - val_loss: 1.6990 - learning_rate: 0.0089\n",
            "Epoch 6/35\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7560 - loss: 0.4422\n",
            "Epoch 6: val_loss did not improve from 0.33811\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7561 - loss: 0.4427 - val_accuracy: 0.7564 - val_loss: 0.9202 - learning_rate: 0.0089\n",
            "Epoch 7/35\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7660 - loss: 0.4278\n",
            "Epoch 7: val_loss did not improve from 0.33811\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7663 - loss: 0.4281 - val_accuracy: 0.8030 - val_loss: 0.3956 - learning_rate: 0.0089\n",
            "Epoch 8/35\n",
            "\u001b[1m66/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.4114\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009090713207057065.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.33811\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7891 - loss: 0.4133 - val_accuracy: 0.7382 - val_loss: 0.6053 - learning_rate: 0.0089\n",
            "Epoch 9/35\n",
            "\u001b[1m70/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7752 - loss: 0.4036\n",
            "Epoch 9: val_loss did not improve from 0.33811\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7762 - loss: 0.4036 - val_accuracy: 0.8146 - val_loss: 0.3635 - learning_rate: 9.0907e-04\n",
            "Epoch 10/35\n",
            "\u001b[1m63/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8026 - loss: 0.3878\n",
            "Epoch 10: val_loss did not improve from 0.33811\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8037 - loss: 0.3882 - val_accuracy: 0.7714 - val_loss: 0.4081 - learning_rate: 9.0907e-04\n",
            "Epoch 11/35\n",
            "\u001b[1m67/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8196 - loss: 0.3696\n",
            "Epoch 11: val_loss did not improve from 0.33811\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8198 - loss: 0.3705 - val_accuracy: 0.8329 - val_loss: 0.3392 - learning_rate: 9.0907e-04\n",
            "Epoch 12/35\n",
            "\u001b[1m63/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8067 - loss: 0.3710\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.275710636398063e-05.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.33811\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8077 - loss: 0.3715 - val_accuracy: 0.8113 - val_loss: 0.3461 - learning_rate: 9.0907e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:24:21,511] Trial 27 finished with value: -0.33811154961586 and parameters: {'epochs': 35, 'batch_size': 64, 'learning_rate': 0.008909405323484797, 'stop_patience': 8, 'reduce_lr_factor': 0.10203501798018233, 'reduce_lr_patience': 4}. Best is trial 21 with value: -0.27439600229263306.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/41\n",
            "\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5716 - loss: 0.6774\n",
            "Epoch 1: val_loss improved from inf to 0.44298, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5729 - loss: 0.6766 - val_accuracy: 0.8105 - val_loss: 0.4430 - learning_rate: 0.0010\n",
            "Epoch 2/41\n",
            "\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6592 - loss: 0.6024\n",
            "Epoch 2: val_loss improved from 0.44298 to 0.39548, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6599 - loss: 0.6016 - val_accuracy: 0.8354 - val_loss: 0.3955 - learning_rate: 0.0010\n",
            "Epoch 3/41\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7037 - loss: 0.5368\n",
            "Epoch 3: val_loss did not improve from 0.39548\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7040 - loss: 0.5365 - val_accuracy: 0.8321 - val_loss: 0.4213 - learning_rate: 0.0010\n",
            "Epoch 4/41\n",
            "\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7263 - loss: 0.4951\n",
            "Epoch 4: val_loss improved from 0.39548 to 0.37489, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7264 - loss: 0.4951 - val_accuracy: 0.8479 - val_loss: 0.3749 - learning_rate: 0.0010\n",
            "Epoch 5/41\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7651 - loss: 0.4679\n",
            "Epoch 5: val_loss did not improve from 0.37489\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7648 - loss: 0.4682 - val_accuracy: 0.7905 - val_loss: 0.5981 - learning_rate: 0.0010\n",
            "Epoch 6/41\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7615 - loss: 0.4574\n",
            "Epoch 6: val_loss did not improve from 0.37489\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7614 - loss: 0.4575 - val_accuracy: 0.8562 - val_loss: 0.4125 - learning_rate: 0.0010\n",
            "Epoch 7/41\n",
            "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7643 - loss: 0.4479\n",
            "Epoch 7: val_loss did not improve from 0.37489\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7643 - loss: 0.4480 - val_accuracy: 0.8587 - val_loss: 0.3819 - learning_rate: 0.0010\n",
            "Epoch 8/41\n",
            "\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7635 - loss: 0.4393\n",
            "Epoch 8: val_loss improved from 0.37489 to 0.35379, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7641 - loss: 0.4393 - val_accuracy: 0.8562 - val_loss: 0.3538 - learning_rate: 0.0010\n",
            "Epoch 9/41\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7799 - loss: 0.4265\n",
            "Epoch 9: val_loss did not improve from 0.35379\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7799 - loss: 0.4266 - val_accuracy: 0.8620 - val_loss: 0.4111 - learning_rate: 0.0010\n",
            "Epoch 10/41\n",
            "\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.4174\n",
            "Epoch 10: val_loss improved from 0.35379 to 0.32472, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7920 - loss: 0.4176 - val_accuracy: 0.8645 - val_loss: 0.3247 - learning_rate: 0.0010\n",
            "Epoch 11/41\n",
            "\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7853 - loss: 0.4165\n",
            "Epoch 11: val_loss did not improve from 0.32472\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7852 - loss: 0.4167 - val_accuracy: 0.8720 - val_loss: 0.3333 - learning_rate: 0.0010\n",
            "Epoch 12/41\n",
            "\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7947 - loss: 0.4035\n",
            "Epoch 12: val_loss did not improve from 0.32472\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7944 - loss: 0.4039 - val_accuracy: 0.8678 - val_loss: 0.3593 - learning_rate: 0.0010\n",
            "Epoch 13/41\n",
            "\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7878 - loss: 0.4092\n",
            "Epoch 13: val_loss improved from 0.32472 to 0.30867, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7878 - loss: 0.4093 - val_accuracy: 0.8795 - val_loss: 0.3087 - learning_rate: 0.0010\n",
            "Epoch 14/41\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7964 - loss: 0.3982\n",
            "Epoch 14: val_loss did not improve from 0.30867\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7963 - loss: 0.3986 - val_accuracy: 0.8670 - val_loss: 0.3384 - learning_rate: 0.0010\n",
            "Epoch 15/41\n",
            "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7914 - loss: 0.3922\n",
            "Epoch 15: val_loss did not improve from 0.30867\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7914 - loss: 0.3925 - val_accuracy: 0.8745 - val_loss: 0.3290 - learning_rate: 0.0010\n",
            "Epoch 16/41\n",
            "\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.3858\n",
            "Epoch 16: val_loss did not improve from 0.30867\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.3859 - val_accuracy: 0.8687 - val_loss: 0.3577 - learning_rate: 0.0010\n",
            "Epoch 17/41\n",
            "\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7975 - loss: 0.3908\n",
            "Epoch 17: val_loss did not improve from 0.30867\n",
            "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7976 - loss: 0.3912 - val_accuracy: 0.8761 - val_loss: 0.3123 - learning_rate: 0.0010\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:24:48,946] Trial 28 finished with value: -0.3086659014225006 and parameters: {'epochs': 41, 'batch_size': 16, 'learning_rate': 0.0010335203609220748, 'stop_patience': 4, 'reduce_lr_factor': 0.2750559056249541, 'reduce_lr_patience': 5}. Best is trial 21 with value: -0.27439600229263306.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "\u001b[1m135/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5820 - loss: 0.6789\n",
            "Epoch 1: val_loss improved from inf to 0.52660, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5851 - loss: 0.6757 - val_accuracy: 0.7456 - val_loss: 0.5266 - learning_rate: 0.0025\n",
            "Epoch 2/32\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6676 - loss: 0.5805\n",
            "Epoch 2: val_loss improved from 0.52660 to 0.48304, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6677 - loss: 0.5805 - val_accuracy: 0.7947 - val_loss: 0.4830 - learning_rate: 0.0025\n",
            "Epoch 3/32\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7065 - loss: 0.5264\n",
            "Epoch 3: val_loss improved from 0.48304 to 0.34677, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7065 - loss: 0.5265 - val_accuracy: 0.8570 - val_loss: 0.3468 - learning_rate: 0.0025\n",
            "Epoch 4/32\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7248 - loss: 0.4892\n",
            "Epoch 4: val_loss did not improve from 0.34677\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7249 - loss: 0.4894 - val_accuracy: 0.7972 - val_loss: 0.5913 - learning_rate: 0.0025\n",
            "Epoch 5/32\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7423 - loss: 0.4669\n",
            "Epoch 5: val_loss improved from 0.34677 to 0.33484, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7425 - loss: 0.4670 - val_accuracy: 0.8695 - val_loss: 0.3348 - learning_rate: 0.0025\n",
            "Epoch 6/32\n",
            "\u001b[1m142/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7667 - loss: 0.4524\n",
            "Epoch 6: val_loss did not improve from 0.33484\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7661 - loss: 0.4527 - val_accuracy: 0.7440 - val_loss: 1.0088 - learning_rate: 0.0025\n",
            "Epoch 7/32\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7585 - loss: 0.4374\n",
            "Epoch 7: val_loss did not improve from 0.33484\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7587 - loss: 0.4375 - val_accuracy: 0.7747 - val_loss: 0.7914 - learning_rate: 0.0025\n",
            "Epoch 8/32\n",
            "\u001b[1m134/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7660 - loss: 0.4242\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0004081689612900915.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.33484\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7664 - loss: 0.4247 - val_accuracy: 0.7165 - val_loss: 1.2077 - learning_rate: 0.0025\n",
            "Epoch 9/32\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7959 - loss: 0.3939\n",
            "Epoch 9: val_loss improved from 0.33484 to 0.30534, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7960 - loss: 0.3939 - val_accuracy: 0.8753 - val_loss: 0.3053 - learning_rate: 4.0817e-04\n",
            "Epoch 10/32\n",
            "\u001b[1m149/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8138 - loss: 0.3744\n",
            "Epoch 10: val_loss improved from 0.30534 to 0.29079, saving model to BEST_CNN_RAM_VALE3.keras\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8138 - loss: 0.3745 - val_accuracy: 0.8786 - val_loss: 0.2908 - learning_rate: 4.0817e-04\n",
            "Epoch 11/32\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8177 - loss: 0.3717\n",
            "Epoch 11: val_loss did not improve from 0.29079\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8177 - loss: 0.3720 - val_accuracy: 0.8670 - val_loss: 0.3114 - learning_rate: 4.0817e-04\n",
            "Epoch 12/32\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.3661\n",
            "Epoch 12: val_loss did not improve from 0.29079\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8231 - loss: 0.3661 - val_accuracy: 0.8712 - val_loss: 0.2976 - learning_rate: 4.0817e-04\n",
            "Epoch 13/32\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8291 - loss: 0.3650\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.764318778061382e-05.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.29079\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8291 - loss: 0.3651 - val_accuracy: 0.8753 - val_loss: 0.3007 - learning_rate: 4.0817e-04\n",
            "Epoch 14/32\n",
            "\u001b[1m139/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8416 - loss: 0.3593\n",
            "Epoch 14: val_loss did not improve from 0.29079\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8414 - loss: 0.3596 - val_accuracy: 0.8761 - val_loss: 0.2959 - learning_rate: 6.7643e-05\n",
            "Epoch 15/32\n",
            "\u001b[1m140/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8434 - loss: 0.3551\n",
            "Epoch 15: val_loss did not improve from 0.29079\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8431 - loss: 0.3556 - val_accuracy: 0.8770 - val_loss: 0.2956 - learning_rate: 6.7643e-05\n",
            "Epoch 16/32\n",
            "\u001b[1m146/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.3539\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.1210065502634705e-05.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.29079\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8378 - loss: 0.3540 - val_accuracy: 0.8745 - val_loss: 0.3067 - learning_rate: 6.7643e-05\n",
            "Epoch 17/32\n",
            "\u001b[1m145/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8424 - loss: 0.3524\n",
            "Epoch 17: val_loss did not improve from 0.29079\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8426 - loss: 0.3526 - val_accuracy: 0.8761 - val_loss: 0.3040 - learning_rate: 1.1210e-05\n",
            "Epoch 18/32\n",
            "\u001b[1m148/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8486 - loss: 0.3517\n",
            "Epoch 18: val_loss did not improve from 0.29079\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8485 - loss: 0.3518 - val_accuracy: 0.8761 - val_loss: 0.3053 - learning_rate: 1.1210e-05\n",
            "Epoch 19/32\n",
            "\u001b[1m150/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8465 - loss: 0.3514\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.8577711681647679e-06.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.29079\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8465 - loss: 0.3515 - val_accuracy: 0.8770 - val_loss: 0.3045 - learning_rate: 1.1210e-05\n",
            "Epoch 20/32\n",
            "\u001b[1m144/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.3491\n",
            "Epoch 20: val_loss did not improve from 0.29079\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8490 - loss: 0.3494 - val_accuracy: 0.8761 - val_loss: 0.3033 - learning_rate: 1.8578e-06\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-13 15:25:10,683] Trial 29 finished with value: -0.29079338908195496 and parameters: {'epochs': 32, 'batch_size': 32, 'learning_rate': 0.002462951788976312, 'stop_patience': 10, 'reduce_lr_factor': 0.16572349405421619, 'reduce_lr_patience': 3}. Best is trial 21 with value: -0.27439600229263306.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Melhor combinação encontrada:\n",
            "trial                  21.000000\n",
            "epochs                 25.000000\n",
            "batch_size             64.000000\n",
            "learning_rate           0.002406\n",
            "stop_patience           5.000000\n",
            "reduce_lr_factor        0.189558\n",
            "reduce_lr_patience      4.000000\n",
            "recall_Compra(1)        0.915282\n",
            "recall_Vende(0)         0.845258\n",
            "precision_Compra(1)     0.855590\n",
            "precision_Vende(0)      0.908766\n",
            "macro_recall            0.880270\n",
            "accuracy                0.880299\n",
            "f1_macro                0.880146\n",
            "f1_weighted             0.880150\n",
            "min_val_loss            0.274396\n",
            "Name: 0, dtype: float64\n",
            "🔍 Hiperparâmetros: {'epochs': 25, 'batch_size': 64, 'learning_rate': 0.002405747033049963, 'stop_patience': 5, 'reduce_lr_factor': 0.1895577900126439, 'reduce_lr_patience': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_history([best_seq_history, best_ram_history], titles=titles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "0RHMjz4w7w2c",
        "outputId": "b27077dc-2492-4306-9883-4c9bbebcc01f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix([best_seq_metrics, best_ram_metrics], titles=titles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "TvZldCag7yLB",
        "outputId": "cf8d7831-7e42-4931-9168-e7f3ce0ee2d5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_classification_reports(\n",
        "    metrics_list=[best_seq_metrics, best_ram_metrics],\n",
        "    titles=titles\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHqUpR9e7zSn",
        "outputId": "09778b06-2802-42eb-a189-2ad44e6192fe"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "📊 Relatório de Classificação - Modelo Sequencial\n",
            "==================================================\n",
            "\n",
            "Vende (0):\n",
            "Precision: 0.87\n",
            "Recall:    0.84\n",
            "F1-Score:  0.85\n",
            "\n",
            "Compra (1):\n",
            "Precision: 0.84\n",
            "Recall:    0.88\n",
            "F1-Score:  0.86\n",
            "\n",
            "Médias:\n",
            "Acurácia:  0.86\n",
            "Precision: 0.86\n",
            "Recall:    0.86\n",
            "F1-Score:  0.86\n",
            "\n",
            "\n",
            "==================================================\n",
            "📊 Relatório de Classificação - Modelo Ramificado\n",
            "==================================================\n",
            "\n",
            "Vende (0):\n",
            "Precision: 0.91\n",
            "Recall:    0.85\n",
            "F1-Score:  0.88\n",
            "\n",
            "Compra (1):\n",
            "Precision: 0.86\n",
            "Recall:    0.92\n",
            "F1-Score:  0.88\n",
            "\n",
            "Médias:\n",
            "Acurácia:  0.88\n",
            "Precision: 0.88\n",
            "Recall:    0.88\n",
            "F1-Score:  0.88\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultado_backtest = run_backtest(\n",
        "    predictions=best_seq_y_pred,\n",
        "    prices=prices,\n",
        "    capital=10000,\n",
        "    model_name=\"CNN Sequencial\",\n",
        "    stock_name=\"VALE3\",\n",
        "    metrics = best_seq_metrics,\n",
        "    cdi_df=cdi,\n",
        "    metric_optimization = metric_optimization)\n",
        "\n",
        "resultado_backtest = run_backtest(\n",
        "    predictions=best_ram_y_pred,\n",
        "    prices=prices,\n",
        "    capital=10000,\n",
        "    model_name=\"CNN Ramificado\",\n",
        "    stock_name=\"VALE3\",\n",
        "    metrics = best_ram_metrics,\n",
        "    cdi_df=cdi,\n",
        "    metric_optimization = metric_optimization)\n",
        "\n",
        "resultado_backtest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "Bxb_V34771Ev",
        "outputId": "8d651e44-ce8f-4c17-866a-fced9d44cf1b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-cadec49cf654>:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  preco_atual = prices[i]\n",
            "<ipython-input-17-cadec49cf654>:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  preco_atual = prices[i]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Data          Modelo   Ação Métrica de Otimização  \\\n",
              "0  2025-04-13 14:10:15.041119  CNN Sequencial  CSAN3              val_loss   \n",
              "1  2025-04-13 14:10:15.069407  CNN Ramificado  CSAN3              val_loss   \n",
              "2  2025-04-13 14:37:38.702181  CNN Sequencial  BBAS3              val_loss   \n",
              "3  2025-04-13 14:37:38.727148  CNN Ramificado  BBAS3              val_loss   \n",
              "4  2025-04-13 15:02:36.679384  CNN Sequencial  PETR4              val_loss   \n",
              "5  2025-04-13 15:02:36.703969  CNN Ramificado  PETR4              val_loss   \n",
              "6  2025-04-13 15:25:11.472139  CNN Sequencial  VALE3              val_loss   \n",
              "7  2025-04-13 15:25:11.497284  CNN Ramificado  VALE3              val_loss   \n",
              "\n",
              "   Acurácia  Precision    Recall        F1       Matriz de Confusão  \\\n",
              "0  0.885329   0.882166  0.882586  0.882373   [[619, 69], [67, 431]]   \n",
              "1  0.881956   0.880287  0.876629  0.878284   [[626, 62], [78, 420]]   \n",
              "2  0.865823   0.861527  0.864002  0.862654   [[603, 86], [73, 423]]   \n",
              "3  0.898734   0.897139  0.894281  0.895610   [[635, 54], [66, 430]]   \n",
              "4  0.831255   0.839039  0.828591  0.829323  [[436, 145], [58, 564]]   \n",
              "5  0.848712   0.850201  0.847515  0.848089  [[472, 109], [73, 549]]   \n",
              "6  0.856193   0.856721  0.856177  0.856136   [[503, 98], [75, 527]]   \n",
              "7  0.880299   0.882178  0.880270  0.880146   [[508, 93], [51, 551]]   \n",
              "\n",
              "   Saldo Inicial  Saldo Final  Total de Ações   Lucro Total   Lucro (%)  \\\n",
              "0          10000     3.640817           990.0   9467.040666   94.670407   \n",
              "1          10000     8.435907          1065.0  10946.335745  109.463357   \n",
              "2          10000    39.235968           247.0   3720.565817   37.205658   \n",
              "3          10000    38.974524           310.0   7209.874334   72.098743   \n",
              "4          10000     1.062806           809.0  20128.224164  201.282242   \n",
              "5          10000    12.695825           817.0  20437.777196  204.377772   \n",
              "6          10000    13.402445           258.0   9931.001657   99.310017   \n",
              "7          10000    69.179995           261.0  10218.379198  102.183792   \n",
              "\n",
              "   Lucro (%) CDI  \n",
              "0      42.269210  \n",
              "1      42.269210  \n",
              "2      42.269210  \n",
              "3      42.269210  \n",
              "4      42.937875  \n",
              "5      42.937875  \n",
              "6      42.937875  \n",
              "7      42.937875  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc5307d3-0ef5-467a-bf93-2c3bcfbea1da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Ação</th>\n",
              "      <th>Métrica de Otimização</th>\n",
              "      <th>Acurácia</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Matriz de Confusão</th>\n",
              "      <th>Saldo Inicial</th>\n",
              "      <th>Saldo Final</th>\n",
              "      <th>Total de Ações</th>\n",
              "      <th>Lucro Total</th>\n",
              "      <th>Lucro (%)</th>\n",
              "      <th>Lucro (%) CDI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-04-13 14:10:15.041119</td>\n",
              "      <td>CNN Sequencial</td>\n",
              "      <td>CSAN3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.885329</td>\n",
              "      <td>0.882166</td>\n",
              "      <td>0.882586</td>\n",
              "      <td>0.882373</td>\n",
              "      <td>[[619, 69], [67, 431]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>3.640817</td>\n",
              "      <td>990.0</td>\n",
              "      <td>9467.040666</td>\n",
              "      <td>94.670407</td>\n",
              "      <td>42.269210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-04-13 14:10:15.069407</td>\n",
              "      <td>CNN Ramificado</td>\n",
              "      <td>CSAN3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.881956</td>\n",
              "      <td>0.880287</td>\n",
              "      <td>0.876629</td>\n",
              "      <td>0.878284</td>\n",
              "      <td>[[626, 62], [78, 420]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>8.435907</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>10946.335745</td>\n",
              "      <td>109.463357</td>\n",
              "      <td>42.269210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-04-13 14:37:38.702181</td>\n",
              "      <td>CNN Sequencial</td>\n",
              "      <td>BBAS3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.865823</td>\n",
              "      <td>0.861527</td>\n",
              "      <td>0.864002</td>\n",
              "      <td>0.862654</td>\n",
              "      <td>[[603, 86], [73, 423]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>39.235968</td>\n",
              "      <td>247.0</td>\n",
              "      <td>3720.565817</td>\n",
              "      <td>37.205658</td>\n",
              "      <td>42.269210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-04-13 14:37:38.727148</td>\n",
              "      <td>CNN Ramificado</td>\n",
              "      <td>BBAS3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.898734</td>\n",
              "      <td>0.897139</td>\n",
              "      <td>0.894281</td>\n",
              "      <td>0.895610</td>\n",
              "      <td>[[635, 54], [66, 430]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>38.974524</td>\n",
              "      <td>310.0</td>\n",
              "      <td>7209.874334</td>\n",
              "      <td>72.098743</td>\n",
              "      <td>42.269210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-04-13 15:02:36.679384</td>\n",
              "      <td>CNN Sequencial</td>\n",
              "      <td>PETR4</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.831255</td>\n",
              "      <td>0.839039</td>\n",
              "      <td>0.828591</td>\n",
              "      <td>0.829323</td>\n",
              "      <td>[[436, 145], [58, 564]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.062806</td>\n",
              "      <td>809.0</td>\n",
              "      <td>20128.224164</td>\n",
              "      <td>201.282242</td>\n",
              "      <td>42.937875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-04-13 15:02:36.703969</td>\n",
              "      <td>CNN Ramificado</td>\n",
              "      <td>PETR4</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.848712</td>\n",
              "      <td>0.850201</td>\n",
              "      <td>0.847515</td>\n",
              "      <td>0.848089</td>\n",
              "      <td>[[472, 109], [73, 549]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>12.695825</td>\n",
              "      <td>817.0</td>\n",
              "      <td>20437.777196</td>\n",
              "      <td>204.377772</td>\n",
              "      <td>42.937875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-04-13 15:25:11.472139</td>\n",
              "      <td>CNN Sequencial</td>\n",
              "      <td>VALE3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.856193</td>\n",
              "      <td>0.856721</td>\n",
              "      <td>0.856177</td>\n",
              "      <td>0.856136</td>\n",
              "      <td>[[503, 98], [75, 527]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>13.402445</td>\n",
              "      <td>258.0</td>\n",
              "      <td>9931.001657</td>\n",
              "      <td>99.310017</td>\n",
              "      <td>42.937875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-04-13 15:25:11.497284</td>\n",
              "      <td>CNN Ramificado</td>\n",
              "      <td>VALE3</td>\n",
              "      <td>val_loss</td>\n",
              "      <td>0.880299</td>\n",
              "      <td>0.882178</td>\n",
              "      <td>0.880270</td>\n",
              "      <td>0.880146</td>\n",
              "      <td>[[508, 93], [51, 551]]</td>\n",
              "      <td>10000</td>\n",
              "      <td>69.179995</td>\n",
              "      <td>261.0</td>\n",
              "      <td>10218.379198</td>\n",
              "      <td>102.183792</td>\n",
              "      <td>42.937875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc5307d3-0ef5-467a-bf93-2c3bcfbea1da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fc5307d3-0ef5-467a-bf93-2c3bcfbea1da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fc5307d3-0ef5-467a-bf93-2c3bcfbea1da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-52c77833-48b0-46fb-aa6d-ae740a43e9a5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52c77833-48b0-46fb-aa6d-ae740a43e9a5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-52c77833-48b0-46fb-aa6d-ae740a43e9a5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ff342e5f-934c-4b9a-b8bc-18bd79e0b60a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('resultado_backtest')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ff342e5f-934c-4b9a-b8bc-18bd79e0b60a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('resultado_backtest');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "resultado_backtest",
              "summary": "{\n  \"name\": \"resultado_backtest\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Data\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"2025-04-13 14:10:15.069407\",\n          \"2025-04-13 15:02:36.703969\",\n          \"2025-04-13 14:10:15.041119\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"CNN Ramificado\",\n          \"CNN Sequencial\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\\u00e7\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"BBAS3\",\n          \"VALE3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"M\\u00e9trica de Otimiza\\u00e7\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"val_loss\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Acur\\u00e1cia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0222164218428191,\n        \"min\": 0.8312551953449709,\n        \"max\": 0.8987341772151899,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.8819561551433389\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.019723019243571137,\n        \"min\": 0.8390388469818356,\n        \"max\": 0.8971392697563103,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.8802869200301773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021489377071352886,\n        \"min\": 0.828591352087265,\n        \"max\": 0.8942805140690107,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.876628607453068\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021605859389121882,\n        \"min\": 0.829322943057327,\n        \"max\": 0.8956100425781823,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.8782840722495895\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Matriz de Confus\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Saldo Inicial\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 10000,\n        \"max\": 10000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          10000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Saldo Final\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23.655083343086797,\n        \"min\": 1.0628061294373763,\n        \"max\": 69.17999458312624,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          8.435907363906153\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total de A\\u00e7\\u00f5es\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 358.4605726476165,\n        \"min\": 247.0,\n        \"max\": 1065.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1065.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lucro Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5877.295603193623,\n        \"min\": 3720.565816879269,\n        \"max\": 20437.777196407304,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          10946.335744857804\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lucro (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 58.77295603193624,\n        \"min\": 37.20565816879269,\n        \"max\": 204.37777196407305,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          109.46335744857802\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lucro (%) CDI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.35741662910234967,\n        \"min\": 42.2692096209317,\n        \"max\": 42.93787490615002,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          42.93787490615002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A arquitetura de rede CNN ramificada foi a vencedora em ambos os ativos, então levaremos ela para a pipeline comlpeta do modelo campeão"
      ],
      "metadata": {
        "id": "9B5YDPJfY1ld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline completa com arquitetura campeã"
      ],
      "metadata": {
        "id": "CPwdi-tkFMA2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "H4a1s9sjZ7ko",
        "cPIFWax3Oz8m"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}